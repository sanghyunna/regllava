{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 8721,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00011466574934067194,
      "grad_norm": 0.0,
      "learning_rate": 0.0,
      "loss": 4.7532,
      "step": 1
    },
    {
      "epoch": 0.00022933149868134388,
      "grad_norm": 0.0,
      "learning_rate": 0.00012447993835362813,
      "loss": 5.1273,
      "step": 2
    },
    {
      "epoch": 0.0003439972480220158,
      "grad_norm": 0.0,
      "learning_rate": 0.0001972960343825818,
      "loss": 4.9931,
      "step": 3
    },
    {
      "epoch": 0.00045866299736268775,
      "grad_norm": 0.0,
      "learning_rate": 0.00024895987670725626,
      "loss": 5.0871,
      "step": 4
    },
    {
      "epoch": 0.0005733287467033597,
      "grad_norm": 0.0,
      "learning_rate": 0.000289033466113136,
      "loss": 4.9399,
      "step": 5
    },
    {
      "epoch": 0.0006879944960440316,
      "grad_norm": 0.0,
      "learning_rate": 0.0003217759727362099,
      "loss": 4.7503,
      "step": 6
    },
    {
      "epoch": 0.0008026602453847036,
      "grad_norm": 0.0,
      "learning_rate": 0.00034945936763448507,
      "loss": 5.227,
      "step": 7
    },
    {
      "epoch": 0.0009173259947253755,
      "grad_norm": 0.0,
      "learning_rate": 0.0003734398150608844,
      "loss": 4.6941,
      "step": 8
    },
    {
      "epoch": 0.0010319917440660474,
      "grad_norm": 0.0,
      "learning_rate": 0.0003945920687651636,
      "loss": 4.8946,
      "step": 9
    },
    {
      "epoch": 0.0011466574934067195,
      "grad_norm": 0.0,
      "learning_rate": 0.00041351340446676424,
      "loss": 4.9576,
      "step": 10
    },
    {
      "epoch": 0.0012613232427473914,
      "grad_norm": 0.0,
      "learning_rate": 0.00043062983462656277,
      "loss": 5.0414,
      "step": 11
    },
    {
      "epoch": 0.0013759889920880633,
      "grad_norm": 0.0,
      "learning_rate": 0.000446255911089838,
      "loss": 5.0216,
      "step": 12
    },
    {
      "epoch": 0.0014906547414287351,
      "grad_norm": 0.0,
      "learning_rate": 0.0004606305079955202,
      "loss": 4.8239,
      "step": 13
    },
    {
      "epoch": 0.0016053204907694072,
      "grad_norm": 0.0,
      "learning_rate": 0.00047393930598811315,
      "loss": 5.1284,
      "step": 14
    },
    {
      "epoch": 0.0017199862401100791,
      "grad_norm": 0.0,
      "learning_rate": 0.0004863295004957178,
      "loss": 4.7119,
      "step": 15
    },
    {
      "epoch": 0.001834651989450751,
      "grad_norm": 0.0,
      "learning_rate": 0.0004979197534145125,
      "loss": 5.1541,
      "step": 16
    },
    {
      "epoch": 0.001949317738791423,
      "grad_norm": 0.0,
      "learning_rate": 0.0005088071225015879,
      "loss": 5.0704,
      "step": 17
    },
    {
      "epoch": 0.0020639834881320948,
      "grad_norm": 0.0,
      "learning_rate": 0.0005190720071187916,
      "loss": 4.9248,
      "step": 18
    },
    {
      "epoch": 0.002178649237472767,
      "grad_norm": 0.0,
      "learning_rate": 0.0005287817550041383,
      "loss": 5.1964,
      "step": 19
    },
    {
      "epoch": 0.002293314986813439,
      "grad_norm": 0.0,
      "learning_rate": 0.0005379933428203923,
      "loss": 5.0233,
      "step": 20
    },
    {
      "epoch": 0.002407980736154111,
      "grad_norm": 0.0,
      "learning_rate": 0.0005467554020170669,
      "loss": 5.0124,
      "step": 21
    },
    {
      "epoch": 0.0025226464854947827,
      "grad_norm": 0.0,
      "learning_rate": 0.000555109772980191,
      "loss": 5.1365,
      "step": 22
    },
    {
      "epoch": 0.0026373122348354546,
      "grad_norm": 0.0,
      "learning_rate": 0.0005630927134287944,
      "loss": 5.2816,
      "step": 23
    },
    {
      "epoch": 0.0027519779841761265,
      "grad_norm": 0.0,
      "learning_rate": 0.0005707358494434663,
      "loss": 5.0243,
      "step": 24
    },
    {
      "epoch": 0.0028666437335167984,
      "grad_norm": 0.0,
      "learning_rate": 0.000578066932226272,
      "loss": 5.0194,
      "step": 25
    },
    {
      "epoch": 0.0029813094828574703,
      "grad_norm": 0.0,
      "learning_rate": 0.0005851104463491483,
      "loss": 4.8961,
      "step": 26
    },
    {
      "epoch": 0.0030959752321981426,
      "grad_norm": 0.0,
      "learning_rate": 0.0005918881031477454,
      "loss": 4.9159,
      "step": 27
    },
    {
      "epoch": 0.0032106409815388145,
      "grad_norm": 0.0,
      "learning_rate": 0.0005984192443417414,
      "loss": 4.8626,
      "step": 28
    },
    {
      "epoch": 0.0033253067308794864,
      "grad_norm": 0.0,
      "learning_rate": 0.0006047211747965772,
      "loss": 4.8807,
      "step": 29
    },
    {
      "epoch": 0.0034399724802201583,
      "grad_norm": 0.0,
      "learning_rate": 0.000610809438849346,
      "loss": 4.9478,
      "step": 30
    },
    {
      "epoch": 0.00355463822956083,
      "grad_norm": 0.0,
      "learning_rate": 0.0006166980513087301,
      "loss": 4.9556,
      "step": 31
    },
    {
      "epoch": 0.003669303978901502,
      "grad_norm": 0.0,
      "learning_rate": 0.0006223996917681406,
      "loss": 5.1673,
      "step": 32
    },
    {
      "epoch": 0.003783969728242174,
      "grad_norm": 0.0,
      "learning_rate": 0.0006279258690091445,
      "loss": 5.0581,
      "step": 33
    },
    {
      "epoch": 0.003898635477582846,
      "grad_norm": 0.0,
      "learning_rate": 0.000633287060855216,
      "loss": 4.9126,
      "step": 34
    },
    {
      "epoch": 0.004013301226923518,
      "grad_norm": 0.0,
      "learning_rate": 0.0006384928337476211,
      "loss": 5.0522,
      "step": 35
    },
    {
      "epoch": 0.0041279669762641896,
      "grad_norm": 0.0,
      "learning_rate": 0.0006435519454724198,
      "loss": 4.8618,
      "step": 36
    },
    {
      "epoch": 0.0042426327256048614,
      "grad_norm": 0.0,
      "learning_rate": 0.0006484724338095922,
      "loss": 5.243,
      "step": 37
    },
    {
      "epoch": 0.004357298474945534,
      "grad_norm": 0.0,
      "learning_rate": 0.0006532616933577664,
      "loss": 5.1148,
      "step": 38
    },
    {
      "epoch": 0.004471964224286206,
      "grad_norm": 0.0,
      "learning_rate": 0.000657926542378102,
      "loss": 4.9408,
      "step": 39
    },
    {
      "epoch": 0.004586629973626878,
      "grad_norm": 0.0,
      "learning_rate": 0.0006624732811740204,
      "loss": 4.9997,
      "step": 40
    },
    {
      "epoch": 0.00470129572296755,
      "grad_norm": 0.0,
      "learning_rate": 0.0006669077432612158,
      "loss": 5.0589,
      "step": 41
    },
    {
      "epoch": 0.004815961472308222,
      "grad_norm": 0.0,
      "learning_rate": 0.000671235340370695,
      "loss": 5.0315,
      "step": 42
    },
    {
      "epoch": 0.004930627221648894,
      "grad_norm": 0.0,
      "learning_rate": 0.0006754611021557821,
      "loss": 5.1457,
      "step": 43
    },
    {
      "epoch": 0.0050452929709895655,
      "grad_norm": 0.0,
      "learning_rate": 0.000679589711333819,
      "loss": 4.9967,
      "step": 44
    },
    {
      "epoch": 0.005159958720330237,
      "grad_norm": 0.0,
      "learning_rate": 0.0006836255348782996,
      "loss": 5.1808,
      "step": 45
    },
    {
      "epoch": 0.005274624469670909,
      "grad_norm": 0.0,
      "learning_rate": 0.0006875726517824225,
      "loss": 5.1913,
      "step": 46
    },
    {
      "epoch": 0.005389290219011581,
      "grad_norm": 0.0,
      "learning_rate": 0.0006914348778365823,
      "loss": 4.8437,
      "step": 47
    },
    {
      "epoch": 0.005503955968352253,
      "grad_norm": 0.0,
      "learning_rate": 0.0006952157877970944,
      "loss": 4.7163,
      "step": 48
    },
    {
      "epoch": 0.005618621717692925,
      "grad_norm": 0.0,
      "learning_rate": 0.0006989187352689701,
      "loss": 5.102,
      "step": 49
    },
    {
      "epoch": 0.005733287467033597,
      "grad_norm": 0.0,
      "learning_rate": 0.0007025468705799002,
      "loss": 4.96,
      "step": 50
    },
    {
      "epoch": 0.005847953216374269,
      "grad_norm": 0.0,
      "learning_rate": 0.0007061031568841697,
      "loss": 5.2096,
      "step": 51
    },
    {
      "epoch": 0.0059626189657149406,
      "grad_norm": 0.0,
      "learning_rate": 0.0007095903847027764,
      "loss": 4.9829,
      "step": 52
    },
    {
      "epoch": 0.006077284715055613,
      "grad_norm": 0.0,
      "learning_rate": 0.0007130111850785127,
      "loss": 4.8667,
      "step": 53
    },
    {
      "epoch": 0.006191950464396285,
      "grad_norm": 0.0,
      "learning_rate": 0.0007163680415013736,
      "loss": 5.2922,
      "step": 54
    },
    {
      "epoch": 0.006306616213736957,
      "grad_norm": 0.0,
      "learning_rate": 0.0007196633007396989,
      "loss": 5.3192,
      "step": 55
    },
    {
      "epoch": 0.006421281963077629,
      "grad_norm": 0.0,
      "learning_rate": 0.0007228991826953695,
      "loss": 5.0294,
      "step": 56
    },
    {
      "epoch": 0.006535947712418301,
      "grad_norm": 0.0,
      "learning_rate": 0.0007260777893867202,
      "loss": 4.9427,
      "step": 57
    },
    {
      "epoch": 0.006650613461758973,
      "grad_norm": 0.0,
      "learning_rate": 0.0007292011131502053,
      "loss": 4.8083,
      "step": 58
    },
    {
      "epoch": 0.006765279211099645,
      "grad_norm": 0.0,
      "learning_rate": 0.000732271044140961,
      "loss": 5.1318,
      "step": 59
    },
    {
      "epoch": 0.0068799449604403165,
      "grad_norm": 0.0,
      "learning_rate": 0.000735289377202974,
      "loss": 5.0973,
      "step": 60
    },
    {
      "epoch": 0.006994610709780988,
      "grad_norm": 0.0,
      "learning_rate": 0.0007382578181713887,
      "loss": 4.9858,
      "step": 61
    },
    {
      "epoch": 0.00710927645912166,
      "grad_norm": 0.0,
      "learning_rate": 0.0007411779896623582,
      "loss": 4.8045,
      "step": 62
    },
    {
      "epoch": 0.007223942208462332,
      "grad_norm": 0.0,
      "learning_rate": 0.0007440514363996486,
      "loss": 5.0892,
      "step": 63
    },
    {
      "epoch": 0.007338607957803004,
      "grad_norm": 0.0,
      "learning_rate": 0.0007468796301217688,
      "loss": 4.9053,
      "step": 64
    },
    {
      "epoch": 0.007453273707143676,
      "grad_norm": 0.0,
      "learning_rate": 0.0007496639741086562,
      "loss": 4.8776,
      "step": 65
    },
    {
      "epoch": 0.007567939456484348,
      "grad_norm": 0.0,
      "learning_rate": 0.0007524058073627726,
      "loss": 5.0105,
      "step": 66
    },
    {
      "epoch": 0.00768260520582502,
      "grad_norm": 0.0,
      "learning_rate": 0.0007551064084757934,
      "loss": 5.0275,
      "step": 67
    },
    {
      "epoch": 0.007797270955165692,
      "grad_norm": 0.0,
      "learning_rate": 0.0007577669992088441,
      "loss": 5.2075,
      "step": 68
    },
    {
      "epoch": 0.007911936704506364,
      "grad_norm": 0.0,
      "learning_rate": 0.0007603887478113763,
      "loss": 5.0552,
      "step": 69
    },
    {
      "epoch": 0.008026602453847035,
      "grad_norm": 0.0,
      "learning_rate": 0.0007629727721012493,
      "loss": 5.1696,
      "step": 70
    },
    {
      "epoch": 0.008141268203187708,
      "grad_norm": 0.0,
      "learning_rate": 0.0007655201423263449,
      "loss": 5.1695,
      "step": 71
    },
    {
      "epoch": 0.008255933952528379,
      "grad_norm": 0.0,
      "learning_rate": 0.0007680318838260479,
      "loss": 4.8077,
      "step": 72
    },
    {
      "epoch": 0.008370599701869052,
      "grad_norm": 0.0,
      "learning_rate": 0.0007705089795091579,
      "loss": 5.1042,
      "step": 73
    },
    {
      "epoch": 0.008485265451209723,
      "grad_norm": 0.0,
      "learning_rate": 0.0007729523721632204,
      "loss": 4.8178,
      "step": 74
    },
    {
      "epoch": 0.008599931200550396,
      "grad_norm": 0.0,
      "learning_rate": 0.0007753629666088539,
      "loss": 5.1159,
      "step": 75
    },
    {
      "epoch": 0.008714596949891068,
      "grad_norm": 0.0,
      "learning_rate": 0.0007777416317113945,
      "loss": 5.0497,
      "step": 76
    },
    {
      "epoch": 0.00882926269923174,
      "grad_norm": 0.0,
      "learning_rate": 0.0007800892022610478,
      "loss": 5.1039,
      "step": 77
    },
    {
      "epoch": 0.008943928448572412,
      "grad_norm": 0.0,
      "learning_rate": 0.0007824064807317302,
      "loss": 5.4731,
      "step": 78
    },
    {
      "epoch": 0.009058594197913083,
      "grad_norm": 0.0,
      "learning_rate": 0.0007846942389278736,
      "loss": 5.1047,
      "step": 79
    },
    {
      "epoch": 0.009173259947253756,
      "grad_norm": 0.0,
      "learning_rate": 0.0007869532195276485,
      "loss": 5.0111,
      "step": 80
    },
    {
      "epoch": 0.009287925696594427,
      "grad_norm": 0.0,
      "learning_rate": 0.0007891841375303273,
      "loss": 4.8375,
      "step": 81
    },
    {
      "epoch": 0.0094025914459351,
      "grad_norm": 0.0,
      "learning_rate": 0.0007913876816148439,
      "loss": 4.925,
      "step": 82
    },
    {
      "epoch": 0.00951725719527577,
      "grad_norm": 0.0,
      "learning_rate": 0.0007935645154160138,
      "loss": 4.9917,
      "step": 83
    },
    {
      "epoch": 0.009631922944616443,
      "grad_norm": 0.0,
      "learning_rate": 0.000795715278724323,
      "loss": 4.8841,
      "step": 84
    },
    {
      "epoch": 0.009746588693957114,
      "grad_norm": 0.0,
      "learning_rate": 0.000797840588614724,
      "loss": 4.9556,
      "step": 85
    },
    {
      "epoch": 0.009861254443297787,
      "grad_norm": 0.0,
      "learning_rate": 0.0007999410405094103,
      "loss": 5.2965,
      "step": 86
    },
    {
      "epoch": 0.009975920192638458,
      "grad_norm": 0.0,
      "learning_rate": 0.0008020172091791589,
      "loss": 5.0775,
      "step": 87
    },
    {
      "epoch": 0.010090585941979131,
      "grad_norm": 0.0,
      "learning_rate": 0.0008040696496874472,
      "loss": 5.1208,
      "step": 88
    },
    {
      "epoch": 0.010205251691319802,
      "grad_norm": 0.0,
      "learning_rate": 0.000806098898281226,
      "loss": 4.9454,
      "step": 89
    },
    {
      "epoch": 0.010319917440660475,
      "grad_norm": 0.0,
      "learning_rate": 0.0008081054732319278,
      "loss": 4.9121,
      "step": 90
    },
    {
      "epoch": 0.010434583190001148,
      "grad_norm": 0.0,
      "learning_rate": 0.0008100898756300052,
      "loss": 4.9913,
      "step": 91
    },
    {
      "epoch": 0.010549248939341819,
      "grad_norm": 0.0,
      "learning_rate": 0.0008120525901360507,
      "loss": 5.196,
      "step": 92
    },
    {
      "epoch": 0.010663914688682491,
      "grad_norm": 0.0,
      "learning_rate": 0.000813994085691312,
      "loss": 4.8446,
      "step": 93
    },
    {
      "epoch": 0.010778580438023162,
      "grad_norm": 0.0,
      "learning_rate": 0.0008159148161902104,
      "loss": 4.8765,
      "step": 94
    },
    {
      "epoch": 0.010893246187363835,
      "grad_norm": 0.0,
      "learning_rate": 0.0008178152211172744,
      "loss": 5.0908,
      "step": 95
    },
    {
      "epoch": 0.011007911936704506,
      "grad_norm": 0.0,
      "learning_rate": 0.0008196957261507224,
      "loss": 4.905,
      "step": 96
    },
    {
      "epoch": 0.011122577686045179,
      "grad_norm": 0.0,
      "learning_rate": 0.0008215567437347723,
      "loss": 5.21,
      "step": 97
    },
    {
      "epoch": 0.01123724343538585,
      "grad_norm": 0.0,
      "learning_rate": 0.0008233986736225984,
      "loss": 4.8425,
      "step": 98
    },
    {
      "epoch": 0.011351909184726523,
      "grad_norm": 0.0,
      "learning_rate": 0.0008252219033917263,
      "loss": 4.9502,
      "step": 99
    },
    {
      "epoch": 0.011466574934067194,
      "grad_norm": 0.0,
      "learning_rate": 0.0008270268089335285,
      "loss": 5.2013,
      "step": 100
    },
    {
      "epoch": 0.011581240683407866,
      "grad_norm": 0.0,
      "learning_rate": 0.0008288137549183624,
      "loss": 5.302,
      "step": 101
    },
    {
      "epoch": 0.011695906432748537,
      "grad_norm": 0.0,
      "learning_rate": 0.0008305830952377978,
      "loss": 4.9051,
      "step": 102
    },
    {
      "epoch": 0.01181057218208921,
      "grad_norm": 0.0,
      "learning_rate": 0.000832335173425269,
      "loss": 5.0454,
      "step": 103
    },
    {
      "epoch": 0.011925237931429881,
      "grad_norm": 0.0,
      "learning_rate": 0.0008340703230564046,
      "loss": 5.1029,
      "step": 104
    },
    {
      "epoch": 0.012039903680770554,
      "grad_norm": 0.0,
      "learning_rate": 0.0008357888681302028,
      "loss": 5.2407,
      "step": 105
    },
    {
      "epoch": 0.012154569430111227,
      "grad_norm": 0.0,
      "learning_rate": 0.0008374911234321407,
      "loss": 4.9318,
      "step": 106
    },
    {
      "epoch": 0.012269235179451898,
      "grad_norm": 0.0,
      "learning_rate": 0.000839177394880234,
      "loss": 5.3672,
      "step": 107
    },
    {
      "epoch": 0.01238390092879257,
      "grad_norm": 0.0,
      "learning_rate": 0.0008408479798550018,
      "loss": 5.1029,
      "step": 108
    },
    {
      "epoch": 0.012498566678133241,
      "grad_norm": 0.0,
      "learning_rate": 0.0008425031675142239,
      "loss": 4.9721,
      "step": 109
    },
    {
      "epoch": 0.012613232427473914,
      "grad_norm": 0.0,
      "learning_rate": 0.0008441432390933271,
      "loss": 5.1467,
      "step": 110
    },
    {
      "epoch": 0.012727898176814585,
      "grad_norm": 0.0,
      "learning_rate": 0.000845768468192174,
      "loss": 5.0739,
      "step": 111
    },
    {
      "epoch": 0.012842563926155258,
      "grad_norm": 0.0,
      "learning_rate": 0.0008473791210489975,
      "loss": 5.0203,
      "step": 112
    },
    {
      "epoch": 0.012957229675495929,
      "grad_norm": 0.0,
      "learning_rate": 0.000848975456802154,
      "loss": 5.0675,
      "step": 113
    },
    {
      "epoch": 0.013071895424836602,
      "grad_norm": 0.0,
      "learning_rate": 0.0008505577277403484,
      "loss": 5.0238,
      "step": 114
    },
    {
      "epoch": 0.013186561174177273,
      "grad_norm": 0.0,
      "learning_rate": 0.0008521261795419305,
      "loss": 5.1825,
      "step": 115
    },
    {
      "epoch": 0.013301226923517945,
      "grad_norm": 0.0,
      "learning_rate": 0.0008536810515038334,
      "loss": 4.8248,
      "step": 116
    },
    {
      "epoch": 0.013415892672858616,
      "grad_norm": 0.0,
      "learning_rate": 0.0008552225767606838,
      "loss": 4.9138,
      "step": 117
    },
    {
      "epoch": 0.01353055842219929,
      "grad_norm": 0.0,
      "learning_rate": 0.0008567509824945891,
      "loss": 4.8079,
      "step": 118
    },
    {
      "epoch": 0.01364522417153996,
      "grad_norm": 0.0,
      "learning_rate": 0.000858266490136073,
      "loss": 4.8555,
      "step": 119
    },
    {
      "epoch": 0.013759889920880633,
      "grad_norm": 0.0,
      "learning_rate": 0.0008597693155566023,
      "loss": 5.2305,
      "step": 120
    },
    {
      "epoch": 0.013874555670221306,
      "grad_norm": 0.0,
      "learning_rate": 0.0008612596692531255,
      "loss": 5.2792,
      "step": 121
    },
    {
      "epoch": 0.013989221419561977,
      "grad_norm": 0.0,
      "learning_rate": 0.0008627377565250168,
      "loss": 5.1607,
      "step": 122
    },
    {
      "epoch": 0.01410388716890265,
      "grad_norm": 0.0,
      "learning_rate": 0.0008642037776437976,
      "loss": 4.9536,
      "step": 123
    },
    {
      "epoch": 0.01421855291824332,
      "grad_norm": 0.0,
      "learning_rate": 0.0008656579280159865,
      "loss": 5.1304,
      "step": 124
    },
    {
      "epoch": 0.014333218667583993,
      "grad_norm": 0.0,
      "learning_rate": 0.0008671003983394082,
      "loss": 4.8445,
      "step": 125
    },
    {
      "epoch": 0.014447884416924664,
      "grad_norm": 0.0,
      "learning_rate": 0.0008685313747532768,
      "loss": 5.2159,
      "step": 126
    },
    {
      "epoch": 0.014562550166265337,
      "grad_norm": 0.0,
      "learning_rate": 0.000869951038982344,
      "loss": 4.9908,
      "step": 127
    },
    {
      "epoch": 0.014677215915606008,
      "grad_norm": 0.0,
      "learning_rate": 0.0008713595684753969,
      "loss": 5.0165,
      "step": 128
    },
    {
      "epoch": 0.01479188166494668,
      "grad_norm": 0.0,
      "learning_rate": 0.000872757136538364,
      "loss": 4.803,
      "step": 129
    },
    {
      "epoch": 0.014906547414287352,
      "grad_norm": 0.0,
      "learning_rate": 0.0008741439124622843,
      "loss": 5.2963,
      "step": 130
    },
    {
      "epoch": 0.015021213163628025,
      "grad_norm": 0.0,
      "learning_rate": 0.0008755200616463719,
      "loss": 5.356,
      "step": 131
    },
    {
      "epoch": 0.015135878912968696,
      "grad_norm": 0.0,
      "learning_rate": 0.0008768857457164008,
      "loss": 4.9845,
      "step": 132
    },
    {
      "epoch": 0.015250544662309368,
      "grad_norm": 0.0,
      "learning_rate": 0.0008782411226386234,
      "loss": 4.7673,
      "step": 133
    },
    {
      "epoch": 0.01536521041165004,
      "grad_norm": 0.0,
      "learning_rate": 0.0008795863468294215,
      "loss": 4.9385,
      "step": 134
    },
    {
      "epoch": 0.015479876160990712,
      "grad_norm": 0.0,
      "learning_rate": 0.0008809215692608815,
      "loss": 4.964,
      "step": 135
    },
    {
      "epoch": 0.015594541910331383,
      "grad_norm": 0.0,
      "learning_rate": 0.0008822469375624724,
      "loss": 4.9196,
      "step": 136
    },
    {
      "epoch": 0.015709207659672056,
      "grad_norm": 0.0,
      "learning_rate": 0.000883562596119001,
      "loss": 4.9694,
      "step": 137
    },
    {
      "epoch": 0.01582387340901273,
      "grad_norm": 0.0,
      "learning_rate": 0.0008848686861650044,
      "loss": 5.0102,
      "step": 138
    },
    {
      "epoch": 0.0159385391583534,
      "grad_norm": 0.0,
      "learning_rate": 0.0008861653458757335,
      "loss": 5.0809,
      "step": 139
    },
    {
      "epoch": 0.01605320490769407,
      "grad_norm": 0.0,
      "learning_rate": 0.0008874527104548773,
      "loss": 5.0463,
      "step": 140
    },
    {
      "epoch": 0.016167870657034743,
      "grad_norm": 0.0,
      "learning_rate": 0.0008887309122191641,
      "loss": 5.1196,
      "step": 141
    },
    {
      "epoch": 0.016282536406375416,
      "grad_norm": 0.0,
      "learning_rate": 0.0008900000806799731,
      "loss": 4.9886,
      "step": 142
    },
    {
      "epoch": 0.01639720215571609,
      "grad_norm": 0.0,
      "learning_rate": 0.0008912603426220829,
      "loss": 4.9041,
      "step": 143
    },
    {
      "epoch": 0.016511867905056758,
      "grad_norm": 0.0,
      "learning_rate": 0.000892511822179676,
      "loss": 4.8938,
      "step": 144
    },
    {
      "epoch": 0.01662653365439743,
      "grad_norm": 0.0,
      "learning_rate": 0.0008937546409097133,
      "loss": 4.9206,
      "step": 145
    },
    {
      "epoch": 0.016741199403738104,
      "grad_norm": 0.0,
      "learning_rate": 0.000894988917862786,
      "loss": 5.0897,
      "step": 146
    },
    {
      "epoch": 0.016855865153078776,
      "grad_norm": 0.0,
      "learning_rate": 0.0008962147696515519,
      "loss": 4.8438,
      "step": 147
    },
    {
      "epoch": 0.016970530902419446,
      "grad_norm": 0.0,
      "learning_rate": 0.0008974323105168483,
      "loss": 5.0107,
      "step": 148
    },
    {
      "epoch": 0.01708519665176012,
      "grad_norm": 0.0,
      "learning_rate": 0.0008986416523915826,
      "loss": 5.1801,
      "step": 149
    },
    {
      "epoch": 0.01719986240110079,
      "grad_norm": 0.0,
      "learning_rate": 0.000899842904962482,
      "loss": 5.2031,
      "step": 150
    },
    {
      "epoch": 0.017314528150441464,
      "grad_norm": 0.0,
      "learning_rate": 0.0009010361757297954,
      "loss": 4.9803,
      "step": 151
    },
    {
      "epoch": 0.017429193899782137,
      "grad_norm": 0.0,
      "learning_rate": 0.0009022215700650227,
      "loss": 5.2998,
      "step": 152
    },
    {
      "epoch": 0.017543859649122806,
      "grad_norm": 0.0,
      "learning_rate": 0.0009033991912667515,
      "loss": 5.0394,
      "step": 153
    },
    {
      "epoch": 0.01765852539846348,
      "grad_norm": 0.0,
      "learning_rate": 0.000904569140614676,
      "loss": 5.1041,
      "step": 154
    },
    {
      "epoch": 0.01777319114780415,
      "grad_norm": 0.0,
      "learning_rate": 0.0009057315174218662,
      "loss": 5.0641,
      "step": 155
    },
    {
      "epoch": 0.017887856897144824,
      "grad_norm": 0.0,
      "learning_rate": 0.0009068864190853583,
      "loss": 5.0563,
      "step": 156
    },
    {
      "epoch": 0.018002522646485494,
      "grad_norm": 0.0,
      "learning_rate": 0.0009080339411351263,
      "loss": 5.0941,
      "step": 157
    },
    {
      "epoch": 0.018117188395826166,
      "grad_norm": 0.0,
      "learning_rate": 0.0009091741772815018,
      "loss": 5.1787,
      "step": 158
    },
    {
      "epoch": 0.01823185414516684,
      "grad_norm": 0.0,
      "learning_rate": 0.0009103072194610944,
      "loss": 5.3225,
      "step": 159
    },
    {
      "epoch": 0.018346519894507512,
      "grad_norm": 0.0,
      "learning_rate": 0.0009114331578812766,
      "loss": 5.1071,
      "step": 160
    },
    {
      "epoch": 0.01846118564384818,
      "grad_norm": 0.0,
      "learning_rate": 0.0009125520810632794,
      "loss": 4.8408,
      "step": 161
    },
    {
      "epoch": 0.018575851393188854,
      "grad_norm": 0.0,
      "learning_rate": 0.0009136640758839553,
      "loss": 4.7682,
      "step": 162
    },
    {
      "epoch": 0.018690517142529527,
      "grad_norm": 0.0,
      "learning_rate": 0.0009147692276162559,
      "loss": 4.8787,
      "step": 163
    },
    {
      "epoch": 0.0188051828918702,
      "grad_norm": 0.0,
      "learning_rate": 0.0009158676199684721,
      "loss": 5.1902,
      "step": 164
    },
    {
      "epoch": 0.01891984864121087,
      "grad_norm": 0.0,
      "learning_rate": 0.0009169593351222806,
      "loss": 4.8692,
      "step": 165
    },
    {
      "epoch": 0.01903451439055154,
      "grad_norm": 0.0,
      "learning_rate": 0.0009180444537696419,
      "loss": 4.858,
      "step": 166
    },
    {
      "epoch": 0.019149180139892214,
      "grad_norm": 0.0,
      "learning_rate": 0.0009191230551485896,
      "loss": 5.1727,
      "step": 167
    },
    {
      "epoch": 0.019263845889232887,
      "grad_norm": 0.0,
      "learning_rate": 0.0009201952170779512,
      "loss": 4.887,
      "step": 168
    },
    {
      "epoch": 0.01937851163857356,
      "grad_norm": 0.0,
      "learning_rate": 0.0009212610159910403,
      "loss": 4.9406,
      "step": 169
    },
    {
      "epoch": 0.01949317738791423,
      "grad_norm": 0.0,
      "learning_rate": 0.0009223205269683521,
      "loss": 5.1915,
      "step": 170
    },
    {
      "epoch": 0.0196078431372549,
      "grad_norm": 0.0,
      "learning_rate": 0.000923373823769302,
      "loss": 4.8497,
      "step": 171
    },
    {
      "epoch": 0.019722508886595574,
      "grad_norm": 0.0,
      "learning_rate": 0.0009244209788630385,
      "loss": 5.1526,
      "step": 172
    },
    {
      "epoch": 0.019837174635936247,
      "grad_norm": 0.0,
      "learning_rate": 0.0009254620634583631,
      "loss": 4.9372,
      "step": 173
    },
    {
      "epoch": 0.019951840385276916,
      "grad_norm": 0.0,
      "learning_rate": 0.0009264971475327872,
      "loss": 5.1434,
      "step": 174
    },
    {
      "epoch": 0.02006650613461759,
      "grad_norm": 0.0,
      "learning_rate": 0.0009275262998607572,
      "loss": 5.3756,
      "step": 175
    },
    {
      "epoch": 0.020181171883958262,
      "grad_norm": 0.0,
      "learning_rate": 0.0009285495880410751,
      "loss": 4.8777,
      "step": 176
    },
    {
      "epoch": 0.020295837633298935,
      "grad_norm": 0.0,
      "learning_rate": 0.0009295670785235428,
      "loss": 4.9175,
      "step": 177
    },
    {
      "epoch": 0.020410503382639604,
      "grad_norm": 0.0,
      "learning_rate": 0.0009305788366348541,
      "loss": 4.9267,
      "step": 178
    },
    {
      "epoch": 0.020525169131980277,
      "grad_norm": 0.0,
      "learning_rate": 0.0009315849266037642,
      "loss": 5.0509,
      "step": 179
    },
    {
      "epoch": 0.02063983488132095,
      "grad_norm": 0.0,
      "learning_rate": 0.0009325854115855559,
      "loss": 4.93,
      "step": 180
    },
    {
      "epoch": 0.020754500630661622,
      "grad_norm": 0.0,
      "learning_rate": 0.0009335803536858289,
      "loss": 5.0025,
      "step": 181
    },
    {
      "epoch": 0.020869166380002295,
      "grad_norm": 0.0,
      "learning_rate": 0.0009345698139836334,
      "loss": 5.0348,
      "step": 182
    },
    {
      "epoch": 0.020983832129342964,
      "grad_norm": 0.0,
      "learning_rate": 0.0009355538525539706,
      "loss": 4.9514,
      "step": 183
    },
    {
      "epoch": 0.021098497878683637,
      "grad_norm": 0.0,
      "learning_rate": 0.0009365325284896789,
      "loss": 5.2453,
      "step": 184
    },
    {
      "epoch": 0.02121316362802431,
      "grad_norm": 0.0,
      "learning_rate": 0.0009375058999227283,
      "loss": 5.0816,
      "step": 185
    },
    {
      "epoch": 0.021327829377364983,
      "grad_norm": 0.0,
      "learning_rate": 0.0009384740240449401,
      "loss": 5.039,
      "step": 186
    },
    {
      "epoch": 0.021442495126705652,
      "grad_norm": 0.0,
      "learning_rate": 0.0009394369571281507,
      "loss": 5.0013,
      "step": 187
    },
    {
      "epoch": 0.021557160876046325,
      "grad_norm": 0.0,
      "learning_rate": 0.0009403947545438386,
      "loss": 5.1499,
      "step": 188
    },
    {
      "epoch": 0.021671826625386997,
      "grad_norm": 0.0,
      "learning_rate": 0.0009413474707822305,
      "loss": 4.9591,
      "step": 189
    },
    {
      "epoch": 0.02178649237472767,
      "grad_norm": 0.0,
      "learning_rate": 0.0009422951594709025,
      "loss": 4.936,
      "step": 190
    },
    {
      "epoch": 0.02190115812406834,
      "grad_norm": 0.0,
      "learning_rate": 0.0009432378733928946,
      "loss": 4.7874,
      "step": 191
    },
    {
      "epoch": 0.022015823873409012,
      "grad_norm": 0.0,
      "learning_rate": 0.0009441756645043505,
      "loss": 5.2889,
      "step": 192
    },
    {
      "epoch": 0.022130489622749685,
      "grad_norm": 0.0,
      "learning_rate": 0.0009451085839517007,
      "loss": 4.9511,
      "step": 193
    },
    {
      "epoch": 0.022245155372090358,
      "grad_norm": 0.0,
      "learning_rate": 0.0009460366820884004,
      "loss": 4.8976,
      "step": 194
    },
    {
      "epoch": 0.022359821121431027,
      "grad_norm": 0.0,
      "learning_rate": 0.000946960008491238,
      "loss": 4.9706,
      "step": 195
    },
    {
      "epoch": 0.0224744868707717,
      "grad_norm": 0.0,
      "learning_rate": 0.0009478786119762263,
      "loss": 4.8273,
      "step": 196
    },
    {
      "epoch": 0.022589152620112372,
      "grad_norm": 0.0,
      "learning_rate": 0.0009487925406140888,
      "loss": 5.1716,
      "step": 197
    },
    {
      "epoch": 0.022703818369453045,
      "grad_norm": 0.0,
      "learning_rate": 0.0009497018417453545,
      "loss": 4.9805,
      "step": 198
    },
    {
      "epoch": 0.022818484118793718,
      "grad_norm": 0.0,
      "learning_rate": 0.0009506065619950721,
      "loss": 4.9911,
      "step": 199
    },
    {
      "epoch": 0.022933149868134387,
      "grad_norm": 0.0,
      "learning_rate": 0.0009515067472871565,
      "loss": 5.0784,
      "step": 200
    },
    {
      "epoch": 0.02304781561747506,
      "grad_norm": 0.0,
      "learning_rate": 0.0009524024428583753,
      "loss": 5.1,
      "step": 201
    },
    {
      "epoch": 0.023162481366815733,
      "grad_norm": 0.0,
      "learning_rate": 0.0009532936932719905,
      "loss": 5.1775,
      "step": 202
    },
    {
      "epoch": 0.023277147116156405,
      "grad_norm": 0.0,
      "learning_rate": 0.0009541805424310622,
      "loss": 4.8268,
      "step": 203
    },
    {
      "epoch": 0.023391812865497075,
      "grad_norm": 0.0,
      "learning_rate": 0.0009550630335914259,
      "loss": 4.829,
      "step": 204
    },
    {
      "epoch": 0.023506478614837747,
      "grad_norm": 0.0,
      "learning_rate": 0.0009559412093743519,
      "loss": 4.9002,
      "step": 205
    },
    {
      "epoch": 0.02362114436417842,
      "grad_norm": 0.0,
      "learning_rate": 0.0009568151117788971,
      "loss": 5.2026,
      "step": 206
    },
    {
      "epoch": 0.023735810113519093,
      "grad_norm": 0.0,
      "learning_rate": 0.0009576847821939579,
      "loss": 4.9261,
      "step": 207
    },
    {
      "epoch": 0.023850475862859762,
      "grad_norm": 0.0,
      "learning_rate": 0.0009585502614100327,
      "loss": 5.4598,
      "step": 208
    },
    {
      "epoch": 0.023965141612200435,
      "grad_norm": 0.0,
      "learning_rate": 0.0009594115896307011,
      "loss": 5.0136,
      "step": 209
    },
    {
      "epoch": 0.024079807361541108,
      "grad_norm": 0.0,
      "learning_rate": 0.000960268806483831,
      "loss": 5.1352,
      "step": 210
    },
    {
      "epoch": 0.02419447311088178,
      "grad_norm": 0.0,
      "learning_rate": 0.0009611219510325186,
      "loss": 4.9434,
      "step": 211
    },
    {
      "epoch": 0.024309138860222453,
      "grad_norm": 0.0,
      "learning_rate": 0.0009619710617857688,
      "loss": 4.9665,
      "step": 212
    },
    {
      "epoch": 0.024423804609563123,
      "grad_norm": 0.0,
      "learning_rate": 0.0009628161767089268,
      "loss": 4.8426,
      "step": 213
    },
    {
      "epoch": 0.024538470358903795,
      "grad_norm": 0.0,
      "learning_rate": 0.0009636573332338621,
      "loss": 5.0046,
      "step": 214
    },
    {
      "epoch": 0.024653136108244468,
      "grad_norm": 0.0,
      "learning_rate": 0.0009644945682689182,
      "loss": 4.9911,
      "step": 215
    },
    {
      "epoch": 0.02476780185758514,
      "grad_norm": 0.0,
      "learning_rate": 0.0009653279182086299,
      "loss": 4.8426,
      "step": 216
    },
    {
      "epoch": 0.02488246760692581,
      "grad_norm": 0.0,
      "learning_rate": 0.0009661574189432152,
      "loss": 4.9779,
      "step": 217
    },
    {
      "epoch": 0.024997133356266483,
      "grad_norm": 0.0,
      "learning_rate": 0.0009669831058678521,
      "loss": 4.732,
      "step": 218
    },
    {
      "epoch": 0.025111799105607156,
      "grad_norm": 0.0,
      "learning_rate": 0.0009678050138917398,
      "loss": 4.8526,
      "step": 219
    },
    {
      "epoch": 0.02522646485494783,
      "grad_norm": 0.0,
      "learning_rate": 0.0009686231774469552,
      "loss": 5.2417,
      "step": 220
    },
    {
      "epoch": 0.025341130604288498,
      "grad_norm": 0.0,
      "learning_rate": 0.000969437630497108,
      "loss": 4.8872,
      "step": 221
    },
    {
      "epoch": 0.02545579635362917,
      "grad_norm": 0.0,
      "learning_rate": 0.0009702484065458022,
      "loss": 5.0898,
      "step": 222
    },
    {
      "epoch": 0.025570462102969843,
      "grad_norm": 0.0,
      "learning_rate": 0.0009710555386449034,
      "loss": 4.7389,
      "step": 223
    },
    {
      "epoch": 0.025685127852310516,
      "grad_norm": 0.0,
      "learning_rate": 0.0009718590594026257,
      "loss": 4.9573,
      "step": 224
    },
    {
      "epoch": 0.025799793601651185,
      "grad_norm": 0.0,
      "learning_rate": 0.0009726590009914356,
      "loss": 5.0205,
      "step": 225
    },
    {
      "epoch": 0.025914459350991858,
      "grad_norm": 0.0,
      "learning_rate": 0.0009734553951557821,
      "loss": 4.935,
      "step": 226
    },
    {
      "epoch": 0.02602912510033253,
      "grad_norm": 0.0,
      "learning_rate": 0.0009742482732196546,
      "loss": 4.8912,
      "step": 227
    },
    {
      "epoch": 0.026143790849673203,
      "grad_norm": 0.0,
      "learning_rate": 0.0009750376660939765,
      "loss": 5.2096,
      "step": 228
    },
    {
      "epoch": 0.026258456599013876,
      "grad_norm": 0.0,
      "learning_rate": 0.0009758236042838358,
      "loss": 4.9767,
      "step": 229
    },
    {
      "epoch": 0.026373122348354545,
      "grad_norm": 0.0,
      "learning_rate": 0.0009766061178955586,
      "loss": 5.1055,
      "step": 230
    },
    {
      "epoch": 0.026487788097695218,
      "grad_norm": 0.0,
      "learning_rate": 0.0009773852366436295,
      "loss": 4.9982,
      "step": 231
    },
    {
      "epoch": 0.02660245384703589,
      "grad_norm": 0.0,
      "learning_rate": 0.0009781609898574617,
      "loss": 4.7301,
      "step": 232
    },
    {
      "epoch": 0.026717119596376564,
      "grad_norm": 0.0,
      "learning_rate": 0.0009789334064880212,
      "loss": 5.1699,
      "step": 233
    },
    {
      "epoch": 0.026831785345717233,
      "grad_norm": 0.0,
      "learning_rate": 0.000979702515114312,
      "loss": 5.416,
      "step": 234
    },
    {
      "epoch": 0.026946451095057906,
      "grad_norm": 0.0,
      "learning_rate": 0.0009804683439497185,
      "loss": 4.9873,
      "step": 235
    },
    {
      "epoch": 0.02706111684439858,
      "grad_norm": 0.0,
      "learning_rate": 0.0009812309208482174,
      "loss": 4.8943,
      "step": 236
    },
    {
      "epoch": 0.02717578259373925,
      "grad_norm": 0.0,
      "learning_rate": 0.0009819902733104555,
      "loss": 4.8349,
      "step": 237
    },
    {
      "epoch": 0.02729044834307992,
      "grad_norm": 0.0,
      "learning_rate": 0.0009827464284897012,
      "loss": 5.204,
      "step": 238
    },
    {
      "epoch": 0.027405114092420593,
      "grad_norm": 0.0,
      "learning_rate": 0.0009834994131976704,
      "loss": 4.8774,
      "step": 239
    },
    {
      "epoch": 0.027519779841761266,
      "grad_norm": 0.0,
      "learning_rate": 0.0009842492539102303,
      "loss": 4.9694,
      "step": 240
    },
    {
      "epoch": 0.02763444559110194,
      "grad_norm": 0.0,
      "learning_rate": 0.000984995976772987,
      "loss": 5.0945,
      "step": 241
    },
    {
      "epoch": 0.02774911134044261,
      "grad_norm": 0.0,
      "learning_rate": 0.0009857396076067536,
      "loss": 4.8028,
      "step": 242
    },
    {
      "epoch": 0.02786377708978328,
      "grad_norm": 0.0,
      "learning_rate": 0.000986480171912909,
      "loss": 5.1199,
      "step": 243
    },
    {
      "epoch": 0.027978442839123954,
      "grad_norm": 0.0,
      "learning_rate": 0.000987217694878645,
      "loss": 5.0393,
      "step": 244
    },
    {
      "epoch": 0.028093108588464626,
      "grad_norm": 0.0,
      "learning_rate": 0.0009879522013821064,
      "loss": 5.0308,
      "step": 245
    },
    {
      "epoch": 0.0282077743378053,
      "grad_norm": 0.0,
      "learning_rate": 0.0009886837159974256,
      "loss": 4.9159,
      "step": 246
    },
    {
      "epoch": 0.02832244008714597,
      "grad_norm": 0.0,
      "learning_rate": 0.0009894122629996586,
      "loss": 4.8442,
      "step": 247
    },
    {
      "epoch": 0.02843710583648664,
      "grad_norm": 0.0,
      "learning_rate": 0.0009901378663696146,
      "loss": 4.8888,
      "step": 248
    },
    {
      "epoch": 0.028551771585827314,
      "grad_norm": 0.0,
      "learning_rate": 0.0009908605497985954,
      "loss": 5.0614,
      "step": 249
    },
    {
      "epoch": 0.028666437335167987,
      "grad_norm": 0.0,
      "learning_rate": 0.0009915803366930362,
      "loss": 5.0508,
      "step": 250
    },
    {
      "epoch": 0.028781103084508656,
      "grad_norm": 0.0,
      "learning_rate": 0.0009922972501790537,
      "loss": 4.8839,
      "step": 251
    },
    {
      "epoch": 0.02889576883384933,
      "grad_norm": 0.0,
      "learning_rate": 0.000993011313106905,
      "loss": 4.8487,
      "step": 252
    },
    {
      "epoch": 0.02901043458319,
      "grad_norm": 0.0,
      "learning_rate": 0.0009937225480553572,
      "loss": 4.9859,
      "step": 253
    },
    {
      "epoch": 0.029125100332530674,
      "grad_norm": 0.0,
      "learning_rate": 0.0009944309773359723,
      "loss": 5.1181,
      "step": 254
    },
    {
      "epoch": 0.029239766081871343,
      "grad_norm": 0.0,
      "learning_rate": 0.0009951366229973056,
      "loss": 5.2362,
      "step": 255
    },
    {
      "epoch": 0.029354431831212016,
      "grad_norm": 0.0,
      "learning_rate": 0.000995839506829025,
      "loss": 5.0658,
      "step": 256
    },
    {
      "epoch": 0.02946909758055269,
      "grad_norm": 0.0,
      "learning_rate": 0.000996539650365946,
      "loss": 5.0651,
      "step": 257
    },
    {
      "epoch": 0.02958376332989336,
      "grad_norm": 0.0,
      "learning_rate": 0.0009972370748919921,
      "loss": 5.0308,
      "step": 258
    },
    {
      "epoch": 0.029698429079234034,
      "grad_norm": 0.0,
      "learning_rate": 0.0009979318014440772,
      "loss": 5.0824,
      "step": 259
    },
    {
      "epoch": 0.029813094828574704,
      "grad_norm": 0.0,
      "learning_rate": 0.0009986238508159124,
      "loss": 4.7987,
      "step": 260
    },
    {
      "epoch": 0.029927760577915376,
      "grad_norm": 0.0,
      "learning_rate": 0.0009993132435617408,
      "loss": 4.7293,
      "step": 261
    },
    {
      "epoch": 0.03004242632725605,
      "grad_norm": 0.0,
      "learning_rate": 0.001,
      "loss": 5.2585,
      "step": 262
    },
    {
      "epoch": 0.030157092076596722,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999999655207136,
      "loss": 4.9093,
      "step": 263
    },
    {
      "epoch": 0.03027175782593739,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999998620828596,
      "loss": 4.9698,
      "step": 264
    },
    {
      "epoch": 0.030386423575278064,
      "grad_norm": 0.0,
      "learning_rate": 0.000999999689686452,
      "loss": 4.99,
      "step": 265
    },
    {
      "epoch": 0.030501089324618737,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999994483315144,
      "loss": 4.8565,
      "step": 266
    },
    {
      "epoch": 0.03061575507395941,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999991380180806,
      "loss": 5.1076,
      "step": 267
    },
    {
      "epoch": 0.03073042082330008,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999987587461928,
      "loss": 5.0657,
      "step": 268
    },
    {
      "epoch": 0.03084508657264075,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999983105159038,
      "loss": 5.1134,
      "step": 269
    },
    {
      "epoch": 0.030959752321981424,
      "grad_norm": 0.0,
      "learning_rate": 0.000999997793327275,
      "loss": 5.1588,
      "step": 270
    },
    {
      "epoch": 0.031074418071322097,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999972071803784,
      "loss": 4.9866,
      "step": 271
    },
    {
      "epoch": 0.031189083820662766,
      "grad_norm": 0.0,
      "learning_rate": 0.000999996552075294,
      "loss": 5.3208,
      "step": 272
    },
    {
      "epoch": 0.03130374957000344,
      "grad_norm": 0.0,
      "learning_rate": 0.000999995828012113,
      "loss": 4.8851,
      "step": 273
    },
    {
      "epoch": 0.03141841531934411,
      "grad_norm": 0.0,
      "learning_rate": 0.000999995034990935,
      "loss": 5.0884,
      "step": 274
    },
    {
      "epoch": 0.031533081068684785,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999941730118686,
      "loss": 5.1838,
      "step": 275
    },
    {
      "epoch": 0.03164774681802546,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999932420750336,
      "loss": 5.0631,
      "step": 276
    },
    {
      "epoch": 0.03176241256736613,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999922421805583,
      "loss": 5.2112,
      "step": 277
    },
    {
      "epoch": 0.0318770783167068,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999911733285802,
      "loss": 5.1817,
      "step": 278
    },
    {
      "epoch": 0.03199174406604747,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999900355192473,
      "loss": 4.8216,
      "step": 279
    },
    {
      "epoch": 0.03210640981538814,
      "grad_norm": 0.0,
      "learning_rate": 0.000999988828752716,
      "loss": 5.0018,
      "step": 280
    },
    {
      "epoch": 0.032221075564728814,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999875530291532,
      "loss": 5.1107,
      "step": 281
    },
    {
      "epoch": 0.03233574131406949,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999862083487341,
      "loss": 5.3082,
      "step": 282
    },
    {
      "epoch": 0.03245040706341016,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999847947116454,
      "loss": 5.0217,
      "step": 283
    },
    {
      "epoch": 0.03256507281275083,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999833121180808,
      "loss": 4.9193,
      "step": 284
    },
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999817605682458,
      "loss": 4.8491,
      "step": 285
    },
    {
      "epoch": 0.03279440431143218,
      "grad_norm": 0.0,
      "learning_rate": 0.000999980140062354,
      "loss": 4.8511,
      "step": 286
    },
    {
      "epoch": 0.032909070060772844,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999784506006287,
      "loss": 4.8171,
      "step": 287
    },
    {
      "epoch": 0.033023735810113516,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999766921833032,
      "loss": 4.9926,
      "step": 288
    },
    {
      "epoch": 0.03313840155945419,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999748648106199,
      "loss": 4.9456,
      "step": 289
    },
    {
      "epoch": 0.03325306730879486,
      "grad_norm": 0.0,
      "learning_rate": 0.000999972968482831,
      "loss": 4.8178,
      "step": 290
    },
    {
      "epoch": 0.033367733058135535,
      "grad_norm": 0.0,
      "learning_rate": 0.000999971003200198,
      "loss": 5.0264,
      "step": 291
    },
    {
      "epoch": 0.03348239880747621,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999689689629923,
      "loss": 5.1287,
      "step": 292
    },
    {
      "epoch": 0.03359706455681688,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999668657714937,
      "loss": 5.096,
      "step": 293
    },
    {
      "epoch": 0.03371173030615755,
      "grad_norm": 0.0,
      "learning_rate": 0.000999964693625993,
      "loss": 5.2478,
      "step": 294
    },
    {
      "epoch": 0.033826396055498226,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999624525267893,
      "loss": 4.9014,
      "step": 295
    },
    {
      "epoch": 0.03394106180483889,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999601424741922,
      "loss": 5.135,
      "step": 296
    },
    {
      "epoch": 0.034055727554179564,
      "grad_norm": 0.0,
      "learning_rate": 0.00099995776346852,
      "loss": 5.1799,
      "step": 297
    },
    {
      "epoch": 0.03417039330352024,
      "grad_norm": 0.0,
      "learning_rate": 0.000999955315510101,
      "loss": 5.1288,
      "step": 298
    },
    {
      "epoch": 0.03428505905286091,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999527985992728,
      "loss": 4.8331,
      "step": 299
    },
    {
      "epoch": 0.03439972480220158,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999502127363822,
      "loss": 5.0172,
      "step": 300
    },
    {
      "epoch": 0.034514390551542255,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999475579217868,
      "loss": 4.8091,
      "step": 301
    },
    {
      "epoch": 0.03462905630088293,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999448341558518,
      "loss": 4.9272,
      "step": 302
    },
    {
      "epoch": 0.0347437220502236,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999420414389536,
      "loss": 5.1546,
      "step": 303
    },
    {
      "epoch": 0.034858387799564274,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999391797714768,
      "loss": 4.9661,
      "step": 304
    },
    {
      "epoch": 0.03497305354890494,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999362491538164,
      "loss": 5.0012,
      "step": 305
    },
    {
      "epoch": 0.03508771929824561,
      "grad_norm": 0.0,
      "learning_rate": 0.000999933249586377,
      "loss": 4.7766,
      "step": 306
    },
    {
      "epoch": 0.035202385047586285,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999301810695714,
      "loss": 5.0939,
      "step": 307
    },
    {
      "epoch": 0.03531705079692696,
      "grad_norm": 0.0,
      "learning_rate": 0.000999927043603824,
      "loss": 4.6452,
      "step": 308
    },
    {
      "epoch": 0.03543171654626763,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999238371895664,
      "loss": 5.071,
      "step": 309
    },
    {
      "epoch": 0.0355463822956083,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999205618272417,
      "loss": 4.627,
      "step": 310
    },
    {
      "epoch": 0.035661048044948976,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999172175173014,
      "loss": 5.1142,
      "step": 311
    },
    {
      "epoch": 0.03577571379428965,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999138042602069,
      "loss": 4.9921,
      "step": 312
    },
    {
      "epoch": 0.035890379543630314,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999103220564285,
      "loss": 5.1816,
      "step": 313
    },
    {
      "epoch": 0.03600504529297099,
      "grad_norm": 0.0,
      "learning_rate": 0.000999906770906447,
      "loss": 5.0947,
      "step": 314
    },
    {
      "epoch": 0.03611971104231166,
      "grad_norm": 0.0,
      "learning_rate": 0.0009999031508107525,
      "loss": 5.0872,
      "step": 315
    },
    {
      "epoch": 0.03623437679165233,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998994617698436,
      "loss": 5.0716,
      "step": 316
    },
    {
      "epoch": 0.036349042540993005,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998957037842295,
      "loss": 4.6392,
      "step": 317
    },
    {
      "epoch": 0.03646370829033368,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998918768544282,
      "loss": 5.0234,
      "step": 318
    },
    {
      "epoch": 0.03657837403967435,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998879809809682,
      "loss": 5.201,
      "step": 319
    },
    {
      "epoch": 0.036693039789015024,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998840161643866,
      "loss": 4.9761,
      "step": 320
    },
    {
      "epoch": 0.036807705538355696,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998799824052298,
      "loss": 4.9012,
      "step": 321
    },
    {
      "epoch": 0.03692237128769636,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998758797040547,
      "loss": 5.0509,
      "step": 322
    },
    {
      "epoch": 0.037037037037037035,
      "grad_norm": 0.0,
      "learning_rate": 0.000999871708061427,
      "loss": 5.093,
      "step": 323
    },
    {
      "epoch": 0.03715170278637771,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998674674779222,
      "loss": 5.1062,
      "step": 324
    },
    {
      "epoch": 0.03726636853571838,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998631579541252,
      "loss": 5.2923,
      "step": 325
    },
    {
      "epoch": 0.03738103428505905,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998587794906304,
      "loss": 4.9099,
      "step": 326
    },
    {
      "epoch": 0.037495700034399726,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998543320880416,
      "loss": 5.228,
      "step": 327
    },
    {
      "epoch": 0.0376103657837404,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998498157469723,
      "loss": 4.8353,
      "step": 328
    },
    {
      "epoch": 0.03772503153308107,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998452304680453,
      "loss": 5.0557,
      "step": 329
    },
    {
      "epoch": 0.03783969728242174,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998405762518935,
      "loss": 4.9656,
      "step": 330
    },
    {
      "epoch": 0.03795436303176241,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998358530991585,
      "loss": 5.0455,
      "step": 331
    },
    {
      "epoch": 0.03806902878110308,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998310610104919,
      "loss": 4.9969,
      "step": 332
    },
    {
      "epoch": 0.038183694530443756,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998261999865545,
      "loss": 4.8588,
      "step": 333
    },
    {
      "epoch": 0.03829836027978443,
      "grad_norm": 0.0,
      "learning_rate": 0.000999821270028017,
      "loss": 5.0182,
      "step": 334
    },
    {
      "epoch": 0.0384130260291251,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998162711355595,
      "loss": 5.2916,
      "step": 335
    },
    {
      "epoch": 0.038527691778465774,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998112033098709,
      "loss": 4.9805,
      "step": 336
    },
    {
      "epoch": 0.03864235752780645,
      "grad_norm": 0.0,
      "learning_rate": 0.000999806066551651,
      "loss": 4.9568,
      "step": 337
    },
    {
      "epoch": 0.03875702327714712,
      "grad_norm": 0.0,
      "learning_rate": 0.0009998008608616076,
      "loss": 4.7811,
      "step": 338
    },
    {
      "epoch": 0.038871689026487785,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997955862404593,
      "loss": 5.0169,
      "step": 339
    },
    {
      "epoch": 0.03898635477582846,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997902426889334,
      "loss": 5.0581,
      "step": 340
    },
    {
      "epoch": 0.03910102052516913,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997848302077668,
      "loss": 5.3845,
      "step": 341
    },
    {
      "epoch": 0.0392156862745098,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997793487977063,
      "loss": 4.8789,
      "step": 342
    },
    {
      "epoch": 0.039330352023850476,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997737984595077,
      "loss": 5.0169,
      "step": 343
    },
    {
      "epoch": 0.03944501777319115,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997681791939369,
      "loss": 4.8645,
      "step": 344
    },
    {
      "epoch": 0.03955968352253182,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997624910017685,
      "loss": 4.9107,
      "step": 345
    },
    {
      "epoch": 0.039674349271872494,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997567338837876,
      "loss": 5.17,
      "step": 346
    },
    {
      "epoch": 0.03978901502121316,
      "grad_norm": 0.0,
      "learning_rate": 0.000999750907840788,
      "loss": 4.9811,
      "step": 347
    },
    {
      "epoch": 0.03990368077055383,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997450128735733,
      "loss": 4.9996,
      "step": 348
    },
    {
      "epoch": 0.040018346519894506,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997390489829565,
      "loss": 4.931,
      "step": 349
    },
    {
      "epoch": 0.04013301226923518,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997330161697605,
      "loss": 4.9569,
      "step": 350
    },
    {
      "epoch": 0.04024767801857585,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997269144348172,
      "loss": 5.1741,
      "step": 351
    },
    {
      "epoch": 0.040362343767916524,
      "grad_norm": 0.0,
      "learning_rate": 0.000999720743778968,
      "loss": 4.93,
      "step": 352
    },
    {
      "epoch": 0.0404770095172572,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997145042030648,
      "loss": 4.9301,
      "step": 353
    },
    {
      "epoch": 0.04059167526659787,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997081957079674,
      "loss": 5.1785,
      "step": 354
    },
    {
      "epoch": 0.04070634101593854,
      "grad_norm": 0.0,
      "learning_rate": 0.0009997018182945462,
      "loss": 4.8035,
      "step": 355
    },
    {
      "epoch": 0.04082100676527921,
      "grad_norm": 0.0,
      "learning_rate": 0.000999695371963681,
      "loss": 4.8432,
      "step": 356
    },
    {
      "epoch": 0.04093567251461988,
      "grad_norm": 0.0,
      "learning_rate": 0.000999688856716261,
      "loss": 5.0907,
      "step": 357
    },
    {
      "epoch": 0.041050338263960554,
      "grad_norm": 0.0,
      "learning_rate": 0.0009996822725531844,
      "loss": 5.0332,
      "step": 358
    },
    {
      "epoch": 0.041165004013301226,
      "grad_norm": 0.0,
      "learning_rate": 0.0009996756194753601,
      "loss": 4.7146,
      "step": 359
    },
    {
      "epoch": 0.0412796697626419,
      "grad_norm": 0.0,
      "learning_rate": 0.000999668897483705,
      "loss": 4.8769,
      "step": 360
    },
    {
      "epoch": 0.04139433551198257,
      "grad_norm": 0.0,
      "learning_rate": 0.0009996621065791467,
      "loss": 5.2396,
      "step": 361
    },
    {
      "epoch": 0.041509001261323245,
      "grad_norm": 0.0,
      "learning_rate": 0.0009996552467626215,
      "loss": 5.3171,
      "step": 362
    },
    {
      "epoch": 0.04162366701066392,
      "grad_norm": 0.0,
      "learning_rate": 0.000999648318035076,
      "loss": 4.8872,
      "step": 363
    },
    {
      "epoch": 0.04173833276000459,
      "grad_norm": 0.0,
      "learning_rate": 0.0009996413203974658,
      "loss": 4.9914,
      "step": 364
    },
    {
      "epoch": 0.041852998509345256,
      "grad_norm": 0.0,
      "learning_rate": 0.000999634253850756,
      "loss": 4.8779,
      "step": 365
    },
    {
      "epoch": 0.04196766425868593,
      "grad_norm": 0.0,
      "learning_rate": 0.0009996271183959214,
      "loss": 4.9792,
      "step": 366
    },
    {
      "epoch": 0.0420823300080266,
      "grad_norm": 0.0,
      "learning_rate": 0.0009996199140339462,
      "loss": 4.7432,
      "step": 367
    },
    {
      "epoch": 0.042196995757367274,
      "grad_norm": 0.0,
      "learning_rate": 0.0009996126407658236,
      "loss": 4.8667,
      "step": 368
    },
    {
      "epoch": 0.04231166150670795,
      "grad_norm": 0.0,
      "learning_rate": 0.0009996052985925576,
      "loss": 4.8934,
      "step": 369
    },
    {
      "epoch": 0.04242632725604862,
      "grad_norm": 0.0,
      "learning_rate": 0.0009995978875151606,
      "loss": 5.0105,
      "step": 370
    },
    {
      "epoch": 0.04254099300538929,
      "grad_norm": 0.0,
      "learning_rate": 0.0009995904075346545,
      "loss": 5.0515,
      "step": 371
    },
    {
      "epoch": 0.042655658754729965,
      "grad_norm": 0.0,
      "learning_rate": 0.0009995828586520715,
      "loss": 4.9262,
      "step": 372
    },
    {
      "epoch": 0.04277032450407063,
      "grad_norm": 0.0,
      "learning_rate": 0.0009995752408684525,
      "loss": 5.0524,
      "step": 373
    },
    {
      "epoch": 0.042884990253411304,
      "grad_norm": 0.0,
      "learning_rate": 0.0009995675541848484,
      "loss": 5.144,
      "step": 374
    },
    {
      "epoch": 0.042999656002751976,
      "grad_norm": 0.0,
      "learning_rate": 0.0009995597986023194,
      "loss": 5.1372,
      "step": 375
    },
    {
      "epoch": 0.04311432175209265,
      "grad_norm": 0.0,
      "learning_rate": 0.000999551974121935,
      "loss": 4.9137,
      "step": 376
    },
    {
      "epoch": 0.04322898750143332,
      "grad_norm": 0.0,
      "learning_rate": 0.0009995440807447748,
      "loss": 5.3438,
      "step": 377
    },
    {
      "epoch": 0.043343653250773995,
      "grad_norm": 0.0,
      "learning_rate": 0.0009995361184719275,
      "loss": 4.8435,
      "step": 378
    },
    {
      "epoch": 0.04345831900011467,
      "grad_norm": 0.0,
      "learning_rate": 0.000999528087304491,
      "loss": 5.0856,
      "step": 379
    },
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 0.0,
      "learning_rate": 0.0009995199872435735,
      "loss": 5.0966,
      "step": 380
    },
    {
      "epoch": 0.04368765049879601,
      "grad_norm": 0.0,
      "learning_rate": 0.0009995118182902919,
      "loss": 4.7137,
      "step": 381
    },
    {
      "epoch": 0.04380231624813668,
      "grad_norm": 0.0,
      "learning_rate": 0.0009995035804457732,
      "loss": 5.0948,
      "step": 382
    },
    {
      "epoch": 0.04391698199747735,
      "grad_norm": 0.0,
      "learning_rate": 0.0009994952737111533,
      "loss": 5.1228,
      "step": 383
    },
    {
      "epoch": 0.044031647746818024,
      "grad_norm": 0.0,
      "learning_rate": 0.0009994868980875782,
      "loss": 5.1485,
      "step": 384
    },
    {
      "epoch": 0.0441463134961587,
      "grad_norm": 0.0,
      "learning_rate": 0.0009994784535762033,
      "loss": 4.9573,
      "step": 385
    },
    {
      "epoch": 0.04426097924549937,
      "grad_norm": 0.0,
      "learning_rate": 0.0009994699401781933,
      "loss": 5.0062,
      "step": 386
    },
    {
      "epoch": 0.04437564499484004,
      "grad_norm": 0.0,
      "learning_rate": 0.000999461357894722,
      "loss": 5.0522,
      "step": 387
    },
    {
      "epoch": 0.044490310744180715,
      "grad_norm": 0.0,
      "learning_rate": 0.0009994527067269739,
      "loss": 4.8437,
      "step": 388
    },
    {
      "epoch": 0.04460497649352139,
      "grad_norm": 0.0,
      "learning_rate": 0.0009994439866761416,
      "loss": 5.1237,
      "step": 389
    },
    {
      "epoch": 0.044719642242862054,
      "grad_norm": 0.0,
      "learning_rate": 0.0009994351977434283,
      "loss": 4.9902,
      "step": 390
    },
    {
      "epoch": 0.04483430799220273,
      "grad_norm": 0.0,
      "learning_rate": 0.000999426339930046,
      "loss": 4.9443,
      "step": 391
    },
    {
      "epoch": 0.0449489737415434,
      "grad_norm": 0.0,
      "learning_rate": 0.0009994174132372169,
      "loss": 4.9705,
      "step": 392
    },
    {
      "epoch": 0.04506363949088407,
      "grad_norm": 0.0,
      "learning_rate": 0.0009994084176661716,
      "loss": 5.2192,
      "step": 393
    },
    {
      "epoch": 0.045178305240224745,
      "grad_norm": 0.0,
      "learning_rate": 0.0009993993532181513,
      "loss": 4.9746,
      "step": 394
    },
    {
      "epoch": 0.04529297098956542,
      "grad_norm": 0.0,
      "learning_rate": 0.0009993902198944065,
      "loss": 5.0294,
      "step": 395
    },
    {
      "epoch": 0.04540763673890609,
      "grad_norm": 0.0,
      "learning_rate": 0.0009993810176961962,
      "loss": 4.9294,
      "step": 396
    },
    {
      "epoch": 0.04552230248824676,
      "grad_norm": 0.0,
      "learning_rate": 0.0009993717466247904,
      "loss": 4.9908,
      "step": 397
    },
    {
      "epoch": 0.045636968237587436,
      "grad_norm": 0.0,
      "learning_rate": 0.0009993624066814673,
      "loss": 5.2447,
      "step": 398
    },
    {
      "epoch": 0.0457516339869281,
      "grad_norm": 0.0,
      "learning_rate": 0.0009993529978675158,
      "loss": 5.0453,
      "step": 399
    },
    {
      "epoch": 0.045866299736268774,
      "grad_norm": 0.0,
      "learning_rate": 0.0009993435201842333,
      "loss": 5.1097,
      "step": 400
    },
    {
      "epoch": 0.04598096548560945,
      "grad_norm": 0.0,
      "learning_rate": 0.000999333973632927,
      "loss": 4.8229,
      "step": 401
    },
    {
      "epoch": 0.04609563123495012,
      "grad_norm": 0.0,
      "learning_rate": 0.0009993243582149137,
      "loss": 4.6021,
      "step": 402
    },
    {
      "epoch": 0.04621029698429079,
      "grad_norm": 0.0,
      "learning_rate": 0.0009993146739315196,
      "loss": 5.2175,
      "step": 403
    },
    {
      "epoch": 0.046324962733631465,
      "grad_norm": 0.0,
      "learning_rate": 0.0009993049207840808,
      "loss": 5.1851,
      "step": 404
    },
    {
      "epoch": 0.04643962848297214,
      "grad_norm": 0.0,
      "learning_rate": 0.0009992950987739422,
      "loss": 4.9329,
      "step": 405
    },
    {
      "epoch": 0.04655429423231281,
      "grad_norm": 0.0,
      "learning_rate": 0.0009992852079024589,
      "loss": 4.7795,
      "step": 406
    },
    {
      "epoch": 0.04666895998165348,
      "grad_norm": 0.0,
      "learning_rate": 0.0009992752481709948,
      "loss": 5.2259,
      "step": 407
    },
    {
      "epoch": 0.04678362573099415,
      "grad_norm": 0.0,
      "learning_rate": 0.0009992652195809238,
      "loss": 4.8455,
      "step": 408
    },
    {
      "epoch": 0.04689829148033482,
      "grad_norm": 0.0,
      "learning_rate": 0.0009992551221336293,
      "loss": 4.9269,
      "step": 409
    },
    {
      "epoch": 0.047012957229675495,
      "grad_norm": 0.0,
      "learning_rate": 0.0009992449558305038,
      "loss": 4.9666,
      "step": 410
    },
    {
      "epoch": 0.04712762297901617,
      "grad_norm": 0.0,
      "learning_rate": 0.0009992347206729498,
      "loss": 4.8327,
      "step": 411
    },
    {
      "epoch": 0.04724228872835684,
      "grad_norm": 0.0,
      "learning_rate": 0.0009992244166623788,
      "loss": 4.9061,
      "step": 412
    },
    {
      "epoch": 0.04735695447769751,
      "grad_norm": 0.0,
      "learning_rate": 0.0009992140438002122,
      "loss": 5.3949,
      "step": 413
    },
    {
      "epoch": 0.047471620227038186,
      "grad_norm": 0.0,
      "learning_rate": 0.0009992036020878806,
      "loss": 5.0413,
      "step": 414
    },
    {
      "epoch": 0.04758628597637886,
      "grad_norm": 0.0,
      "learning_rate": 0.0009991930915268245,
      "loss": 5.1022,
      "step": 415
    },
    {
      "epoch": 0.047700951725719525,
      "grad_norm": 0.0,
      "learning_rate": 0.0009991825121184932,
      "loss": 5.1536,
      "step": 416
    },
    {
      "epoch": 0.0478156174750602,
      "grad_norm": 0.0,
      "learning_rate": 0.0009991718638643462,
      "loss": 4.7412,
      "step": 417
    },
    {
      "epoch": 0.04793028322440087,
      "grad_norm": 0.0,
      "learning_rate": 0.0009991611467658524,
      "loss": 4.9672,
      "step": 418
    },
    {
      "epoch": 0.04804494897374154,
      "grad_norm": 0.0,
      "learning_rate": 0.00099915036082449,
      "loss": 5.1122,
      "step": 419
    },
    {
      "epoch": 0.048159614723082216,
      "grad_norm": 0.0,
      "learning_rate": 0.000999139506041746,
      "loss": 5.009,
      "step": 420
    },
    {
      "epoch": 0.04827428047242289,
      "grad_norm": 0.0,
      "learning_rate": 0.0009991285824191187,
      "loss": 5.1714,
      "step": 421
    },
    {
      "epoch": 0.04838894622176356,
      "grad_norm": 0.0,
      "learning_rate": 0.000999117589958114,
      "loss": 5.0387,
      "step": 422
    },
    {
      "epoch": 0.048503611971104234,
      "grad_norm": 0.0,
      "learning_rate": 0.0009991065286602482,
      "loss": 4.9773,
      "step": 423
    },
    {
      "epoch": 0.04861827772044491,
      "grad_norm": 0.0,
      "learning_rate": 0.0009990953985270475,
      "loss": 4.841,
      "step": 424
    },
    {
      "epoch": 0.04873294346978557,
      "grad_norm": 0.0,
      "learning_rate": 0.0009990841995600466,
      "loss": 5.2873,
      "step": 425
    },
    {
      "epoch": 0.048847609219126245,
      "grad_norm": 0.0,
      "learning_rate": 0.0009990729317607902,
      "loss": 5.0263,
      "step": 426
    },
    {
      "epoch": 0.04896227496846692,
      "grad_norm": 0.0,
      "learning_rate": 0.0009990615951308325,
      "loss": 4.96,
      "step": 427
    },
    {
      "epoch": 0.04907694071780759,
      "grad_norm": 0.0,
      "learning_rate": 0.0009990501896717378,
      "loss": 5.1366,
      "step": 428
    },
    {
      "epoch": 0.04919160646714826,
      "grad_norm": 0.0,
      "learning_rate": 0.0009990387153850783,
      "loss": 4.8766,
      "step": 429
    },
    {
      "epoch": 0.049306272216488936,
      "grad_norm": 0.0,
      "learning_rate": 0.0009990271722724374,
      "loss": 5.0366,
      "step": 430
    },
    {
      "epoch": 0.04942093796582961,
      "grad_norm": 0.0,
      "learning_rate": 0.0009990155603354066,
      "loss": 5.1203,
      "step": 431
    },
    {
      "epoch": 0.04953560371517028,
      "grad_norm": 0.0,
      "learning_rate": 0.000999003879575588,
      "loss": 4.8651,
      "step": 432
    },
    {
      "epoch": 0.04965026946451095,
      "grad_norm": 0.0,
      "learning_rate": 0.0009989921299945928,
      "loss": 4.9534,
      "step": 433
    },
    {
      "epoch": 0.04976493521385162,
      "grad_norm": 0.0,
      "learning_rate": 0.0009989803115940414,
      "loss": 4.9373,
      "step": 434
    },
    {
      "epoch": 0.04987960096319229,
      "grad_norm": 0.0,
      "learning_rate": 0.000998968424375564,
      "loss": 4.8318,
      "step": 435
    },
    {
      "epoch": 0.049994266712532966,
      "grad_norm": 0.0,
      "learning_rate": 0.0009989564683408002,
      "loss": 4.8566,
      "step": 436
    },
    {
      "epoch": 0.05010893246187364,
      "grad_norm": 0.0,
      "learning_rate": 0.000998944443491399,
      "loss": 5.0398,
      "step": 437
    },
    {
      "epoch": 0.05022359821121431,
      "grad_norm": 0.0,
      "learning_rate": 0.0009989323498290192,
      "loss": 4.7555,
      "step": 438
    },
    {
      "epoch": 0.050338263960554984,
      "grad_norm": 0.0,
      "learning_rate": 0.0009989201873553289,
      "loss": 5.0819,
      "step": 439
    },
    {
      "epoch": 0.05045292970989566,
      "grad_norm": 0.0,
      "learning_rate": 0.0009989079560720055,
      "loss": 5.1608,
      "step": 440
    },
    {
      "epoch": 0.05056759545923633,
      "grad_norm": 0.0,
      "learning_rate": 0.0009988956559807362,
      "loss": 4.7162,
      "step": 441
    },
    {
      "epoch": 0.050682261208576995,
      "grad_norm": 0.0,
      "learning_rate": 0.0009988832870832175,
      "loss": 4.7762,
      "step": 442
    },
    {
      "epoch": 0.05079692695791767,
      "grad_norm": 0.0,
      "learning_rate": 0.0009988708493811555,
      "loss": 5.0866,
      "step": 443
    },
    {
      "epoch": 0.05091159270725834,
      "grad_norm": 0.0,
      "learning_rate": 0.0009988583428762656,
      "loss": 5.4124,
      "step": 444
    },
    {
      "epoch": 0.051026258456599013,
      "grad_norm": 0.0,
      "learning_rate": 0.0009988457675702731,
      "loss": 5.135,
      "step": 445
    },
    {
      "epoch": 0.051140924205939686,
      "grad_norm": 0.0,
      "learning_rate": 0.0009988331234649123,
      "loss": 5.1528,
      "step": 446
    },
    {
      "epoch": 0.05125558995528036,
      "grad_norm": 0.0,
      "learning_rate": 0.0009988204105619272,
      "loss": 5.1833,
      "step": 447
    },
    {
      "epoch": 0.05137025570462103,
      "grad_norm": 0.0,
      "learning_rate": 0.0009988076288630716,
      "loss": 4.7815,
      "step": 448
    },
    {
      "epoch": 0.051484921453961704,
      "grad_norm": 0.0,
      "learning_rate": 0.000998794778370108,
      "loss": 5.0444,
      "step": 449
    },
    {
      "epoch": 0.05159958720330237,
      "grad_norm": 0.0,
      "learning_rate": 0.0009987818590848096,
      "loss": 5.1518,
      "step": 450
    },
    {
      "epoch": 0.05171425295264304,
      "grad_norm": 0.0,
      "learning_rate": 0.0009987688710089576,
      "loss": 4.9471,
      "step": 451
    },
    {
      "epoch": 0.051828918701983716,
      "grad_norm": 0.0,
      "learning_rate": 0.000998755814144344,
      "loss": 5.1403,
      "step": 452
    },
    {
      "epoch": 0.05194358445132439,
      "grad_norm": 0.0,
      "learning_rate": 0.0009987426884927693,
      "loss": 4.7741,
      "step": 453
    },
    {
      "epoch": 0.05205825020066506,
      "grad_norm": 0.0,
      "learning_rate": 0.0009987294940560442,
      "loss": 4.9515,
      "step": 454
    },
    {
      "epoch": 0.052172915950005734,
      "grad_norm": 0.0,
      "learning_rate": 0.0009987162308359885,
      "loss": 4.8656,
      "step": 455
    },
    {
      "epoch": 0.05228758169934641,
      "grad_norm": 0.0,
      "learning_rate": 0.000998702898834432,
      "loss": 4.9706,
      "step": 456
    },
    {
      "epoch": 0.05240224744868708,
      "grad_norm": 0.0,
      "learning_rate": 0.0009986894980532131,
      "loss": 5.2065,
      "step": 457
    },
    {
      "epoch": 0.05251691319802775,
      "grad_norm": 0.0,
      "learning_rate": 0.0009986760284941805,
      "loss": 4.9023,
      "step": 458
    },
    {
      "epoch": 0.05263157894736842,
      "grad_norm": 0.0,
      "learning_rate": 0.0009986624901591919,
      "loss": 4.8901,
      "step": 459
    },
    {
      "epoch": 0.05274624469670909,
      "grad_norm": 0.0,
      "learning_rate": 0.0009986488830501146,
      "loss": 4.7581,
      "step": 460
    },
    {
      "epoch": 0.052860910446049764,
      "grad_norm": 0.0,
      "learning_rate": 0.0009986352071688258,
      "loss": 4.9972,
      "step": 461
    },
    {
      "epoch": 0.052975576195390436,
      "grad_norm": 0.0,
      "learning_rate": 0.0009986214625172113,
      "loss": 4.7948,
      "step": 462
    },
    {
      "epoch": 0.05309024194473111,
      "grad_norm": 0.0,
      "learning_rate": 0.0009986076490971674,
      "loss": 5.0291,
      "step": 463
    },
    {
      "epoch": 0.05320490769407178,
      "grad_norm": 0.0,
      "learning_rate": 0.000998593766910599,
      "loss": 5.2901,
      "step": 464
    },
    {
      "epoch": 0.053319573443412455,
      "grad_norm": 0.0,
      "learning_rate": 0.0009985798159594212,
      "loss": 5.0602,
      "step": 465
    },
    {
      "epoch": 0.05343423919275313,
      "grad_norm": 0.0,
      "learning_rate": 0.0009985657962455579,
      "loss": 4.9439,
      "step": 466
    },
    {
      "epoch": 0.05354890494209379,
      "grad_norm": 0.0,
      "learning_rate": 0.0009985517077709433,
      "loss": 4.9782,
      "step": 467
    },
    {
      "epoch": 0.053663570691434466,
      "grad_norm": 0.0,
      "learning_rate": 0.0009985375505375202,
      "loss": 5.2437,
      "step": 468
    },
    {
      "epoch": 0.05377823644077514,
      "grad_norm": 0.0,
      "learning_rate": 0.0009985233245472418,
      "loss": 5.1024,
      "step": 469
    },
    {
      "epoch": 0.05389290219011581,
      "grad_norm": 0.0,
      "learning_rate": 0.00099850902980207,
      "loss": 4.9276,
      "step": 470
    },
    {
      "epoch": 0.054007567939456484,
      "grad_norm": 0.0,
      "learning_rate": 0.0009984946663039763,
      "loss": 4.9451,
      "step": 471
    },
    {
      "epoch": 0.05412223368879716,
      "grad_norm": 0.0,
      "learning_rate": 0.0009984802340549425,
      "loss": 5.1181,
      "step": 472
    },
    {
      "epoch": 0.05423689943813783,
      "grad_norm": 0.0,
      "learning_rate": 0.0009984657330569585,
      "loss": 5.2897,
      "step": 473
    },
    {
      "epoch": 0.0543515651874785,
      "grad_norm": 0.0,
      "learning_rate": 0.000998451163312025,
      "loss": 4.876,
      "step": 474
    },
    {
      "epoch": 0.054466230936819175,
      "grad_norm": 0.0,
      "learning_rate": 0.0009984365248221513,
      "loss": 5.2973,
      "step": 475
    },
    {
      "epoch": 0.05458089668615984,
      "grad_norm": 0.0,
      "learning_rate": 0.0009984218175893567,
      "loss": 4.6672,
      "step": 476
    },
    {
      "epoch": 0.054695562435500514,
      "grad_norm": 0.0,
      "learning_rate": 0.0009984070416156694,
      "loss": 5.1324,
      "step": 477
    },
    {
      "epoch": 0.054810228184841187,
      "grad_norm": 0.0,
      "learning_rate": 0.0009983921969031282,
      "loss": 4.8486,
      "step": 478
    },
    {
      "epoch": 0.05492489393418186,
      "grad_norm": 0.0,
      "learning_rate": 0.00099837728345378,
      "loss": 5.0748,
      "step": 479
    },
    {
      "epoch": 0.05503955968352253,
      "grad_norm": 0.0,
      "learning_rate": 0.000998362301269682,
      "loss": 4.9694,
      "step": 480
    },
    {
      "epoch": 0.055154225432863205,
      "grad_norm": 0.0,
      "learning_rate": 0.0009983472503529006,
      "loss": 4.8686,
      "step": 481
    },
    {
      "epoch": 0.05526889118220388,
      "grad_norm": 0.0,
      "learning_rate": 0.0009983321307055122,
      "loss": 5.2214,
      "step": 482
    },
    {
      "epoch": 0.05538355693154455,
      "grad_norm": 0.0,
      "learning_rate": 0.000998316942329602,
      "loss": 5.1425,
      "step": 483
    },
    {
      "epoch": 0.05549822268088522,
      "grad_norm": 0.0,
      "learning_rate": 0.0009983016852272647,
      "loss": 5.0617,
      "step": 484
    },
    {
      "epoch": 0.05561288843022589,
      "grad_norm": 0.0,
      "learning_rate": 0.0009982863594006051,
      "loss": 5.1879,
      "step": 485
    },
    {
      "epoch": 0.05572755417956656,
      "grad_norm": 0.0,
      "learning_rate": 0.000998270964851737,
      "loss": 5.0502,
      "step": 486
    },
    {
      "epoch": 0.055842219928907234,
      "grad_norm": 0.0,
      "learning_rate": 0.0009982555015827837,
      "loss": 4.9755,
      "step": 487
    },
    {
      "epoch": 0.05595688567824791,
      "grad_norm": 0.0,
      "learning_rate": 0.0009982399695958781,
      "loss": 5.0904,
      "step": 488
    },
    {
      "epoch": 0.05607155142758858,
      "grad_norm": 0.0,
      "learning_rate": 0.0009982243688931626,
      "loss": 5.0575,
      "step": 489
    },
    {
      "epoch": 0.05618621717692925,
      "grad_norm": 0.0,
      "learning_rate": 0.000998208699476789,
      "loss": 4.7352,
      "step": 490
    },
    {
      "epoch": 0.056300882926269925,
      "grad_norm": 0.0,
      "learning_rate": 0.0009981929613489186,
      "loss": 5.2035,
      "step": 491
    },
    {
      "epoch": 0.0564155486756106,
      "grad_norm": 0.0,
      "learning_rate": 0.000998177154511722,
      "loss": 4.9832,
      "step": 492
    },
    {
      "epoch": 0.056530214424951264,
      "grad_norm": 0.0,
      "learning_rate": 0.0009981612789673796,
      "loss": 4.9605,
      "step": 493
    },
    {
      "epoch": 0.05664488017429194,
      "grad_norm": 0.0,
      "learning_rate": 0.0009981453347180814,
      "loss": 4.9973,
      "step": 494
    },
    {
      "epoch": 0.05675954592363261,
      "grad_norm": 0.0,
      "learning_rate": 0.000998129321766026,
      "loss": 5.2481,
      "step": 495
    },
    {
      "epoch": 0.05687421167297328,
      "grad_norm": 0.0,
      "learning_rate": 0.0009981132401134228,
      "loss": 4.914,
      "step": 496
    },
    {
      "epoch": 0.056988877422313955,
      "grad_norm": 0.0,
      "learning_rate": 0.0009980970897624892,
      "loss": 4.8996,
      "step": 497
    },
    {
      "epoch": 0.05710354317165463,
      "grad_norm": 0.0,
      "learning_rate": 0.0009980808707154532,
      "loss": 5.1229,
      "step": 498
    },
    {
      "epoch": 0.0572182089209953,
      "grad_norm": 0.0,
      "learning_rate": 0.0009980645829745522,
      "loss": 4.8842,
      "step": 499
    },
    {
      "epoch": 0.05733287467033597,
      "grad_norm": 0.0,
      "learning_rate": 0.0009980482265420324,
      "loss": 4.9344,
      "step": 500
    },
    {
      "epoch": 0.057447540419676646,
      "grad_norm": 0.0,
      "learning_rate": 0.00099803180142015,
      "loss": 5.022,
      "step": 501
    },
    {
      "epoch": 0.05756220616901731,
      "grad_norm": 0.0,
      "learning_rate": 0.0009980153076111704,
      "loss": 5.0786,
      "step": 502
    },
    {
      "epoch": 0.057676871918357984,
      "grad_norm": 0.0,
      "learning_rate": 0.0009979987451173688,
      "loss": 4.6304,
      "step": 503
    },
    {
      "epoch": 0.05779153766769866,
      "grad_norm": 0.0,
      "learning_rate": 0.0009979821139410295,
      "loss": 4.9237,
      "step": 504
    },
    {
      "epoch": 0.05790620341703933,
      "grad_norm": 0.0,
      "learning_rate": 0.0009979654140844466,
      "loss": 5.1312,
      "step": 505
    },
    {
      "epoch": 0.05802086916638,
      "grad_norm": 0.0,
      "learning_rate": 0.0009979486455499232,
      "loss": 5.0354,
      "step": 506
    },
    {
      "epoch": 0.058135534915720675,
      "grad_norm": 0.0,
      "learning_rate": 0.0009979318083397728,
      "loss": 4.7704,
      "step": 507
    },
    {
      "epoch": 0.05825020066506135,
      "grad_norm": 0.0,
      "learning_rate": 0.0009979149024563173,
      "loss": 5.0807,
      "step": 508
    },
    {
      "epoch": 0.05836486641440202,
      "grad_norm": 0.0,
      "learning_rate": 0.0009978979279018885,
      "loss": 4.7813,
      "step": 509
    },
    {
      "epoch": 0.05847953216374269,
      "grad_norm": 0.0,
      "learning_rate": 0.000997880884678828,
      "loss": 5.0807,
      "step": 510
    },
    {
      "epoch": 0.05859419791308336,
      "grad_norm": 0.0,
      "learning_rate": 0.0009978637727894866,
      "loss": 4.9692,
      "step": 511
    },
    {
      "epoch": 0.05870886366242403,
      "grad_norm": 0.0,
      "learning_rate": 0.0009978465922362244,
      "loss": 5.1188,
      "step": 512
    },
    {
      "epoch": 0.058823529411764705,
      "grad_norm": 0.0,
      "learning_rate": 0.000997829343021411,
      "loss": 5.053,
      "step": 513
    },
    {
      "epoch": 0.05893819516110538,
      "grad_norm": 0.0,
      "learning_rate": 0.000997812025147426,
      "loss": 5.1651,
      "step": 514
    },
    {
      "epoch": 0.05905286091044605,
      "grad_norm": 0.0,
      "learning_rate": 0.0009977946386166578,
      "loss": 4.9549,
      "step": 515
    },
    {
      "epoch": 0.05916752665978672,
      "grad_norm": 0.0,
      "learning_rate": 0.0009977771834315044,
      "loss": 5.1278,
      "step": 516
    },
    {
      "epoch": 0.059282192409127396,
      "grad_norm": 0.0,
      "learning_rate": 0.0009977596595943737,
      "loss": 4.6528,
      "step": 517
    },
    {
      "epoch": 0.05939685815846807,
      "grad_norm": 0.0,
      "learning_rate": 0.0009977420671076827,
      "loss": 4.9328,
      "step": 518
    },
    {
      "epoch": 0.059511523907808735,
      "grad_norm": 0.0,
      "learning_rate": 0.0009977244059738578,
      "loss": 4.9961,
      "step": 519
    },
    {
      "epoch": 0.05962618965714941,
      "grad_norm": 0.0,
      "learning_rate": 0.0009977066761953353,
      "loss": 5.0752,
      "step": 520
    },
    {
      "epoch": 0.05974085540649008,
      "grad_norm": 0.0,
      "learning_rate": 0.0009976888777745605,
      "loss": 5.3336,
      "step": 521
    },
    {
      "epoch": 0.05985552115583075,
      "grad_norm": 0.0,
      "learning_rate": 0.0009976710107139884,
      "loss": 5.0713,
      "step": 522
    },
    {
      "epoch": 0.059970186905171426,
      "grad_norm": 0.0,
      "learning_rate": 0.0009976530750160832,
      "loss": 4.7287,
      "step": 523
    },
    {
      "epoch": 0.0600848526545121,
      "grad_norm": 0.0,
      "learning_rate": 0.000997635070683319,
      "loss": 5.0656,
      "step": 524
    },
    {
      "epoch": 0.06019951840385277,
      "grad_norm": 0.0,
      "learning_rate": 0.0009976169977181793,
      "loss": 4.9489,
      "step": 525
    },
    {
      "epoch": 0.060314184153193444,
      "grad_norm": 0.0,
      "learning_rate": 0.0009975988561231567,
      "loss": 5.1255,
      "step": 526
    },
    {
      "epoch": 0.06042884990253411,
      "grad_norm": 0.0,
      "learning_rate": 0.0009975806459007535,
      "loss": 5.0374,
      "step": 527
    },
    {
      "epoch": 0.06054351565187478,
      "grad_norm": 0.0,
      "learning_rate": 0.0009975623670534814,
      "loss": 5.0298,
      "step": 528
    },
    {
      "epoch": 0.060658181401215455,
      "grad_norm": 0.0,
      "learning_rate": 0.000997544019583862,
      "loss": 5.0963,
      "step": 529
    },
    {
      "epoch": 0.06077284715055613,
      "grad_norm": 0.0,
      "learning_rate": 0.0009975256034944254,
      "loss": 4.8682,
      "step": 530
    },
    {
      "epoch": 0.0608875128998968,
      "grad_norm": 0.0,
      "learning_rate": 0.0009975071187877122,
      "loss": 4.7886,
      "step": 531
    },
    {
      "epoch": 0.06100217864923747,
      "grad_norm": 0.0,
      "learning_rate": 0.0009974885654662718,
      "loss": 5.0564,
      "step": 532
    },
    {
      "epoch": 0.061116844398578146,
      "grad_norm": 0.0,
      "learning_rate": 0.0009974699435326634,
      "loss": 4.8967,
      "step": 533
    },
    {
      "epoch": 0.06123151014791882,
      "grad_norm": 0.0,
      "learning_rate": 0.0009974512529894554,
      "loss": 5.1203,
      "step": 534
    },
    {
      "epoch": 0.06134617589725949,
      "grad_norm": 0.0,
      "learning_rate": 0.000997432493839226,
      "loss": 5.0916,
      "step": 535
    },
    {
      "epoch": 0.06146084164660016,
      "grad_norm": 0.0,
      "learning_rate": 0.0009974136660845625,
      "loss": 5.0376,
      "step": 536
    },
    {
      "epoch": 0.06157550739594083,
      "grad_norm": 0.0,
      "learning_rate": 0.0009973947697280616,
      "loss": 4.8789,
      "step": 537
    },
    {
      "epoch": 0.0616901731452815,
      "grad_norm": 0.0,
      "learning_rate": 0.0009973758047723302,
      "loss": 4.9944,
      "step": 538
    },
    {
      "epoch": 0.061804838894622176,
      "grad_norm": 0.0,
      "learning_rate": 0.000997356771219984,
      "loss": 5.1856,
      "step": 539
    },
    {
      "epoch": 0.06191950464396285,
      "grad_norm": 0.0,
      "learning_rate": 0.000997337669073648,
      "loss": 5.0598,
      "step": 540
    },
    {
      "epoch": 0.06203417039330352,
      "grad_norm": 0.0,
      "learning_rate": 0.0009973184983359576,
      "loss": 5.1027,
      "step": 541
    },
    {
      "epoch": 0.062148836142644194,
      "grad_norm": 0.0,
      "learning_rate": 0.0009972992590095565,
      "loss": 4.9551,
      "step": 542
    },
    {
      "epoch": 0.06226350189198487,
      "grad_norm": 0.0,
      "learning_rate": 0.0009972799510970984,
      "loss": 5.1619,
      "step": 543
    },
    {
      "epoch": 0.06237816764132553,
      "grad_norm": 0.0,
      "learning_rate": 0.0009972605746012468,
      "loss": 4.9114,
      "step": 544
    },
    {
      "epoch": 0.062492833390666205,
      "grad_norm": 0.0,
      "learning_rate": 0.000997241129524674,
      "loss": 4.9524,
      "step": 545
    },
    {
      "epoch": 0.06260749914000688,
      "grad_norm": 0.0,
      "learning_rate": 0.0009972216158700622,
      "loss": 4.6613,
      "step": 546
    },
    {
      "epoch": 0.06272216488934755,
      "grad_norm": 0.0,
      "learning_rate": 0.000997202033640103,
      "loss": 5.1735,
      "step": 547
    },
    {
      "epoch": 0.06283683063868822,
      "grad_norm": 0.0,
      "learning_rate": 0.0009971823828374973,
      "loss": 5.0319,
      "step": 548
    },
    {
      "epoch": 0.0629514963880289,
      "grad_norm": 0.0,
      "learning_rate": 0.0009971626634649557,
      "loss": 4.9844,
      "step": 549
    },
    {
      "epoch": 0.06306616213736957,
      "grad_norm": 0.0,
      "learning_rate": 0.000997142875525198,
      "loss": 4.9059,
      "step": 550
    },
    {
      "epoch": 0.06318082788671024,
      "grad_norm": 0.0,
      "learning_rate": 0.0009971230190209534,
      "loss": 5.209,
      "step": 551
    },
    {
      "epoch": 0.06329549363605091,
      "grad_norm": 0.0,
      "learning_rate": 0.0009971030939549608,
      "loss": 5.0795,
      "step": 552
    },
    {
      "epoch": 0.06341015938539159,
      "grad_norm": 0.0,
      "learning_rate": 0.0009970831003299691,
      "loss": 5.1064,
      "step": 553
    },
    {
      "epoch": 0.06352482513473226,
      "grad_norm": 0.0,
      "learning_rate": 0.0009970630381487351,
      "loss": 5.0472,
      "step": 554
    },
    {
      "epoch": 0.06363949088407293,
      "grad_norm": 0.0,
      "learning_rate": 0.0009970429074140266,
      "loss": 5.0598,
      "step": 555
    },
    {
      "epoch": 0.0637541566334136,
      "grad_norm": 0.0,
      "learning_rate": 0.0009970227081286197,
      "loss": 5.2181,
      "step": 556
    },
    {
      "epoch": 0.06386882238275426,
      "grad_norm": 0.0,
      "learning_rate": 0.0009970024402953014,
      "loss": 5.0097,
      "step": 557
    },
    {
      "epoch": 0.06398348813209494,
      "grad_norm": 0.0,
      "learning_rate": 0.0009969821039168664,
      "loss": 5.1544,
      "step": 558
    },
    {
      "epoch": 0.06409815388143561,
      "grad_norm": 0.0,
      "learning_rate": 0.0009969616989961203,
      "loss": 4.9826,
      "step": 559
    },
    {
      "epoch": 0.06421281963077628,
      "grad_norm": 0.0,
      "learning_rate": 0.000996941225535877,
      "loss": 5.0401,
      "step": 560
    },
    {
      "epoch": 0.06432748538011696,
      "grad_norm": 0.0,
      "learning_rate": 0.000996920683538961,
      "loss": 4.7661,
      "step": 561
    },
    {
      "epoch": 0.06444215112945763,
      "grad_norm": 0.0,
      "learning_rate": 0.0009969000730082054,
      "loss": 5.0017,
      "step": 562
    },
    {
      "epoch": 0.0645568168787983,
      "grad_norm": 0.0,
      "learning_rate": 0.000996879393946453,
      "loss": 5.2596,
      "step": 563
    },
    {
      "epoch": 0.06467148262813897,
      "grad_norm": 0.0,
      "learning_rate": 0.0009968586463565562,
      "loss": 5.1912,
      "step": 564
    },
    {
      "epoch": 0.06478614837747965,
      "grad_norm": 0.0,
      "learning_rate": 0.0009968378302413765,
      "loss": 5.1783,
      "step": 565
    },
    {
      "epoch": 0.06490081412682032,
      "grad_norm": 0.0,
      "learning_rate": 0.0009968169456037854,
      "loss": 5.0062,
      "step": 566
    },
    {
      "epoch": 0.06501547987616099,
      "grad_norm": 0.0,
      "learning_rate": 0.0009967959924466632,
      "loss": 5.3274,
      "step": 567
    },
    {
      "epoch": 0.06513014562550166,
      "grad_norm": 0.0,
      "learning_rate": 0.0009967749707729004,
      "loss": 5.1491,
      "step": 568
    },
    {
      "epoch": 0.06524481137484234,
      "grad_norm": 0.0,
      "learning_rate": 0.0009967538805853962,
      "loss": 5.1164,
      "step": 569
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 0.0,
      "learning_rate": 0.0009967327218870599,
      "loss": 5.2264,
      "step": 570
    },
    {
      "epoch": 0.06547414287352368,
      "grad_norm": 0.0,
      "learning_rate": 0.0009967114946808095,
      "loss": 4.9729,
      "step": 571
    },
    {
      "epoch": 0.06558880862286436,
      "grad_norm": 0.0,
      "learning_rate": 0.0009966901989695734,
      "loss": 5.099,
      "step": 572
    },
    {
      "epoch": 0.06570347437220503,
      "grad_norm": 0.0,
      "learning_rate": 0.0009966688347562884,
      "loss": 4.9278,
      "step": 573
    },
    {
      "epoch": 0.06581814012154569,
      "grad_norm": 0.0,
      "learning_rate": 0.0009966474020439017,
      "loss": 5.0603,
      "step": 574
    },
    {
      "epoch": 0.06593280587088636,
      "grad_norm": 0.0,
      "learning_rate": 0.0009966259008353693,
      "loss": 5.0192,
      "step": 575
    },
    {
      "epoch": 0.06604747162022703,
      "grad_norm": 0.0,
      "learning_rate": 0.000996604331133657,
      "loss": 5.2071,
      "step": 576
    },
    {
      "epoch": 0.0661621373695677,
      "grad_norm": 0.0,
      "learning_rate": 0.00099658269294174,
      "loss": 5.0401,
      "step": 577
    },
    {
      "epoch": 0.06627680311890838,
      "grad_norm": 0.0,
      "learning_rate": 0.000996560986262603,
      "loss": 4.8148,
      "step": 578
    },
    {
      "epoch": 0.06639146886824905,
      "grad_norm": 0.0,
      "learning_rate": 0.0009965392110992395,
      "loss": 5.186,
      "step": 579
    },
    {
      "epoch": 0.06650613461758972,
      "grad_norm": 0.0,
      "learning_rate": 0.0009965173674546532,
      "loss": 4.9777,
      "step": 580
    },
    {
      "epoch": 0.0666208003669304,
      "grad_norm": 0.0,
      "learning_rate": 0.0009964954553318573,
      "loss": 5.013,
      "step": 581
    },
    {
      "epoch": 0.06673546611627107,
      "grad_norm": 0.0,
      "learning_rate": 0.0009964734747338738,
      "loss": 5.0303,
      "step": 582
    },
    {
      "epoch": 0.06685013186561174,
      "grad_norm": 0.0,
      "learning_rate": 0.0009964514256637347,
      "loss": 4.8994,
      "step": 583
    },
    {
      "epoch": 0.06696479761495241,
      "grad_norm": 0.0,
      "learning_rate": 0.0009964293081244813,
      "loss": 4.8347,
      "step": 584
    },
    {
      "epoch": 0.06707946336429309,
      "grad_norm": 0.0,
      "learning_rate": 0.000996407122119164,
      "loss": 4.7761,
      "step": 585
    },
    {
      "epoch": 0.06719412911363376,
      "grad_norm": 0.0,
      "learning_rate": 0.0009963848676508434,
      "loss": 5.3003,
      "step": 586
    },
    {
      "epoch": 0.06730879486297443,
      "grad_norm": 0.0,
      "learning_rate": 0.0009963625447225886,
      "loss": 4.856,
      "step": 587
    },
    {
      "epoch": 0.0674234606123151,
      "grad_norm": 0.0,
      "learning_rate": 0.0009963401533374789,
      "loss": 5.241,
      "step": 588
    },
    {
      "epoch": 0.06753812636165578,
      "grad_norm": 0.0,
      "learning_rate": 0.0009963176934986025,
      "loss": 4.945,
      "step": 589
    },
    {
      "epoch": 0.06765279211099645,
      "grad_norm": 0.0,
      "learning_rate": 0.000996295165209058,
      "loss": 5.0595,
      "step": 590
    },
    {
      "epoch": 0.06776745786033712,
      "grad_norm": 0.0,
      "learning_rate": 0.0009962725684719519,
      "loss": 4.8807,
      "step": 591
    },
    {
      "epoch": 0.06788212360967778,
      "grad_norm": 0.0,
      "learning_rate": 0.0009962499032904013,
      "loss": 4.9375,
      "step": 592
    },
    {
      "epoch": 0.06799678935901846,
      "grad_norm": 0.0,
      "learning_rate": 0.0009962271696675325,
      "loss": 4.9069,
      "step": 593
    },
    {
      "epoch": 0.06811145510835913,
      "grad_norm": 0.0,
      "learning_rate": 0.0009962043676064812,
      "loss": 4.9722,
      "step": 594
    },
    {
      "epoch": 0.0682261208576998,
      "grad_norm": 0.0,
      "learning_rate": 0.0009961814971103926,
      "loss": 4.9209,
      "step": 595
    },
    {
      "epoch": 0.06834078660704047,
      "grad_norm": 0.0,
      "learning_rate": 0.0009961585581824209,
      "loss": 4.8572,
      "step": 596
    },
    {
      "epoch": 0.06845545235638115,
      "grad_norm": 0.0,
      "learning_rate": 0.0009961355508257303,
      "loss": 4.9041,
      "step": 597
    },
    {
      "epoch": 0.06857011810572182,
      "grad_norm": 0.0,
      "learning_rate": 0.0009961124750434943,
      "loss": 5.0056,
      "step": 598
    },
    {
      "epoch": 0.06868478385506249,
      "grad_norm": 0.0,
      "learning_rate": 0.0009960893308388957,
      "loss": 4.9101,
      "step": 599
    },
    {
      "epoch": 0.06879944960440317,
      "grad_norm": 0.0,
      "learning_rate": 0.0009960661182151268,
      "loss": 5.0098,
      "step": 600
    },
    {
      "epoch": 0.06891411535374384,
      "grad_norm": 0.0,
      "learning_rate": 0.000996042837175389,
      "loss": 5.1481,
      "step": 601
    },
    {
      "epoch": 0.06902878110308451,
      "grad_norm": 0.0,
      "learning_rate": 0.000996019487722894,
      "loss": 5.2401,
      "step": 602
    },
    {
      "epoch": 0.06914344685242518,
      "grad_norm": 0.0,
      "learning_rate": 0.0009959960698608624,
      "loss": 5.0531,
      "step": 603
    },
    {
      "epoch": 0.06925811260176586,
      "grad_norm": 0.0,
      "learning_rate": 0.0009959725835925238,
      "loss": 5.2601,
      "step": 604
    },
    {
      "epoch": 0.06937277835110653,
      "grad_norm": 0.0,
      "learning_rate": 0.0009959490289211182,
      "loss": 4.9691,
      "step": 605
    },
    {
      "epoch": 0.0694874441004472,
      "grad_norm": 0.0,
      "learning_rate": 0.000995925405849894,
      "loss": 5.015,
      "step": 606
    },
    {
      "epoch": 0.06960210984978787,
      "grad_norm": 0.0,
      "learning_rate": 0.0009959017143821099,
      "loss": 5.0185,
      "step": 607
    },
    {
      "epoch": 0.06971677559912855,
      "grad_norm": 0.0,
      "learning_rate": 0.0009958779545210337,
      "loss": 5.2035,
      "step": 608
    },
    {
      "epoch": 0.0698314413484692,
      "grad_norm": 0.0,
      "learning_rate": 0.0009958541262699422,
      "loss": 4.8217,
      "step": 609
    },
    {
      "epoch": 0.06994610709780988,
      "grad_norm": 0.0,
      "learning_rate": 0.0009958302296321226,
      "loss": 5.1136,
      "step": 610
    },
    {
      "epoch": 0.07006077284715055,
      "grad_norm": 0.0,
      "learning_rate": 0.0009958062646108707,
      "loss": 5.2475,
      "step": 611
    },
    {
      "epoch": 0.07017543859649122,
      "grad_norm": 0.0,
      "learning_rate": 0.000995782231209492,
      "loss": 4.964,
      "step": 612
    },
    {
      "epoch": 0.0702901043458319,
      "grad_norm": 0.0,
      "learning_rate": 0.0009957581294313016,
      "loss": 4.9172,
      "step": 613
    },
    {
      "epoch": 0.07040477009517257,
      "grad_norm": 0.0,
      "learning_rate": 0.000995733959279624,
      "loss": 4.8424,
      "step": 614
    },
    {
      "epoch": 0.07051943584451324,
      "grad_norm": 0.0,
      "learning_rate": 0.0009957097207577926,
      "loss": 5.2321,
      "step": 615
    },
    {
      "epoch": 0.07063410159385392,
      "grad_norm": 0.0,
      "learning_rate": 0.0009956854138691508,
      "loss": 5.3024,
      "step": 616
    },
    {
      "epoch": 0.07074876734319459,
      "grad_norm": 0.0,
      "learning_rate": 0.0009956610386170515,
      "loss": 5.1705,
      "step": 617
    },
    {
      "epoch": 0.07086343309253526,
      "grad_norm": 0.0,
      "learning_rate": 0.0009956365950048566,
      "loss": 5.196,
      "step": 618
    },
    {
      "epoch": 0.07097809884187593,
      "grad_norm": 0.0,
      "learning_rate": 0.0009956120830359376,
      "loss": 5.0256,
      "step": 619
    },
    {
      "epoch": 0.0710927645912166,
      "grad_norm": 0.0,
      "learning_rate": 0.0009955875027136754,
      "loss": 5.2326,
      "step": 620
    },
    {
      "epoch": 0.07120743034055728,
      "grad_norm": 0.0,
      "learning_rate": 0.0009955628540414608,
      "loss": 4.8909,
      "step": 621
    },
    {
      "epoch": 0.07132209608989795,
      "grad_norm": 0.0,
      "learning_rate": 0.0009955381370226931,
      "loss": 4.8417,
      "step": 622
    },
    {
      "epoch": 0.07143676183923862,
      "grad_norm": 0.0,
      "learning_rate": 0.0009955133516607818,
      "loss": 4.8552,
      "step": 623
    },
    {
      "epoch": 0.0715514275885793,
      "grad_norm": 0.0,
      "learning_rate": 0.0009954884979591456,
      "loss": 5.1679,
      "step": 624
    },
    {
      "epoch": 0.07166609333791997,
      "grad_norm": 0.0,
      "learning_rate": 0.0009954635759212124,
      "loss": 5.0498,
      "step": 625
    },
    {
      "epoch": 0.07178075908726063,
      "grad_norm": 0.0,
      "learning_rate": 0.00099543858555042,
      "loss": 5.1034,
      "step": 626
    },
    {
      "epoch": 0.0718954248366013,
      "grad_norm": 0.0,
      "learning_rate": 0.0009954135268502148,
      "loss": 4.6706,
      "step": 627
    },
    {
      "epoch": 0.07201009058594197,
      "grad_norm": 0.0,
      "learning_rate": 0.000995388399824054,
      "loss": 5.0221,
      "step": 628
    },
    {
      "epoch": 0.07212475633528265,
      "grad_norm": 0.0,
      "learning_rate": 0.000995363204475403,
      "loss": 4.7398,
      "step": 629
    },
    {
      "epoch": 0.07223942208462332,
      "grad_norm": 0.0,
      "learning_rate": 0.0009953379408077366,
      "loss": 5.0417,
      "step": 630
    },
    {
      "epoch": 0.07235408783396399,
      "grad_norm": 0.0,
      "learning_rate": 0.00099531260882454,
      "loss": 5.0171,
      "step": 631
    },
    {
      "epoch": 0.07246875358330467,
      "grad_norm": 0.0,
      "learning_rate": 0.000995287208529307,
      "loss": 4.9531,
      "step": 632
    },
    {
      "epoch": 0.07258341933264534,
      "grad_norm": 0.0,
      "learning_rate": 0.0009952617399255413,
      "loss": 4.8655,
      "step": 633
    },
    {
      "epoch": 0.07269808508198601,
      "grad_norm": 0.0,
      "learning_rate": 0.0009952362030167556,
      "loss": 4.9416,
      "step": 634
    },
    {
      "epoch": 0.07281275083132668,
      "grad_norm": 0.0,
      "learning_rate": 0.0009952105978064721,
      "loss": 5.0152,
      "step": 635
    },
    {
      "epoch": 0.07292741658066736,
      "grad_norm": 0.0,
      "learning_rate": 0.0009951849242982231,
      "loss": 5.129,
      "step": 636
    },
    {
      "epoch": 0.07304208233000803,
      "grad_norm": 0.0,
      "learning_rate": 0.0009951591824955493,
      "loss": 4.7022,
      "step": 637
    },
    {
      "epoch": 0.0731567480793487,
      "grad_norm": 0.0,
      "learning_rate": 0.0009951333724020012,
      "loss": 4.8892,
      "step": 638
    },
    {
      "epoch": 0.07327141382868937,
      "grad_norm": 0.0,
      "learning_rate": 0.0009951074940211394,
      "loss": 4.8261,
      "step": 639
    },
    {
      "epoch": 0.07338607957803005,
      "grad_norm": 0.0,
      "learning_rate": 0.0009950815473565328,
      "loss": 4.957,
      "step": 640
    },
    {
      "epoch": 0.07350074532737072,
      "grad_norm": 0.0,
      "learning_rate": 0.0009950555324117602,
      "loss": 4.9434,
      "step": 641
    },
    {
      "epoch": 0.07361541107671139,
      "grad_norm": 0.0,
      "learning_rate": 0.0009950294491904103,
      "loss": 4.9155,
      "step": 642
    },
    {
      "epoch": 0.07373007682605205,
      "grad_norm": 0.0,
      "learning_rate": 0.0009950032976960806,
      "loss": 5.0767,
      "step": 643
    },
    {
      "epoch": 0.07384474257539272,
      "grad_norm": 0.0,
      "learning_rate": 0.000994977077932378,
      "loss": 4.8263,
      "step": 644
    },
    {
      "epoch": 0.0739594083247334,
      "grad_norm": 0.0,
      "learning_rate": 0.0009949507899029192,
      "loss": 5.3029,
      "step": 645
    },
    {
      "epoch": 0.07407407407407407,
      "grad_norm": 0.0,
      "learning_rate": 0.00099492443361133,
      "loss": 5.1065,
      "step": 646
    },
    {
      "epoch": 0.07418873982341474,
      "grad_norm": 0.0,
      "learning_rate": 0.000994898009061246,
      "loss": 4.9658,
      "step": 647
    },
    {
      "epoch": 0.07430340557275542,
      "grad_norm": 0.0,
      "learning_rate": 0.0009948715162563118,
      "loss": 5.136,
      "step": 648
    },
    {
      "epoch": 0.07441807132209609,
      "grad_norm": 0.0,
      "learning_rate": 0.0009948449552001817,
      "loss": 4.8766,
      "step": 649
    },
    {
      "epoch": 0.07453273707143676,
      "grad_norm": 0.0,
      "learning_rate": 0.000994818325896519,
      "loss": 5.3317,
      "step": 650
    },
    {
      "epoch": 0.07464740282077743,
      "grad_norm": 0.0,
      "learning_rate": 0.0009947916283489968,
      "loss": 4.8638,
      "step": 651
    },
    {
      "epoch": 0.0747620685701181,
      "grad_norm": 0.0,
      "learning_rate": 0.0009947648625612978,
      "loss": 5.054,
      "step": 652
    },
    {
      "epoch": 0.07487673431945878,
      "grad_norm": 0.0,
      "learning_rate": 0.0009947380285371134,
      "loss": 4.9184,
      "step": 653
    },
    {
      "epoch": 0.07499140006879945,
      "grad_norm": 0.0,
      "learning_rate": 0.0009947111262801453,
      "loss": 5.2743,
      "step": 654
    },
    {
      "epoch": 0.07510606581814012,
      "grad_norm": 0.0,
      "learning_rate": 0.000994684155794104,
      "loss": 5.0269,
      "step": 655
    },
    {
      "epoch": 0.0752207315674808,
      "grad_norm": 0.0,
      "learning_rate": 0.0009946571170827091,
      "loss": 5.0537,
      "step": 656
    },
    {
      "epoch": 0.07533539731682147,
      "grad_norm": 0.0,
      "learning_rate": 0.0009946300101496908,
      "loss": 4.8995,
      "step": 657
    },
    {
      "epoch": 0.07545006306616214,
      "grad_norm": 0.0,
      "learning_rate": 0.0009946028349987876,
      "loss": 5.1361,
      "step": 658
    },
    {
      "epoch": 0.07556472881550282,
      "grad_norm": 0.0,
      "learning_rate": 0.0009945755916337478,
      "loss": 5.0841,
      "step": 659
    },
    {
      "epoch": 0.07567939456484347,
      "grad_norm": 0.0,
      "learning_rate": 0.0009945482800583292,
      "loss": 5.2644,
      "step": 660
    },
    {
      "epoch": 0.07579406031418415,
      "grad_norm": 0.0,
      "learning_rate": 0.0009945209002762989,
      "loss": 4.9167,
      "step": 661
    },
    {
      "epoch": 0.07590872606352482,
      "grad_norm": 0.0,
      "learning_rate": 0.0009944934522914332,
      "loss": 4.9455,
      "step": 662
    },
    {
      "epoch": 0.07602339181286549,
      "grad_norm": 0.0,
      "learning_rate": 0.0009944659361075183,
      "loss": 5.0457,
      "step": 663
    },
    {
      "epoch": 0.07613805756220617,
      "grad_norm": 0.0,
      "learning_rate": 0.0009944383517283494,
      "loss": 4.8522,
      "step": 664
    },
    {
      "epoch": 0.07625272331154684,
      "grad_norm": 0.0,
      "learning_rate": 0.0009944106991577315,
      "loss": 5.2327,
      "step": 665
    },
    {
      "epoch": 0.07636738906088751,
      "grad_norm": 0.0,
      "learning_rate": 0.0009943829783994782,
      "loss": 4.6546,
      "step": 666
    },
    {
      "epoch": 0.07648205481022818,
      "grad_norm": 0.0,
      "learning_rate": 0.0009943551894574135,
      "loss": 4.9646,
      "step": 667
    },
    {
      "epoch": 0.07659672055956886,
      "grad_norm": 0.0,
      "learning_rate": 0.0009943273323353705,
      "loss": 4.859,
      "step": 668
    },
    {
      "epoch": 0.07671138630890953,
      "grad_norm": 0.0,
      "learning_rate": 0.000994299407037191,
      "loss": 5.0807,
      "step": 669
    },
    {
      "epoch": 0.0768260520582502,
      "grad_norm": 0.0,
      "learning_rate": 0.000994271413566727,
      "loss": 4.8309,
      "step": 670
    },
    {
      "epoch": 0.07694071780759087,
      "grad_norm": 0.0,
      "learning_rate": 0.0009942433519278399,
      "loss": 5.0023,
      "step": 671
    },
    {
      "epoch": 0.07705538355693155,
      "grad_norm": 0.0,
      "learning_rate": 0.0009942152221244,
      "loss": 5.1156,
      "step": 672
    },
    {
      "epoch": 0.07717004930627222,
      "grad_norm": 0.0,
      "learning_rate": 0.0009941870241602874,
      "loss": 5.1489,
      "step": 673
    },
    {
      "epoch": 0.0772847150556129,
      "grad_norm": 0.0,
      "learning_rate": 0.0009941587580393912,
      "loss": 5.073,
      "step": 674
    },
    {
      "epoch": 0.07739938080495357,
      "grad_norm": 0.0,
      "learning_rate": 0.0009941304237656107,
      "loss": 5.0212,
      "step": 675
    },
    {
      "epoch": 0.07751404655429424,
      "grad_norm": 0.0,
      "learning_rate": 0.0009941020213428534,
      "loss": 4.8197,
      "step": 676
    },
    {
      "epoch": 0.0776287123036349,
      "grad_norm": 0.0,
      "learning_rate": 0.0009940735507750376,
      "loss": 5.0211,
      "step": 677
    },
    {
      "epoch": 0.07774337805297557,
      "grad_norm": 0.0,
      "learning_rate": 0.00099404501206609,
      "loss": 5.1277,
      "step": 678
    },
    {
      "epoch": 0.07785804380231624,
      "grad_norm": 0.0,
      "learning_rate": 0.0009940164052199467,
      "loss": 5.0592,
      "step": 679
    },
    {
      "epoch": 0.07797270955165692,
      "grad_norm": 0.0,
      "learning_rate": 0.0009939877302405534,
      "loss": 4.9382,
      "step": 680
    },
    {
      "epoch": 0.07808737530099759,
      "grad_norm": 0.0,
      "learning_rate": 0.000993958987131866,
      "loss": 5.0953,
      "step": 681
    },
    {
      "epoch": 0.07820204105033826,
      "grad_norm": 0.0,
      "learning_rate": 0.0009939301758978482,
      "loss": 4.8618,
      "step": 682
    },
    {
      "epoch": 0.07831670679967893,
      "grad_norm": 0.0,
      "learning_rate": 0.0009939012965424745,
      "loss": 4.9368,
      "step": 683
    },
    {
      "epoch": 0.0784313725490196,
      "grad_norm": 0.0,
      "learning_rate": 0.0009938723490697282,
      "loss": 5.3142,
      "step": 684
    },
    {
      "epoch": 0.07854603829836028,
      "grad_norm": 0.0,
      "learning_rate": 0.0009938433334836017,
      "loss": 4.8864,
      "step": 685
    },
    {
      "epoch": 0.07866070404770095,
      "grad_norm": 0.0,
      "learning_rate": 0.0009938142497880975,
      "loss": 4.7587,
      "step": 686
    },
    {
      "epoch": 0.07877536979704163,
      "grad_norm": 0.0,
      "learning_rate": 0.0009937850979872271,
      "loss": 4.9096,
      "step": 687
    },
    {
      "epoch": 0.0788900355463823,
      "grad_norm": 0.0,
      "learning_rate": 0.0009937558780850116,
      "loss": 4.7611,
      "step": 688
    },
    {
      "epoch": 0.07900470129572297,
      "grad_norm": 0.0,
      "learning_rate": 0.0009937265900854808,
      "loss": 4.9289,
      "step": 689
    },
    {
      "epoch": 0.07911936704506364,
      "grad_norm": 0.0,
      "learning_rate": 0.0009936972339926748,
      "loss": 4.9848,
      "step": 690
    },
    {
      "epoch": 0.07923403279440432,
      "grad_norm": 0.0,
      "learning_rate": 0.0009936678098106427,
      "loss": 5.1614,
      "step": 691
    },
    {
      "epoch": 0.07934869854374499,
      "grad_norm": 0.0,
      "learning_rate": 0.000993638317543443,
      "loss": 4.9728,
      "step": 692
    },
    {
      "epoch": 0.07946336429308566,
      "grad_norm": 0.0,
      "learning_rate": 0.0009936087571951434,
      "loss": 5.2215,
      "step": 693
    },
    {
      "epoch": 0.07957803004242632,
      "grad_norm": 0.0,
      "learning_rate": 0.0009935791287698213,
      "loss": 5.0717,
      "step": 694
    },
    {
      "epoch": 0.079692695791767,
      "grad_norm": 0.0,
      "learning_rate": 0.0009935494322715636,
      "loss": 5.0878,
      "step": 695
    },
    {
      "epoch": 0.07980736154110767,
      "grad_norm": 0.0,
      "learning_rate": 0.0009935196677044662,
      "loss": 4.9979,
      "step": 696
    },
    {
      "epoch": 0.07992202729044834,
      "grad_norm": 0.0,
      "learning_rate": 0.0009934898350726343,
      "loss": 5.0742,
      "step": 697
    },
    {
      "epoch": 0.08003669303978901,
      "grad_norm": 0.0,
      "learning_rate": 0.000993459934380183,
      "loss": 4.8647,
      "step": 698
    },
    {
      "epoch": 0.08015135878912968,
      "grad_norm": 0.0,
      "learning_rate": 0.0009934299656312367,
      "loss": 4.9052,
      "step": 699
    },
    {
      "epoch": 0.08026602453847036,
      "grad_norm": 0.0,
      "learning_rate": 0.0009933999288299286,
      "loss": 5.0671,
      "step": 700
    },
    {
      "epoch": 0.08038069028781103,
      "grad_norm": 0.0,
      "learning_rate": 0.000993369823980402,
      "loss": 5.0908,
      "step": 701
    },
    {
      "epoch": 0.0804953560371517,
      "grad_norm": 0.0,
      "learning_rate": 0.0009933396510868095,
      "loss": 4.8508,
      "step": 702
    },
    {
      "epoch": 0.08061002178649238,
      "grad_norm": 0.0,
      "learning_rate": 0.000993309410153312,
      "loss": 5.2088,
      "step": 703
    },
    {
      "epoch": 0.08072468753583305,
      "grad_norm": 0.0,
      "learning_rate": 0.0009932791011840816,
      "loss": 5.0183,
      "step": 704
    },
    {
      "epoch": 0.08083935328517372,
      "grad_norm": 0.0,
      "learning_rate": 0.0009932487241832986,
      "loss": 4.98,
      "step": 705
    },
    {
      "epoch": 0.0809540190345144,
      "grad_norm": 0.0,
      "learning_rate": 0.0009932182791551527,
      "loss": 5.1314,
      "step": 706
    },
    {
      "epoch": 0.08106868478385507,
      "grad_norm": 0.0,
      "learning_rate": 0.0009931877661038433,
      "loss": 5.1293,
      "step": 707
    },
    {
      "epoch": 0.08118335053319574,
      "grad_norm": 0.0,
      "learning_rate": 0.000993157185033579,
      "loss": 4.9491,
      "step": 708
    },
    {
      "epoch": 0.08129801628253641,
      "grad_norm": 0.0,
      "learning_rate": 0.0009931265359485783,
      "loss": 4.8892,
      "step": 709
    },
    {
      "epoch": 0.08141268203187708,
      "grad_norm": 0.0,
      "learning_rate": 0.0009930958188530683,
      "loss": 5.1281,
      "step": 710
    },
    {
      "epoch": 0.08152734778121776,
      "grad_norm": 0.0,
      "learning_rate": 0.0009930650337512856,
      "loss": 4.9401,
      "step": 711
    },
    {
      "epoch": 0.08164201353055842,
      "grad_norm": 0.0,
      "learning_rate": 0.000993034180647477,
      "loss": 4.9544,
      "step": 712
    },
    {
      "epoch": 0.08175667927989909,
      "grad_norm": 0.0,
      "learning_rate": 0.0009930032595458977,
      "loss": 5.0227,
      "step": 713
    },
    {
      "epoch": 0.08187134502923976,
      "grad_norm": 0.0,
      "learning_rate": 0.000992972270450813,
      "loss": 5.0939,
      "step": 714
    },
    {
      "epoch": 0.08198601077858043,
      "grad_norm": 0.0,
      "learning_rate": 0.0009929412133664966,
      "loss": 4.8493,
      "step": 715
    },
    {
      "epoch": 0.08210067652792111,
      "grad_norm": 0.0,
      "learning_rate": 0.000992910088297233,
      "loss": 5.0272,
      "step": 716
    },
    {
      "epoch": 0.08221534227726178,
      "grad_norm": 0.0,
      "learning_rate": 0.0009928788952473149,
      "loss": 5.2722,
      "step": 717
    },
    {
      "epoch": 0.08233000802660245,
      "grad_norm": 0.0,
      "learning_rate": 0.000992847634221045,
      "loss": 5.1877,
      "step": 718
    },
    {
      "epoch": 0.08244467377594313,
      "grad_norm": 0.0,
      "learning_rate": 0.000992816305222735,
      "loss": 5.0666,
      "step": 719
    },
    {
      "epoch": 0.0825593395252838,
      "grad_norm": 0.0,
      "learning_rate": 0.000992784908256706,
      "loss": 4.9637,
      "step": 720
    },
    {
      "epoch": 0.08267400527462447,
      "grad_norm": 0.0,
      "learning_rate": 0.000992753443327289,
      "loss": 4.841,
      "step": 721
    },
    {
      "epoch": 0.08278867102396514,
      "grad_norm": 0.0,
      "learning_rate": 0.0009927219104388237,
      "loss": 5.0658,
      "step": 722
    },
    {
      "epoch": 0.08290333677330582,
      "grad_norm": 0.0,
      "learning_rate": 0.0009926903095956595,
      "loss": 5.0807,
      "step": 723
    },
    {
      "epoch": 0.08301800252264649,
      "grad_norm": 0.0,
      "learning_rate": 0.0009926586408021553,
      "loss": 4.8518,
      "step": 724
    },
    {
      "epoch": 0.08313266827198716,
      "grad_norm": 0.0,
      "learning_rate": 0.0009926269040626788,
      "loss": 5.2161,
      "step": 725
    },
    {
      "epoch": 0.08324733402132783,
      "grad_norm": 0.0,
      "learning_rate": 0.000992595099381608,
      "loss": 5.1579,
      "step": 726
    },
    {
      "epoch": 0.08336199977066851,
      "grad_norm": 0.0,
      "learning_rate": 0.0009925632267633292,
      "loss": 4.9969,
      "step": 727
    },
    {
      "epoch": 0.08347666552000918,
      "grad_norm": 0.0,
      "learning_rate": 0.0009925312862122393,
      "loss": 5.1826,
      "step": 728
    },
    {
      "epoch": 0.08359133126934984,
      "grad_norm": 0.0,
      "learning_rate": 0.0009924992777327433,
      "loss": 5.058,
      "step": 729
    },
    {
      "epoch": 0.08370599701869051,
      "grad_norm": 0.0,
      "learning_rate": 0.0009924672013292566,
      "loss": 5.0198,
      "step": 730
    },
    {
      "epoch": 0.08382066276803118,
      "grad_norm": 0.0,
      "learning_rate": 0.000992435057006203,
      "loss": 5.0593,
      "step": 731
    },
    {
      "epoch": 0.08393532851737186,
      "grad_norm": 0.0,
      "learning_rate": 0.0009924028447680167,
      "loss": 5.0967,
      "step": 732
    },
    {
      "epoch": 0.08404999426671253,
      "grad_norm": 0.0,
      "learning_rate": 0.0009923705646191405,
      "loss": 4.9837,
      "step": 733
    },
    {
      "epoch": 0.0841646600160532,
      "grad_norm": 0.0,
      "learning_rate": 0.0009923382165640269,
      "loss": 4.7946,
      "step": 734
    },
    {
      "epoch": 0.08427932576539388,
      "grad_norm": 0.0,
      "learning_rate": 0.0009923058006071376,
      "loss": 5.0498,
      "step": 735
    },
    {
      "epoch": 0.08439399151473455,
      "grad_norm": 0.0,
      "learning_rate": 0.0009922733167529439,
      "loss": 5.2459,
      "step": 736
    },
    {
      "epoch": 0.08450865726407522,
      "grad_norm": 0.0,
      "learning_rate": 0.0009922407650059264,
      "loss": 4.8751,
      "step": 737
    },
    {
      "epoch": 0.0846233230134159,
      "grad_norm": 0.0,
      "learning_rate": 0.0009922081453705748,
      "loss": 5.0299,
      "step": 738
    },
    {
      "epoch": 0.08473798876275657,
      "grad_norm": 0.0,
      "learning_rate": 0.0009921754578513884,
      "loss": 4.8799,
      "step": 739
    },
    {
      "epoch": 0.08485265451209724,
      "grad_norm": 0.0,
      "learning_rate": 0.000992142702452876,
      "loss": 4.8786,
      "step": 740
    },
    {
      "epoch": 0.08496732026143791,
      "grad_norm": 0.0,
      "learning_rate": 0.0009921098791795552,
      "loss": 4.9375,
      "step": 741
    },
    {
      "epoch": 0.08508198601077858,
      "grad_norm": 0.0,
      "learning_rate": 0.0009920769880359538,
      "loss": 4.8639,
      "step": 742
    },
    {
      "epoch": 0.08519665176011926,
      "grad_norm": 0.0,
      "learning_rate": 0.0009920440290266082,
      "loss": 4.6086,
      "step": 743
    },
    {
      "epoch": 0.08531131750945993,
      "grad_norm": 0.0,
      "learning_rate": 0.0009920110021560645,
      "loss": 5.1607,
      "step": 744
    },
    {
      "epoch": 0.0854259832588006,
      "grad_norm": 0.0,
      "learning_rate": 0.0009919779074288784,
      "loss": 5.1491,
      "step": 745
    },
    {
      "epoch": 0.08554064900814126,
      "grad_norm": 0.0,
      "learning_rate": 0.000991944744849614,
      "loss": 5.0393,
      "step": 746
    },
    {
      "epoch": 0.08565531475748193,
      "grad_norm": 0.0,
      "learning_rate": 0.0009919115144228464,
      "loss": 4.8348,
      "step": 747
    },
    {
      "epoch": 0.08576998050682261,
      "grad_norm": 0.0,
      "learning_rate": 0.0009918782161531584,
      "loss": 5.0458,
      "step": 748
    },
    {
      "epoch": 0.08588464625616328,
      "grad_norm": 0.0,
      "learning_rate": 0.0009918448500451432,
      "loss": 4.8718,
      "step": 749
    },
    {
      "epoch": 0.08599931200550395,
      "grad_norm": 0.0,
      "learning_rate": 0.0009918114161034028,
      "loss": 5.2461,
      "step": 750
    },
    {
      "epoch": 0.08611397775484463,
      "grad_norm": 0.0,
      "learning_rate": 0.0009917779143325488,
      "loss": 5.0759,
      "step": 751
    },
    {
      "epoch": 0.0862286435041853,
      "grad_norm": 0.0,
      "learning_rate": 0.0009917443447372022,
      "loss": 4.9145,
      "step": 752
    },
    {
      "epoch": 0.08634330925352597,
      "grad_norm": 0.0,
      "learning_rate": 0.0009917107073219933,
      "loss": 4.8365,
      "step": 753
    },
    {
      "epoch": 0.08645797500286664,
      "grad_norm": 0.0,
      "learning_rate": 0.000991677002091562,
      "loss": 5.3376,
      "step": 754
    },
    {
      "epoch": 0.08657264075220732,
      "grad_norm": 0.0,
      "learning_rate": 0.000991643229050557,
      "loss": 4.9163,
      "step": 755
    },
    {
      "epoch": 0.08668730650154799,
      "grad_norm": 0.0,
      "learning_rate": 0.0009916093882036364,
      "loss": 4.9651,
      "step": 756
    },
    {
      "epoch": 0.08680197225088866,
      "grad_norm": 0.0,
      "learning_rate": 0.0009915754795554682,
      "loss": 5.1671,
      "step": 757
    },
    {
      "epoch": 0.08691663800022933,
      "grad_norm": 0.0,
      "learning_rate": 0.0009915415031107296,
      "loss": 4.9189,
      "step": 758
    },
    {
      "epoch": 0.08703130374957001,
      "grad_norm": 0.0,
      "learning_rate": 0.0009915074588741067,
      "loss": 5.027,
      "step": 759
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 0.0,
      "learning_rate": 0.0009914733468502953,
      "loss": 4.8596,
      "step": 760
    },
    {
      "epoch": 0.08726063524825135,
      "grad_norm": 0.0,
      "learning_rate": 0.0009914391670440008,
      "loss": 5.2849,
      "step": 761
    },
    {
      "epoch": 0.08737530099759203,
      "grad_norm": 0.0,
      "learning_rate": 0.0009914049194599374,
      "loss": 4.8973,
      "step": 762
    },
    {
      "epoch": 0.08748996674693268,
      "grad_norm": 0.0,
      "learning_rate": 0.0009913706041028288,
      "loss": 4.8853,
      "step": 763
    },
    {
      "epoch": 0.08760463249627336,
      "grad_norm": 0.0,
      "learning_rate": 0.0009913362209774082,
      "loss": 4.9682,
      "step": 764
    },
    {
      "epoch": 0.08771929824561403,
      "grad_norm": 0.0,
      "learning_rate": 0.0009913017700884186,
      "loss": 5.0345,
      "step": 765
    },
    {
      "epoch": 0.0878339639949547,
      "grad_norm": 0.0,
      "learning_rate": 0.0009912672514406108,
      "loss": 4.881,
      "step": 766
    },
    {
      "epoch": 0.08794862974429538,
      "grad_norm": 0.0,
      "learning_rate": 0.0009912326650387473,
      "loss": 4.8009,
      "step": 767
    },
    {
      "epoch": 0.08806329549363605,
      "grad_norm": 0.0,
      "learning_rate": 0.0009911980108875975,
      "loss": 4.795,
      "step": 768
    },
    {
      "epoch": 0.08817796124297672,
      "grad_norm": 0.0,
      "learning_rate": 0.000991163288991942,
      "loss": 4.9985,
      "step": 769
    },
    {
      "epoch": 0.0882926269923174,
      "grad_norm": 0.0,
      "learning_rate": 0.0009911284993565695,
      "loss": 4.9612,
      "step": 770
    },
    {
      "epoch": 0.08840729274165807,
      "grad_norm": 0.0,
      "learning_rate": 0.000991093641986279,
      "loss": 5.0277,
      "step": 771
    },
    {
      "epoch": 0.08852195849099874,
      "grad_norm": 0.0,
      "learning_rate": 0.0009910587168858783,
      "loss": 4.9511,
      "step": 772
    },
    {
      "epoch": 0.08863662424033941,
      "grad_norm": 0.0,
      "learning_rate": 0.0009910237240601844,
      "loss": 5.0499,
      "step": 773
    },
    {
      "epoch": 0.08875128998968008,
      "grad_norm": 0.0,
      "learning_rate": 0.000990988663514024,
      "loss": 5.2297,
      "step": 774
    },
    {
      "epoch": 0.08886595573902076,
      "grad_norm": 0.0,
      "learning_rate": 0.000990953535252233,
      "loss": 5.1623,
      "step": 775
    },
    {
      "epoch": 0.08898062148836143,
      "grad_norm": 0.0,
      "learning_rate": 0.0009909183392796572,
      "loss": 5.0496,
      "step": 776
    },
    {
      "epoch": 0.0890952872377021,
      "grad_norm": 0.0,
      "learning_rate": 0.0009908830756011507,
      "loss": 5.1654,
      "step": 777
    },
    {
      "epoch": 0.08920995298704278,
      "grad_norm": 0.0,
      "learning_rate": 0.0009908477442215774,
      "loss": 4.7242,
      "step": 778
    },
    {
      "epoch": 0.08932461873638345,
      "grad_norm": 0.0,
      "learning_rate": 0.000990812345145811,
      "loss": 4.7196,
      "step": 779
    },
    {
      "epoch": 0.08943928448572411,
      "grad_norm": 0.0,
      "learning_rate": 0.0009907768783787335,
      "loss": 5.2303,
      "step": 780
    },
    {
      "epoch": 0.08955395023506478,
      "grad_norm": 0.0,
      "learning_rate": 0.0009907413439252375,
      "loss": 4.8159,
      "step": 781
    },
    {
      "epoch": 0.08966861598440545,
      "grad_norm": 0.0,
      "learning_rate": 0.0009907057417902238,
      "loss": 5.2138,
      "step": 782
    },
    {
      "epoch": 0.08978328173374613,
      "grad_norm": 0.0,
      "learning_rate": 0.0009906700719786036,
      "loss": 4.9248,
      "step": 783
    },
    {
      "epoch": 0.0898979474830868,
      "grad_norm": 0.0,
      "learning_rate": 0.0009906343344952965,
      "loss": 4.9653,
      "step": 784
    },
    {
      "epoch": 0.09001261323242747,
      "grad_norm": 0.0,
      "learning_rate": 0.0009905985293452314,
      "loss": 5.0473,
      "step": 785
    },
    {
      "epoch": 0.09012727898176814,
      "grad_norm": 0.0,
      "learning_rate": 0.0009905626565333478,
      "loss": 5.1064,
      "step": 786
    },
    {
      "epoch": 0.09024194473110882,
      "grad_norm": 0.0,
      "learning_rate": 0.000990526716064593,
      "loss": 5.0227,
      "step": 787
    },
    {
      "epoch": 0.09035661048044949,
      "grad_norm": 0.0,
      "learning_rate": 0.000990490707943925,
      "loss": 5.0178,
      "step": 788
    },
    {
      "epoch": 0.09047127622979016,
      "grad_norm": 0.0,
      "learning_rate": 0.0009904546321763096,
      "loss": 5.0766,
      "step": 789
    },
    {
      "epoch": 0.09058594197913084,
      "grad_norm": 0.0,
      "learning_rate": 0.0009904184887667231,
      "loss": 4.9338,
      "step": 790
    },
    {
      "epoch": 0.09070060772847151,
      "grad_norm": 0.0,
      "learning_rate": 0.000990382277720151,
      "loss": 5.2276,
      "step": 791
    },
    {
      "epoch": 0.09081527347781218,
      "grad_norm": 0.0,
      "learning_rate": 0.0009903459990415879,
      "loss": 5.1906,
      "step": 792
    },
    {
      "epoch": 0.09092993922715285,
      "grad_norm": 0.0,
      "learning_rate": 0.0009903096527360375,
      "loss": 5.0163,
      "step": 793
    },
    {
      "epoch": 0.09104460497649353,
      "grad_norm": 0.0,
      "learning_rate": 0.0009902732388085132,
      "loss": 5.1376,
      "step": 794
    },
    {
      "epoch": 0.0911592707258342,
      "grad_norm": 0.0,
      "learning_rate": 0.0009902367572640375,
      "loss": 5.0804,
      "step": 795
    },
    {
      "epoch": 0.09127393647517487,
      "grad_norm": 0.0,
      "learning_rate": 0.0009902002081076426,
      "loss": 4.9826,
      "step": 796
    },
    {
      "epoch": 0.09138860222451553,
      "grad_norm": 0.0,
      "learning_rate": 0.0009901635913443696,
      "loss": 5.0764,
      "step": 797
    },
    {
      "epoch": 0.0915032679738562,
      "grad_norm": 0.0,
      "learning_rate": 0.0009901269069792688,
      "loss": 5.0998,
      "step": 798
    },
    {
      "epoch": 0.09161793372319688,
      "grad_norm": 0.0,
      "learning_rate": 0.0009900901550174007,
      "loss": 5.1674,
      "step": 799
    },
    {
      "epoch": 0.09173259947253755,
      "grad_norm": 0.0,
      "learning_rate": 0.0009900533354638343,
      "loss": 5.0477,
      "step": 800
    },
    {
      "epoch": 0.09184726522187822,
      "grad_norm": 0.0,
      "learning_rate": 0.000990016448323648,
      "loss": 5.1837,
      "step": 801
    },
    {
      "epoch": 0.0919619309712189,
      "grad_norm": 0.0,
      "learning_rate": 0.0009899794936019297,
      "loss": 4.9127,
      "step": 802
    },
    {
      "epoch": 0.09207659672055957,
      "grad_norm": 0.0,
      "learning_rate": 0.0009899424713037766,
      "loss": 4.9503,
      "step": 803
    },
    {
      "epoch": 0.09219126246990024,
      "grad_norm": 0.0,
      "learning_rate": 0.0009899053814342955,
      "loss": 5.1856,
      "step": 804
    },
    {
      "epoch": 0.09230592821924091,
      "grad_norm": 0.0,
      "learning_rate": 0.0009898682239986019,
      "loss": 5.1605,
      "step": 805
    },
    {
      "epoch": 0.09242059396858159,
      "grad_norm": 0.0,
      "learning_rate": 0.0009898309990018209,
      "loss": 5.3097,
      "step": 806
    },
    {
      "epoch": 0.09253525971792226,
      "grad_norm": 0.0,
      "learning_rate": 0.0009897937064490875,
      "loss": 5.0207,
      "step": 807
    },
    {
      "epoch": 0.09264992546726293,
      "grad_norm": 0.0,
      "learning_rate": 0.000989756346345545,
      "loss": 4.8604,
      "step": 808
    },
    {
      "epoch": 0.0927645912166036,
      "grad_norm": 0.0,
      "learning_rate": 0.0009897189186963465,
      "loss": 4.892,
      "step": 809
    },
    {
      "epoch": 0.09287925696594428,
      "grad_norm": 0.0,
      "learning_rate": 0.0009896814235066547,
      "loss": 5.0549,
      "step": 810
    },
    {
      "epoch": 0.09299392271528495,
      "grad_norm": 0.0,
      "learning_rate": 0.0009896438607816414,
      "loss": 5.0003,
      "step": 811
    },
    {
      "epoch": 0.09310858846462562,
      "grad_norm": 0.0,
      "learning_rate": 0.0009896062305264875,
      "loss": 5.1905,
      "step": 812
    },
    {
      "epoch": 0.0932232542139663,
      "grad_norm": 0.0,
      "learning_rate": 0.0009895685327463832,
      "loss": 5.092,
      "step": 813
    },
    {
      "epoch": 0.09333791996330695,
      "grad_norm": 0.0,
      "learning_rate": 0.0009895307674465286,
      "loss": 5.1384,
      "step": 814
    },
    {
      "epoch": 0.09345258571264763,
      "grad_norm": 0.0,
      "learning_rate": 0.0009894929346321323,
      "loss": 4.9725,
      "step": 815
    },
    {
      "epoch": 0.0935672514619883,
      "grad_norm": 0.0,
      "learning_rate": 0.000989455034308413,
      "loss": 4.8403,
      "step": 816
    },
    {
      "epoch": 0.09368191721132897,
      "grad_norm": 0.0,
      "learning_rate": 0.000989417066480598,
      "loss": 4.9577,
      "step": 817
    },
    {
      "epoch": 0.09379658296066964,
      "grad_norm": 0.0,
      "learning_rate": 0.0009893790311539244,
      "loss": 5.0229,
      "step": 818
    },
    {
      "epoch": 0.09391124871001032,
      "grad_norm": 0.0,
      "learning_rate": 0.0009893409283336385,
      "loss": 4.8798,
      "step": 819
    },
    {
      "epoch": 0.09402591445935099,
      "grad_norm": 0.0,
      "learning_rate": 0.0009893027580249955,
      "loss": 5.0963,
      "step": 820
    },
    {
      "epoch": 0.09414058020869166,
      "grad_norm": 0.0,
      "learning_rate": 0.0009892645202332607,
      "loss": 5.1291,
      "step": 821
    },
    {
      "epoch": 0.09425524595803234,
      "grad_norm": 0.0,
      "learning_rate": 0.000989226214963708,
      "loss": 4.918,
      "step": 822
    },
    {
      "epoch": 0.09436991170737301,
      "grad_norm": 0.0,
      "learning_rate": 0.000989187842221621,
      "loss": 4.9998,
      "step": 823
    },
    {
      "epoch": 0.09448457745671368,
      "grad_norm": 0.0,
      "learning_rate": 0.000989149402012293,
      "loss": 4.9283,
      "step": 824
    },
    {
      "epoch": 0.09459924320605435,
      "grad_norm": 0.0,
      "learning_rate": 0.000989110894341025,
      "loss": 4.8701,
      "step": 825
    },
    {
      "epoch": 0.09471390895539503,
      "grad_norm": 0.0,
      "learning_rate": 0.000989072319213129,
      "loss": 4.9855,
      "step": 826
    },
    {
      "epoch": 0.0948285747047357,
      "grad_norm": 0.0,
      "learning_rate": 0.0009890336766339258,
      "loss": 5.094,
      "step": 827
    },
    {
      "epoch": 0.09494324045407637,
      "grad_norm": 0.0,
      "learning_rate": 0.0009889949666087453,
      "loss": 5.0423,
      "step": 828
    },
    {
      "epoch": 0.09505790620341704,
      "grad_norm": 0.0,
      "learning_rate": 0.0009889561891429268,
      "loss": 4.7852,
      "step": 829
    },
    {
      "epoch": 0.09517257195275772,
      "grad_norm": 0.0,
      "learning_rate": 0.000988917344241819,
      "loss": 5.002,
      "step": 830
    },
    {
      "epoch": 0.09528723770209838,
      "grad_norm": 0.0,
      "learning_rate": 0.0009888784319107796,
      "loss": 4.7908,
      "step": 831
    },
    {
      "epoch": 0.09540190345143905,
      "grad_norm": 0.0,
      "learning_rate": 0.000988839452155176,
      "loss": 4.6879,
      "step": 832
    },
    {
      "epoch": 0.09551656920077972,
      "grad_norm": 0.0,
      "learning_rate": 0.0009888004049803845,
      "loss": 4.9792,
      "step": 833
    },
    {
      "epoch": 0.0956312349501204,
      "grad_norm": 0.0,
      "learning_rate": 0.0009887612903917912,
      "loss": 4.9737,
      "step": 834
    },
    {
      "epoch": 0.09574590069946107,
      "grad_norm": 0.0,
      "learning_rate": 0.000988722108394791,
      "loss": 5.0705,
      "step": 835
    },
    {
      "epoch": 0.09586056644880174,
      "grad_norm": 0.0,
      "learning_rate": 0.0009886828589947886,
      "loss": 5.0486,
      "step": 836
    },
    {
      "epoch": 0.09597523219814241,
      "grad_norm": 0.0,
      "learning_rate": 0.0009886435421971973,
      "loss": 4.958,
      "step": 837
    },
    {
      "epoch": 0.09608989794748309,
      "grad_norm": 0.0,
      "learning_rate": 0.0009886041580074402,
      "loss": 5.1462,
      "step": 838
    },
    {
      "epoch": 0.09620456369682376,
      "grad_norm": 0.0,
      "learning_rate": 0.0009885647064309497,
      "loss": 4.9753,
      "step": 839
    },
    {
      "epoch": 0.09631922944616443,
      "grad_norm": 0.0,
      "learning_rate": 0.0009885251874731677,
      "loss": 5.0069,
      "step": 840
    },
    {
      "epoch": 0.0964338951955051,
      "grad_norm": 0.0,
      "learning_rate": 0.0009884856011395445,
      "loss": 4.9835,
      "step": 841
    },
    {
      "epoch": 0.09654856094484578,
      "grad_norm": 0.0,
      "learning_rate": 0.0009884459474355405,
      "loss": 5.1574,
      "step": 842
    },
    {
      "epoch": 0.09666322669418645,
      "grad_norm": 0.0,
      "learning_rate": 0.0009884062263666254,
      "loss": 4.8134,
      "step": 843
    },
    {
      "epoch": 0.09677789244352712,
      "grad_norm": 0.0,
      "learning_rate": 0.0009883664379382777,
      "loss": 4.8683,
      "step": 844
    },
    {
      "epoch": 0.0968925581928678,
      "grad_norm": 0.0,
      "learning_rate": 0.0009883265821559856,
      "loss": 5.0905,
      "step": 845
    },
    {
      "epoch": 0.09700722394220847,
      "grad_norm": 0.0,
      "learning_rate": 0.0009882866590252464,
      "loss": 5.0194,
      "step": 846
    },
    {
      "epoch": 0.09712188969154914,
      "grad_norm": 0.0,
      "learning_rate": 0.0009882466685515667,
      "loss": 4.7954,
      "step": 847
    },
    {
      "epoch": 0.09723655544088981,
      "grad_norm": 0.0,
      "learning_rate": 0.0009882066107404623,
      "loss": 5.0893,
      "step": 848
    },
    {
      "epoch": 0.09735122119023047,
      "grad_norm": 0.0,
      "learning_rate": 0.000988166485597459,
      "loss": 5.0724,
      "step": 849
    },
    {
      "epoch": 0.09746588693957114,
      "grad_norm": 0.0,
      "learning_rate": 0.0009881262931280904,
      "loss": 4.8376,
      "step": 850
    },
    {
      "epoch": 0.09758055268891182,
      "grad_norm": 0.0,
      "learning_rate": 0.0009880860333379008,
      "loss": 5.1897,
      "step": 851
    },
    {
      "epoch": 0.09769521843825249,
      "grad_norm": 0.0,
      "learning_rate": 0.0009880457062324433,
      "loss": 4.9691,
      "step": 852
    },
    {
      "epoch": 0.09780988418759316,
      "grad_norm": 0.0,
      "learning_rate": 0.0009880053118172802,
      "loss": 5.3419,
      "step": 853
    },
    {
      "epoch": 0.09792454993693384,
      "grad_norm": 0.0,
      "learning_rate": 0.0009879648500979831,
      "loss": 5.1117,
      "step": 854
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.0,
      "learning_rate": 0.000987924321080133,
      "loss": 4.9963,
      "step": 855
    },
    {
      "epoch": 0.09815388143561518,
      "grad_norm": 0.0,
      "learning_rate": 0.0009878837247693198,
      "loss": 5.1935,
      "step": 856
    },
    {
      "epoch": 0.09826854718495585,
      "grad_norm": 0.0,
      "learning_rate": 0.0009878430611711434,
      "loss": 5.0799,
      "step": 857
    },
    {
      "epoch": 0.09838321293429653,
      "grad_norm": 0.0,
      "learning_rate": 0.0009878023302912124,
      "loss": 5.0894,
      "step": 858
    },
    {
      "epoch": 0.0984978786836372,
      "grad_norm": 0.0,
      "learning_rate": 0.000987761532135145,
      "loss": 5.1071,
      "step": 859
    },
    {
      "epoch": 0.09861254443297787,
      "grad_norm": 0.0,
      "learning_rate": 0.000987720666708568,
      "loss": 4.8362,
      "step": 860
    },
    {
      "epoch": 0.09872721018231854,
      "grad_norm": 0.0,
      "learning_rate": 0.0009876797340171186,
      "loss": 5.2421,
      "step": 861
    },
    {
      "epoch": 0.09884187593165922,
      "grad_norm": 0.0,
      "learning_rate": 0.0009876387340664425,
      "loss": 5.0724,
      "step": 862
    },
    {
      "epoch": 0.09895654168099989,
      "grad_norm": 0.0,
      "learning_rate": 0.0009875976668621946,
      "loss": 5.1118,
      "step": 863
    },
    {
      "epoch": 0.09907120743034056,
      "grad_norm": 0.0,
      "learning_rate": 0.0009875565324100398,
      "loss": 4.9883,
      "step": 864
    },
    {
      "epoch": 0.09918587317968124,
      "grad_norm": 0.0,
      "learning_rate": 0.0009875153307156515,
      "loss": 4.8221,
      "step": 865
    },
    {
      "epoch": 0.0993005389290219,
      "grad_norm": 0.0,
      "learning_rate": 0.0009874740617847127,
      "loss": 5.0539,
      "step": 866
    },
    {
      "epoch": 0.09941520467836257,
      "grad_norm": 0.0,
      "learning_rate": 0.0009874327256229158,
      "loss": 4.9825,
      "step": 867
    },
    {
      "epoch": 0.09952987042770324,
      "grad_norm": 0.0,
      "learning_rate": 0.0009873913222359623,
      "loss": 4.9637,
      "step": 868
    },
    {
      "epoch": 0.09964453617704391,
      "grad_norm": 0.0,
      "learning_rate": 0.0009873498516295629,
      "loss": 4.807,
      "step": 869
    },
    {
      "epoch": 0.09975920192638459,
      "grad_norm": 0.0,
      "learning_rate": 0.0009873083138094377,
      "loss": 5.2365,
      "step": 870
    },
    {
      "epoch": 0.09987386767572526,
      "grad_norm": 0.0,
      "learning_rate": 0.0009872667087813163,
      "loss": 4.896,
      "step": 871
    },
    {
      "epoch": 0.09998853342506593,
      "grad_norm": 0.0,
      "learning_rate": 0.0009872250365509368,
      "loss": 4.7277,
      "step": 872
    },
    {
      "epoch": 0.1001031991744066,
      "grad_norm": 0.0,
      "learning_rate": 0.0009871832971240476,
      "loss": 4.9343,
      "step": 873
    },
    {
      "epoch": 0.10021786492374728,
      "grad_norm": 0.0,
      "learning_rate": 0.0009871414905064056,
      "loss": 5.1257,
      "step": 874
    },
    {
      "epoch": 0.10033253067308795,
      "grad_norm": 0.0,
      "learning_rate": 0.0009870996167037774,
      "loss": 5.0424,
      "step": 875
    },
    {
      "epoch": 0.10044719642242862,
      "grad_norm": 0.0,
      "learning_rate": 0.0009870576757219384,
      "loss": 5.1133,
      "step": 876
    },
    {
      "epoch": 0.1005618621717693,
      "grad_norm": 0.0,
      "learning_rate": 0.0009870156675666738,
      "loss": 4.8087,
      "step": 877
    },
    {
      "epoch": 0.10067652792110997,
      "grad_norm": 0.0,
      "learning_rate": 0.0009869735922437778,
      "loss": 4.9034,
      "step": 878
    },
    {
      "epoch": 0.10079119367045064,
      "grad_norm": 0.0,
      "learning_rate": 0.000986931449759054,
      "loss": 4.8413,
      "step": 879
    },
    {
      "epoch": 0.10090585941979131,
      "grad_norm": 0.0,
      "learning_rate": 0.000986889240118315,
      "loss": 4.9534,
      "step": 880
    },
    {
      "epoch": 0.10102052516913199,
      "grad_norm": 0.0,
      "learning_rate": 0.0009868469633273827,
      "loss": 5.1075,
      "step": 881
    },
    {
      "epoch": 0.10113519091847266,
      "grad_norm": 0.0,
      "learning_rate": 0.0009868046193920886,
      "loss": 5.0821,
      "step": 882
    },
    {
      "epoch": 0.10124985666781332,
      "grad_norm": 0.0,
      "learning_rate": 0.000986762208318273,
      "loss": 4.8473,
      "step": 883
    },
    {
      "epoch": 0.10136452241715399,
      "grad_norm": 0.0,
      "learning_rate": 0.0009867197301117858,
      "loss": 5.0687,
      "step": 884
    },
    {
      "epoch": 0.10147918816649466,
      "grad_norm": 0.0,
      "learning_rate": 0.0009866771847784864,
      "loss": 5.2539,
      "step": 885
    },
    {
      "epoch": 0.10159385391583534,
      "grad_norm": 0.0,
      "learning_rate": 0.0009866345723242426,
      "loss": 5.0002,
      "step": 886
    },
    {
      "epoch": 0.10170851966517601,
      "grad_norm": 0.0,
      "learning_rate": 0.000986591892754932,
      "loss": 5.2735,
      "step": 887
    },
    {
      "epoch": 0.10182318541451668,
      "grad_norm": 0.0,
      "learning_rate": 0.000986549146076442,
      "loss": 5.1784,
      "step": 888
    },
    {
      "epoch": 0.10193785116385735,
      "grad_norm": 0.0,
      "learning_rate": 0.0009865063322946682,
      "loss": 5.0823,
      "step": 889
    },
    {
      "epoch": 0.10205251691319803,
      "grad_norm": 0.0,
      "learning_rate": 0.000986463451415516,
      "loss": 4.8728,
      "step": 890
    },
    {
      "epoch": 0.1021671826625387,
      "grad_norm": 0.0,
      "learning_rate": 0.0009864205034449001,
      "loss": 4.8451,
      "step": 891
    },
    {
      "epoch": 0.10228184841187937,
      "grad_norm": 0.0,
      "learning_rate": 0.0009863774883887442,
      "loss": 4.9867,
      "step": 892
    },
    {
      "epoch": 0.10239651416122005,
      "grad_norm": 0.0,
      "learning_rate": 0.0009863344062529817,
      "loss": 4.9005,
      "step": 893
    },
    {
      "epoch": 0.10251117991056072,
      "grad_norm": 0.0,
      "learning_rate": 0.0009862912570435547,
      "loss": 5.2709,
      "step": 894
    },
    {
      "epoch": 0.10262584565990139,
      "grad_norm": 0.0,
      "learning_rate": 0.0009862480407664149,
      "loss": 5.0078,
      "step": 895
    },
    {
      "epoch": 0.10274051140924206,
      "grad_norm": 0.0,
      "learning_rate": 0.0009862047574275231,
      "loss": 5.0758,
      "step": 896
    },
    {
      "epoch": 0.10285517715858274,
      "grad_norm": 0.0,
      "learning_rate": 0.0009861614070328494,
      "loss": 5.2183,
      "step": 897
    },
    {
      "epoch": 0.10296984290792341,
      "grad_norm": 0.0,
      "learning_rate": 0.0009861179895883736,
      "loss": 5.163,
      "step": 898
    },
    {
      "epoch": 0.10308450865726408,
      "grad_norm": 0.0,
      "learning_rate": 0.0009860745051000837,
      "loss": 4.7753,
      "step": 899
    },
    {
      "epoch": 0.10319917440660474,
      "grad_norm": 0.0,
      "learning_rate": 0.0009860309535739777,
      "loss": 5.0846,
      "step": 900
    },
    {
      "epoch": 0.10331384015594541,
      "grad_norm": 0.0,
      "learning_rate": 0.0009859873350160629,
      "loss": 5.0549,
      "step": 901
    },
    {
      "epoch": 0.10342850590528609,
      "grad_norm": 0.0,
      "learning_rate": 0.0009859436494323555,
      "loss": 4.9763,
      "step": 902
    },
    {
      "epoch": 0.10354317165462676,
      "grad_norm": 0.0,
      "learning_rate": 0.000985899896828881,
      "loss": 5.3303,
      "step": 903
    },
    {
      "epoch": 0.10365783740396743,
      "grad_norm": 0.0,
      "learning_rate": 0.0009858560772116748,
      "loss": 4.8869,
      "step": 904
    },
    {
      "epoch": 0.1037725031533081,
      "grad_norm": 0.0,
      "learning_rate": 0.00098581219058678,
      "loss": 5.0275,
      "step": 905
    },
    {
      "epoch": 0.10388716890264878,
      "grad_norm": 0.0,
      "learning_rate": 0.0009857682369602508,
      "loss": 5.1661,
      "step": 906
    },
    {
      "epoch": 0.10400183465198945,
      "grad_norm": 0.0,
      "learning_rate": 0.0009857242163381495,
      "loss": 5.3442,
      "step": 907
    },
    {
      "epoch": 0.10411650040133012,
      "grad_norm": 0.0,
      "learning_rate": 0.0009856801287265477,
      "loss": 4.986,
      "step": 908
    },
    {
      "epoch": 0.1042311661506708,
      "grad_norm": 0.0,
      "learning_rate": 0.0009856359741315266,
      "loss": 4.97,
      "step": 909
    },
    {
      "epoch": 0.10434583190001147,
      "grad_norm": 0.0,
      "learning_rate": 0.0009855917525591765,
      "loss": 4.9847,
      "step": 910
    },
    {
      "epoch": 0.10446049764935214,
      "grad_norm": 0.0,
      "learning_rate": 0.000985547464015597,
      "loss": 4.8483,
      "step": 911
    },
    {
      "epoch": 0.10457516339869281,
      "grad_norm": 0.0,
      "learning_rate": 0.0009855031085068968,
      "loss": 4.8108,
      "step": 912
    },
    {
      "epoch": 0.10468982914803349,
      "grad_norm": 0.0,
      "learning_rate": 0.0009854586860391936,
      "loss": 5.2073,
      "step": 913
    },
    {
      "epoch": 0.10480449489737416,
      "grad_norm": 0.0,
      "learning_rate": 0.000985414196618615,
      "loss": 4.8824,
      "step": 914
    },
    {
      "epoch": 0.10491916064671483,
      "grad_norm": 0.0,
      "learning_rate": 0.0009853696402512976,
      "loss": 5.1039,
      "step": 915
    },
    {
      "epoch": 0.1050338263960555,
      "grad_norm": 0.0,
      "learning_rate": 0.0009853250169433866,
      "loss": 5.2417,
      "step": 916
    },
    {
      "epoch": 0.10514849214539616,
      "grad_norm": 0.0,
      "learning_rate": 0.0009852803267010374,
      "loss": 4.6474,
      "step": 917
    },
    {
      "epoch": 0.10526315789473684,
      "grad_norm": 0.0,
      "learning_rate": 0.0009852355695304136,
      "loss": 4.7356,
      "step": 918
    },
    {
      "epoch": 0.10537782364407751,
      "grad_norm": 0.0,
      "learning_rate": 0.0009851907454376892,
      "loss": 5.0527,
      "step": 919
    },
    {
      "epoch": 0.10549248939341818,
      "grad_norm": 0.0,
      "learning_rate": 0.0009851458544290466,
      "loss": 4.8994,
      "step": 920
    },
    {
      "epoch": 0.10560715514275885,
      "grad_norm": 0.0,
      "learning_rate": 0.0009851008965106776,
      "loss": 5.3398,
      "step": 921
    },
    {
      "epoch": 0.10572182089209953,
      "grad_norm": 0.0,
      "learning_rate": 0.0009850558716887833,
      "loss": 5.0189,
      "step": 922
    },
    {
      "epoch": 0.1058364866414402,
      "grad_norm": 0.0,
      "learning_rate": 0.000985010779969574,
      "loss": 5.0617,
      "step": 923
    },
    {
      "epoch": 0.10595115239078087,
      "grad_norm": 0.0,
      "learning_rate": 0.0009849656213592696,
      "loss": 4.8246,
      "step": 924
    },
    {
      "epoch": 0.10606581814012155,
      "grad_norm": 0.0,
      "learning_rate": 0.0009849203958640983,
      "loss": 5.0431,
      "step": 925
    },
    {
      "epoch": 0.10618048388946222,
      "grad_norm": 0.0,
      "learning_rate": 0.0009848751034902984,
      "loss": 5.1349,
      "step": 926
    },
    {
      "epoch": 0.10629514963880289,
      "grad_norm": 0.0,
      "learning_rate": 0.0009848297442441173,
      "loss": 4.909,
      "step": 927
    },
    {
      "epoch": 0.10640981538814356,
      "grad_norm": 0.0,
      "learning_rate": 0.0009847843181318109,
      "loss": 4.9151,
      "step": 928
    },
    {
      "epoch": 0.10652448113748424,
      "grad_norm": 0.0,
      "learning_rate": 0.0009847388251596452,
      "loss": 5.1425,
      "step": 929
    },
    {
      "epoch": 0.10663914688682491,
      "grad_norm": 0.0,
      "learning_rate": 0.0009846932653338953,
      "loss": 5.0825,
      "step": 930
    },
    {
      "epoch": 0.10675381263616558,
      "grad_norm": 0.0,
      "learning_rate": 0.000984647638660845,
      "loss": 4.9418,
      "step": 931
    },
    {
      "epoch": 0.10686847838550625,
      "grad_norm": 0.0,
      "learning_rate": 0.0009846019451467878,
      "loss": 5.1021,
      "step": 932
    },
    {
      "epoch": 0.10698314413484693,
      "grad_norm": 0.0,
      "learning_rate": 0.000984556184798026,
      "loss": 4.9696,
      "step": 933
    },
    {
      "epoch": 0.10709780988418759,
      "grad_norm": 0.0,
      "learning_rate": 0.0009845103576208716,
      "loss": 5.07,
      "step": 934
    },
    {
      "epoch": 0.10721247563352826,
      "grad_norm": 0.0,
      "learning_rate": 0.0009844644636216456,
      "loss": 4.9342,
      "step": 935
    },
    {
      "epoch": 0.10732714138286893,
      "grad_norm": 0.0,
      "learning_rate": 0.0009844185028066782,
      "loss": 5.3609,
      "step": 936
    },
    {
      "epoch": 0.1074418071322096,
      "grad_norm": 0.0,
      "learning_rate": 0.0009843724751823085,
      "loss": 4.8862,
      "step": 937
    },
    {
      "epoch": 0.10755647288155028,
      "grad_norm": 0.0,
      "learning_rate": 0.0009843263807548855,
      "loss": 5.0668,
      "step": 938
    },
    {
      "epoch": 0.10767113863089095,
      "grad_norm": 0.0,
      "learning_rate": 0.0009842802195307667,
      "loss": 5.0836,
      "step": 939
    },
    {
      "epoch": 0.10778580438023162,
      "grad_norm": 0.0,
      "learning_rate": 0.0009842339915163197,
      "loss": 4.8749,
      "step": 940
    },
    {
      "epoch": 0.1079004701295723,
      "grad_norm": 0.0,
      "learning_rate": 0.0009841876967179204,
      "loss": 5.1551,
      "step": 941
    },
    {
      "epoch": 0.10801513587891297,
      "grad_norm": 0.0,
      "learning_rate": 0.0009841413351419543,
      "loss": 5.0971,
      "step": 942
    },
    {
      "epoch": 0.10812980162825364,
      "grad_norm": 0.0,
      "learning_rate": 0.0009840949067948161,
      "loss": 5.0383,
      "step": 943
    },
    {
      "epoch": 0.10824446737759431,
      "grad_norm": 0.0,
      "learning_rate": 0.0009840484116829097,
      "loss": 5.0453,
      "step": 944
    },
    {
      "epoch": 0.10835913312693499,
      "grad_norm": 0.0,
      "learning_rate": 0.0009840018498126484,
      "loss": 5.0698,
      "step": 945
    },
    {
      "epoch": 0.10847379887627566,
      "grad_norm": 0.0,
      "learning_rate": 0.0009839552211904543,
      "loss": 4.8063,
      "step": 946
    },
    {
      "epoch": 0.10858846462561633,
      "grad_norm": 0.0,
      "learning_rate": 0.000983908525822759,
      "loss": 5.0679,
      "step": 947
    },
    {
      "epoch": 0.108703130374957,
      "grad_norm": 0.0,
      "learning_rate": 0.0009838617637160031,
      "loss": 5.174,
      "step": 948
    },
    {
      "epoch": 0.10881779612429768,
      "grad_norm": 0.0,
      "learning_rate": 0.000983814934876637,
      "loss": 4.9348,
      "step": 949
    },
    {
      "epoch": 0.10893246187363835,
      "grad_norm": 0.0,
      "learning_rate": 0.0009837680393111193,
      "loss": 4.6616,
      "step": 950
    },
    {
      "epoch": 0.10904712762297901,
      "grad_norm": 0.0,
      "learning_rate": 0.0009837210770259185,
      "loss": 5.0035,
      "step": 951
    },
    {
      "epoch": 0.10916179337231968,
      "grad_norm": 0.0,
      "learning_rate": 0.0009836740480275127,
      "loss": 4.8541,
      "step": 952
    },
    {
      "epoch": 0.10927645912166035,
      "grad_norm": 0.0,
      "learning_rate": 0.0009836269523223876,
      "loss": 4.7828,
      "step": 953
    },
    {
      "epoch": 0.10939112487100103,
      "grad_norm": 0.0,
      "learning_rate": 0.00098357978991704,
      "loss": 5.2599,
      "step": 954
    },
    {
      "epoch": 0.1095057906203417,
      "grad_norm": 0.0,
      "learning_rate": 0.000983532560817975,
      "loss": 4.7849,
      "step": 955
    },
    {
      "epoch": 0.10962045636968237,
      "grad_norm": 0.0,
      "learning_rate": 0.0009834852650317065,
      "loss": 5.0578,
      "step": 956
    },
    {
      "epoch": 0.10973512211902305,
      "grad_norm": 0.0,
      "learning_rate": 0.0009834379025647584,
      "loss": 4.8783,
      "step": 957
    },
    {
      "epoch": 0.10984978786836372,
      "grad_norm": 0.0,
      "learning_rate": 0.0009833904734236633,
      "loss": 5.0164,
      "step": 958
    },
    {
      "epoch": 0.10996445361770439,
      "grad_norm": 0.0,
      "learning_rate": 0.0009833429776149633,
      "loss": 5.1437,
      "step": 959
    },
    {
      "epoch": 0.11007911936704506,
      "grad_norm": 0.0,
      "learning_rate": 0.0009832954151452094,
      "loss": 5.1522,
      "step": 960
    },
    {
      "epoch": 0.11019378511638574,
      "grad_norm": 0.0,
      "learning_rate": 0.0009832477860209617,
      "loss": 5.1481,
      "step": 961
    },
    {
      "epoch": 0.11030845086572641,
      "grad_norm": 0.0,
      "learning_rate": 0.0009832000902487905,
      "loss": 5.0864,
      "step": 962
    },
    {
      "epoch": 0.11042311661506708,
      "grad_norm": 0.0,
      "learning_rate": 0.0009831523278352736,
      "loss": 5.1338,
      "step": 963
    },
    {
      "epoch": 0.11053778236440776,
      "grad_norm": 0.0,
      "learning_rate": 0.0009831044987869996,
      "loss": 5.151,
      "step": 964
    },
    {
      "epoch": 0.11065244811374843,
      "grad_norm": 0.0,
      "learning_rate": 0.0009830566031105651,
      "loss": 4.9296,
      "step": 965
    },
    {
      "epoch": 0.1107671138630891,
      "grad_norm": 0.0,
      "learning_rate": 0.0009830086408125769,
      "loss": 4.8198,
      "step": 966
    },
    {
      "epoch": 0.11088177961242977,
      "grad_norm": 0.0,
      "learning_rate": 0.0009829606118996503,
      "loss": 5.1846,
      "step": 967
    },
    {
      "epoch": 0.11099644536177045,
      "grad_norm": 0.0,
      "learning_rate": 0.0009829125163784097,
      "loss": 5.0146,
      "step": 968
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 0.0,
      "learning_rate": 0.000982864354255489,
      "loss": 5.0162,
      "step": 969
    },
    {
      "epoch": 0.11122577686045178,
      "grad_norm": 0.0,
      "learning_rate": 0.0009828161255375318,
      "loss": 4.9518,
      "step": 970
    },
    {
      "epoch": 0.11134044260979245,
      "grad_norm": 0.0,
      "learning_rate": 0.0009827678302311896,
      "loss": 5.0706,
      "step": 971
    },
    {
      "epoch": 0.11145510835913312,
      "grad_norm": 0.0,
      "learning_rate": 0.0009827194683431244,
      "loss": 4.9484,
      "step": 972
    },
    {
      "epoch": 0.1115697741084738,
      "grad_norm": 0.0,
      "learning_rate": 0.0009826710398800065,
      "loss": 4.8323,
      "step": 973
    },
    {
      "epoch": 0.11168443985781447,
      "grad_norm": 0.0,
      "learning_rate": 0.0009826225448485157,
      "loss": 4.9305,
      "step": 974
    },
    {
      "epoch": 0.11179910560715514,
      "grad_norm": 0.0,
      "learning_rate": 0.000982573983255341,
      "loss": 5.368,
      "step": 975
    },
    {
      "epoch": 0.11191377135649581,
      "grad_norm": 0.0,
      "learning_rate": 0.0009825253551071806,
      "loss": 4.9454,
      "step": 976
    },
    {
      "epoch": 0.11202843710583649,
      "grad_norm": 0.0,
      "learning_rate": 0.0009824766604107416,
      "loss": 4.6537,
      "step": 977
    },
    {
      "epoch": 0.11214310285517716,
      "grad_norm": 0.0,
      "learning_rate": 0.000982427899172741,
      "loss": 5.1037,
      "step": 978
    },
    {
      "epoch": 0.11225776860451783,
      "grad_norm": 0.0,
      "learning_rate": 0.0009823790713999038,
      "loss": 4.8724,
      "step": 979
    },
    {
      "epoch": 0.1123724343538585,
      "grad_norm": 0.0,
      "learning_rate": 0.0009823301770989657,
      "loss": 5.024,
      "step": 980
    },
    {
      "epoch": 0.11248710010319918,
      "grad_norm": 0.0,
      "learning_rate": 0.00098228121627667,
      "loss": 4.8897,
      "step": 981
    },
    {
      "epoch": 0.11260176585253985,
      "grad_norm": 0.0,
      "learning_rate": 0.00098223218893977,
      "loss": 4.9636,
      "step": 982
    },
    {
      "epoch": 0.11271643160188052,
      "grad_norm": 0.0,
      "learning_rate": 0.0009821830950950286,
      "loss": 4.8191,
      "step": 983
    },
    {
      "epoch": 0.1128310973512212,
      "grad_norm": 0.0,
      "learning_rate": 0.0009821339347492169,
      "loss": 5.1096,
      "step": 984
    },
    {
      "epoch": 0.11294576310056187,
      "grad_norm": 0.0,
      "learning_rate": 0.0009820847079091155,
      "loss": 5.1072,
      "step": 985
    },
    {
      "epoch": 0.11306042884990253,
      "grad_norm": 0.0,
      "learning_rate": 0.000982035414581515,
      "loss": 5.0303,
      "step": 986
    },
    {
      "epoch": 0.1131750945992432,
      "grad_norm": 0.0,
      "learning_rate": 0.0009819860547732138,
      "loss": 4.9369,
      "step": 987
    },
    {
      "epoch": 0.11328976034858387,
      "grad_norm": 0.0,
      "learning_rate": 0.0009819366284910204,
      "loss": 5.1193,
      "step": 988
    },
    {
      "epoch": 0.11340442609792455,
      "grad_norm": 0.0,
      "learning_rate": 0.0009818871357417523,
      "loss": 4.8527,
      "step": 989
    },
    {
      "epoch": 0.11351909184726522,
      "grad_norm": 0.0,
      "learning_rate": 0.0009818375765322357,
      "loss": 5.1112,
      "step": 990
    },
    {
      "epoch": 0.11363375759660589,
      "grad_norm": 0.0,
      "learning_rate": 0.000981787950869307,
      "loss": 5.2239,
      "step": 991
    },
    {
      "epoch": 0.11374842334594656,
      "grad_norm": 0.0,
      "learning_rate": 0.0009817382587598105,
      "loss": 5.0261,
      "step": 992
    },
    {
      "epoch": 0.11386308909528724,
      "grad_norm": 0.0,
      "learning_rate": 0.0009816885002106005,
      "loss": 4.9396,
      "step": 993
    },
    {
      "epoch": 0.11397775484462791,
      "grad_norm": 0.0,
      "learning_rate": 0.0009816386752285401,
      "loss": 4.9898,
      "step": 994
    },
    {
      "epoch": 0.11409242059396858,
      "grad_norm": 0.0,
      "learning_rate": 0.0009815887838205022,
      "loss": 5.0082,
      "step": 995
    },
    {
      "epoch": 0.11420708634330926,
      "grad_norm": 0.0,
      "learning_rate": 0.000981538825993368,
      "loss": 5.0734,
      "step": 996
    },
    {
      "epoch": 0.11432175209264993,
      "grad_norm": 0.0,
      "learning_rate": 0.0009814888017540282,
      "loss": 5.1829,
      "step": 997
    },
    {
      "epoch": 0.1144364178419906,
      "grad_norm": 0.0,
      "learning_rate": 0.0009814387111093828,
      "loss": 4.7147,
      "step": 998
    },
    {
      "epoch": 0.11455108359133127,
      "grad_norm": 0.0,
      "learning_rate": 0.0009813885540663407,
      "loss": 5.0782,
      "step": 999
    },
    {
      "epoch": 0.11466574934067195,
      "grad_norm": 0.0,
      "learning_rate": 0.00098133833063182,
      "loss": 4.8433,
      "step": 1000
    },
    {
      "epoch": 0.11478041509001262,
      "grad_norm": 0.0,
      "learning_rate": 0.0009812880408127489,
      "loss": 4.9312,
      "step": 1001
    },
    {
      "epoch": 0.11489508083935329,
      "grad_norm": 0.0,
      "learning_rate": 0.0009812376846160629,
      "loss": 5.2428,
      "step": 1002
    },
    {
      "epoch": 0.11500974658869395,
      "grad_norm": 0.0,
      "learning_rate": 0.0009811872620487082,
      "loss": 4.9457,
      "step": 1003
    },
    {
      "epoch": 0.11512441233803462,
      "grad_norm": 0.0,
      "learning_rate": 0.0009811367731176392,
      "loss": 5.2946,
      "step": 1004
    },
    {
      "epoch": 0.1152390780873753,
      "grad_norm": 0.0,
      "learning_rate": 0.0009810862178298205,
      "loss": 4.8133,
      "step": 1005
    },
    {
      "epoch": 0.11535374383671597,
      "grad_norm": 0.0,
      "learning_rate": 0.000981035596192225,
      "loss": 5.003,
      "step": 1006
    },
    {
      "epoch": 0.11546840958605664,
      "grad_norm": 0.0,
      "learning_rate": 0.0009809849082118346,
      "loss": 5.1659,
      "step": 1007
    },
    {
      "epoch": 0.11558307533539731,
      "grad_norm": 0.0,
      "learning_rate": 0.0009809341538956414,
      "loss": 4.9429,
      "step": 1008
    },
    {
      "epoch": 0.11569774108473799,
      "grad_norm": 0.0,
      "learning_rate": 0.0009808833332506453,
      "loss": 5.0766,
      "step": 1009
    },
    {
      "epoch": 0.11581240683407866,
      "grad_norm": 0.0,
      "learning_rate": 0.0009808324462838567,
      "loss": 5.0198,
      "step": 1010
    },
    {
      "epoch": 0.11592707258341933,
      "grad_norm": 0.0,
      "learning_rate": 0.0009807814930022942,
      "loss": 4.9471,
      "step": 1011
    },
    {
      "epoch": 0.11604173833276,
      "grad_norm": 0.0,
      "learning_rate": 0.0009807304734129856,
      "loss": 5.2505,
      "step": 1012
    },
    {
      "epoch": 0.11615640408210068,
      "grad_norm": 0.0,
      "learning_rate": 0.0009806793875229685,
      "loss": 5.2133,
      "step": 1013
    },
    {
      "epoch": 0.11627106983144135,
      "grad_norm": 0.0,
      "learning_rate": 0.0009806282353392887,
      "loss": 4.898,
      "step": 1014
    },
    {
      "epoch": 0.11638573558078202,
      "grad_norm": 0.0,
      "learning_rate": 0.0009805770168690023,
      "loss": 5.1543,
      "step": 1015
    },
    {
      "epoch": 0.1165004013301227,
      "grad_norm": 0.0,
      "learning_rate": 0.0009805257321191735,
      "loss": 4.8778,
      "step": 1016
    },
    {
      "epoch": 0.11661506707946337,
      "grad_norm": 0.0,
      "learning_rate": 0.0009804743810968763,
      "loss": 4.7372,
      "step": 1017
    },
    {
      "epoch": 0.11672973282880404,
      "grad_norm": 0.0,
      "learning_rate": 0.0009804229638091934,
      "loss": 5.1369,
      "step": 1018
    },
    {
      "epoch": 0.11684439857814471,
      "grad_norm": 0.0,
      "learning_rate": 0.0009803714802632166,
      "loss": 4.9653,
      "step": 1019
    },
    {
      "epoch": 0.11695906432748537,
      "grad_norm": 0.0,
      "learning_rate": 0.0009803199304660476,
      "loss": 5.1434,
      "step": 1020
    },
    {
      "epoch": 0.11707373007682605,
      "grad_norm": 0.0,
      "learning_rate": 0.0009802683144247964,
      "loss": 5.0342,
      "step": 1021
    },
    {
      "epoch": 0.11718839582616672,
      "grad_norm": 0.0,
      "learning_rate": 0.0009802166321465826,
      "loss": 5.3673,
      "step": 1022
    },
    {
      "epoch": 0.11730306157550739,
      "grad_norm": 0.0,
      "learning_rate": 0.0009801648836385347,
      "loss": 4.9497,
      "step": 1023
    },
    {
      "epoch": 0.11741772732484806,
      "grad_norm": 0.0,
      "learning_rate": 0.0009801130689077904,
      "loss": 4.9053,
      "step": 1024
    },
    {
      "epoch": 0.11753239307418874,
      "grad_norm": 0.0,
      "learning_rate": 0.0009800611879614966,
      "loss": 5.027,
      "step": 1025
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 0.0,
      "learning_rate": 0.0009800092408068092,
      "loss": 5.0046,
      "step": 1026
    },
    {
      "epoch": 0.11776172457287008,
      "grad_norm": 0.0,
      "learning_rate": 0.0009799572274508935,
      "loss": 5.1616,
      "step": 1027
    },
    {
      "epoch": 0.11787639032221076,
      "grad_norm": 0.0,
      "learning_rate": 0.0009799051479009234,
      "loss": 4.9894,
      "step": 1028
    },
    {
      "epoch": 0.11799105607155143,
      "grad_norm": 0.0,
      "learning_rate": 0.0009798530021640826,
      "loss": 4.9447,
      "step": 1029
    },
    {
      "epoch": 0.1181057218208921,
      "grad_norm": 0.0,
      "learning_rate": 0.0009798007902475636,
      "loss": 5.1168,
      "step": 1030
    },
    {
      "epoch": 0.11822038757023277,
      "grad_norm": 0.0,
      "learning_rate": 0.000979748512158568,
      "loss": 4.7762,
      "step": 1031
    },
    {
      "epoch": 0.11833505331957345,
      "grad_norm": 0.0,
      "learning_rate": 0.0009796961679043065,
      "loss": 5.208,
      "step": 1032
    },
    {
      "epoch": 0.11844971906891412,
      "grad_norm": 0.0,
      "learning_rate": 0.000979643757491999,
      "loss": 4.8221,
      "step": 1033
    },
    {
      "epoch": 0.11856438481825479,
      "grad_norm": 0.0,
      "learning_rate": 0.0009795912809288747,
      "loss": 4.7388,
      "step": 1034
    },
    {
      "epoch": 0.11867905056759546,
      "grad_norm": 0.0,
      "learning_rate": 0.0009795387382221714,
      "loss": 5.1194,
      "step": 1035
    },
    {
      "epoch": 0.11879371631693614,
      "grad_norm": 0.0,
      "learning_rate": 0.0009794861293791364,
      "loss": 5.1697,
      "step": 1036
    },
    {
      "epoch": 0.1189083820662768,
      "grad_norm": 0.0,
      "learning_rate": 0.0009794334544070266,
      "loss": 5.0705,
      "step": 1037
    },
    {
      "epoch": 0.11902304781561747,
      "grad_norm": 0.0,
      "learning_rate": 0.000979380713313107,
      "loss": 4.9201,
      "step": 1038
    },
    {
      "epoch": 0.11913771356495814,
      "grad_norm": 0.0,
      "learning_rate": 0.0009793279061046524,
      "loss": 4.8714,
      "step": 1039
    },
    {
      "epoch": 0.11925237931429881,
      "grad_norm": 0.0,
      "learning_rate": 0.0009792750327889464,
      "loss": 4.9737,
      "step": 1040
    },
    {
      "epoch": 0.11936704506363949,
      "grad_norm": 0.0,
      "learning_rate": 0.0009792220933732818,
      "loss": 4.8057,
      "step": 1041
    },
    {
      "epoch": 0.11948171081298016,
      "grad_norm": 0.0,
      "learning_rate": 0.0009791690878649612,
      "loss": 4.844,
      "step": 1042
    },
    {
      "epoch": 0.11959637656232083,
      "grad_norm": 0.0,
      "learning_rate": 0.000979116016271295,
      "loss": 5.0229,
      "step": 1043
    },
    {
      "epoch": 0.1197110423116615,
      "grad_norm": 0.0,
      "learning_rate": 0.0009790628785996038,
      "loss": 4.9853,
      "step": 1044
    },
    {
      "epoch": 0.11982570806100218,
      "grad_norm": 0.0,
      "learning_rate": 0.0009790096748572169,
      "loss": 5.0065,
      "step": 1045
    },
    {
      "epoch": 0.11994037381034285,
      "grad_norm": 0.0,
      "learning_rate": 0.0009789564050514726,
      "loss": 4.9301,
      "step": 1046
    },
    {
      "epoch": 0.12005503955968352,
      "grad_norm": 0.0,
      "learning_rate": 0.0009789030691897186,
      "loss": 5.1743,
      "step": 1047
    },
    {
      "epoch": 0.1201697053090242,
      "grad_norm": 0.0,
      "learning_rate": 0.0009788496672793112,
      "loss": 5.1795,
      "step": 1048
    },
    {
      "epoch": 0.12028437105836487,
      "grad_norm": 0.0,
      "learning_rate": 0.0009787961993276166,
      "loss": 5.037,
      "step": 1049
    },
    {
      "epoch": 0.12039903680770554,
      "grad_norm": 0.0,
      "learning_rate": 0.0009787426653420095,
      "loss": 5.1214,
      "step": 1050
    },
    {
      "epoch": 0.12051370255704622,
      "grad_norm": 0.0,
      "learning_rate": 0.000978689065329874,
      "loss": 5.2027,
      "step": 1051
    },
    {
      "epoch": 0.12062836830638689,
      "grad_norm": 0.0,
      "learning_rate": 0.000978635399298603,
      "loss": 5.1828,
      "step": 1052
    },
    {
      "epoch": 0.12074303405572756,
      "grad_norm": 0.0,
      "learning_rate": 0.000978581667255599,
      "loss": 4.987,
      "step": 1053
    },
    {
      "epoch": 0.12085769980506822,
      "grad_norm": 0.0,
      "learning_rate": 0.000978527869208273,
      "loss": 4.9878,
      "step": 1054
    },
    {
      "epoch": 0.12097236555440889,
      "grad_norm": 0.0,
      "learning_rate": 0.0009784740051640456,
      "loss": 4.9648,
      "step": 1055
    },
    {
      "epoch": 0.12108703130374956,
      "grad_norm": 0.0,
      "learning_rate": 0.0009784200751303462,
      "loss": 5.1278,
      "step": 1056
    },
    {
      "epoch": 0.12120169705309024,
      "grad_norm": 0.0,
      "learning_rate": 0.0009783660791146138,
      "loss": 5.111,
      "step": 1057
    },
    {
      "epoch": 0.12131636280243091,
      "grad_norm": 0.0,
      "learning_rate": 0.0009783120171242955,
      "loss": 4.7434,
      "step": 1058
    },
    {
      "epoch": 0.12143102855177158,
      "grad_norm": 0.0,
      "learning_rate": 0.0009782578891668486,
      "loss": 5.2506,
      "step": 1059
    },
    {
      "epoch": 0.12154569430111226,
      "grad_norm": 0.0,
      "learning_rate": 0.0009782036952497388,
      "loss": 5.0456,
      "step": 1060
    },
    {
      "epoch": 0.12166036005045293,
      "grad_norm": 0.0,
      "learning_rate": 0.000978149435380441,
      "loss": 4.9653,
      "step": 1061
    },
    {
      "epoch": 0.1217750257997936,
      "grad_norm": 0.0,
      "learning_rate": 0.0009780951095664397,
      "loss": 4.9816,
      "step": 1062
    },
    {
      "epoch": 0.12188969154913427,
      "grad_norm": 0.0,
      "learning_rate": 0.0009780407178152282,
      "loss": 5.1847,
      "step": 1063
    },
    {
      "epoch": 0.12200435729847495,
      "grad_norm": 0.0,
      "learning_rate": 0.000977986260134308,
      "loss": 4.9572,
      "step": 1064
    },
    {
      "epoch": 0.12211902304781562,
      "grad_norm": 0.0,
      "learning_rate": 0.0009779317365311913,
      "loss": 4.6676,
      "step": 1065
    },
    {
      "epoch": 0.12223368879715629,
      "grad_norm": 0.0,
      "learning_rate": 0.0009778771470133982,
      "loss": 4.945,
      "step": 1066
    },
    {
      "epoch": 0.12234835454649697,
      "grad_norm": 0.0,
      "learning_rate": 0.0009778224915884585,
      "loss": 5.0375,
      "step": 1067
    },
    {
      "epoch": 0.12246302029583764,
      "grad_norm": 0.0,
      "learning_rate": 0.0009777677702639106,
      "loss": 4.9144,
      "step": 1068
    },
    {
      "epoch": 0.12257768604517831,
      "grad_norm": 0.0,
      "learning_rate": 0.0009777129830473024,
      "loss": 5.0804,
      "step": 1069
    },
    {
      "epoch": 0.12269235179451898,
      "grad_norm": 0.0,
      "learning_rate": 0.000977658129946191,
      "loss": 5.2789,
      "step": 1070
    },
    {
      "epoch": 0.12280701754385964,
      "grad_norm": 0.0,
      "learning_rate": 0.0009776032109681417,
      "loss": 4.912,
      "step": 1071
    },
    {
      "epoch": 0.12292168329320032,
      "grad_norm": 0.0,
      "learning_rate": 0.0009775482261207304,
      "loss": 5.1649,
      "step": 1072
    },
    {
      "epoch": 0.12303634904254099,
      "grad_norm": 0.0,
      "learning_rate": 0.0009774931754115404,
      "loss": 4.6938,
      "step": 1073
    },
    {
      "epoch": 0.12315101479188166,
      "grad_norm": 0.0,
      "learning_rate": 0.0009774380588481655,
      "loss": 4.8651,
      "step": 1074
    },
    {
      "epoch": 0.12326568054122233,
      "grad_norm": 0.0,
      "learning_rate": 0.0009773828764382075,
      "loss": 4.9984,
      "step": 1075
    },
    {
      "epoch": 0.123380346290563,
      "grad_norm": 0.0,
      "learning_rate": 0.0009773276281892782,
      "loss": 5.2828,
      "step": 1076
    },
    {
      "epoch": 0.12349501203990368,
      "grad_norm": 0.0,
      "learning_rate": 0.0009772723141089977,
      "loss": 4.9042,
      "step": 1077
    },
    {
      "epoch": 0.12360967778924435,
      "grad_norm": 0.0,
      "learning_rate": 0.0009772169342049956,
      "loss": 5.0354,
      "step": 1078
    },
    {
      "epoch": 0.12372434353858502,
      "grad_norm": 0.0,
      "learning_rate": 0.0009771614884849108,
      "loss": 5.3083,
      "step": 1079
    },
    {
      "epoch": 0.1238390092879257,
      "grad_norm": 0.0,
      "learning_rate": 0.0009771059769563906,
      "loss": 5.2404,
      "step": 1080
    },
    {
      "epoch": 0.12395367503726637,
      "grad_norm": 0.0,
      "learning_rate": 0.0009770503996270918,
      "loss": 4.9522,
      "step": 1081
    },
    {
      "epoch": 0.12406834078660704,
      "grad_norm": 0.0,
      "learning_rate": 0.0009769947565046804,
      "loss": 4.7874,
      "step": 1082
    },
    {
      "epoch": 0.12418300653594772,
      "grad_norm": 0.0,
      "learning_rate": 0.0009769390475968314,
      "loss": 4.9183,
      "step": 1083
    },
    {
      "epoch": 0.12429767228528839,
      "grad_norm": 0.0,
      "learning_rate": 0.0009768832729112283,
      "loss": 5.0387,
      "step": 1084
    },
    {
      "epoch": 0.12441233803462906,
      "grad_norm": 0.0,
      "learning_rate": 0.0009768274324555646,
      "loss": 5.1811,
      "step": 1085
    },
    {
      "epoch": 0.12452700378396973,
      "grad_norm": 0.0,
      "learning_rate": 0.0009767715262375422,
      "loss": 4.99,
      "step": 1086
    },
    {
      "epoch": 0.1246416695333104,
      "grad_norm": 0.0,
      "learning_rate": 0.0009767155542648727,
      "loss": 4.9794,
      "step": 1087
    },
    {
      "epoch": 0.12475633528265107,
      "grad_norm": 0.0,
      "learning_rate": 0.000976659516545276,
      "loss": 4.9014,
      "step": 1088
    },
    {
      "epoch": 0.12487100103199174,
      "grad_norm": 0.0,
      "learning_rate": 0.0009766034130864812,
      "loss": 4.8991,
      "step": 1089
    },
    {
      "epoch": 0.12498566678133241,
      "grad_norm": 0.0,
      "learning_rate": 0.0009765472438962272,
      "loss": 5.0789,
      "step": 1090
    },
    {
      "epoch": 0.1251003325306731,
      "grad_norm": 0.0,
      "learning_rate": 0.0009764910089822612,
      "loss": 5.0736,
      "step": 1091
    },
    {
      "epoch": 0.12521499828001376,
      "grad_norm": 0.0,
      "learning_rate": 0.00097643470835234,
      "loss": 5.2898,
      "step": 1092
    },
    {
      "epoch": 0.12532966402935444,
      "grad_norm": 0.0,
      "learning_rate": 0.0009763783420142289,
      "loss": 5.0988,
      "step": 1093
    },
    {
      "epoch": 0.1254443297786951,
      "grad_norm": 0.0,
      "learning_rate": 0.0009763219099757025,
      "loss": 5.0906,
      "step": 1094
    },
    {
      "epoch": 0.1255589955280358,
      "grad_norm": 0.0,
      "learning_rate": 0.000976265412244545,
      "loss": 5.0063,
      "step": 1095
    },
    {
      "epoch": 0.12567366127737645,
      "grad_norm": 0.0,
      "learning_rate": 0.0009762088488285485,
      "loss": 5.0225,
      "step": 1096
    },
    {
      "epoch": 0.1257883270267171,
      "grad_norm": 0.0,
      "learning_rate": 0.0009761522197355153,
      "loss": 5.2156,
      "step": 1097
    },
    {
      "epoch": 0.1259029927760578,
      "grad_norm": 0.0,
      "learning_rate": 0.0009760955249732563,
      "loss": 4.736,
      "step": 1098
    },
    {
      "epoch": 0.12601765852539845,
      "grad_norm": 0.0,
      "learning_rate": 0.0009760387645495915,
      "loss": 5.2037,
      "step": 1099
    },
    {
      "epoch": 0.12613232427473914,
      "grad_norm": 0.0,
      "learning_rate": 0.0009759819384723496,
      "loss": 4.9698,
      "step": 1100
    },
    {
      "epoch": 0.1262469900240798,
      "grad_norm": 0.0,
      "learning_rate": 0.0009759250467493691,
      "loss": 4.9748,
      "step": 1101
    },
    {
      "epoch": 0.12636165577342048,
      "grad_norm": 0.0,
      "learning_rate": 0.0009758680893884967,
      "loss": 4.9012,
      "step": 1102
    },
    {
      "epoch": 0.12647632152276114,
      "grad_norm": 0.0,
      "learning_rate": 0.0009758110663975889,
      "loss": 5.1113,
      "step": 1103
    },
    {
      "epoch": 0.12659098727210183,
      "grad_norm": 0.0,
      "learning_rate": 0.0009757539777845108,
      "loss": 5.2881,
      "step": 1104
    },
    {
      "epoch": 0.1267056530214425,
      "grad_norm": 0.0,
      "learning_rate": 0.0009756968235571367,
      "loss": 5.0736,
      "step": 1105
    },
    {
      "epoch": 0.12682031877078317,
      "grad_norm": 0.0,
      "learning_rate": 0.0009756396037233499,
      "loss": 5.0998,
      "step": 1106
    },
    {
      "epoch": 0.12693498452012383,
      "grad_norm": 0.0,
      "learning_rate": 0.0009755823182910428,
      "loss": 4.8493,
      "step": 1107
    },
    {
      "epoch": 0.12704965026946452,
      "grad_norm": 0.0,
      "learning_rate": 0.000975524967268117,
      "loss": 5.0894,
      "step": 1108
    },
    {
      "epoch": 0.12716431601880518,
      "grad_norm": 0.0,
      "learning_rate": 0.0009754675506624828,
      "loss": 5.0304,
      "step": 1109
    },
    {
      "epoch": 0.12727898176814587,
      "grad_norm": 0.0,
      "learning_rate": 0.0009754100684820597,
      "loss": 4.7938,
      "step": 1110
    },
    {
      "epoch": 0.12739364751748652,
      "grad_norm": 0.0,
      "learning_rate": 0.0009753525207347763,
      "loss": 4.9905,
      "step": 1111
    },
    {
      "epoch": 0.1275083132668272,
      "grad_norm": 0.0,
      "learning_rate": 0.0009752949074285704,
      "loss": 5.1203,
      "step": 1112
    },
    {
      "epoch": 0.12762297901616787,
      "grad_norm": 0.0,
      "learning_rate": 0.0009752372285713885,
      "loss": 4.8641,
      "step": 1113
    },
    {
      "epoch": 0.12773764476550853,
      "grad_norm": 0.0,
      "learning_rate": 0.0009751794841711862,
      "loss": 4.5812,
      "step": 1114
    },
    {
      "epoch": 0.12785231051484922,
      "grad_norm": 0.0,
      "learning_rate": 0.0009751216742359285,
      "loss": 5.0378,
      "step": 1115
    },
    {
      "epoch": 0.12796697626418987,
      "grad_norm": 0.0,
      "learning_rate": 0.0009750637987735889,
      "loss": 5.1276,
      "step": 1116
    },
    {
      "epoch": 0.12808164201353056,
      "grad_norm": 0.0,
      "learning_rate": 0.0009750058577921504,
      "loss": 5.1141,
      "step": 1117
    },
    {
      "epoch": 0.12819630776287122,
      "grad_norm": 0.0,
      "learning_rate": 0.0009749478512996047,
      "loss": 5.3202,
      "step": 1118
    },
    {
      "epoch": 0.1283109735122119,
      "grad_norm": 0.0,
      "learning_rate": 0.0009748897793039529,
      "loss": 4.729,
      "step": 1119
    },
    {
      "epoch": 0.12842563926155257,
      "grad_norm": 0.0,
      "learning_rate": 0.0009748316418132047,
      "loss": 5.1896,
      "step": 1120
    },
    {
      "epoch": 0.12854030501089325,
      "grad_norm": 0.0,
      "learning_rate": 0.0009747734388353792,
      "loss": 4.8163,
      "step": 1121
    },
    {
      "epoch": 0.1286549707602339,
      "grad_norm": 0.0,
      "learning_rate": 0.0009747151703785045,
      "loss": 4.9617,
      "step": 1122
    },
    {
      "epoch": 0.1287696365095746,
      "grad_norm": 0.0,
      "learning_rate": 0.0009746568364506175,
      "loss": 4.9084,
      "step": 1123
    },
    {
      "epoch": 0.12888430225891526,
      "grad_norm": 0.0,
      "learning_rate": 0.0009745984370597642,
      "loss": 5.0312,
      "step": 1124
    },
    {
      "epoch": 0.12899896800825594,
      "grad_norm": 0.0,
      "learning_rate": 0.0009745399722139997,
      "loss": 4.8962,
      "step": 1125
    },
    {
      "epoch": 0.1291136337575966,
      "grad_norm": 0.0,
      "learning_rate": 0.0009744814419213881,
      "loss": 4.789,
      "step": 1126
    },
    {
      "epoch": 0.1292282995069373,
      "grad_norm": 0.0,
      "learning_rate": 0.0009744228461900026,
      "loss": 5.3122,
      "step": 1127
    },
    {
      "epoch": 0.12934296525627795,
      "grad_norm": 0.0,
      "learning_rate": 0.0009743641850279252,
      "loss": 4.9731,
      "step": 1128
    },
    {
      "epoch": 0.12945763100561863,
      "grad_norm": 0.0,
      "learning_rate": 0.0009743054584432474,
      "loss": 4.9449,
      "step": 1129
    },
    {
      "epoch": 0.1295722967549593,
      "grad_norm": 0.0,
      "learning_rate": 0.0009742466664440691,
      "loss": 4.9209,
      "step": 1130
    },
    {
      "epoch": 0.12968696250429995,
      "grad_norm": 0.0,
      "learning_rate": 0.0009741878090384998,
      "loss": 4.8246,
      "step": 1131
    },
    {
      "epoch": 0.12980162825364064,
      "grad_norm": 0.0,
      "learning_rate": 0.0009741288862346576,
      "loss": 5.1338,
      "step": 1132
    },
    {
      "epoch": 0.1299162940029813,
      "grad_norm": 0.0,
      "learning_rate": 0.00097406989804067,
      "loss": 4.8365,
      "step": 1133
    },
    {
      "epoch": 0.13003095975232198,
      "grad_norm": 0.0,
      "learning_rate": 0.0009740108444646726,
      "loss": 4.936,
      "step": 1134
    },
    {
      "epoch": 0.13014562550166264,
      "grad_norm": 0.0,
      "learning_rate": 0.0009739517255148117,
      "loss": 5.0088,
      "step": 1135
    },
    {
      "epoch": 0.13026029125100333,
      "grad_norm": 0.0,
      "learning_rate": 0.0009738925411992409,
      "loss": 4.9472,
      "step": 1136
    },
    {
      "epoch": 0.130374957000344,
      "grad_norm": 0.0,
      "learning_rate": 0.000973833291526124,
      "loss": 5.0884,
      "step": 1137
    },
    {
      "epoch": 0.13048962274968468,
      "grad_norm": 0.0,
      "learning_rate": 0.0009737739765036331,
      "loss": 4.7891,
      "step": 1138
    },
    {
      "epoch": 0.13060428849902533,
      "grad_norm": 0.0,
      "learning_rate": 0.0009737145961399495,
      "loss": 4.8975,
      "step": 1139
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 0.0,
      "learning_rate": 0.0009736551504432638,
      "loss": 5.2223,
      "step": 1140
    },
    {
      "epoch": 0.13083361999770668,
      "grad_norm": 0.0,
      "learning_rate": 0.0009735956394217755,
      "loss": 4.8253,
      "step": 1141
    },
    {
      "epoch": 0.13094828574704737,
      "grad_norm": 0.0,
      "learning_rate": 0.0009735360630836926,
      "loss": 4.7068,
      "step": 1142
    },
    {
      "epoch": 0.13106295149638802,
      "grad_norm": 0.0,
      "learning_rate": 0.0009734764214372328,
      "loss": 5.1128,
      "step": 1143
    },
    {
      "epoch": 0.1311776172457287,
      "grad_norm": 0.0,
      "learning_rate": 0.0009734167144906227,
      "loss": 5.0628,
      "step": 1144
    },
    {
      "epoch": 0.13129228299506937,
      "grad_norm": 0.0,
      "learning_rate": 0.0009733569422520973,
      "loss": 4.9294,
      "step": 1145
    },
    {
      "epoch": 0.13140694874441006,
      "grad_norm": 0.0,
      "learning_rate": 0.0009732971047299014,
      "loss": 4.7278,
      "step": 1146
    },
    {
      "epoch": 0.13152161449375072,
      "grad_norm": 0.0,
      "learning_rate": 0.0009732372019322882,
      "loss": 5.0794,
      "step": 1147
    },
    {
      "epoch": 0.13163628024309137,
      "grad_norm": 0.0,
      "learning_rate": 0.0009731772338675203,
      "loss": 4.9861,
      "step": 1148
    },
    {
      "epoch": 0.13175094599243206,
      "grad_norm": 0.0,
      "learning_rate": 0.0009731172005438691,
      "loss": 5.0742,
      "step": 1149
    },
    {
      "epoch": 0.13186561174177272,
      "grad_norm": 0.0,
      "learning_rate": 0.0009730571019696152,
      "loss": 5.0514,
      "step": 1150
    },
    {
      "epoch": 0.1319802774911134,
      "grad_norm": 0.0,
      "learning_rate": 0.0009729969381530478,
      "loss": 5.0717,
      "step": 1151
    },
    {
      "epoch": 0.13209494324045407,
      "grad_norm": 0.0,
      "learning_rate": 0.0009729367091024655,
      "loss": 4.8059,
      "step": 1152
    },
    {
      "epoch": 0.13220960898979475,
      "grad_norm": 0.0,
      "learning_rate": 0.0009728764148261757,
      "loss": 5.1456,
      "step": 1153
    },
    {
      "epoch": 0.1323242747391354,
      "grad_norm": 0.0,
      "learning_rate": 0.0009728160553324949,
      "loss": 4.8343,
      "step": 1154
    },
    {
      "epoch": 0.1324389404884761,
      "grad_norm": 0.0,
      "learning_rate": 0.0009727556306297486,
      "loss": 4.976,
      "step": 1155
    },
    {
      "epoch": 0.13255360623781676,
      "grad_norm": 0.0,
      "learning_rate": 0.0009726951407262709,
      "loss": 4.7795,
      "step": 1156
    },
    {
      "epoch": 0.13266827198715744,
      "grad_norm": 0.0,
      "learning_rate": 0.0009726345856304056,
      "loss": 5.0696,
      "step": 1157
    },
    {
      "epoch": 0.1327829377364981,
      "grad_norm": 0.0,
      "learning_rate": 0.0009725739653505051,
      "loss": 4.9653,
      "step": 1158
    },
    {
      "epoch": 0.1328976034858388,
      "grad_norm": 0.0,
      "learning_rate": 0.0009725132798949305,
      "loss": 4.8989,
      "step": 1159
    },
    {
      "epoch": 0.13301226923517945,
      "grad_norm": 0.0,
      "learning_rate": 0.0009724525292720527,
      "loss": 4.8201,
      "step": 1160
    },
    {
      "epoch": 0.13312693498452013,
      "grad_norm": 0.0,
      "learning_rate": 0.0009723917134902505,
      "loss": 5.0272,
      "step": 1161
    },
    {
      "epoch": 0.1332416007338608,
      "grad_norm": 0.0,
      "learning_rate": 0.0009723308325579127,
      "loss": 5.1219,
      "step": 1162
    },
    {
      "epoch": 0.13335626648320148,
      "grad_norm": 0.0,
      "learning_rate": 0.0009722698864834364,
      "loss": 5.109,
      "step": 1163
    },
    {
      "epoch": 0.13347093223254214,
      "grad_norm": 0.0,
      "learning_rate": 0.0009722088752752283,
      "loss": 4.9384,
      "step": 1164
    },
    {
      "epoch": 0.13358559798188283,
      "grad_norm": 0.0,
      "learning_rate": 0.0009721477989417035,
      "loss": 5.1917,
      "step": 1165
    },
    {
      "epoch": 0.13370026373122348,
      "grad_norm": 0.0,
      "learning_rate": 0.0009720866574912862,
      "loss": 5.1578,
      "step": 1166
    },
    {
      "epoch": 0.13381492948056414,
      "grad_norm": 0.0,
      "learning_rate": 0.0009720254509324099,
      "loss": 4.9851,
      "step": 1167
    },
    {
      "epoch": 0.13392959522990483,
      "grad_norm": 0.0,
      "learning_rate": 0.0009719641792735168,
      "loss": 5.2156,
      "step": 1168
    },
    {
      "epoch": 0.1340442609792455,
      "grad_norm": 0.0,
      "learning_rate": 0.0009719028425230582,
      "loss": 5.2443,
      "step": 1169
    },
    {
      "epoch": 0.13415892672858618,
      "grad_norm": 0.0,
      "learning_rate": 0.0009718414406894943,
      "loss": 4.8561,
      "step": 1170
    },
    {
      "epoch": 0.13427359247792683,
      "grad_norm": 0.0,
      "learning_rate": 0.0009717799737812943,
      "loss": 5.1325,
      "step": 1171
    },
    {
      "epoch": 0.13438825822726752,
      "grad_norm": 0.0,
      "learning_rate": 0.0009717184418069366,
      "loss": 5.0399,
      "step": 1172
    },
    {
      "epoch": 0.13450292397660818,
      "grad_norm": 0.0,
      "learning_rate": 0.0009716568447749079,
      "loss": 4.8722,
      "step": 1173
    },
    {
      "epoch": 0.13461758972594887,
      "grad_norm": 0.0,
      "learning_rate": 0.0009715951826937048,
      "loss": 4.994,
      "step": 1174
    },
    {
      "epoch": 0.13473225547528953,
      "grad_norm": 0.0,
      "learning_rate": 0.0009715334555718321,
      "loss": 5.1477,
      "step": 1175
    },
    {
      "epoch": 0.1348469212246302,
      "grad_norm": 0.0,
      "learning_rate": 0.0009714716634178039,
      "loss": 4.99,
      "step": 1176
    },
    {
      "epoch": 0.13496158697397087,
      "grad_norm": 0.0,
      "learning_rate": 0.0009714098062401436,
      "loss": 5.0182,
      "step": 1177
    },
    {
      "epoch": 0.13507625272331156,
      "grad_norm": 0.0,
      "learning_rate": 0.0009713478840473828,
      "loss": 5.0274,
      "step": 1178
    },
    {
      "epoch": 0.13519091847265222,
      "grad_norm": 0.0,
      "learning_rate": 0.0009712858968480627,
      "loss": 5.0618,
      "step": 1179
    },
    {
      "epoch": 0.1353055842219929,
      "grad_norm": 0.0,
      "learning_rate": 0.0009712238446507332,
      "loss": 4.9621,
      "step": 1180
    },
    {
      "epoch": 0.13542024997133356,
      "grad_norm": 0.0,
      "learning_rate": 0.0009711617274639532,
      "loss": 4.9873,
      "step": 1181
    },
    {
      "epoch": 0.13553491572067425,
      "grad_norm": 0.0,
      "learning_rate": 0.0009710995452962907,
      "loss": 4.9254,
      "step": 1182
    },
    {
      "epoch": 0.1356495814700149,
      "grad_norm": 0.0,
      "learning_rate": 0.0009710372981563222,
      "loss": 5.0145,
      "step": 1183
    },
    {
      "epoch": 0.13576424721935557,
      "grad_norm": 0.0,
      "learning_rate": 0.0009709749860526341,
      "loss": 4.9389,
      "step": 1184
    },
    {
      "epoch": 0.13587891296869625,
      "grad_norm": 0.0,
      "learning_rate": 0.0009709126089938206,
      "loss": 5.0166,
      "step": 1185
    },
    {
      "epoch": 0.1359935787180369,
      "grad_norm": 0.0,
      "learning_rate": 0.0009708501669884856,
      "loss": 5.1209,
      "step": 1186
    },
    {
      "epoch": 0.1361082444673776,
      "grad_norm": 0.0,
      "learning_rate": 0.0009707876600452419,
      "loss": 5.0347,
      "step": 1187
    },
    {
      "epoch": 0.13622291021671826,
      "grad_norm": 0.0,
      "learning_rate": 0.0009707250881727111,
      "loss": 4.9948,
      "step": 1188
    },
    {
      "epoch": 0.13633757596605894,
      "grad_norm": 0.0,
      "learning_rate": 0.0009706624513795238,
      "loss": 4.9901,
      "step": 1189
    },
    {
      "epoch": 0.1364522417153996,
      "grad_norm": 0.0,
      "learning_rate": 0.0009705997496743195,
      "loss": 4.9178,
      "step": 1190
    },
    {
      "epoch": 0.1365669074647403,
      "grad_norm": 0.0,
      "learning_rate": 0.0009705369830657466,
      "loss": 4.7497,
      "step": 1191
    },
    {
      "epoch": 0.13668157321408095,
      "grad_norm": 0.0,
      "learning_rate": 0.0009704741515624629,
      "loss": 5.0802,
      "step": 1192
    },
    {
      "epoch": 0.13679623896342163,
      "grad_norm": 0.0,
      "learning_rate": 0.0009704112551731345,
      "loss": 4.7692,
      "step": 1193
    },
    {
      "epoch": 0.1369109047127623,
      "grad_norm": 0.0,
      "learning_rate": 0.0009703482939064367,
      "loss": 5.0565,
      "step": 1194
    },
    {
      "epoch": 0.13702557046210298,
      "grad_norm": 0.0,
      "learning_rate": 0.0009702852677710543,
      "loss": 4.7582,
      "step": 1195
    },
    {
      "epoch": 0.13714023621144364,
      "grad_norm": 0.0,
      "learning_rate": 0.0009702221767756799,
      "loss": 5.4087,
      "step": 1196
    },
    {
      "epoch": 0.13725490196078433,
      "grad_norm": 0.0,
      "learning_rate": 0.0009701590209290161,
      "loss": 4.7789,
      "step": 1197
    },
    {
      "epoch": 0.13736956771012498,
      "grad_norm": 0.0,
      "learning_rate": 0.000970095800239774,
      "loss": 4.7273,
      "step": 1198
    },
    {
      "epoch": 0.13748423345946567,
      "grad_norm": 0.0,
      "learning_rate": 0.0009700325147166735,
      "loss": 4.9561,
      "step": 1199
    },
    {
      "epoch": 0.13759889920880633,
      "grad_norm": 0.0,
      "learning_rate": 0.0009699691643684441,
      "loss": 4.8236,
      "step": 1200
    },
    {
      "epoch": 0.137713564958147,
      "grad_norm": 0.0,
      "learning_rate": 0.0009699057492038231,
      "loss": 4.8939,
      "step": 1201
    },
    {
      "epoch": 0.13782823070748768,
      "grad_norm": 0.0,
      "learning_rate": 0.0009698422692315579,
      "loss": 4.8276,
      "step": 1202
    },
    {
      "epoch": 0.13794289645682833,
      "grad_norm": 0.0,
      "learning_rate": 0.0009697787244604041,
      "loss": 5.0226,
      "step": 1203
    },
    {
      "epoch": 0.13805756220616902,
      "grad_norm": 0.0,
      "learning_rate": 0.0009697151148991268,
      "loss": 4.8672,
      "step": 1204
    },
    {
      "epoch": 0.13817222795550968,
      "grad_norm": 0.0,
      "learning_rate": 0.0009696514405564995,
      "loss": 4.9506,
      "step": 1205
    },
    {
      "epoch": 0.13828689370485037,
      "grad_norm": 0.0,
      "learning_rate": 0.0009695877014413048,
      "loss": 4.7553,
      "step": 1206
    },
    {
      "epoch": 0.13840155945419103,
      "grad_norm": 0.0,
      "learning_rate": 0.0009695238975623344,
      "loss": 4.9479,
      "step": 1207
    },
    {
      "epoch": 0.1385162252035317,
      "grad_norm": 0.0,
      "learning_rate": 0.0009694600289283889,
      "loss": 5.1422,
      "step": 1208
    },
    {
      "epoch": 0.13863089095287237,
      "grad_norm": 0.0,
      "learning_rate": 0.0009693960955482776,
      "loss": 5.1473,
      "step": 1209
    },
    {
      "epoch": 0.13874555670221306,
      "grad_norm": 0.0,
      "learning_rate": 0.0009693320974308191,
      "loss": 4.8403,
      "step": 1210
    },
    {
      "epoch": 0.13886022245155372,
      "grad_norm": 0.0,
      "learning_rate": 0.0009692680345848404,
      "loss": 5.1101,
      "step": 1211
    },
    {
      "epoch": 0.1389748882008944,
      "grad_norm": 0.0,
      "learning_rate": 0.000969203907019178,
      "loss": 4.7709,
      "step": 1212
    },
    {
      "epoch": 0.13908955395023506,
      "grad_norm": 0.0,
      "learning_rate": 0.000969139714742677,
      "loss": 5.0267,
      "step": 1213
    },
    {
      "epoch": 0.13920421969957575,
      "grad_norm": 0.0,
      "learning_rate": 0.0009690754577641917,
      "loss": 5.0891,
      "step": 1214
    },
    {
      "epoch": 0.1393188854489164,
      "grad_norm": 0.0,
      "learning_rate": 0.0009690111360925848,
      "loss": 4.9375,
      "step": 1215
    },
    {
      "epoch": 0.1394335511982571,
      "grad_norm": 0.0,
      "learning_rate": 0.0009689467497367284,
      "loss": 5.1936,
      "step": 1216
    },
    {
      "epoch": 0.13954821694759775,
      "grad_norm": 0.0,
      "learning_rate": 0.0009688822987055034,
      "loss": 4.8819,
      "step": 1217
    },
    {
      "epoch": 0.1396628826969384,
      "grad_norm": 0.0,
      "learning_rate": 0.0009688177830077994,
      "loss": 4.8684,
      "step": 1218
    },
    {
      "epoch": 0.1397775484462791,
      "grad_norm": 0.0,
      "learning_rate": 0.0009687532026525154,
      "loss": 5.0531,
      "step": 1219
    },
    {
      "epoch": 0.13989221419561976,
      "grad_norm": 0.0,
      "learning_rate": 0.0009686885576485588,
      "loss": 4.9084,
      "step": 1220
    },
    {
      "epoch": 0.14000687994496044,
      "grad_norm": 0.0,
      "learning_rate": 0.0009686238480048463,
      "loss": 5.2755,
      "step": 1221
    },
    {
      "epoch": 0.1401215456943011,
      "grad_norm": 0.0,
      "learning_rate": 0.0009685590737303032,
      "loss": 4.9947,
      "step": 1222
    },
    {
      "epoch": 0.1402362114436418,
      "grad_norm": 0.0,
      "learning_rate": 0.000968494234833864,
      "loss": 4.9163,
      "step": 1223
    },
    {
      "epoch": 0.14035087719298245,
      "grad_norm": 0.0,
      "learning_rate": 0.0009684293313244721,
      "loss": 4.7681,
      "step": 1224
    },
    {
      "epoch": 0.14046554294232313,
      "grad_norm": 0.0,
      "learning_rate": 0.0009683643632110796,
      "loss": 4.8624,
      "step": 1225
    },
    {
      "epoch": 0.1405802086916638,
      "grad_norm": 0.0,
      "learning_rate": 0.0009682993305026474,
      "loss": 4.8401,
      "step": 1226
    },
    {
      "epoch": 0.14069487444100448,
      "grad_norm": 0.0,
      "learning_rate": 0.0009682342332081456,
      "loss": 4.9599,
      "step": 1227
    },
    {
      "epoch": 0.14080954019034514,
      "grad_norm": 0.0,
      "learning_rate": 0.0009681690713365535,
      "loss": 5.1202,
      "step": 1228
    },
    {
      "epoch": 0.14092420593968583,
      "grad_norm": 0.0,
      "learning_rate": 0.0009681038448968585,
      "loss": 4.8647,
      "step": 1229
    },
    {
      "epoch": 0.14103887168902648,
      "grad_norm": 0.0,
      "learning_rate": 0.0009680385538980576,
      "loss": 4.7852,
      "step": 1230
    },
    {
      "epoch": 0.14115353743836717,
      "grad_norm": 0.0,
      "learning_rate": 0.0009679731983491564,
      "loss": 5.0875,
      "step": 1231
    },
    {
      "epoch": 0.14126820318770783,
      "grad_norm": 0.0,
      "learning_rate": 0.0009679077782591694,
      "loss": 5.0201,
      "step": 1232
    },
    {
      "epoch": 0.14138286893704852,
      "grad_norm": 0.0,
      "learning_rate": 0.0009678422936371199,
      "loss": 5.171,
      "step": 1233
    },
    {
      "epoch": 0.14149753468638918,
      "grad_norm": 0.0,
      "learning_rate": 0.0009677767444920407,
      "loss": 5.0502,
      "step": 1234
    },
    {
      "epoch": 0.14161220043572983,
      "grad_norm": 0.0,
      "learning_rate": 0.0009677111308329726,
      "loss": 4.8514,
      "step": 1235
    },
    {
      "epoch": 0.14172686618507052,
      "grad_norm": 0.0,
      "learning_rate": 0.0009676454526689661,
      "loss": 5.1767,
      "step": 1236
    },
    {
      "epoch": 0.14184153193441118,
      "grad_norm": 0.0,
      "learning_rate": 0.0009675797100090798,
      "loss": 4.7681,
      "step": 1237
    },
    {
      "epoch": 0.14195619768375187,
      "grad_norm": 0.0,
      "learning_rate": 0.0009675139028623822,
      "loss": 5.1473,
      "step": 1238
    },
    {
      "epoch": 0.14207086343309253,
      "grad_norm": 0.0,
      "learning_rate": 0.0009674480312379497,
      "loss": 5.1343,
      "step": 1239
    },
    {
      "epoch": 0.1421855291824332,
      "grad_norm": 0.0,
      "learning_rate": 0.0009673820951448683,
      "loss": 4.9885,
      "step": 1240
    },
    {
      "epoch": 0.14230019493177387,
      "grad_norm": 0.0,
      "learning_rate": 0.0009673160945922325,
      "loss": 4.778,
      "step": 1241
    },
    {
      "epoch": 0.14241486068111456,
      "grad_norm": 0.0,
      "learning_rate": 0.0009672500295891458,
      "loss": 4.9649,
      "step": 1242
    },
    {
      "epoch": 0.14252952643045522,
      "grad_norm": 0.0,
      "learning_rate": 0.0009671839001447207,
      "loss": 4.8988,
      "step": 1243
    },
    {
      "epoch": 0.1426441921797959,
      "grad_norm": 0.0,
      "learning_rate": 0.0009671177062680785,
      "loss": 4.9994,
      "step": 1244
    },
    {
      "epoch": 0.14275885792913656,
      "grad_norm": 0.0,
      "learning_rate": 0.0009670514479683493,
      "loss": 4.9441,
      "step": 1245
    },
    {
      "epoch": 0.14287352367847725,
      "grad_norm": 0.0,
      "learning_rate": 0.0009669851252546722,
      "loss": 4.8108,
      "step": 1246
    },
    {
      "epoch": 0.1429881894278179,
      "grad_norm": 0.0,
      "learning_rate": 0.0009669187381361953,
      "loss": 5.1378,
      "step": 1247
    },
    {
      "epoch": 0.1431028551771586,
      "grad_norm": 0.0,
      "learning_rate": 0.0009668522866220752,
      "loss": 5.2943,
      "step": 1248
    },
    {
      "epoch": 0.14321752092649925,
      "grad_norm": 0.0,
      "learning_rate": 0.0009667857707214776,
      "loss": 5.1051,
      "step": 1249
    },
    {
      "epoch": 0.14333218667583994,
      "grad_norm": 0.0,
      "learning_rate": 0.0009667191904435772,
      "loss": 4.7295,
      "step": 1250
    },
    {
      "epoch": 0.1434468524251806,
      "grad_norm": 0.0,
      "learning_rate": 0.0009666525457975578,
      "loss": 5.0686,
      "step": 1251
    },
    {
      "epoch": 0.14356151817452126,
      "grad_norm": 0.0,
      "learning_rate": 0.0009665858367926113,
      "loss": 5.1573,
      "step": 1252
    },
    {
      "epoch": 0.14367618392386194,
      "grad_norm": 0.0,
      "learning_rate": 0.000966519063437939,
      "loss": 5.0805,
      "step": 1253
    },
    {
      "epoch": 0.1437908496732026,
      "grad_norm": 0.0,
      "learning_rate": 0.0009664522257427512,
      "loss": 4.959,
      "step": 1254
    },
    {
      "epoch": 0.1439055154225433,
      "grad_norm": 0.0,
      "learning_rate": 0.0009663853237162668,
      "loss": 4.9108,
      "step": 1255
    },
    {
      "epoch": 0.14402018117188395,
      "grad_norm": 0.0,
      "learning_rate": 0.0009663183573677136,
      "loss": 5.0389,
      "step": 1256
    },
    {
      "epoch": 0.14413484692122464,
      "grad_norm": 0.0,
      "learning_rate": 0.0009662513267063284,
      "loss": 4.9799,
      "step": 1257
    },
    {
      "epoch": 0.1442495126705653,
      "grad_norm": 0.0,
      "learning_rate": 0.0009661842317413569,
      "loss": 4.9579,
      "step": 1258
    },
    {
      "epoch": 0.14436417841990598,
      "grad_norm": 0.0,
      "learning_rate": 0.0009661170724820535,
      "loss": 5.0599,
      "step": 1259
    },
    {
      "epoch": 0.14447884416924664,
      "grad_norm": 0.0,
      "learning_rate": 0.0009660498489376812,
      "loss": 4.8448,
      "step": 1260
    },
    {
      "epoch": 0.14459350991858733,
      "grad_norm": 0.0,
      "learning_rate": 0.0009659825611175128,
      "loss": 5.1592,
      "step": 1261
    },
    {
      "epoch": 0.14470817566792799,
      "grad_norm": 0.0,
      "learning_rate": 0.000965915209030829,
      "loss": 5.0217,
      "step": 1262
    },
    {
      "epoch": 0.14482284141726867,
      "grad_norm": 0.0,
      "learning_rate": 0.0009658477926869197,
      "loss": 4.9194,
      "step": 1263
    },
    {
      "epoch": 0.14493750716660933,
      "grad_norm": 0.0,
      "learning_rate": 0.0009657803120950839,
      "loss": 5.0759,
      "step": 1264
    },
    {
      "epoch": 0.14505217291595002,
      "grad_norm": 0.0,
      "learning_rate": 0.0009657127672646291,
      "loss": 5.0848,
      "step": 1265
    },
    {
      "epoch": 0.14516683866529068,
      "grad_norm": 0.0,
      "learning_rate": 0.000965645158204872,
      "loss": 5.2266,
      "step": 1266
    },
    {
      "epoch": 0.14528150441463136,
      "grad_norm": 0.0,
      "learning_rate": 0.0009655774849251377,
      "loss": 4.8639,
      "step": 1267
    },
    {
      "epoch": 0.14539617016397202,
      "grad_norm": 0.0,
      "learning_rate": 0.0009655097474347608,
      "loss": 4.9772,
      "step": 1268
    },
    {
      "epoch": 0.14551083591331268,
      "grad_norm": 0.0,
      "learning_rate": 0.0009654419457430841,
      "loss": 4.9254,
      "step": 1269
    },
    {
      "epoch": 0.14562550166265337,
      "grad_norm": 0.0,
      "learning_rate": 0.0009653740798594598,
      "loss": 4.8444,
      "step": 1270
    },
    {
      "epoch": 0.14574016741199403,
      "grad_norm": 0.0,
      "learning_rate": 0.0009653061497932484,
      "loss": 4.6857,
      "step": 1271
    },
    {
      "epoch": 0.1458548331613347,
      "grad_norm": 0.0,
      "learning_rate": 0.00096523815555382,
      "loss": 4.9565,
      "step": 1272
    },
    {
      "epoch": 0.14596949891067537,
      "grad_norm": 0.0,
      "learning_rate": 0.0009651700971505525,
      "loss": 4.9728,
      "step": 1273
    },
    {
      "epoch": 0.14608416466001606,
      "grad_norm": 0.0,
      "learning_rate": 0.0009651019745928337,
      "loss": 4.9153,
      "step": 1274
    },
    {
      "epoch": 0.14619883040935672,
      "grad_norm": 0.0,
      "learning_rate": 0.0009650337878900599,
      "loss": 5.0359,
      "step": 1275
    },
    {
      "epoch": 0.1463134961586974,
      "grad_norm": 0.0,
      "learning_rate": 0.0009649655370516357,
      "loss": 4.8172,
      "step": 1276
    },
    {
      "epoch": 0.14642816190803806,
      "grad_norm": 0.0,
      "learning_rate": 0.0009648972220869753,
      "loss": 5.161,
      "step": 1277
    },
    {
      "epoch": 0.14654282765737875,
      "grad_norm": 0.0,
      "learning_rate": 0.0009648288430055016,
      "loss": 4.976,
      "step": 1278
    },
    {
      "epoch": 0.1466574934067194,
      "grad_norm": 0.0,
      "learning_rate": 0.0009647603998166458,
      "loss": 4.8346,
      "step": 1279
    },
    {
      "epoch": 0.1467721591560601,
      "grad_norm": 0.0,
      "learning_rate": 0.0009646918925298486,
      "loss": 4.9355,
      "step": 1280
    },
    {
      "epoch": 0.14688682490540075,
      "grad_norm": 0.0,
      "learning_rate": 0.0009646233211545592,
      "loss": 5.2911,
      "step": 1281
    },
    {
      "epoch": 0.14700149065474144,
      "grad_norm": 0.0,
      "learning_rate": 0.0009645546857002357,
      "loss": 5.2649,
      "step": 1282
    },
    {
      "epoch": 0.1471161564040821,
      "grad_norm": 0.0,
      "learning_rate": 0.0009644859861763451,
      "loss": 5.1176,
      "step": 1283
    },
    {
      "epoch": 0.14723082215342279,
      "grad_norm": 0.0,
      "learning_rate": 0.0009644172225923632,
      "loss": 5.3895,
      "step": 1284
    },
    {
      "epoch": 0.14734548790276344,
      "grad_norm": 0.0,
      "learning_rate": 0.0009643483949577745,
      "loss": 4.9338,
      "step": 1285
    },
    {
      "epoch": 0.1474601536521041,
      "grad_norm": 0.0,
      "learning_rate": 0.0009642795032820726,
      "loss": 4.8309,
      "step": 1286
    },
    {
      "epoch": 0.1475748194014448,
      "grad_norm": 0.0,
      "learning_rate": 0.0009642105475747597,
      "loss": 4.8942,
      "step": 1287
    },
    {
      "epoch": 0.14768948515078545,
      "grad_norm": 0.0,
      "learning_rate": 0.000964141527845347,
      "loss": 4.9686,
      "step": 1288
    },
    {
      "epoch": 0.14780415090012614,
      "grad_norm": 0.0,
      "learning_rate": 0.0009640724441033544,
      "loss": 5.0432,
      "step": 1289
    },
    {
      "epoch": 0.1479188166494668,
      "grad_norm": 0.0,
      "learning_rate": 0.0009640032963583109,
      "loss": 4.9902,
      "step": 1290
    },
    {
      "epoch": 0.14803348239880748,
      "grad_norm": 0.0,
      "learning_rate": 0.0009639340846197536,
      "loss": 4.9907,
      "step": 1291
    },
    {
      "epoch": 0.14814814814814814,
      "grad_norm": 0.0,
      "learning_rate": 0.0009638648088972294,
      "loss": 5.0461,
      "step": 1292
    },
    {
      "epoch": 0.14826281389748883,
      "grad_norm": 0.0,
      "learning_rate": 0.0009637954692002935,
      "loss": 4.8317,
      "step": 1293
    },
    {
      "epoch": 0.14837747964682949,
      "grad_norm": 0.0,
      "learning_rate": 0.0009637260655385099,
      "loss": 4.8077,
      "step": 1294
    },
    {
      "epoch": 0.14849214539617017,
      "grad_norm": 0.0,
      "learning_rate": 0.0009636565979214514,
      "loss": 4.9155,
      "step": 1295
    },
    {
      "epoch": 0.14860681114551083,
      "grad_norm": 0.0,
      "learning_rate": 0.0009635870663587,
      "loss": 5.1274,
      "step": 1296
    },
    {
      "epoch": 0.14872147689485152,
      "grad_norm": 0.0,
      "learning_rate": 0.0009635174708598461,
      "loss": 5.2727,
      "step": 1297
    },
    {
      "epoch": 0.14883614264419218,
      "grad_norm": 0.0,
      "learning_rate": 0.0009634478114344889,
      "loss": 5.2597,
      "step": 1298
    },
    {
      "epoch": 0.14895080839353286,
      "grad_norm": 0.0,
      "learning_rate": 0.000963378088092237,
      "loss": 4.8103,
      "step": 1299
    },
    {
      "epoch": 0.14906547414287352,
      "grad_norm": 0.0,
      "learning_rate": 0.0009633083008427072,
      "loss": 5.0869,
      "step": 1300
    },
    {
      "epoch": 0.1491801398922142,
      "grad_norm": 0.0,
      "learning_rate": 0.0009632384496955251,
      "loss": 5.1331,
      "step": 1301
    },
    {
      "epoch": 0.14929480564155487,
      "grad_norm": 0.0,
      "learning_rate": 0.0009631685346603257,
      "loss": 4.9461,
      "step": 1302
    },
    {
      "epoch": 0.14940947139089553,
      "grad_norm": 0.0,
      "learning_rate": 0.0009630985557467523,
      "loss": 5.0004,
      "step": 1303
    },
    {
      "epoch": 0.1495241371402362,
      "grad_norm": 0.0,
      "learning_rate": 0.000963028512964457,
      "loss": 5.1109,
      "step": 1304
    },
    {
      "epoch": 0.14963880288957687,
      "grad_norm": 0.0,
      "learning_rate": 0.0009629584063231011,
      "loss": 5.0704,
      "step": 1305
    },
    {
      "epoch": 0.14975346863891756,
      "grad_norm": 0.0,
      "learning_rate": 0.0009628882358323544,
      "loss": 4.9198,
      "step": 1306
    },
    {
      "epoch": 0.14986813438825822,
      "grad_norm": 0.0,
      "learning_rate": 0.0009628180015018956,
      "loss": 4.8132,
      "step": 1307
    },
    {
      "epoch": 0.1499828001375989,
      "grad_norm": 0.0,
      "learning_rate": 0.000962747703341412,
      "loss": 4.726,
      "step": 1308
    },
    {
      "epoch": 0.15009746588693956,
      "grad_norm": 0.0,
      "learning_rate": 0.0009626773413606003,
      "loss": 4.9892,
      "step": 1309
    },
    {
      "epoch": 0.15021213163628025,
      "grad_norm": 0.0,
      "learning_rate": 0.000962606915569165,
      "loss": 5.1799,
      "step": 1310
    },
    {
      "epoch": 0.1503267973856209,
      "grad_norm": 0.0,
      "learning_rate": 0.0009625364259768206,
      "loss": 5.2896,
      "step": 1311
    },
    {
      "epoch": 0.1504414631349616,
      "grad_norm": 0.0,
      "learning_rate": 0.0009624658725932894,
      "loss": 4.787,
      "step": 1312
    },
    {
      "epoch": 0.15055612888430225,
      "grad_norm": 0.0,
      "learning_rate": 0.0009623952554283032,
      "loss": 5.1493,
      "step": 1313
    },
    {
      "epoch": 0.15067079463364294,
      "grad_norm": 0.0,
      "learning_rate": 0.0009623245744916019,
      "loss": 5.2036,
      "step": 1314
    },
    {
      "epoch": 0.1507854603829836,
      "grad_norm": 0.0,
      "learning_rate": 0.0009622538297929349,
      "loss": 4.8893,
      "step": 1315
    },
    {
      "epoch": 0.15090012613232429,
      "grad_norm": 0.0,
      "learning_rate": 0.0009621830213420601,
      "loss": 4.9593,
      "step": 1316
    },
    {
      "epoch": 0.15101479188166494,
      "grad_norm": 0.0,
      "learning_rate": 0.0009621121491487439,
      "loss": 5.2812,
      "step": 1317
    },
    {
      "epoch": 0.15112945763100563,
      "grad_norm": 0.0,
      "learning_rate": 0.000962041213222762,
      "loss": 5.096,
      "step": 1318
    },
    {
      "epoch": 0.1512441233803463,
      "grad_norm": 0.0,
      "learning_rate": 0.0009619702135738986,
      "loss": 4.9934,
      "step": 1319
    },
    {
      "epoch": 0.15135878912968695,
      "grad_norm": 0.0,
      "learning_rate": 0.0009618991502119465,
      "loss": 5.0293,
      "step": 1320
    },
    {
      "epoch": 0.15147345487902764,
      "grad_norm": 0.0,
      "learning_rate": 0.000961828023146708,
      "loss": 4.8629,
      "step": 1321
    },
    {
      "epoch": 0.1515881206283683,
      "grad_norm": 0.0,
      "learning_rate": 0.0009617568323879935,
      "loss": 4.9136,
      "step": 1322
    },
    {
      "epoch": 0.15170278637770898,
      "grad_norm": 0.0,
      "learning_rate": 0.0009616855779456224,
      "loss": 4.9221,
      "step": 1323
    },
    {
      "epoch": 0.15181745212704964,
      "grad_norm": 0.0,
      "learning_rate": 0.000961614259829423,
      "loss": 4.7916,
      "step": 1324
    },
    {
      "epoch": 0.15193211787639033,
      "grad_norm": 0.0,
      "learning_rate": 0.0009615428780492319,
      "loss": 4.6459,
      "step": 1325
    },
    {
      "epoch": 0.15204678362573099,
      "grad_norm": 0.0,
      "learning_rate": 0.0009614714326148955,
      "loss": 5.0565,
      "step": 1326
    },
    {
      "epoch": 0.15216144937507167,
      "grad_norm": 0.0,
      "learning_rate": 0.0009613999235362675,
      "loss": 4.9414,
      "step": 1327
    },
    {
      "epoch": 0.15227611512441233,
      "grad_norm": 0.0,
      "learning_rate": 0.0009613283508232119,
      "loss": 4.8766,
      "step": 1328
    },
    {
      "epoch": 0.15239078087375302,
      "grad_norm": 0.0,
      "learning_rate": 0.0009612567144856007,
      "loss": 4.9187,
      "step": 1329
    },
    {
      "epoch": 0.15250544662309368,
      "grad_norm": 0.0,
      "learning_rate": 0.0009611850145333146,
      "loss": 5.3375,
      "step": 1330
    },
    {
      "epoch": 0.15262011237243436,
      "grad_norm": 0.0,
      "learning_rate": 0.0009611132509762431,
      "loss": 5.1032,
      "step": 1331
    },
    {
      "epoch": 0.15273477812177502,
      "grad_norm": 0.0,
      "learning_rate": 0.000961041423824285,
      "loss": 5.0865,
      "step": 1332
    },
    {
      "epoch": 0.1528494438711157,
      "grad_norm": 0.0,
      "learning_rate": 0.000960969533087347,
      "loss": 5.1874,
      "step": 1333
    },
    {
      "epoch": 0.15296410962045637,
      "grad_norm": 0.0,
      "learning_rate": 0.0009608975787753456,
      "loss": 4.8821,
      "step": 1334
    },
    {
      "epoch": 0.15307877536979705,
      "grad_norm": 0.0,
      "learning_rate": 0.0009608255608982052,
      "loss": 5.1914,
      "step": 1335
    },
    {
      "epoch": 0.1531934411191377,
      "grad_norm": 0.0,
      "learning_rate": 0.0009607534794658592,
      "loss": 4.9019,
      "step": 1336
    },
    {
      "epoch": 0.15330810686847837,
      "grad_norm": 0.0,
      "learning_rate": 0.0009606813344882502,
      "loss": 5.122,
      "step": 1337
    },
    {
      "epoch": 0.15342277261781906,
      "grad_norm": 0.0,
      "learning_rate": 0.000960609125975329,
      "loss": 5.1323,
      "step": 1338
    },
    {
      "epoch": 0.15353743836715972,
      "grad_norm": 0.0,
      "learning_rate": 0.0009605368539370554,
      "loss": 4.7845,
      "step": 1339
    },
    {
      "epoch": 0.1536521041165004,
      "grad_norm": 0.0,
      "learning_rate": 0.000960464518383398,
      "loss": 5.0852,
      "step": 1340
    },
    {
      "epoch": 0.15376676986584106,
      "grad_norm": 0.0,
      "learning_rate": 0.0009603921193243342,
      "loss": 4.6902,
      "step": 1341
    },
    {
      "epoch": 0.15388143561518175,
      "grad_norm": 0.0,
      "learning_rate": 0.0009603196567698497,
      "loss": 4.8679,
      "step": 1342
    },
    {
      "epoch": 0.1539961013645224,
      "grad_norm": 0.0,
      "learning_rate": 0.0009602471307299398,
      "loss": 4.901,
      "step": 1343
    },
    {
      "epoch": 0.1541107671138631,
      "grad_norm": 0.0,
      "learning_rate": 0.0009601745412146077,
      "loss": 5.0899,
      "step": 1344
    },
    {
      "epoch": 0.15422543286320375,
      "grad_norm": 0.0,
      "learning_rate": 0.0009601018882338659,
      "loss": 5.0462,
      "step": 1345
    },
    {
      "epoch": 0.15434009861254444,
      "grad_norm": 0.0,
      "learning_rate": 0.0009600291717977357,
      "loss": 4.9483,
      "step": 1346
    },
    {
      "epoch": 0.1544547643618851,
      "grad_norm": 0.0,
      "learning_rate": 0.0009599563919162466,
      "loss": 5.0889,
      "step": 1347
    },
    {
      "epoch": 0.1545694301112258,
      "grad_norm": 0.0,
      "learning_rate": 0.0009598835485994375,
      "loss": 5.0976,
      "step": 1348
    },
    {
      "epoch": 0.15468409586056645,
      "grad_norm": 0.0,
      "learning_rate": 0.0009598106418573554,
      "loss": 5.1126,
      "step": 1349
    },
    {
      "epoch": 0.15479876160990713,
      "grad_norm": 0.0,
      "learning_rate": 0.0009597376717000569,
      "loss": 5.0727,
      "step": 1350
    },
    {
      "epoch": 0.1549134273592478,
      "grad_norm": 0.0,
      "learning_rate": 0.0009596646381376062,
      "loss": 5.046,
      "step": 1351
    },
    {
      "epoch": 0.15502809310858848,
      "grad_norm": 0.0,
      "learning_rate": 0.0009595915411800773,
      "loss": 4.9878,
      "step": 1352
    },
    {
      "epoch": 0.15514275885792914,
      "grad_norm": 0.0,
      "learning_rate": 0.0009595183808375525,
      "loss": 5.1527,
      "step": 1353
    },
    {
      "epoch": 0.1552574246072698,
      "grad_norm": 0.0,
      "learning_rate": 0.0009594451571201229,
      "loss": 4.9423,
      "step": 1354
    },
    {
      "epoch": 0.15537209035661048,
      "grad_norm": 0.0,
      "learning_rate": 0.0009593718700378882,
      "loss": 5.0479,
      "step": 1355
    },
    {
      "epoch": 0.15548675610595114,
      "grad_norm": 0.0,
      "learning_rate": 0.0009592985196009569,
      "loss": 4.9689,
      "step": 1356
    },
    {
      "epoch": 0.15560142185529183,
      "grad_norm": 0.0,
      "learning_rate": 0.0009592251058194465,
      "loss": 5.1563,
      "step": 1357
    },
    {
      "epoch": 0.15571608760463249,
      "grad_norm": 0.0,
      "learning_rate": 0.0009591516287034828,
      "loss": 4.9732,
      "step": 1358
    },
    {
      "epoch": 0.15583075335397317,
      "grad_norm": 0.0,
      "learning_rate": 0.0009590780882632008,
      "loss": 5.0167,
      "step": 1359
    },
    {
      "epoch": 0.15594541910331383,
      "grad_norm": 0.0,
      "learning_rate": 0.0009590044845087438,
      "loss": 4.8351,
      "step": 1360
    },
    {
      "epoch": 0.15606008485265452,
      "grad_norm": 0.0,
      "learning_rate": 0.0009589308174502644,
      "loss": 4.7902,
      "step": 1361
    },
    {
      "epoch": 0.15617475060199518,
      "grad_norm": 0.0,
      "learning_rate": 0.0009588570870979231,
      "loss": 4.9851,
      "step": 1362
    },
    {
      "epoch": 0.15628941635133586,
      "grad_norm": 0.0,
      "learning_rate": 0.0009587832934618896,
      "loss": 4.9711,
      "step": 1363
    },
    {
      "epoch": 0.15640408210067652,
      "grad_norm": 0.0,
      "learning_rate": 0.0009587094365523429,
      "loss": 5.198,
      "step": 1364
    },
    {
      "epoch": 0.1565187478500172,
      "grad_norm": 0.0,
      "learning_rate": 0.0009586355163794696,
      "loss": 5.1119,
      "step": 1365
    },
    {
      "epoch": 0.15663341359935787,
      "grad_norm": 0.0,
      "learning_rate": 0.0009585615329534656,
      "loss": 5.1501,
      "step": 1366
    },
    {
      "epoch": 0.15674807934869855,
      "grad_norm": 0.0,
      "learning_rate": 0.0009584874862845358,
      "loss": 4.9539,
      "step": 1367
    },
    {
      "epoch": 0.1568627450980392,
      "grad_norm": 0.0,
      "learning_rate": 0.0009584133763828935,
      "loss": 5.1092,
      "step": 1368
    },
    {
      "epoch": 0.1569774108473799,
      "grad_norm": 0.0,
      "learning_rate": 0.0009583392032587603,
      "loss": 4.8758,
      "step": 1369
    },
    {
      "epoch": 0.15709207659672056,
      "grad_norm": 0.0,
      "learning_rate": 0.0009582649669223676,
      "loss": 4.96,
      "step": 1370
    },
    {
      "epoch": 0.15720674234606122,
      "grad_norm": 0.0,
      "learning_rate": 0.0009581906673839546,
      "loss": 4.8842,
      "step": 1371
    },
    {
      "epoch": 0.1573214080954019,
      "grad_norm": 0.0,
      "learning_rate": 0.0009581163046537693,
      "loss": 5.0304,
      "step": 1372
    },
    {
      "epoch": 0.15743607384474256,
      "grad_norm": 0.0,
      "learning_rate": 0.0009580418787420689,
      "loss": 5.0856,
      "step": 1373
    },
    {
      "epoch": 0.15755073959408325,
      "grad_norm": 0.0,
      "learning_rate": 0.0009579673896591189,
      "loss": 4.9705,
      "step": 1374
    },
    {
      "epoch": 0.1576654053434239,
      "grad_norm": 0.0,
      "learning_rate": 0.0009578928374151937,
      "loss": 4.9231,
      "step": 1375
    },
    {
      "epoch": 0.1577800710927646,
      "grad_norm": 0.0,
      "learning_rate": 0.0009578182220205764,
      "loss": 4.9645,
      "step": 1376
    },
    {
      "epoch": 0.15789473684210525,
      "grad_norm": 0.0,
      "learning_rate": 0.0009577435434855587,
      "loss": 4.9305,
      "step": 1377
    },
    {
      "epoch": 0.15800940259144594,
      "grad_norm": 0.0,
      "learning_rate": 0.0009576688018204412,
      "loss": 5.1168,
      "step": 1378
    },
    {
      "epoch": 0.1581240683407866,
      "grad_norm": 0.0,
      "learning_rate": 0.0009575939970355329,
      "loss": 5.1247,
      "step": 1379
    },
    {
      "epoch": 0.1582387340901273,
      "grad_norm": 0.0,
      "learning_rate": 0.0009575191291411516,
      "loss": 5.0141,
      "step": 1380
    },
    {
      "epoch": 0.15835339983946795,
      "grad_norm": 0.0,
      "learning_rate": 0.0009574441981476245,
      "loss": 4.73,
      "step": 1381
    },
    {
      "epoch": 0.15846806558880863,
      "grad_norm": 0.0,
      "learning_rate": 0.0009573692040652864,
      "loss": 4.9552,
      "step": 1382
    },
    {
      "epoch": 0.1585827313381493,
      "grad_norm": 0.0,
      "learning_rate": 0.0009572941469044811,
      "loss": 4.9859,
      "step": 1383
    },
    {
      "epoch": 0.15869739708748998,
      "grad_norm": 0.0,
      "learning_rate": 0.0009572190266755619,
      "loss": 5.1084,
      "step": 1384
    },
    {
      "epoch": 0.15881206283683064,
      "grad_norm": 0.0,
      "learning_rate": 0.0009571438433888897,
      "loss": 4.9884,
      "step": 1385
    },
    {
      "epoch": 0.15892672858617132,
      "grad_norm": 0.0,
      "learning_rate": 0.0009570685970548351,
      "loss": 5.163,
      "step": 1386
    },
    {
      "epoch": 0.15904139433551198,
      "grad_norm": 0.0,
      "learning_rate": 0.0009569932876837763,
      "loss": 5.3435,
      "step": 1387
    },
    {
      "epoch": 0.15915606008485264,
      "grad_norm": 0.0,
      "learning_rate": 0.0009569179152861012,
      "loss": 4.8135,
      "step": 1388
    },
    {
      "epoch": 0.15927072583419333,
      "grad_norm": 0.0,
      "learning_rate": 0.000956842479872206,
      "loss": 4.9982,
      "step": 1389
    },
    {
      "epoch": 0.159385391583534,
      "grad_norm": 0.0,
      "learning_rate": 0.0009567669814524953,
      "loss": 4.9577,
      "step": 1390
    },
    {
      "epoch": 0.15950005733287467,
      "grad_norm": 0.0,
      "learning_rate": 0.0009566914200373828,
      "loss": 4.8252,
      "step": 1391
    },
    {
      "epoch": 0.15961472308221533,
      "grad_norm": 0.0,
      "learning_rate": 0.0009566157956372908,
      "loss": 4.9813,
      "step": 1392
    },
    {
      "epoch": 0.15972938883155602,
      "grad_norm": 0.0,
      "learning_rate": 0.0009565401082626502,
      "loss": 5.0896,
      "step": 1393
    },
    {
      "epoch": 0.15984405458089668,
      "grad_norm": 0.0,
      "learning_rate": 0.0009564643579239008,
      "loss": 4.9985,
      "step": 1394
    },
    {
      "epoch": 0.15995872033023736,
      "grad_norm": 0.0,
      "learning_rate": 0.0009563885446314907,
      "loss": 4.7148,
      "step": 1395
    },
    {
      "epoch": 0.16007338607957802,
      "grad_norm": 0.0,
      "learning_rate": 0.000956312668395877,
      "loss": 4.9076,
      "step": 1396
    },
    {
      "epoch": 0.1601880518289187,
      "grad_norm": 0.0,
      "learning_rate": 0.0009562367292275253,
      "loss": 4.9346,
      "step": 1397
    },
    {
      "epoch": 0.16030271757825937,
      "grad_norm": 0.0,
      "learning_rate": 0.0009561607271369102,
      "loss": 5.0769,
      "step": 1398
    },
    {
      "epoch": 0.16041738332760005,
      "grad_norm": 0.0,
      "learning_rate": 0.0009560846621345143,
      "loss": 4.9173,
      "step": 1399
    },
    {
      "epoch": 0.1605320490769407,
      "grad_norm": 0.0,
      "learning_rate": 0.0009560085342308295,
      "loss": 5.0496,
      "step": 1400
    },
    {
      "epoch": 0.1606467148262814,
      "grad_norm": 0.0,
      "learning_rate": 0.0009559323434363564,
      "loss": 4.982,
      "step": 1401
    },
    {
      "epoch": 0.16076138057562206,
      "grad_norm": 0.0,
      "learning_rate": 0.0009558560897616042,
      "loss": 5.109,
      "step": 1402
    },
    {
      "epoch": 0.16087604632496275,
      "grad_norm": 0.0,
      "learning_rate": 0.0009557797732170902,
      "loss": 5.0971,
      "step": 1403
    },
    {
      "epoch": 0.1609907120743034,
      "grad_norm": 0.0,
      "learning_rate": 0.0009557033938133408,
      "loss": 4.9077,
      "step": 1404
    },
    {
      "epoch": 0.16110537782364406,
      "grad_norm": 0.0,
      "learning_rate": 0.0009556269515608914,
      "loss": 4.669,
      "step": 1405
    },
    {
      "epoch": 0.16122004357298475,
      "grad_norm": 0.0,
      "learning_rate": 0.0009555504464702857,
      "loss": 5.0452,
      "step": 1406
    },
    {
      "epoch": 0.1613347093223254,
      "grad_norm": 0.0,
      "learning_rate": 0.0009554738785520759,
      "loss": 4.8205,
      "step": 1407
    },
    {
      "epoch": 0.1614493750716661,
      "grad_norm": 0.0,
      "learning_rate": 0.0009553972478168232,
      "loss": 5.0131,
      "step": 1408
    },
    {
      "epoch": 0.16156404082100675,
      "grad_norm": 0.0,
      "learning_rate": 0.0009553205542750975,
      "loss": 5.1336,
      "step": 1409
    },
    {
      "epoch": 0.16167870657034744,
      "grad_norm": 0.0,
      "learning_rate": 0.0009552437979374771,
      "loss": 5.195,
      "step": 1410
    },
    {
      "epoch": 0.1617933723196881,
      "grad_norm": 0.0,
      "learning_rate": 0.0009551669788145489,
      "loss": 4.9198,
      "step": 1411
    },
    {
      "epoch": 0.1619080380690288,
      "grad_norm": 0.0,
      "learning_rate": 0.0009550900969169089,
      "loss": 4.7516,
      "step": 1412
    },
    {
      "epoch": 0.16202270381836945,
      "grad_norm": 0.0,
      "learning_rate": 0.0009550131522551613,
      "loss": 5.0092,
      "step": 1413
    },
    {
      "epoch": 0.16213736956771013,
      "grad_norm": 0.0,
      "learning_rate": 0.0009549361448399193,
      "loss": 5.004,
      "step": 1414
    },
    {
      "epoch": 0.1622520353170508,
      "grad_norm": 0.0,
      "learning_rate": 0.0009548590746818044,
      "loss": 4.8256,
      "step": 1415
    },
    {
      "epoch": 0.16236670106639148,
      "grad_norm": 0.0,
      "learning_rate": 0.0009547819417914474,
      "loss": 5.117,
      "step": 1416
    },
    {
      "epoch": 0.16248136681573214,
      "grad_norm": 0.0,
      "learning_rate": 0.0009547047461794868,
      "loss": 4.9594,
      "step": 1417
    },
    {
      "epoch": 0.16259603256507282,
      "grad_norm": 0.0,
      "learning_rate": 0.0009546274878565705,
      "loss": 4.8334,
      "step": 1418
    },
    {
      "epoch": 0.16271069831441348,
      "grad_norm": 0.0,
      "learning_rate": 0.0009545501668333548,
      "loss": 4.9891,
      "step": 1419
    },
    {
      "epoch": 0.16282536406375417,
      "grad_norm": 0.0,
      "learning_rate": 0.0009544727831205046,
      "loss": 4.8334,
      "step": 1420
    },
    {
      "epoch": 0.16294002981309483,
      "grad_norm": 0.0,
      "learning_rate": 0.0009543953367286936,
      "loss": 4.9508,
      "step": 1421
    },
    {
      "epoch": 0.16305469556243551,
      "grad_norm": 0.0,
      "learning_rate": 0.000954317827668604,
      "loss": 4.6402,
      "step": 1422
    },
    {
      "epoch": 0.16316936131177617,
      "grad_norm": 0.0,
      "learning_rate": 0.0009542402559509267,
      "loss": 4.9475,
      "step": 1423
    },
    {
      "epoch": 0.16328402706111683,
      "grad_norm": 0.0,
      "learning_rate": 0.0009541626215863612,
      "loss": 4.9225,
      "step": 1424
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.0,
      "learning_rate": 0.0009540849245856158,
      "loss": 4.8241,
      "step": 1425
    },
    {
      "epoch": 0.16351335855979818,
      "grad_norm": 0.0,
      "learning_rate": 0.0009540071649594072,
      "loss": 4.9136,
      "step": 1426
    },
    {
      "epoch": 0.16362802430913886,
      "grad_norm": 0.0,
      "learning_rate": 0.000953929342718461,
      "loss": 5.2231,
      "step": 1427
    },
    {
      "epoch": 0.16374269005847952,
      "grad_norm": 0.0,
      "learning_rate": 0.0009538514578735112,
      "loss": 4.8416,
      "step": 1428
    },
    {
      "epoch": 0.1638573558078202,
      "grad_norm": 0.0,
      "learning_rate": 0.0009537735104353004,
      "loss": 5.1047,
      "step": 1429
    },
    {
      "epoch": 0.16397202155716087,
      "grad_norm": 0.0,
      "learning_rate": 0.0009536955004145801,
      "loss": 4.9056,
      "step": 1430
    },
    {
      "epoch": 0.16408668730650156,
      "grad_norm": 0.0,
      "learning_rate": 0.0009536174278221103,
      "loss": 4.8719,
      "step": 1431
    },
    {
      "epoch": 0.16420135305584221,
      "grad_norm": 0.0,
      "learning_rate": 0.0009535392926686597,
      "loss": 5.1691,
      "step": 1432
    },
    {
      "epoch": 0.1643160188051829,
      "grad_norm": 0.0,
      "learning_rate": 0.0009534610949650054,
      "loss": 5.1624,
      "step": 1433
    },
    {
      "epoch": 0.16443068455452356,
      "grad_norm": 0.0,
      "learning_rate": 0.0009533828347219333,
      "loss": 5.1519,
      "step": 1434
    },
    {
      "epoch": 0.16454535030386425,
      "grad_norm": 0.0,
      "learning_rate": 0.000953304511950238,
      "loss": 4.9172,
      "step": 1435
    },
    {
      "epoch": 0.1646600160532049,
      "grad_norm": 0.0,
      "learning_rate": 0.0009532261266607228,
      "loss": 4.8599,
      "step": 1436
    },
    {
      "epoch": 0.1647746818025456,
      "grad_norm": 0.0,
      "learning_rate": 0.000953147678864199,
      "loss": 5.3015,
      "step": 1437
    },
    {
      "epoch": 0.16488934755188625,
      "grad_norm": 0.0,
      "learning_rate": 0.0009530691685714872,
      "loss": 5.0912,
      "step": 1438
    },
    {
      "epoch": 0.16500401330122694,
      "grad_norm": 0.0,
      "learning_rate": 0.0009529905957934166,
      "loss": 4.9837,
      "step": 1439
    },
    {
      "epoch": 0.1651186790505676,
      "grad_norm": 0.0,
      "learning_rate": 0.0009529119605408246,
      "loss": 5.0159,
      "step": 1440
    },
    {
      "epoch": 0.16523334479990825,
      "grad_norm": 0.0,
      "learning_rate": 0.0009528332628245575,
      "loss": 4.954,
      "step": 1441
    },
    {
      "epoch": 0.16534801054924894,
      "grad_norm": 0.0,
      "learning_rate": 0.0009527545026554702,
      "loss": 4.8677,
      "step": 1442
    },
    {
      "epoch": 0.1654626762985896,
      "grad_norm": 0.0,
      "learning_rate": 0.0009526756800444259,
      "loss": 4.9125,
      "step": 1443
    },
    {
      "epoch": 0.1655773420479303,
      "grad_norm": 0.0,
      "learning_rate": 0.0009525967950022967,
      "loss": 5.1252,
      "step": 1444
    },
    {
      "epoch": 0.16569200779727095,
      "grad_norm": 0.0,
      "learning_rate": 0.0009525178475399638,
      "loss": 5.0019,
      "step": 1445
    },
    {
      "epoch": 0.16580667354661163,
      "grad_norm": 0.0,
      "learning_rate": 0.0009524388376683162,
      "loss": 5.0376,
      "step": 1446
    },
    {
      "epoch": 0.1659213392959523,
      "grad_norm": 0.0,
      "learning_rate": 0.0009523597653982515,
      "loss": 4.9512,
      "step": 1447
    },
    {
      "epoch": 0.16603600504529298,
      "grad_norm": 0.0,
      "learning_rate": 0.0009522806307406765,
      "loss": 4.918,
      "step": 1448
    },
    {
      "epoch": 0.16615067079463364,
      "grad_norm": 0.0,
      "learning_rate": 0.0009522014337065063,
      "loss": 4.9668,
      "step": 1449
    },
    {
      "epoch": 0.16626533654397432,
      "grad_norm": 0.0,
      "learning_rate": 0.0009521221743066649,
      "loss": 4.7923,
      "step": 1450
    },
    {
      "epoch": 0.16638000229331498,
      "grad_norm": 0.0,
      "learning_rate": 0.000952042852552084,
      "loss": 5.0424,
      "step": 1451
    },
    {
      "epoch": 0.16649466804265567,
      "grad_norm": 0.0,
      "learning_rate": 0.000951963468453705,
      "loss": 4.9041,
      "step": 1452
    },
    {
      "epoch": 0.16660933379199633,
      "grad_norm": 0.0,
      "learning_rate": 0.0009518840220224772,
      "loss": 5.2475,
      "step": 1453
    },
    {
      "epoch": 0.16672399954133701,
      "grad_norm": 0.0,
      "learning_rate": 0.0009518045132693589,
      "loss": 4.8973,
      "step": 1454
    },
    {
      "epoch": 0.16683866529067767,
      "grad_norm": 0.0,
      "learning_rate": 0.0009517249422053168,
      "loss": 5.0095,
      "step": 1455
    },
    {
      "epoch": 0.16695333104001836,
      "grad_norm": 0.0,
      "learning_rate": 0.000951645308841326,
      "loss": 5.043,
      "step": 1456
    },
    {
      "epoch": 0.16706799678935902,
      "grad_norm": 0.0,
      "learning_rate": 0.0009515656131883704,
      "loss": 5.1005,
      "step": 1457
    },
    {
      "epoch": 0.16718266253869968,
      "grad_norm": 0.0,
      "learning_rate": 0.0009514858552574428,
      "loss": 4.977,
      "step": 1458
    },
    {
      "epoch": 0.16729732828804036,
      "grad_norm": 0.0,
      "learning_rate": 0.0009514060350595442,
      "loss": 5.0587,
      "step": 1459
    },
    {
      "epoch": 0.16741199403738102,
      "grad_norm": 0.0,
      "learning_rate": 0.0009513261526056839,
      "loss": 4.9189,
      "step": 1460
    },
    {
      "epoch": 0.1675266597867217,
      "grad_norm": 0.0,
      "learning_rate": 0.0009512462079068806,
      "loss": 5.136,
      "step": 1461
    },
    {
      "epoch": 0.16764132553606237,
      "grad_norm": 0.0,
      "learning_rate": 0.0009511662009741612,
      "loss": 5.2029,
      "step": 1462
    },
    {
      "epoch": 0.16775599128540306,
      "grad_norm": 0.0,
      "learning_rate": 0.0009510861318185607,
      "loss": 5.0573,
      "step": 1463
    },
    {
      "epoch": 0.16787065703474371,
      "grad_norm": 0.0,
      "learning_rate": 0.0009510060004511235,
      "loss": 5.1244,
      "step": 1464
    },
    {
      "epoch": 0.1679853227840844,
      "grad_norm": 0.0,
      "learning_rate": 0.0009509258068829019,
      "loss": 4.7537,
      "step": 1465
    },
    {
      "epoch": 0.16809998853342506,
      "grad_norm": 0.0,
      "learning_rate": 0.0009508455511249572,
      "loss": 5.096,
      "step": 1466
    },
    {
      "epoch": 0.16821465428276575,
      "grad_norm": 0.0,
      "learning_rate": 0.0009507652331883591,
      "loss": 4.9443,
      "step": 1467
    },
    {
      "epoch": 0.1683293200321064,
      "grad_norm": 0.0,
      "learning_rate": 0.0009506848530841864,
      "loss": 5.157,
      "step": 1468
    },
    {
      "epoch": 0.1684439857814471,
      "grad_norm": 0.0,
      "learning_rate": 0.0009506044108235252,
      "loss": 4.9444,
      "step": 1469
    },
    {
      "epoch": 0.16855865153078775,
      "grad_norm": 0.0,
      "learning_rate": 0.0009505239064174716,
      "loss": 4.7491,
      "step": 1470
    },
    {
      "epoch": 0.16867331728012844,
      "grad_norm": 0.0,
      "learning_rate": 0.0009504433398771293,
      "loss": 4.8332,
      "step": 1471
    },
    {
      "epoch": 0.1687879830294691,
      "grad_norm": 0.0,
      "learning_rate": 0.0009503627112136111,
      "loss": 5.0728,
      "step": 1472
    },
    {
      "epoch": 0.16890264877880978,
      "grad_norm": 0.0,
      "learning_rate": 0.000950282020438038,
      "loss": 5.1755,
      "step": 1473
    },
    {
      "epoch": 0.16901731452815044,
      "grad_norm": 0.0,
      "learning_rate": 0.00095020126756154,
      "loss": 5.2879,
      "step": 1474
    },
    {
      "epoch": 0.1691319802774911,
      "grad_norm": 0.0,
      "learning_rate": 0.0009501204525952554,
      "loss": 5.1677,
      "step": 1475
    },
    {
      "epoch": 0.1692466460268318,
      "grad_norm": 0.0,
      "learning_rate": 0.0009500395755503308,
      "loss": 5.0842,
      "step": 1476
    },
    {
      "epoch": 0.16936131177617245,
      "grad_norm": 0.0,
      "learning_rate": 0.0009499586364379218,
      "loss": 5.0297,
      "step": 1477
    },
    {
      "epoch": 0.16947597752551313,
      "grad_norm": 0.0,
      "learning_rate": 0.0009498776352691927,
      "loss": 4.9721,
      "step": 1478
    },
    {
      "epoch": 0.1695906432748538,
      "grad_norm": 0.0,
      "learning_rate": 0.0009497965720553157,
      "loss": 4.9075,
      "step": 1479
    },
    {
      "epoch": 0.16970530902419448,
      "grad_norm": 0.0,
      "learning_rate": 0.0009497154468074719,
      "loss": 4.8985,
      "step": 1480
    },
    {
      "epoch": 0.16981997477353514,
      "grad_norm": 0.0,
      "learning_rate": 0.0009496342595368513,
      "loss": 4.856,
      "step": 1481
    },
    {
      "epoch": 0.16993464052287582,
      "grad_norm": 0.0,
      "learning_rate": 0.0009495530102546518,
      "loss": 5.1226,
      "step": 1482
    },
    {
      "epoch": 0.17004930627221648,
      "grad_norm": 0.0,
      "learning_rate": 0.0009494716989720804,
      "loss": 4.85,
      "step": 1483
    },
    {
      "epoch": 0.17016397202155717,
      "grad_norm": 0.0,
      "learning_rate": 0.0009493903257003525,
      "loss": 5.275,
      "step": 1484
    },
    {
      "epoch": 0.17027863777089783,
      "grad_norm": 0.0,
      "learning_rate": 0.0009493088904506915,
      "loss": 5.1496,
      "step": 1485
    },
    {
      "epoch": 0.17039330352023851,
      "grad_norm": 0.0,
      "learning_rate": 0.0009492273932343306,
      "loss": 5.1658,
      "step": 1486
    },
    {
      "epoch": 0.17050796926957917,
      "grad_norm": 0.0,
      "learning_rate": 0.0009491458340625103,
      "loss": 4.8945,
      "step": 1487
    },
    {
      "epoch": 0.17062263501891986,
      "grad_norm": 0.0,
      "learning_rate": 0.0009490642129464802,
      "loss": 5.0883,
      "step": 1488
    },
    {
      "epoch": 0.17073730076826052,
      "grad_norm": 0.0,
      "learning_rate": 0.0009489825298974984,
      "loss": 4.8631,
      "step": 1489
    },
    {
      "epoch": 0.1708519665176012,
      "grad_norm": 0.0,
      "learning_rate": 0.0009489007849268318,
      "loss": 5.3196,
      "step": 1490
    },
    {
      "epoch": 0.17096663226694186,
      "grad_norm": 0.0,
      "learning_rate": 0.000948818978045755,
      "loss": 4.8335,
      "step": 1491
    },
    {
      "epoch": 0.17108129801628252,
      "grad_norm": 0.0,
      "learning_rate": 0.0009487371092655519,
      "loss": 4.6615,
      "step": 1492
    },
    {
      "epoch": 0.1711959637656232,
      "grad_norm": 0.0,
      "learning_rate": 0.000948655178597515,
      "loss": 5.0923,
      "step": 1493
    },
    {
      "epoch": 0.17131062951496387,
      "grad_norm": 0.0,
      "learning_rate": 0.000948573186052945,
      "loss": 5.2617,
      "step": 1494
    },
    {
      "epoch": 0.17142529526430456,
      "grad_norm": 0.0,
      "learning_rate": 0.000948491131643151,
      "loss": 4.9548,
      "step": 1495
    },
    {
      "epoch": 0.17153996101364521,
      "grad_norm": 0.0,
      "learning_rate": 0.0009484090153794509,
      "loss": 4.9335,
      "step": 1496
    },
    {
      "epoch": 0.1716546267629859,
      "grad_norm": 0.0,
      "learning_rate": 0.0009483268372731714,
      "loss": 4.9481,
      "step": 1497
    },
    {
      "epoch": 0.17176929251232656,
      "grad_norm": 0.0,
      "learning_rate": 0.0009482445973356468,
      "loss": 4.964,
      "step": 1498
    },
    {
      "epoch": 0.17188395826166725,
      "grad_norm": 0.0,
      "learning_rate": 0.000948162295578221,
      "loss": 5.0924,
      "step": 1499
    },
    {
      "epoch": 0.1719986240110079,
      "grad_norm": 0.0,
      "learning_rate": 0.0009480799320122457,
      "loss": 5.1415,
      "step": 1500
    },
    {
      "epoch": 0.1721132897603486,
      "grad_norm": 0.0,
      "learning_rate": 0.0009479975066490815,
      "loss": 4.9898,
      "step": 1501
    },
    {
      "epoch": 0.17222795550968925,
      "grad_norm": 0.0,
      "learning_rate": 0.0009479150195000977,
      "loss": 4.9757,
      "step": 1502
    },
    {
      "epoch": 0.17234262125902994,
      "grad_norm": 0.0,
      "learning_rate": 0.0009478324705766714,
      "loss": 5.1132,
      "step": 1503
    },
    {
      "epoch": 0.1724572870083706,
      "grad_norm": 0.0,
      "learning_rate": 0.0009477498598901888,
      "loss": 4.9946,
      "step": 1504
    },
    {
      "epoch": 0.17257195275771128,
      "grad_norm": 0.0,
      "learning_rate": 0.0009476671874520444,
      "loss": 4.6724,
      "step": 1505
    },
    {
      "epoch": 0.17268661850705194,
      "grad_norm": 0.0,
      "learning_rate": 0.0009475844532736413,
      "loss": 4.9383,
      "step": 1506
    },
    {
      "epoch": 0.17280128425639263,
      "grad_norm": 0.0,
      "learning_rate": 0.0009475016573663913,
      "loss": 4.9551,
      "step": 1507
    },
    {
      "epoch": 0.1729159500057333,
      "grad_norm": 0.0,
      "learning_rate": 0.0009474187997417143,
      "loss": 4.8832,
      "step": 1508
    },
    {
      "epoch": 0.17303061575507395,
      "grad_norm": 0.0,
      "learning_rate": 0.000947335880411039,
      "loss": 5.0422,
      "step": 1509
    },
    {
      "epoch": 0.17314528150441463,
      "grad_norm": 0.0,
      "learning_rate": 0.0009472528993858026,
      "loss": 4.8003,
      "step": 1510
    },
    {
      "epoch": 0.1732599472537553,
      "grad_norm": 0.0,
      "learning_rate": 0.0009471698566774505,
      "loss": 4.9504,
      "step": 1511
    },
    {
      "epoch": 0.17337461300309598,
      "grad_norm": 0.0,
      "learning_rate": 0.0009470867522974373,
      "loss": 4.7144,
      "step": 1512
    },
    {
      "epoch": 0.17348927875243664,
      "grad_norm": 0.0,
      "learning_rate": 0.0009470035862572254,
      "loss": 4.9219,
      "step": 1513
    },
    {
      "epoch": 0.17360394450177732,
      "grad_norm": 0.0,
      "learning_rate": 0.0009469203585682858,
      "loss": 5.0981,
      "step": 1514
    },
    {
      "epoch": 0.17371861025111798,
      "grad_norm": 0.0,
      "learning_rate": 0.0009468370692420985,
      "loss": 4.8194,
      "step": 1515
    },
    {
      "epoch": 0.17383327600045867,
      "grad_norm": 0.0,
      "learning_rate": 0.0009467537182901515,
      "loss": 5.0893,
      "step": 1516
    },
    {
      "epoch": 0.17394794174979933,
      "grad_norm": 0.0,
      "learning_rate": 0.0009466703057239414,
      "loss": 5.2355,
      "step": 1517
    },
    {
      "epoch": 0.17406260749914002,
      "grad_norm": 0.0,
      "learning_rate": 0.0009465868315549736,
      "loss": 4.7451,
      "step": 1518
    },
    {
      "epoch": 0.17417727324848067,
      "grad_norm": 0.0,
      "learning_rate": 0.0009465032957947615,
      "loss": 4.9409,
      "step": 1519
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 0.0,
      "learning_rate": 0.0009464196984548277,
      "loss": 5.1298,
      "step": 1520
    },
    {
      "epoch": 0.17440660474716202,
      "grad_norm": 0.0,
      "learning_rate": 0.0009463360395467025,
      "loss": 4.9756,
      "step": 1521
    },
    {
      "epoch": 0.1745212704965027,
      "grad_norm": 0.0,
      "learning_rate": 0.000946252319081925,
      "loss": 5.2302,
      "step": 1522
    },
    {
      "epoch": 0.17463593624584337,
      "grad_norm": 0.0,
      "learning_rate": 0.0009461685370720431,
      "loss": 4.8284,
      "step": 1523
    },
    {
      "epoch": 0.17475060199518405,
      "grad_norm": 0.0,
      "learning_rate": 0.0009460846935286127,
      "loss": 5.0292,
      "step": 1524
    },
    {
      "epoch": 0.1748652677445247,
      "grad_norm": 0.0,
      "learning_rate": 0.0009460007884631985,
      "loss": 4.9869,
      "step": 1525
    },
    {
      "epoch": 0.17497993349386537,
      "grad_norm": 0.0,
      "learning_rate": 0.0009459168218873737,
      "loss": 5.056,
      "step": 1526
    },
    {
      "epoch": 0.17509459924320606,
      "grad_norm": 0.0,
      "learning_rate": 0.0009458327938127198,
      "loss": 5.0183,
      "step": 1527
    },
    {
      "epoch": 0.17520926499254671,
      "grad_norm": 0.0,
      "learning_rate": 0.000945748704250827,
      "loss": 4.857,
      "step": 1528
    },
    {
      "epoch": 0.1753239307418874,
      "grad_norm": 0.0,
      "learning_rate": 0.0009456645532132936,
      "loss": 5.0381,
      "step": 1529
    },
    {
      "epoch": 0.17543859649122806,
      "grad_norm": 0.0,
      "learning_rate": 0.0009455803407117267,
      "loss": 4.8298,
      "step": 1530
    },
    {
      "epoch": 0.17555326224056875,
      "grad_norm": 0.0,
      "learning_rate": 0.000945496066757742,
      "loss": 4.8853,
      "step": 1531
    },
    {
      "epoch": 0.1756679279899094,
      "grad_norm": 0.0,
      "learning_rate": 0.0009454117313629633,
      "loss": 4.7742,
      "step": 1532
    },
    {
      "epoch": 0.1757825937392501,
      "grad_norm": 0.0,
      "learning_rate": 0.0009453273345390233,
      "loss": 4.9592,
      "step": 1533
    },
    {
      "epoch": 0.17589725948859075,
      "grad_norm": 0.0,
      "learning_rate": 0.0009452428762975625,
      "loss": 5.029,
      "step": 1534
    },
    {
      "epoch": 0.17601192523793144,
      "grad_norm": 0.0,
      "learning_rate": 0.0009451583566502307,
      "loss": 4.8057,
      "step": 1535
    },
    {
      "epoch": 0.1761265909872721,
      "grad_norm": 0.0,
      "learning_rate": 0.0009450737756086858,
      "loss": 4.7931,
      "step": 1536
    },
    {
      "epoch": 0.17624125673661278,
      "grad_norm": 0.0,
      "learning_rate": 0.0009449891331845937,
      "loss": 5.2415,
      "step": 1537
    },
    {
      "epoch": 0.17635592248595344,
      "grad_norm": 0.0,
      "learning_rate": 0.0009449044293896296,
      "loss": 4.9559,
      "step": 1538
    },
    {
      "epoch": 0.17647058823529413,
      "grad_norm": 0.0,
      "learning_rate": 0.0009448196642354766,
      "loss": 5.007,
      "step": 1539
    },
    {
      "epoch": 0.1765852539846348,
      "grad_norm": 0.0,
      "learning_rate": 0.0009447348377338267,
      "loss": 4.9198,
      "step": 1540
    },
    {
      "epoch": 0.17669991973397547,
      "grad_norm": 0.0,
      "learning_rate": 0.0009446499498963796,
      "loss": 5.0918,
      "step": 1541
    },
    {
      "epoch": 0.17681458548331613,
      "grad_norm": 0.0,
      "learning_rate": 0.0009445650007348446,
      "loss": 5.1206,
      "step": 1542
    },
    {
      "epoch": 0.1769292512326568,
      "grad_norm": 0.0,
      "learning_rate": 0.0009444799902609384,
      "loss": 5.1089,
      "step": 1543
    },
    {
      "epoch": 0.17704391698199748,
      "grad_norm": 0.0,
      "learning_rate": 0.0009443949184863862,
      "loss": 5.0919,
      "step": 1544
    },
    {
      "epoch": 0.17715858273133814,
      "grad_norm": 0.0,
      "learning_rate": 0.000944309785422923,
      "loss": 5.0147,
      "step": 1545
    },
    {
      "epoch": 0.17727324848067882,
      "grad_norm": 0.0,
      "learning_rate": 0.0009442245910822906,
      "loss": 5.151,
      "step": 1546
    },
    {
      "epoch": 0.17738791423001948,
      "grad_norm": 0.0,
      "learning_rate": 0.0009441393354762401,
      "loss": 5.1573,
      "step": 1547
    },
    {
      "epoch": 0.17750257997936017,
      "grad_norm": 0.0,
      "learning_rate": 0.0009440540186165307,
      "loss": 5.0476,
      "step": 1548
    },
    {
      "epoch": 0.17761724572870083,
      "grad_norm": 0.0,
      "learning_rate": 0.0009439686405149307,
      "loss": 4.794,
      "step": 1549
    },
    {
      "epoch": 0.17773191147804152,
      "grad_norm": 0.0,
      "learning_rate": 0.0009438832011832159,
      "loss": 5.0464,
      "step": 1550
    },
    {
      "epoch": 0.17784657722738217,
      "grad_norm": 0.0,
      "learning_rate": 0.0009437977006331714,
      "loss": 5.1593,
      "step": 1551
    },
    {
      "epoch": 0.17796124297672286,
      "grad_norm": 0.0,
      "learning_rate": 0.0009437121388765901,
      "loss": 5.1322,
      "step": 1552
    },
    {
      "epoch": 0.17807590872606352,
      "grad_norm": 0.0,
      "learning_rate": 0.0009436265159252737,
      "loss": 5.1304,
      "step": 1553
    },
    {
      "epoch": 0.1781905744754042,
      "grad_norm": 0.0,
      "learning_rate": 0.0009435408317910323,
      "loss": 5.0771,
      "step": 1554
    },
    {
      "epoch": 0.17830524022474487,
      "grad_norm": 0.0,
      "learning_rate": 0.0009434550864856843,
      "loss": 4.895,
      "step": 1555
    },
    {
      "epoch": 0.17841990597408555,
      "grad_norm": 0.0,
      "learning_rate": 0.0009433692800210568,
      "loss": 5.0953,
      "step": 1556
    },
    {
      "epoch": 0.1785345717234262,
      "grad_norm": 0.0,
      "learning_rate": 0.000943283412408985,
      "loss": 5.0492,
      "step": 1557
    },
    {
      "epoch": 0.1786492374727669,
      "grad_norm": 0.0,
      "learning_rate": 0.0009431974836613127,
      "loss": 5.1454,
      "step": 1558
    },
    {
      "epoch": 0.17876390322210756,
      "grad_norm": 0.0,
      "learning_rate": 0.0009431114937898923,
      "loss": 5.2845,
      "step": 1559
    },
    {
      "epoch": 0.17887856897144822,
      "grad_norm": 0.0,
      "learning_rate": 0.0009430254428065843,
      "loss": 4.8711,
      "step": 1560
    },
    {
      "epoch": 0.1789932347207889,
      "grad_norm": 0.0,
      "learning_rate": 0.0009429393307232578,
      "loss": 4.9794,
      "step": 1561
    },
    {
      "epoch": 0.17910790047012956,
      "grad_norm": 0.0,
      "learning_rate": 0.0009428531575517904,
      "loss": 4.9316,
      "step": 1562
    },
    {
      "epoch": 0.17922256621947025,
      "grad_norm": 0.0,
      "learning_rate": 0.000942766923304068,
      "loss": 5.1607,
      "step": 1563
    },
    {
      "epoch": 0.1793372319688109,
      "grad_norm": 0.0,
      "learning_rate": 0.000942680627991985,
      "loss": 5.1803,
      "step": 1564
    },
    {
      "epoch": 0.1794518977181516,
      "grad_norm": 0.0,
      "learning_rate": 0.0009425942716274441,
      "loss": 4.8999,
      "step": 1565
    },
    {
      "epoch": 0.17956656346749225,
      "grad_norm": 0.0,
      "learning_rate": 0.0009425078542223568,
      "loss": 4.6966,
      "step": 1566
    },
    {
      "epoch": 0.17968122921683294,
      "grad_norm": 0.0,
      "learning_rate": 0.0009424213757886423,
      "loss": 4.8773,
      "step": 1567
    },
    {
      "epoch": 0.1797958949661736,
      "grad_norm": 0.0,
      "learning_rate": 0.000942334836338229,
      "loss": 5.0854,
      "step": 1568
    },
    {
      "epoch": 0.17991056071551428,
      "grad_norm": 0.0,
      "learning_rate": 0.0009422482358830531,
      "loss": 4.942,
      "step": 1569
    },
    {
      "epoch": 0.18002522646485494,
      "grad_norm": 0.0,
      "learning_rate": 0.0009421615744350598,
      "loss": 4.9003,
      "step": 1570
    },
    {
      "epoch": 0.18013989221419563,
      "grad_norm": 0.0,
      "learning_rate": 0.0009420748520062021,
      "loss": 5.0379,
      "step": 1571
    },
    {
      "epoch": 0.1802545579635363,
      "grad_norm": 0.0,
      "learning_rate": 0.0009419880686084419,
      "loss": 4.9216,
      "step": 1572
    },
    {
      "epoch": 0.18036922371287697,
      "grad_norm": 0.0,
      "learning_rate": 0.0009419012242537492,
      "loss": 5.1295,
      "step": 1573
    },
    {
      "epoch": 0.18048388946221763,
      "grad_norm": 0.0,
      "learning_rate": 0.0009418143189541026,
      "loss": 5.1171,
      "step": 1574
    },
    {
      "epoch": 0.18059855521155832,
      "grad_norm": 0.0,
      "learning_rate": 0.0009417273527214889,
      "loss": 4.8726,
      "step": 1575
    },
    {
      "epoch": 0.18071322096089898,
      "grad_norm": 0.0,
      "learning_rate": 0.0009416403255679037,
      "loss": 4.9571,
      "step": 1576
    },
    {
      "epoch": 0.18082788671023964,
      "grad_norm": 0.0,
      "learning_rate": 0.0009415532375053505,
      "loss": 5.2286,
      "step": 1577
    },
    {
      "epoch": 0.18094255245958032,
      "grad_norm": 0.0,
      "learning_rate": 0.0009414660885458415,
      "loss": 4.8851,
      "step": 1578
    },
    {
      "epoch": 0.18105721820892098,
      "grad_norm": 0.0,
      "learning_rate": 0.0009413788787013971,
      "loss": 5.2586,
      "step": 1579
    },
    {
      "epoch": 0.18117188395826167,
      "grad_norm": 0.0,
      "learning_rate": 0.0009412916079840466,
      "loss": 4.9053,
      "step": 1580
    },
    {
      "epoch": 0.18128654970760233,
      "grad_norm": 0.0,
      "learning_rate": 0.000941204276405827,
      "loss": 4.9635,
      "step": 1581
    },
    {
      "epoch": 0.18140121545694302,
      "grad_norm": 0.0,
      "learning_rate": 0.000941116883978784,
      "loss": 5.1775,
      "step": 1582
    },
    {
      "epoch": 0.18151588120628367,
      "grad_norm": 0.0,
      "learning_rate": 0.000941029430714972,
      "loss": 5.0878,
      "step": 1583
    },
    {
      "epoch": 0.18163054695562436,
      "grad_norm": 0.0,
      "learning_rate": 0.0009409419166264534,
      "loss": 5.0809,
      "step": 1584
    },
    {
      "epoch": 0.18174521270496502,
      "grad_norm": 0.0,
      "learning_rate": 0.000940854341725299,
      "loss": 5.2119,
      "step": 1585
    },
    {
      "epoch": 0.1818598784543057,
      "grad_norm": 0.0,
      "learning_rate": 0.0009407667060235881,
      "loss": 5.05,
      "step": 1586
    },
    {
      "epoch": 0.18197454420364637,
      "grad_norm": 0.0,
      "learning_rate": 0.0009406790095334086,
      "loss": 5.1361,
      "step": 1587
    },
    {
      "epoch": 0.18208920995298705,
      "grad_norm": 0.0,
      "learning_rate": 0.0009405912522668562,
      "loss": 4.7475,
      "step": 1588
    },
    {
      "epoch": 0.1822038757023277,
      "grad_norm": 0.0,
      "learning_rate": 0.0009405034342360357,
      "loss": 4.9641,
      "step": 1589
    },
    {
      "epoch": 0.1823185414516684,
      "grad_norm": 0.0,
      "learning_rate": 0.0009404155554530595,
      "loss": 5.0761,
      "step": 1590
    },
    {
      "epoch": 0.18243320720100906,
      "grad_norm": 0.0,
      "learning_rate": 0.0009403276159300494,
      "loss": 5.0864,
      "step": 1591
    },
    {
      "epoch": 0.18254787295034974,
      "grad_norm": 0.0,
      "learning_rate": 0.0009402396156791346,
      "loss": 4.8316,
      "step": 1592
    },
    {
      "epoch": 0.1826625386996904,
      "grad_norm": 0.0,
      "learning_rate": 0.0009401515547124528,
      "loss": 5.0108,
      "step": 1593
    },
    {
      "epoch": 0.18277720444903106,
      "grad_norm": 0.0,
      "learning_rate": 0.0009400634330421508,
      "loss": 5.0375,
      "step": 1594
    },
    {
      "epoch": 0.18289187019837175,
      "grad_norm": 0.0,
      "learning_rate": 0.000939975250680383,
      "loss": 4.9819,
      "step": 1595
    },
    {
      "epoch": 0.1830065359477124,
      "grad_norm": 0.0,
      "learning_rate": 0.0009398870076393129,
      "loss": 5.0976,
      "step": 1596
    },
    {
      "epoch": 0.1831212016970531,
      "grad_norm": 0.0,
      "learning_rate": 0.0009397987039311115,
      "loss": 5.1126,
      "step": 1597
    },
    {
      "epoch": 0.18323586744639375,
      "grad_norm": 0.0,
      "learning_rate": 0.0009397103395679587,
      "loss": 5.0689,
      "step": 1598
    },
    {
      "epoch": 0.18335053319573444,
      "grad_norm": 0.0,
      "learning_rate": 0.0009396219145620427,
      "loss": 5.03,
      "step": 1599
    },
    {
      "epoch": 0.1834651989450751,
      "grad_norm": 0.0,
      "learning_rate": 0.0009395334289255603,
      "loss": 4.9871,
      "step": 1600
    },
    {
      "epoch": 0.18357986469441578,
      "grad_norm": 0.0,
      "learning_rate": 0.0009394448826707159,
      "loss": 4.9153,
      "step": 1601
    },
    {
      "epoch": 0.18369453044375644,
      "grad_norm": 0.0,
      "learning_rate": 0.0009393562758097233,
      "loss": 5.0954,
      "step": 1602
    },
    {
      "epoch": 0.18380919619309713,
      "grad_norm": 0.0,
      "learning_rate": 0.0009392676083548038,
      "loss": 5.0105,
      "step": 1603
    },
    {
      "epoch": 0.1839238619424378,
      "grad_norm": 0.0,
      "learning_rate": 0.0009391788803181875,
      "loss": 5.2131,
      "step": 1604
    },
    {
      "epoch": 0.18403852769177848,
      "grad_norm": 0.0,
      "learning_rate": 0.0009390900917121127,
      "loss": 5.1217,
      "step": 1605
    },
    {
      "epoch": 0.18415319344111913,
      "grad_norm": 0.0,
      "learning_rate": 0.0009390012425488263,
      "loss": 4.7482,
      "step": 1606
    },
    {
      "epoch": 0.18426785919045982,
      "grad_norm": 0.0,
      "learning_rate": 0.0009389123328405829,
      "loss": 5.1031,
      "step": 1607
    },
    {
      "epoch": 0.18438252493980048,
      "grad_norm": 0.0,
      "learning_rate": 0.0009388233625996463,
      "loss": 5.1364,
      "step": 1608
    },
    {
      "epoch": 0.18449719068914117,
      "grad_norm": 0.0,
      "learning_rate": 0.0009387343318382881,
      "loss": 5.1087,
      "step": 1609
    },
    {
      "epoch": 0.18461185643848183,
      "grad_norm": 0.0,
      "learning_rate": 0.0009386452405687883,
      "loss": 4.7181,
      "step": 1610
    },
    {
      "epoch": 0.18472652218782248,
      "grad_norm": 0.0,
      "learning_rate": 0.0009385560888034355,
      "loss": 5.1188,
      "step": 1611
    },
    {
      "epoch": 0.18484118793716317,
      "grad_norm": 0.0,
      "learning_rate": 0.0009384668765545264,
      "loss": 5.3139,
      "step": 1612
    },
    {
      "epoch": 0.18495585368650383,
      "grad_norm": 0.0,
      "learning_rate": 0.0009383776038343664,
      "loss": 4.9917,
      "step": 1613
    },
    {
      "epoch": 0.18507051943584452,
      "grad_norm": 0.0,
      "learning_rate": 0.0009382882706552686,
      "loss": 5.0897,
      "step": 1614
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 0.0,
      "learning_rate": 0.0009381988770295548,
      "loss": 4.9289,
      "step": 1615
    },
    {
      "epoch": 0.18529985093452586,
      "grad_norm": 0.0,
      "learning_rate": 0.0009381094229695554,
      "loss": 5.0104,
      "step": 1616
    },
    {
      "epoch": 0.18541451668386652,
      "grad_norm": 0.0,
      "learning_rate": 0.0009380199084876087,
      "loss": 5.068,
      "step": 1617
    },
    {
      "epoch": 0.1855291824332072,
      "grad_norm": 0.0,
      "learning_rate": 0.0009379303335960617,
      "loss": 4.9064,
      "step": 1618
    },
    {
      "epoch": 0.18564384818254787,
      "grad_norm": 0.0,
      "learning_rate": 0.0009378406983072693,
      "loss": 5.0813,
      "step": 1619
    },
    {
      "epoch": 0.18575851393188855,
      "grad_norm": 0.0,
      "learning_rate": 0.0009377510026335955,
      "loss": 5.0275,
      "step": 1620
    },
    {
      "epoch": 0.1858731796812292,
      "grad_norm": 0.0,
      "learning_rate": 0.0009376612465874114,
      "loss": 5.1291,
      "step": 1621
    },
    {
      "epoch": 0.1859878454305699,
      "grad_norm": 0.0,
      "learning_rate": 0.0009375714301810974,
      "loss": 5.0097,
      "step": 1622
    },
    {
      "epoch": 0.18610251117991056,
      "grad_norm": 0.0,
      "learning_rate": 0.0009374815534270422,
      "loss": 5.1417,
      "step": 1623
    },
    {
      "epoch": 0.18621717692925124,
      "grad_norm": 0.0,
      "learning_rate": 0.0009373916163376424,
      "loss": 4.9958,
      "step": 1624
    },
    {
      "epoch": 0.1863318426785919,
      "grad_norm": 0.0,
      "learning_rate": 0.000937301618925303,
      "loss": 4.9761,
      "step": 1625
    },
    {
      "epoch": 0.1864465084279326,
      "grad_norm": 0.0,
      "learning_rate": 0.0009372115612024377,
      "loss": 4.9131,
      "step": 1626
    },
    {
      "epoch": 0.18656117417727325,
      "grad_norm": 0.0,
      "learning_rate": 0.0009371214431814678,
      "loss": 5.1789,
      "step": 1627
    },
    {
      "epoch": 0.1866758399266139,
      "grad_norm": 0.0,
      "learning_rate": 0.000937031264874824,
      "loss": 5.0152,
      "step": 1628
    },
    {
      "epoch": 0.1867905056759546,
      "grad_norm": 0.0,
      "learning_rate": 0.0009369410262949441,
      "loss": 5.1361,
      "step": 1629
    },
    {
      "epoch": 0.18690517142529525,
      "grad_norm": 0.0,
      "learning_rate": 0.0009368507274542751,
      "loss": 5.2367,
      "step": 1630
    },
    {
      "epoch": 0.18701983717463594,
      "grad_norm": 0.0,
      "learning_rate": 0.0009367603683652719,
      "loss": 5.0608,
      "step": 1631
    },
    {
      "epoch": 0.1871345029239766,
      "grad_norm": 0.0,
      "learning_rate": 0.0009366699490403979,
      "loss": 5.104,
      "step": 1632
    },
    {
      "epoch": 0.18724916867331728,
      "grad_norm": 0.0,
      "learning_rate": 0.0009365794694921245,
      "loss": 4.8602,
      "step": 1633
    },
    {
      "epoch": 0.18736383442265794,
      "grad_norm": 0.0,
      "learning_rate": 0.000936488929732932,
      "loss": 5.1032,
      "step": 1634
    },
    {
      "epoch": 0.18747850017199863,
      "grad_norm": 0.0,
      "learning_rate": 0.0009363983297753084,
      "loss": 5.0923,
      "step": 1635
    },
    {
      "epoch": 0.1875931659213393,
      "grad_norm": 0.0,
      "learning_rate": 0.0009363076696317502,
      "loss": 4.8996,
      "step": 1636
    },
    {
      "epoch": 0.18770783167067998,
      "grad_norm": 0.0,
      "learning_rate": 0.0009362169493147623,
      "loss": 5.0677,
      "step": 1637
    },
    {
      "epoch": 0.18782249742002063,
      "grad_norm": 0.0,
      "learning_rate": 0.0009361261688368578,
      "loss": 5.1139,
      "step": 1638
    },
    {
      "epoch": 0.18793716316936132,
      "grad_norm": 0.0,
      "learning_rate": 0.0009360353282105583,
      "loss": 5.0012,
      "step": 1639
    },
    {
      "epoch": 0.18805182891870198,
      "grad_norm": 0.0,
      "learning_rate": 0.0009359444274483934,
      "loss": 4.7715,
      "step": 1640
    },
    {
      "epoch": 0.18816649466804267,
      "grad_norm": 0.0,
      "learning_rate": 0.0009358534665629009,
      "loss": 5.4503,
      "step": 1641
    },
    {
      "epoch": 0.18828116041738333,
      "grad_norm": 0.0,
      "learning_rate": 0.0009357624455666276,
      "loss": 4.832,
      "step": 1642
    },
    {
      "epoch": 0.188395826166724,
      "grad_norm": 0.0,
      "learning_rate": 0.0009356713644721277,
      "loss": 5.0167,
      "step": 1643
    },
    {
      "epoch": 0.18851049191606467,
      "grad_norm": 0.0,
      "learning_rate": 0.0009355802232919644,
      "loss": 5.092,
      "step": 1644
    },
    {
      "epoch": 0.18862515766540533,
      "grad_norm": 0.0,
      "learning_rate": 0.0009354890220387088,
      "loss": 5.0143,
      "step": 1645
    },
    {
      "epoch": 0.18873982341474602,
      "grad_norm": 0.0,
      "learning_rate": 0.0009353977607249404,
      "loss": 5.0525,
      "step": 1646
    },
    {
      "epoch": 0.18885448916408668,
      "grad_norm": 0.0,
      "learning_rate": 0.0009353064393632466,
      "loss": 4.857,
      "step": 1647
    },
    {
      "epoch": 0.18896915491342736,
      "grad_norm": 0.0,
      "learning_rate": 0.0009352150579662239,
      "loss": 4.8256,
      "step": 1648
    },
    {
      "epoch": 0.18908382066276802,
      "grad_norm": 0.0,
      "learning_rate": 0.0009351236165464766,
      "loss": 5.2199,
      "step": 1649
    },
    {
      "epoch": 0.1891984864121087,
      "grad_norm": 0.0,
      "learning_rate": 0.0009350321151166168,
      "loss": 5.12,
      "step": 1650
    },
    {
      "epoch": 0.18931315216144937,
      "grad_norm": 0.0,
      "learning_rate": 0.000934940553689266,
      "loss": 4.9014,
      "step": 1651
    },
    {
      "epoch": 0.18942781791079005,
      "grad_norm": 0.0,
      "learning_rate": 0.0009348489322770529,
      "loss": 5.1887,
      "step": 1652
    },
    {
      "epoch": 0.1895424836601307,
      "grad_norm": 0.0,
      "learning_rate": 0.0009347572508926154,
      "loss": 4.9336,
      "step": 1653
    },
    {
      "epoch": 0.1896571494094714,
      "grad_norm": 0.0,
      "learning_rate": 0.0009346655095485988,
      "loss": 4.9509,
      "step": 1654
    },
    {
      "epoch": 0.18977181515881206,
      "grad_norm": 0.0,
      "learning_rate": 0.0009345737082576571,
      "loss": 4.8985,
      "step": 1655
    },
    {
      "epoch": 0.18988648090815274,
      "grad_norm": 0.0,
      "learning_rate": 0.0009344818470324527,
      "loss": 5.3052,
      "step": 1656
    },
    {
      "epoch": 0.1900011466574934,
      "grad_norm": 0.0,
      "learning_rate": 0.0009343899258856559,
      "loss": 5.249,
      "step": 1657
    },
    {
      "epoch": 0.1901158124068341,
      "grad_norm": 0.0,
      "learning_rate": 0.0009342979448299457,
      "loss": 4.9758,
      "step": 1658
    },
    {
      "epoch": 0.19023047815617475,
      "grad_norm": 0.0,
      "learning_rate": 0.0009342059038780089,
      "loss": 4.9554,
      "step": 1659
    },
    {
      "epoch": 0.19034514390551543,
      "grad_norm": 0.0,
      "learning_rate": 0.0009341138030425411,
      "loss": 5.2363,
      "step": 1660
    },
    {
      "epoch": 0.1904598096548561,
      "grad_norm": 0.0,
      "learning_rate": 0.0009340216423362455,
      "loss": 4.9697,
      "step": 1661
    },
    {
      "epoch": 0.19057447540419675,
      "grad_norm": 0.0,
      "learning_rate": 0.0009339294217718343,
      "loss": 5.0287,
      "step": 1662
    },
    {
      "epoch": 0.19068914115353744,
      "grad_norm": 0.0,
      "learning_rate": 0.0009338371413620272,
      "loss": 4.7464,
      "step": 1663
    },
    {
      "epoch": 0.1908038069028781,
      "grad_norm": 0.0,
      "learning_rate": 0.0009337448011195527,
      "loss": 5.0743,
      "step": 1664
    },
    {
      "epoch": 0.19091847265221878,
      "grad_norm": 0.0,
      "learning_rate": 0.0009336524010571474,
      "loss": 4.8404,
      "step": 1665
    },
    {
      "epoch": 0.19103313840155944,
      "grad_norm": 0.0,
      "learning_rate": 0.0009335599411875562,
      "loss": 5.0792,
      "step": 1666
    },
    {
      "epoch": 0.19114780415090013,
      "grad_norm": 0.0,
      "learning_rate": 0.0009334674215235319,
      "loss": 5.2772,
      "step": 1667
    },
    {
      "epoch": 0.1912624699002408,
      "grad_norm": 0.0,
      "learning_rate": 0.000933374842077836,
      "loss": 4.9581,
      "step": 1668
    },
    {
      "epoch": 0.19137713564958148,
      "grad_norm": 0.0,
      "learning_rate": 0.0009332822028632382,
      "loss": 5.0513,
      "step": 1669
    },
    {
      "epoch": 0.19149180139892213,
      "grad_norm": 0.0,
      "learning_rate": 0.000933189503892516,
      "loss": 5.0916,
      "step": 1670
    },
    {
      "epoch": 0.19160646714826282,
      "grad_norm": 0.0,
      "learning_rate": 0.0009330967451784556,
      "loss": 5.0161,
      "step": 1671
    },
    {
      "epoch": 0.19172113289760348,
      "grad_norm": 0.0,
      "learning_rate": 0.0009330039267338516,
      "loss": 5.0394,
      "step": 1672
    },
    {
      "epoch": 0.19183579864694417,
      "grad_norm": 0.0,
      "learning_rate": 0.0009329110485715061,
      "loss": 4.9394,
      "step": 1673
    },
    {
      "epoch": 0.19195046439628483,
      "grad_norm": 0.0,
      "learning_rate": 0.0009328181107042299,
      "loss": 5.1713,
      "step": 1674
    },
    {
      "epoch": 0.1920651301456255,
      "grad_norm": 0.0,
      "learning_rate": 0.0009327251131448424,
      "loss": 4.9566,
      "step": 1675
    },
    {
      "epoch": 0.19217979589496617,
      "grad_norm": 0.0,
      "learning_rate": 0.0009326320559061703,
      "loss": 5.2261,
      "step": 1676
    },
    {
      "epoch": 0.19229446164430686,
      "grad_norm": 0.0,
      "learning_rate": 0.0009325389390010495,
      "loss": 4.909,
      "step": 1677
    },
    {
      "epoch": 0.19240912739364752,
      "grad_norm": 0.0,
      "learning_rate": 0.0009324457624423236,
      "loss": 4.9796,
      "step": 1678
    },
    {
      "epoch": 0.1925237931429882,
      "grad_norm": 0.0,
      "learning_rate": 0.0009323525262428443,
      "loss": 4.9427,
      "step": 1679
    },
    {
      "epoch": 0.19263845889232886,
      "grad_norm": 0.0,
      "learning_rate": 0.0009322592304154722,
      "loss": 4.9447,
      "step": 1680
    },
    {
      "epoch": 0.19275312464166952,
      "grad_norm": 0.0,
      "learning_rate": 0.0009321658749730752,
      "loss": 5.0462,
      "step": 1681
    },
    {
      "epoch": 0.1928677903910102,
      "grad_norm": 0.0,
      "learning_rate": 0.0009320724599285303,
      "loss": 4.9251,
      "step": 1682
    },
    {
      "epoch": 0.19298245614035087,
      "grad_norm": 0.0,
      "learning_rate": 0.0009319789852947219,
      "loss": 4.8747,
      "step": 1683
    },
    {
      "epoch": 0.19309712188969155,
      "grad_norm": 0.0,
      "learning_rate": 0.0009318854510845436,
      "loss": 4.8747,
      "step": 1684
    },
    {
      "epoch": 0.1932117876390322,
      "grad_norm": 0.0,
      "learning_rate": 0.0009317918573108962,
      "loss": 4.9664,
      "step": 1685
    },
    {
      "epoch": 0.1933264533883729,
      "grad_norm": 0.0,
      "learning_rate": 0.0009316982039866893,
      "loss": 5.1268,
      "step": 1686
    },
    {
      "epoch": 0.19344111913771356,
      "grad_norm": 0.0,
      "learning_rate": 0.0009316044911248408,
      "loss": 4.9026,
      "step": 1687
    },
    {
      "epoch": 0.19355578488705424,
      "grad_norm": 0.0,
      "learning_rate": 0.0009315107187382762,
      "loss": 5.0056,
      "step": 1688
    },
    {
      "epoch": 0.1936704506363949,
      "grad_norm": 0.0,
      "learning_rate": 0.00093141688683993,
      "loss": 4.8965,
      "step": 1689
    },
    {
      "epoch": 0.1937851163857356,
      "grad_norm": 0.0,
      "learning_rate": 0.0009313229954427442,
      "loss": 4.9337,
      "step": 1690
    },
    {
      "epoch": 0.19389978213507625,
      "grad_norm": 0.0,
      "learning_rate": 0.0009312290445596695,
      "loss": 5.0991,
      "step": 1691
    },
    {
      "epoch": 0.19401444788441694,
      "grad_norm": 0.0,
      "learning_rate": 0.0009311350342036648,
      "loss": 4.9073,
      "step": 1692
    },
    {
      "epoch": 0.1941291136337576,
      "grad_norm": 0.0,
      "learning_rate": 0.0009310409643876967,
      "loss": 4.7932,
      "step": 1693
    },
    {
      "epoch": 0.19424377938309828,
      "grad_norm": 0.0,
      "learning_rate": 0.0009309468351247405,
      "loss": 5.0253,
      "step": 1694
    },
    {
      "epoch": 0.19435844513243894,
      "grad_norm": 0.0,
      "learning_rate": 0.0009308526464277798,
      "loss": 5.2038,
      "step": 1695
    },
    {
      "epoch": 0.19447311088177963,
      "grad_norm": 0.0,
      "learning_rate": 0.0009307583983098057,
      "loss": 4.9684,
      "step": 1696
    },
    {
      "epoch": 0.19458777663112028,
      "grad_norm": 0.0,
      "learning_rate": 0.000930664090783818,
      "loss": 5.3866,
      "step": 1697
    },
    {
      "epoch": 0.19470244238046094,
      "grad_norm": 0.0,
      "learning_rate": 0.000930569723862825,
      "loss": 5.0391,
      "step": 1698
    },
    {
      "epoch": 0.19481710812980163,
      "grad_norm": 0.0,
      "learning_rate": 0.0009304752975598422,
      "loss": 4.9549,
      "step": 1699
    },
    {
      "epoch": 0.1949317738791423,
      "grad_norm": 0.0,
      "learning_rate": 0.0009303808118878943,
      "loss": 4.7503,
      "step": 1700
    },
    {
      "epoch": 0.19504643962848298,
      "grad_norm": 0.0,
      "learning_rate": 0.0009302862668600139,
      "loss": 5.5244,
      "step": 1701
    },
    {
      "epoch": 0.19516110537782363,
      "grad_norm": 0.0,
      "learning_rate": 0.0009301916624892414,
      "loss": 5.1484,
      "step": 1702
    },
    {
      "epoch": 0.19527577112716432,
      "grad_norm": 0.0,
      "learning_rate": 0.0009300969987886261,
      "loss": 4.8908,
      "step": 1703
    },
    {
      "epoch": 0.19539043687650498,
      "grad_norm": 0.0,
      "learning_rate": 0.0009300022757712245,
      "loss": 5.1437,
      "step": 1704
    },
    {
      "epoch": 0.19550510262584567,
      "grad_norm": 0.0,
      "learning_rate": 0.0009299074934501021,
      "loss": 5.1536,
      "step": 1705
    },
    {
      "epoch": 0.19561976837518633,
      "grad_norm": 0.0,
      "learning_rate": 0.0009298126518383324,
      "loss": 5.1276,
      "step": 1706
    },
    {
      "epoch": 0.195734434124527,
      "grad_norm": 0.0,
      "learning_rate": 0.0009297177509489968,
      "loss": 5.0765,
      "step": 1707
    },
    {
      "epoch": 0.19584909987386767,
      "grad_norm": 0.0,
      "learning_rate": 0.0009296227907951852,
      "loss": 5.0972,
      "step": 1708
    },
    {
      "epoch": 0.19596376562320836,
      "grad_norm": 0.0,
      "learning_rate": 0.0009295277713899955,
      "loss": 4.6973,
      "step": 1709
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.0,
      "learning_rate": 0.000929432692746534,
      "loss": 4.9625,
      "step": 1710
    },
    {
      "epoch": 0.1961930971218897,
      "grad_norm": 0.0,
      "learning_rate": 0.0009293375548779146,
      "loss": 5.1367,
      "step": 1711
    },
    {
      "epoch": 0.19630776287123036,
      "grad_norm": 0.0,
      "learning_rate": 0.0009292423577972601,
      "loss": 5.1501,
      "step": 1712
    },
    {
      "epoch": 0.19642242862057105,
      "grad_norm": 0.0,
      "learning_rate": 0.000929147101517701,
      "loss": 4.9802,
      "step": 1713
    },
    {
      "epoch": 0.1965370943699117,
      "grad_norm": 0.0,
      "learning_rate": 0.0009290517860523759,
      "loss": 4.9584,
      "step": 1714
    },
    {
      "epoch": 0.19665176011925237,
      "grad_norm": 0.0,
      "learning_rate": 0.0009289564114144322,
      "loss": 5.1265,
      "step": 1715
    },
    {
      "epoch": 0.19676642586859305,
      "grad_norm": 0.0,
      "learning_rate": 0.0009288609776170243,
      "loss": 5.1336,
      "step": 1716
    },
    {
      "epoch": 0.1968810916179337,
      "grad_norm": 0.0,
      "learning_rate": 0.0009287654846733165,
      "loss": 5.1089,
      "step": 1717
    },
    {
      "epoch": 0.1969957573672744,
      "grad_norm": 0.0,
      "learning_rate": 0.0009286699325964793,
      "loss": 4.8478,
      "step": 1718
    },
    {
      "epoch": 0.19711042311661506,
      "grad_norm": 0.0,
      "learning_rate": 0.0009285743213996927,
      "loss": 5.0145,
      "step": 1719
    },
    {
      "epoch": 0.19722508886595574,
      "grad_norm": 0.0,
      "learning_rate": 0.0009284786510961444,
      "loss": 5.3407,
      "step": 1720
    },
    {
      "epoch": 0.1973397546152964,
      "grad_norm": 0.0,
      "learning_rate": 0.0009283829216990303,
      "loss": 4.9048,
      "step": 1721
    },
    {
      "epoch": 0.1974544203646371,
      "grad_norm": 0.0,
      "learning_rate": 0.0009282871332215542,
      "loss": 4.8881,
      "step": 1722
    },
    {
      "epoch": 0.19756908611397775,
      "grad_norm": 0.0,
      "learning_rate": 0.0009281912856769288,
      "loss": 5.031,
      "step": 1723
    },
    {
      "epoch": 0.19768375186331844,
      "grad_norm": 0.0,
      "learning_rate": 0.000928095379078374,
      "loss": 5.1015,
      "step": 1724
    },
    {
      "epoch": 0.1977984176126591,
      "grad_norm": 0.0,
      "learning_rate": 0.0009279994134391185,
      "loss": 5.1138,
      "step": 1725
    },
    {
      "epoch": 0.19791308336199978,
      "grad_norm": 0.0,
      "learning_rate": 0.000927903388772399,
      "loss": 5.2963,
      "step": 1726
    },
    {
      "epoch": 0.19802774911134044,
      "grad_norm": 0.0,
      "learning_rate": 0.0009278073050914599,
      "loss": 4.8921,
      "step": 1727
    },
    {
      "epoch": 0.19814241486068113,
      "grad_norm": 0.0,
      "learning_rate": 0.0009277111624095545,
      "loss": 5.0629,
      "step": 1728
    },
    {
      "epoch": 0.19825708061002179,
      "grad_norm": 0.0,
      "learning_rate": 0.0009276149607399437,
      "loss": 5.195,
      "step": 1729
    },
    {
      "epoch": 0.19837174635936247,
      "grad_norm": 0.0,
      "learning_rate": 0.0009275187000958966,
      "loss": 4.8763,
      "step": 1730
    },
    {
      "epoch": 0.19848641210870313,
      "grad_norm": 0.0,
      "learning_rate": 0.0009274223804906907,
      "loss": 5.1518,
      "step": 1731
    },
    {
      "epoch": 0.1986010778580438,
      "grad_norm": 0.0,
      "learning_rate": 0.0009273260019376114,
      "loss": 4.8057,
      "step": 1732
    },
    {
      "epoch": 0.19871574360738448,
      "grad_norm": 0.0,
      "learning_rate": 0.0009272295644499522,
      "loss": 5.1301,
      "step": 1733
    },
    {
      "epoch": 0.19883040935672514,
      "grad_norm": 0.0,
      "learning_rate": 0.0009271330680410149,
      "loss": 5.2364,
      "step": 1734
    },
    {
      "epoch": 0.19894507510606582,
      "grad_norm": 0.0,
      "learning_rate": 0.0009270365127241093,
      "loss": 4.8359,
      "step": 1735
    },
    {
      "epoch": 0.19905974085540648,
      "grad_norm": 0.0,
      "learning_rate": 0.0009269398985125534,
      "loss": 5.046,
      "step": 1736
    },
    {
      "epoch": 0.19917440660474717,
      "grad_norm": 0.0,
      "learning_rate": 0.0009268432254196732,
      "loss": 5.0529,
      "step": 1737
    },
    {
      "epoch": 0.19928907235408783,
      "grad_norm": 0.0,
      "learning_rate": 0.000926746493458803,
      "loss": 5.2806,
      "step": 1738
    },
    {
      "epoch": 0.1994037381034285,
      "grad_norm": 0.0,
      "learning_rate": 0.0009266497026432851,
      "loss": 4.995,
      "step": 1739
    },
    {
      "epoch": 0.19951840385276917,
      "grad_norm": 0.0,
      "learning_rate": 0.00092655285298647,
      "loss": 5.1493,
      "step": 1740
    },
    {
      "epoch": 0.19963306960210986,
      "grad_norm": 0.0,
      "learning_rate": 0.0009264559445017162,
      "loss": 5.1043,
      "step": 1741
    },
    {
      "epoch": 0.19974773535145052,
      "grad_norm": 0.0,
      "learning_rate": 0.0009263589772023903,
      "loss": 5.0783,
      "step": 1742
    },
    {
      "epoch": 0.1998624011007912,
      "grad_norm": 0.0,
      "learning_rate": 0.0009262619511018671,
      "loss": 4.9547,
      "step": 1743
    },
    {
      "epoch": 0.19997706685013186,
      "grad_norm": 0.0,
      "learning_rate": 0.0009261648662135298,
      "loss": 4.9626,
      "step": 1744
    },
    {
      "epoch": 0.20009173259947255,
      "grad_norm": 0.0,
      "learning_rate": 0.0009260677225507693,
      "loss": 4.8713,
      "step": 1745
    },
    {
      "epoch": 0.2002063983488132,
      "grad_norm": 0.0,
      "learning_rate": 0.0009259705201269844,
      "loss": 4.9407,
      "step": 1746
    },
    {
      "epoch": 0.2003210640981539,
      "grad_norm": 0.0,
      "learning_rate": 0.0009258732589555825,
      "loss": 5.0818,
      "step": 1747
    },
    {
      "epoch": 0.20043572984749455,
      "grad_norm": 0.0,
      "learning_rate": 0.000925775939049979,
      "loss": 4.8989,
      "step": 1748
    },
    {
      "epoch": 0.2005503955968352,
      "grad_norm": 0.0,
      "learning_rate": 0.0009256785604235974,
      "loss": 4.9465,
      "step": 1749
    },
    {
      "epoch": 0.2006650613461759,
      "grad_norm": 0.0,
      "learning_rate": 0.0009255811230898689,
      "loss": 4.6777,
      "step": 1750
    },
    {
      "epoch": 0.20077972709551656,
      "grad_norm": 0.0,
      "learning_rate": 0.0009254836270622335,
      "loss": 5.0728,
      "step": 1751
    },
    {
      "epoch": 0.20089439284485724,
      "grad_norm": 0.0,
      "learning_rate": 0.0009253860723541388,
      "loss": 5.2595,
      "step": 1752
    },
    {
      "epoch": 0.2010090585941979,
      "grad_norm": 0.0,
      "learning_rate": 0.0009252884589790403,
      "loss": 4.9303,
      "step": 1753
    },
    {
      "epoch": 0.2011237243435386,
      "grad_norm": 0.0,
      "learning_rate": 0.0009251907869504024,
      "loss": 4.8664,
      "step": 1754
    },
    {
      "epoch": 0.20123839009287925,
      "grad_norm": 0.0,
      "learning_rate": 0.0009250930562816967,
      "loss": 4.9666,
      "step": 1755
    },
    {
      "epoch": 0.20135305584221994,
      "grad_norm": 0.0,
      "learning_rate": 0.0009249952669864035,
      "loss": 5.0262,
      "step": 1756
    },
    {
      "epoch": 0.2014677215915606,
      "grad_norm": 0.0,
      "learning_rate": 0.000924897419078011,
      "loss": 4.9592,
      "step": 1757
    },
    {
      "epoch": 0.20158238734090128,
      "grad_norm": 0.0,
      "learning_rate": 0.0009247995125700153,
      "loss": 4.9889,
      "step": 1758
    },
    {
      "epoch": 0.20169705309024194,
      "grad_norm": 0.0,
      "learning_rate": 0.0009247015474759208,
      "loss": 5.1409,
      "step": 1759
    },
    {
      "epoch": 0.20181171883958263,
      "grad_norm": 0.0,
      "learning_rate": 0.00092460352380924,
      "loss": 4.8712,
      "step": 1760
    },
    {
      "epoch": 0.20192638458892329,
      "grad_norm": 0.0,
      "learning_rate": 0.0009245054415834932,
      "loss": 5.25,
      "step": 1761
    },
    {
      "epoch": 0.20204105033826397,
      "grad_norm": 0.0,
      "learning_rate": 0.0009244073008122092,
      "loss": 4.9844,
      "step": 1762
    },
    {
      "epoch": 0.20215571608760463,
      "grad_norm": 0.0,
      "learning_rate": 0.0009243091015089244,
      "loss": 5.0651,
      "step": 1763
    },
    {
      "epoch": 0.20227038183694532,
      "grad_norm": 0.0,
      "learning_rate": 0.0009242108436871838,
      "loss": 4.9208,
      "step": 1764
    },
    {
      "epoch": 0.20238504758628598,
      "grad_norm": 0.0,
      "learning_rate": 0.0009241125273605399,
      "loss": 4.6917,
      "step": 1765
    },
    {
      "epoch": 0.20249971333562664,
      "grad_norm": 0.0,
      "learning_rate": 0.0009240141525425538,
      "loss": 4.9956,
      "step": 1766
    },
    {
      "epoch": 0.20261437908496732,
      "grad_norm": 0.0,
      "learning_rate": 0.0009239157192467944,
      "loss": 4.9043,
      "step": 1767
    },
    {
      "epoch": 0.20272904483430798,
      "grad_norm": 0.0,
      "learning_rate": 0.0009238172274868385,
      "loss": 4.9995,
      "step": 1768
    },
    {
      "epoch": 0.20284371058364867,
      "grad_norm": 0.0,
      "learning_rate": 0.0009237186772762714,
      "loss": 5.1226,
      "step": 1769
    },
    {
      "epoch": 0.20295837633298933,
      "grad_norm": 0.0,
      "learning_rate": 0.0009236200686286862,
      "loss": 5.0362,
      "step": 1770
    },
    {
      "epoch": 0.20307304208233,
      "grad_norm": 0.0,
      "learning_rate": 0.000923521401557684,
      "loss": 5.1642,
      "step": 1771
    },
    {
      "epoch": 0.20318770783167067,
      "grad_norm": 0.0,
      "learning_rate": 0.0009234226760768739,
      "loss": 5.0542,
      "step": 1772
    },
    {
      "epoch": 0.20330237358101136,
      "grad_norm": 0.0,
      "learning_rate": 0.0009233238921998734,
      "loss": 4.956,
      "step": 1773
    },
    {
      "epoch": 0.20341703933035202,
      "grad_norm": 0.0,
      "learning_rate": 0.0009232250499403079,
      "loss": 5.0801,
      "step": 1774
    },
    {
      "epoch": 0.2035317050796927,
      "grad_norm": 0.0,
      "learning_rate": 0.0009231261493118107,
      "loss": 5.3163,
      "step": 1775
    },
    {
      "epoch": 0.20364637082903336,
      "grad_norm": 0.0,
      "learning_rate": 0.0009230271903280233,
      "loss": 4.8341,
      "step": 1776
    },
    {
      "epoch": 0.20376103657837405,
      "grad_norm": 0.0,
      "learning_rate": 0.0009229281730025953,
      "loss": 4.7395,
      "step": 1777
    },
    {
      "epoch": 0.2038757023277147,
      "grad_norm": 0.0,
      "learning_rate": 0.0009228290973491838,
      "loss": 4.7576,
      "step": 1778
    },
    {
      "epoch": 0.2039903680770554,
      "grad_norm": 0.0,
      "learning_rate": 0.0009227299633814549,
      "loss": 4.9683,
      "step": 1779
    },
    {
      "epoch": 0.20410503382639605,
      "grad_norm": 0.0,
      "learning_rate": 0.000922630771113082,
      "loss": 4.8088,
      "step": 1780
    },
    {
      "epoch": 0.20421969957573674,
      "grad_norm": 0.0,
      "learning_rate": 0.000922531520557747,
      "loss": 4.9441,
      "step": 1781
    },
    {
      "epoch": 0.2043343653250774,
      "grad_norm": 0.0,
      "learning_rate": 0.000922432211729139,
      "loss": 4.9392,
      "step": 1782
    },
    {
      "epoch": 0.20444903107441806,
      "grad_norm": 0.0,
      "learning_rate": 0.0009223328446409568,
      "loss": 4.8316,
      "step": 1783
    },
    {
      "epoch": 0.20456369682375874,
      "grad_norm": 0.0,
      "learning_rate": 0.0009222334193069053,
      "loss": 4.9782,
      "step": 1784
    },
    {
      "epoch": 0.2046783625730994,
      "grad_norm": 0.0,
      "learning_rate": 0.0009221339357406988,
      "loss": 4.9291,
      "step": 1785
    },
    {
      "epoch": 0.2047930283224401,
      "grad_norm": 0.0,
      "learning_rate": 0.000922034393956059,
      "loss": 5.2503,
      "step": 1786
    },
    {
      "epoch": 0.20490769407178075,
      "grad_norm": 0.0,
      "learning_rate": 0.0009219347939667157,
      "loss": 4.8812,
      "step": 1787
    },
    {
      "epoch": 0.20502235982112144,
      "grad_norm": 0.0,
      "learning_rate": 0.0009218351357864069,
      "loss": 5.0615,
      "step": 1788
    },
    {
      "epoch": 0.2051370255704621,
      "grad_norm": 0.0,
      "learning_rate": 0.0009217354194288788,
      "loss": 4.8301,
      "step": 1789
    },
    {
      "epoch": 0.20525169131980278,
      "grad_norm": 0.0,
      "learning_rate": 0.0009216356449078851,
      "loss": 5.0647,
      "step": 1790
    },
    {
      "epoch": 0.20536635706914344,
      "grad_norm": 0.0,
      "learning_rate": 0.0009215358122371878,
      "loss": 4.9061,
      "step": 1791
    },
    {
      "epoch": 0.20548102281848413,
      "grad_norm": 0.0,
      "learning_rate": 0.0009214359214305569,
      "loss": 5.1866,
      "step": 1792
    },
    {
      "epoch": 0.20559568856782479,
      "grad_norm": 0.0,
      "learning_rate": 0.0009213359725017705,
      "loss": 5.0261,
      "step": 1793
    },
    {
      "epoch": 0.20571035431716547,
      "grad_norm": 0.0,
      "learning_rate": 0.0009212359654646147,
      "loss": 5.1034,
      "step": 1794
    },
    {
      "epoch": 0.20582502006650613,
      "grad_norm": 0.0,
      "learning_rate": 0.0009211359003328835,
      "loss": 5.0963,
      "step": 1795
    },
    {
      "epoch": 0.20593968581584682,
      "grad_norm": 0.0,
      "learning_rate": 0.0009210357771203786,
      "loss": 4.9785,
      "step": 1796
    },
    {
      "epoch": 0.20605435156518748,
      "grad_norm": 0.0,
      "learning_rate": 0.0009209355958409109,
      "loss": 5.1128,
      "step": 1797
    },
    {
      "epoch": 0.20616901731452816,
      "grad_norm": 0.0,
      "learning_rate": 0.0009208353565082979,
      "loss": 4.8332,
      "step": 1798
    },
    {
      "epoch": 0.20628368306386882,
      "grad_norm": 0.0,
      "learning_rate": 0.000920735059136366,
      "loss": 5.1329,
      "step": 1799
    },
    {
      "epoch": 0.20639834881320948,
      "grad_norm": 0.0,
      "learning_rate": 0.0009206347037389491,
      "loss": 4.9813,
      "step": 1800
    },
    {
      "epoch": 0.20651301456255017,
      "grad_norm": 0.0,
      "learning_rate": 0.0009205342903298892,
      "loss": 4.9115,
      "step": 1801
    },
    {
      "epoch": 0.20662768031189083,
      "grad_norm": 0.0,
      "learning_rate": 0.0009204338189230369,
      "loss": 5.0222,
      "step": 1802
    },
    {
      "epoch": 0.2067423460612315,
      "grad_norm": 0.0,
      "learning_rate": 0.0009203332895322499,
      "loss": 4.9408,
      "step": 1803
    },
    {
      "epoch": 0.20685701181057217,
      "grad_norm": 0.0,
      "learning_rate": 0.0009202327021713945,
      "loss": 4.9946,
      "step": 1804
    },
    {
      "epoch": 0.20697167755991286,
      "grad_norm": 0.0,
      "learning_rate": 0.0009201320568543446,
      "loss": 5.1644,
      "step": 1805
    },
    {
      "epoch": 0.20708634330925352,
      "grad_norm": 0.0,
      "learning_rate": 0.0009200313535949827,
      "loss": 5.0414,
      "step": 1806
    },
    {
      "epoch": 0.2072010090585942,
      "grad_norm": 0.0,
      "learning_rate": 0.0009199305924071984,
      "loss": 5.2619,
      "step": 1807
    },
    {
      "epoch": 0.20731567480793486,
      "grad_norm": 0.0,
      "learning_rate": 0.0009198297733048901,
      "loss": 5.0195,
      "step": 1808
    },
    {
      "epoch": 0.20743034055727555,
      "grad_norm": 0.0,
      "learning_rate": 0.0009197288963019638,
      "loss": 4.8921,
      "step": 1809
    },
    {
      "epoch": 0.2075450063066162,
      "grad_norm": 0.0,
      "learning_rate": 0.0009196279614123337,
      "loss": 5.0049,
      "step": 1810
    },
    {
      "epoch": 0.2076596720559569,
      "grad_norm": 0.0,
      "learning_rate": 0.0009195269686499216,
      "loss": 4.9882,
      "step": 1811
    },
    {
      "epoch": 0.20777433780529755,
      "grad_norm": 0.0,
      "learning_rate": 0.0009194259180286575,
      "loss": 4.9313,
      "step": 1812
    },
    {
      "epoch": 0.20788900355463824,
      "grad_norm": 0.0,
      "learning_rate": 0.0009193248095624798,
      "loss": 5.0581,
      "step": 1813
    },
    {
      "epoch": 0.2080036693039789,
      "grad_norm": 0.0,
      "learning_rate": 0.0009192236432653341,
      "loss": 5.1542,
      "step": 1814
    },
    {
      "epoch": 0.2081183350533196,
      "grad_norm": 0.0,
      "learning_rate": 0.0009191224191511745,
      "loss": 4.8452,
      "step": 1815
    },
    {
      "epoch": 0.20823300080266025,
      "grad_norm": 0.0,
      "learning_rate": 0.0009190211372339628,
      "loss": 4.7757,
      "step": 1816
    },
    {
      "epoch": 0.2083476665520009,
      "grad_norm": 0.0,
      "learning_rate": 0.0009189197975276692,
      "loss": 5.1607,
      "step": 1817
    },
    {
      "epoch": 0.2084623323013416,
      "grad_norm": 0.0,
      "learning_rate": 0.0009188184000462713,
      "loss": 4.932,
      "step": 1818
    },
    {
      "epoch": 0.20857699805068225,
      "grad_norm": 0.0,
      "learning_rate": 0.0009187169448037551,
      "loss": 5.1834,
      "step": 1819
    },
    {
      "epoch": 0.20869166380002294,
      "grad_norm": 0.0,
      "learning_rate": 0.0009186154318141144,
      "loss": 4.874,
      "step": 1820
    },
    {
      "epoch": 0.2088063295493636,
      "grad_norm": 0.0,
      "learning_rate": 0.000918513861091351,
      "loss": 5.1485,
      "step": 1821
    },
    {
      "epoch": 0.20892099529870428,
      "grad_norm": 0.0,
      "learning_rate": 0.0009184122326494746,
      "loss": 5.2837,
      "step": 1822
    },
    {
      "epoch": 0.20903566104804494,
      "grad_norm": 0.0,
      "learning_rate": 0.0009183105465025028,
      "loss": 4.994,
      "step": 1823
    },
    {
      "epoch": 0.20915032679738563,
      "grad_norm": 0.0,
      "learning_rate": 0.0009182088026644615,
      "loss": 5.0663,
      "step": 1824
    },
    {
      "epoch": 0.2092649925467263,
      "grad_norm": 0.0,
      "learning_rate": 0.0009181070011493842,
      "loss": 5.0399,
      "step": 1825
    },
    {
      "epoch": 0.20937965829606697,
      "grad_norm": 0.0,
      "learning_rate": 0.0009180051419713125,
      "loss": 4.9003,
      "step": 1826
    },
    {
      "epoch": 0.20949432404540763,
      "grad_norm": 0.0,
      "learning_rate": 0.0009179032251442959,
      "loss": 4.8912,
      "step": 1827
    },
    {
      "epoch": 0.20960898979474832,
      "grad_norm": 0.0,
      "learning_rate": 0.0009178012506823918,
      "loss": 4.856,
      "step": 1828
    },
    {
      "epoch": 0.20972365554408898,
      "grad_norm": 0.0,
      "learning_rate": 0.0009176992185996657,
      "loss": 4.9009,
      "step": 1829
    },
    {
      "epoch": 0.20983832129342966,
      "grad_norm": 0.0,
      "learning_rate": 0.0009175971289101914,
      "loss": 5.1528,
      "step": 1830
    },
    {
      "epoch": 0.20995298704277032,
      "grad_norm": 0.0,
      "learning_rate": 0.0009174949816280495,
      "loss": 4.9472,
      "step": 1831
    },
    {
      "epoch": 0.210067652792111,
      "grad_norm": 0.0,
      "learning_rate": 0.0009173927767673297,
      "loss": 4.9448,
      "step": 1832
    },
    {
      "epoch": 0.21018231854145167,
      "grad_norm": 0.0,
      "learning_rate": 0.000917290514342129,
      "loss": 5.0504,
      "step": 1833
    },
    {
      "epoch": 0.21029698429079233,
      "grad_norm": 0.0,
      "learning_rate": 0.0009171881943665528,
      "loss": 4.9189,
      "step": 1834
    },
    {
      "epoch": 0.210411650040133,
      "grad_norm": 0.0,
      "learning_rate": 0.0009170858168547141,
      "loss": 5.2416,
      "step": 1835
    },
    {
      "epoch": 0.21052631578947367,
      "grad_norm": 0.0,
      "learning_rate": 0.0009169833818207338,
      "loss": 5.3785,
      "step": 1836
    },
    {
      "epoch": 0.21064098153881436,
      "grad_norm": 0.0,
      "learning_rate": 0.0009168808892787409,
      "loss": 4.7096,
      "step": 1837
    },
    {
      "epoch": 0.21075564728815502,
      "grad_norm": 0.0,
      "learning_rate": 0.0009167783392428723,
      "loss": 4.8641,
      "step": 1838
    },
    {
      "epoch": 0.2108703130374957,
      "grad_norm": 0.0,
      "learning_rate": 0.000916675731727273,
      "loss": 5.0317,
      "step": 1839
    },
    {
      "epoch": 0.21098497878683636,
      "grad_norm": 0.0,
      "learning_rate": 0.0009165730667460958,
      "loss": 5.1246,
      "step": 1840
    },
    {
      "epoch": 0.21109964453617705,
      "grad_norm": 0.0,
      "learning_rate": 0.000916470344313501,
      "loss": 5.1666,
      "step": 1841
    },
    {
      "epoch": 0.2112143102855177,
      "grad_norm": 0.0,
      "learning_rate": 0.0009163675644436572,
      "loss": 5.0932,
      "step": 1842
    },
    {
      "epoch": 0.2113289760348584,
      "grad_norm": 0.0,
      "learning_rate": 0.0009162647271507413,
      "loss": 4.9153,
      "step": 1843
    },
    {
      "epoch": 0.21144364178419905,
      "grad_norm": 0.0,
      "learning_rate": 0.0009161618324489376,
      "loss": 5.1444,
      "step": 1844
    },
    {
      "epoch": 0.21155830753353974,
      "grad_norm": 0.0,
      "learning_rate": 0.0009160588803524385,
      "loss": 4.9016,
      "step": 1845
    },
    {
      "epoch": 0.2116729732828804,
      "grad_norm": 0.0,
      "learning_rate": 0.000915955870875444,
      "loss": 4.9771,
      "step": 1846
    },
    {
      "epoch": 0.2117876390322211,
      "grad_norm": 0.0,
      "learning_rate": 0.0009158528040321627,
      "loss": 5.138,
      "step": 1847
    },
    {
      "epoch": 0.21190230478156175,
      "grad_norm": 0.0,
      "learning_rate": 0.0009157496798368103,
      "loss": 4.9377,
      "step": 1848
    },
    {
      "epoch": 0.21201697053090243,
      "grad_norm": 0.0,
      "learning_rate": 0.0009156464983036112,
      "loss": 4.8178,
      "step": 1849
    },
    {
      "epoch": 0.2121316362802431,
      "grad_norm": 0.0,
      "learning_rate": 0.000915543259446797,
      "loss": 4.936,
      "step": 1850
    },
    {
      "epoch": 0.21224630202958375,
      "grad_norm": 0.0,
      "learning_rate": 0.0009154399632806078,
      "loss": 5.0903,
      "step": 1851
    },
    {
      "epoch": 0.21236096777892444,
      "grad_norm": 0.0,
      "learning_rate": 0.0009153366098192913,
      "loss": 4.7204,
      "step": 1852
    },
    {
      "epoch": 0.2124756335282651,
      "grad_norm": 0.0,
      "learning_rate": 0.0009152331990771028,
      "loss": 5.2088,
      "step": 1853
    },
    {
      "epoch": 0.21259029927760578,
      "grad_norm": 0.0,
      "learning_rate": 0.0009151297310683064,
      "loss": 4.8727,
      "step": 1854
    },
    {
      "epoch": 0.21270496502694644,
      "grad_norm": 0.0,
      "learning_rate": 0.0009150262058071729,
      "loss": 4.9645,
      "step": 1855
    },
    {
      "epoch": 0.21281963077628713,
      "grad_norm": 0.0,
      "learning_rate": 0.0009149226233079822,
      "loss": 4.8822,
      "step": 1856
    },
    {
      "epoch": 0.2129342965256278,
      "grad_norm": 0.0,
      "learning_rate": 0.0009148189835850212,
      "loss": 4.9605,
      "step": 1857
    },
    {
      "epoch": 0.21304896227496847,
      "grad_norm": 0.0,
      "learning_rate": 0.0009147152866525853,
      "loss": 4.8872,
      "step": 1858
    },
    {
      "epoch": 0.21316362802430913,
      "grad_norm": 0.0,
      "learning_rate": 0.0009146115325249772,
      "loss": 5.0742,
      "step": 1859
    },
    {
      "epoch": 0.21327829377364982,
      "grad_norm": 0.0,
      "learning_rate": 0.000914507721216508,
      "loss": 4.9522,
      "step": 1860
    },
    {
      "epoch": 0.21339295952299048,
      "grad_norm": 0.0,
      "learning_rate": 0.0009144038527414964,
      "loss": 5.0208,
      "step": 1861
    },
    {
      "epoch": 0.21350762527233116,
      "grad_norm": 0.0,
      "learning_rate": 0.0009142999271142693,
      "loss": 5.0046,
      "step": 1862
    },
    {
      "epoch": 0.21362229102167182,
      "grad_norm": 0.0,
      "learning_rate": 0.0009141959443491607,
      "loss": 5.036,
      "step": 1863
    },
    {
      "epoch": 0.2137369567710125,
      "grad_norm": 0.0,
      "learning_rate": 0.0009140919044605137,
      "loss": 5.1405,
      "step": 1864
    },
    {
      "epoch": 0.21385162252035317,
      "grad_norm": 0.0,
      "learning_rate": 0.0009139878074626782,
      "loss": 5.0019,
      "step": 1865
    },
    {
      "epoch": 0.21396628826969386,
      "grad_norm": 0.0,
      "learning_rate": 0.0009138836533700127,
      "loss": 4.8908,
      "step": 1866
    },
    {
      "epoch": 0.21408095401903451,
      "grad_norm": 0.0,
      "learning_rate": 0.0009137794421968831,
      "loss": 5.2068,
      "step": 1867
    },
    {
      "epoch": 0.21419561976837517,
      "grad_norm": 0.0,
      "learning_rate": 0.0009136751739576632,
      "loss": 5.0243,
      "step": 1868
    },
    {
      "epoch": 0.21431028551771586,
      "grad_norm": 0.0,
      "learning_rate": 0.000913570848666735,
      "loss": 4.8171,
      "step": 1869
    },
    {
      "epoch": 0.21442495126705652,
      "grad_norm": 0.0,
      "learning_rate": 0.0009134664663384882,
      "loss": 4.9184,
      "step": 1870
    },
    {
      "epoch": 0.2145396170163972,
      "grad_norm": 0.0,
      "learning_rate": 0.0009133620269873203,
      "loss": 5.1139,
      "step": 1871
    },
    {
      "epoch": 0.21465428276573786,
      "grad_norm": 0.0,
      "learning_rate": 0.0009132575306276368,
      "loss": 4.8439,
      "step": 1872
    },
    {
      "epoch": 0.21476894851507855,
      "grad_norm": 0.0,
      "learning_rate": 0.0009131529772738507,
      "loss": 4.8895,
      "step": 1873
    },
    {
      "epoch": 0.2148836142644192,
      "grad_norm": 0.0,
      "learning_rate": 0.0009130483669403834,
      "loss": 5.2378,
      "step": 1874
    },
    {
      "epoch": 0.2149982800137599,
      "grad_norm": 0.0,
      "learning_rate": 0.0009129436996416639,
      "loss": 4.8971,
      "step": 1875
    },
    {
      "epoch": 0.21511294576310055,
      "grad_norm": 0.0,
      "learning_rate": 0.0009128389753921291,
      "loss": 5.0685,
      "step": 1876
    },
    {
      "epoch": 0.21522761151244124,
      "grad_norm": 0.0,
      "learning_rate": 0.0009127341942062235,
      "loss": 4.956,
      "step": 1877
    },
    {
      "epoch": 0.2153422772617819,
      "grad_norm": 0.0,
      "learning_rate": 0.0009126293560983998,
      "loss": 4.8034,
      "step": 1878
    },
    {
      "epoch": 0.2154569430111226,
      "grad_norm": 0.0,
      "learning_rate": 0.0009125244610831184,
      "loss": 4.9098,
      "step": 1879
    },
    {
      "epoch": 0.21557160876046325,
      "grad_norm": 0.0,
      "learning_rate": 0.0009124195091748475,
      "loss": 5.1498,
      "step": 1880
    },
    {
      "epoch": 0.21568627450980393,
      "grad_norm": 0.0,
      "learning_rate": 0.0009123145003880635,
      "loss": 4.9459,
      "step": 1881
    },
    {
      "epoch": 0.2158009402591446,
      "grad_norm": 0.0,
      "learning_rate": 0.00091220943473725,
      "loss": 5.3665,
      "step": 1882
    },
    {
      "epoch": 0.21591560600848528,
      "grad_norm": 0.0,
      "learning_rate": 0.0009121043122368989,
      "loss": 4.9657,
      "step": 1883
    },
    {
      "epoch": 0.21603027175782594,
      "grad_norm": 0.0,
      "learning_rate": 0.0009119991329015099,
      "loss": 5.0109,
      "step": 1884
    },
    {
      "epoch": 0.2161449375071666,
      "grad_norm": 0.0,
      "learning_rate": 0.0009118938967455906,
      "loss": 4.9686,
      "step": 1885
    },
    {
      "epoch": 0.21625960325650728,
      "grad_norm": 0.0,
      "learning_rate": 0.0009117886037836562,
      "loss": 4.9812,
      "step": 1886
    },
    {
      "epoch": 0.21637426900584794,
      "grad_norm": 0.0,
      "learning_rate": 0.0009116832540302296,
      "loss": 4.9293,
      "step": 1887
    },
    {
      "epoch": 0.21648893475518863,
      "grad_norm": 0.0,
      "learning_rate": 0.0009115778474998424,
      "loss": 4.7611,
      "step": 1888
    },
    {
      "epoch": 0.2166036005045293,
      "grad_norm": 0.0,
      "learning_rate": 0.0009114723842070329,
      "loss": 4.8891,
      "step": 1889
    },
    {
      "epoch": 0.21671826625386997,
      "grad_norm": 0.0,
      "learning_rate": 0.000911366864166348,
      "loss": 4.9141,
      "step": 1890
    },
    {
      "epoch": 0.21683293200321063,
      "grad_norm": 0.0,
      "learning_rate": 0.0009112612873923421,
      "loss": 4.9274,
      "step": 1891
    },
    {
      "epoch": 0.21694759775255132,
      "grad_norm": 0.0,
      "learning_rate": 0.0009111556538995774,
      "loss": 4.9476,
      "step": 1892
    },
    {
      "epoch": 0.21706226350189198,
      "grad_norm": 0.0,
      "learning_rate": 0.0009110499637026243,
      "loss": 4.9097,
      "step": 1893
    },
    {
      "epoch": 0.21717692925123266,
      "grad_norm": 0.0,
      "learning_rate": 0.0009109442168160605,
      "loss": 4.9253,
      "step": 1894
    },
    {
      "epoch": 0.21729159500057332,
      "grad_norm": 0.0,
      "learning_rate": 0.0009108384132544717,
      "loss": 4.7369,
      "step": 1895
    },
    {
      "epoch": 0.217406260749914,
      "grad_norm": 0.0,
      "learning_rate": 0.0009107325530324517,
      "loss": 5.247,
      "step": 1896
    },
    {
      "epoch": 0.21752092649925467,
      "grad_norm": 0.0,
      "learning_rate": 0.0009106266361646019,
      "loss": 5.0956,
      "step": 1897
    },
    {
      "epoch": 0.21763559224859536,
      "grad_norm": 0.0,
      "learning_rate": 0.0009105206626655314,
      "loss": 4.9686,
      "step": 1898
    },
    {
      "epoch": 0.21775025799793601,
      "grad_norm": 0.0,
      "learning_rate": 0.0009104146325498573,
      "loss": 4.9838,
      "step": 1899
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 0.0,
      "learning_rate": 0.0009103085458322045,
      "loss": 4.7628,
      "step": 1900
    },
    {
      "epoch": 0.21797958949661736,
      "grad_norm": 0.0,
      "learning_rate": 0.0009102024025272053,
      "loss": 4.8417,
      "step": 1901
    },
    {
      "epoch": 0.21809425524595802,
      "grad_norm": 0.0,
      "learning_rate": 0.0009100962026495005,
      "loss": 4.9271,
      "step": 1902
    },
    {
      "epoch": 0.2182089209952987,
      "grad_norm": 0.0,
      "learning_rate": 0.0009099899462137383,
      "loss": 4.606,
      "step": 1903
    },
    {
      "epoch": 0.21832358674463936,
      "grad_norm": 0.0,
      "learning_rate": 0.0009098836332345747,
      "loss": 5.1268,
      "step": 1904
    },
    {
      "epoch": 0.21843825249398005,
      "grad_norm": 0.0,
      "learning_rate": 0.0009097772637266735,
      "loss": 4.9457,
      "step": 1905
    },
    {
      "epoch": 0.2185529182433207,
      "grad_norm": 0.0,
      "learning_rate": 0.0009096708377047063,
      "loss": 5.097,
      "step": 1906
    },
    {
      "epoch": 0.2186675839926614,
      "grad_norm": 0.0,
      "learning_rate": 0.0009095643551833526,
      "loss": 4.8441,
      "step": 1907
    },
    {
      "epoch": 0.21878224974200206,
      "grad_norm": 0.0,
      "learning_rate": 0.0009094578161772998,
      "loss": 4.871,
      "step": 1908
    },
    {
      "epoch": 0.21889691549134274,
      "grad_norm": 0.0,
      "learning_rate": 0.0009093512207012426,
      "loss": 4.8427,
      "step": 1909
    },
    {
      "epoch": 0.2190115812406834,
      "grad_norm": 0.0,
      "learning_rate": 0.0009092445687698843,
      "loss": 5.0511,
      "step": 1910
    },
    {
      "epoch": 0.2191262469900241,
      "grad_norm": 0.0,
      "learning_rate": 0.0009091378603979349,
      "loss": 4.9222,
      "step": 1911
    },
    {
      "epoch": 0.21924091273936475,
      "grad_norm": 0.0,
      "learning_rate": 0.0009090310956001131,
      "loss": 4.884,
      "step": 1912
    },
    {
      "epoch": 0.21935557848870543,
      "grad_norm": 0.0,
      "learning_rate": 0.0009089242743911452,
      "loss": 4.9639,
      "step": 1913
    },
    {
      "epoch": 0.2194702442380461,
      "grad_norm": 0.0,
      "learning_rate": 0.0009088173967857651,
      "loss": 5.0774,
      "step": 1914
    },
    {
      "epoch": 0.21958490998738678,
      "grad_norm": 0.0,
      "learning_rate": 0.000908710462798714,
      "loss": 5.2018,
      "step": 1915
    },
    {
      "epoch": 0.21969957573672744,
      "grad_norm": 0.0,
      "learning_rate": 0.0009086034724447423,
      "loss": 5.1015,
      "step": 1916
    },
    {
      "epoch": 0.21981424148606812,
      "grad_norm": 0.0,
      "learning_rate": 0.0009084964257386065,
      "loss": 4.926,
      "step": 1917
    },
    {
      "epoch": 0.21992890723540878,
      "grad_norm": 0.0,
      "learning_rate": 0.0009083893226950722,
      "loss": 5.0097,
      "step": 1918
    },
    {
      "epoch": 0.22004357298474944,
      "grad_norm": 0.0,
      "learning_rate": 0.0009082821633289119,
      "loss": 4.7942,
      "step": 1919
    },
    {
      "epoch": 0.22015823873409013,
      "grad_norm": 0.0,
      "learning_rate": 0.0009081749476549061,
      "loss": 4.8795,
      "step": 1920
    },
    {
      "epoch": 0.2202729044834308,
      "grad_norm": 0.0,
      "learning_rate": 0.0009080676756878435,
      "loss": 5.1813,
      "step": 1921
    },
    {
      "epoch": 0.22038757023277147,
      "grad_norm": 0.0,
      "learning_rate": 0.0009079603474425201,
      "loss": 5.1192,
      "step": 1922
    },
    {
      "epoch": 0.22050223598211213,
      "grad_norm": 0.0,
      "learning_rate": 0.0009078529629337398,
      "loss": 5.0492,
      "step": 1923
    },
    {
      "epoch": 0.22061690173145282,
      "grad_norm": 0.0,
      "learning_rate": 0.0009077455221763141,
      "loss": 4.7652,
      "step": 1924
    },
    {
      "epoch": 0.22073156748079348,
      "grad_norm": 0.0,
      "learning_rate": 0.0009076380251850625,
      "loss": 5.0511,
      "step": 1925
    },
    {
      "epoch": 0.22084623323013416,
      "grad_norm": 0.0,
      "learning_rate": 0.0009075304719748121,
      "loss": 4.8105,
      "step": 1926
    },
    {
      "epoch": 0.22096089897947482,
      "grad_norm": 0.0,
      "learning_rate": 0.000907422862560398,
      "loss": 5.1572,
      "step": 1927
    },
    {
      "epoch": 0.2210755647288155,
      "grad_norm": 0.0,
      "learning_rate": 0.0009073151969566627,
      "loss": 5.0718,
      "step": 1928
    },
    {
      "epoch": 0.22119023047815617,
      "grad_norm": 0.0,
      "learning_rate": 0.0009072074751784566,
      "loss": 4.8916,
      "step": 1929
    },
    {
      "epoch": 0.22130489622749686,
      "grad_norm": 0.0,
      "learning_rate": 0.0009070996972406379,
      "loss": 4.9589,
      "step": 1930
    },
    {
      "epoch": 0.22141956197683751,
      "grad_norm": 0.0,
      "learning_rate": 0.0009069918631580726,
      "loss": 4.8578,
      "step": 1931
    },
    {
      "epoch": 0.2215342277261782,
      "grad_norm": 0.0,
      "learning_rate": 0.0009068839729456344,
      "loss": 5.0038,
      "step": 1932
    },
    {
      "epoch": 0.22164889347551886,
      "grad_norm": 0.0,
      "learning_rate": 0.0009067760266182046,
      "loss": 4.9523,
      "step": 1933
    },
    {
      "epoch": 0.22176355922485955,
      "grad_norm": 0.0,
      "learning_rate": 0.000906668024190672,
      "loss": 5.1852,
      "step": 1934
    },
    {
      "epoch": 0.2218782249742002,
      "grad_norm": 0.0,
      "learning_rate": 0.0009065599656779341,
      "loss": 4.9155,
      "step": 1935
    },
    {
      "epoch": 0.2219928907235409,
      "grad_norm": 0.0,
      "learning_rate": 0.0009064518510948951,
      "loss": 5.028,
      "step": 1936
    },
    {
      "epoch": 0.22210755647288155,
      "grad_norm": 0.0,
      "learning_rate": 0.0009063436804564675,
      "loss": 4.7931,
      "step": 1937
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.0,
      "learning_rate": 0.0009062354537775714,
      "loss": 5.2808,
      "step": 1938
    },
    {
      "epoch": 0.2223368879715629,
      "grad_norm": 0.0,
      "learning_rate": 0.0009061271710731346,
      "loss": 5.291,
      "step": 1939
    },
    {
      "epoch": 0.22245155372090356,
      "grad_norm": 0.0,
      "learning_rate": 0.0009060188323580925,
      "loss": 5.237,
      "step": 1940
    },
    {
      "epoch": 0.22256621947024424,
      "grad_norm": 0.0,
      "learning_rate": 0.0009059104376473884,
      "loss": 5.043,
      "step": 1941
    },
    {
      "epoch": 0.2226808852195849,
      "grad_norm": 0.0,
      "learning_rate": 0.0009058019869559732,
      "loss": 5.0918,
      "step": 1942
    },
    {
      "epoch": 0.2227955509689256,
      "grad_norm": 0.0,
      "learning_rate": 0.0009056934802988061,
      "loss": 4.9149,
      "step": 1943
    },
    {
      "epoch": 0.22291021671826625,
      "grad_norm": 0.0,
      "learning_rate": 0.000905584917690853,
      "loss": 5.0888,
      "step": 1944
    },
    {
      "epoch": 0.22302488246760693,
      "grad_norm": 0.0,
      "learning_rate": 0.0009054762991470881,
      "loss": 4.8419,
      "step": 1945
    },
    {
      "epoch": 0.2231395482169476,
      "grad_norm": 0.0,
      "learning_rate": 0.0009053676246824934,
      "loss": 4.9948,
      "step": 1946
    },
    {
      "epoch": 0.22325421396628828,
      "grad_norm": 0.0,
      "learning_rate": 0.0009052588943120586,
      "loss": 5.1363,
      "step": 1947
    },
    {
      "epoch": 0.22336887971562894,
      "grad_norm": 0.0,
      "learning_rate": 0.0009051501080507805,
      "loss": 5.0039,
      "step": 1948
    },
    {
      "epoch": 0.22348354546496962,
      "grad_norm": 0.0,
      "learning_rate": 0.0009050412659136648,
      "loss": 4.9537,
      "step": 1949
    },
    {
      "epoch": 0.22359821121431028,
      "grad_norm": 0.0,
      "learning_rate": 0.0009049323679157234,
      "loss": 4.9277,
      "step": 1950
    },
    {
      "epoch": 0.22371287696365097,
      "grad_norm": 0.0,
      "learning_rate": 0.0009048234140719774,
      "loss": 4.8793,
      "step": 1951
    },
    {
      "epoch": 0.22382754271299163,
      "grad_norm": 0.0,
      "learning_rate": 0.0009047144043974545,
      "loss": 4.9306,
      "step": 1952
    },
    {
      "epoch": 0.22394220846233232,
      "grad_norm": 0.0,
      "learning_rate": 0.0009046053389071907,
      "loss": 5.1712,
      "step": 1953
    },
    {
      "epoch": 0.22405687421167297,
      "grad_norm": 0.0,
      "learning_rate": 0.0009044962176162293,
      "loss": 4.9038,
      "step": 1954
    },
    {
      "epoch": 0.22417153996101363,
      "grad_norm": 0.0,
      "learning_rate": 0.0009043870405396217,
      "loss": 5.0143,
      "step": 1955
    },
    {
      "epoch": 0.22428620571035432,
      "grad_norm": 0.0,
      "learning_rate": 0.0009042778076924265,
      "loss": 4.9855,
      "step": 1956
    },
    {
      "epoch": 0.22440087145969498,
      "grad_norm": 0.0,
      "learning_rate": 0.0009041685190897108,
      "loss": 4.9657,
      "step": 1957
    },
    {
      "epoch": 0.22451553720903566,
      "grad_norm": 0.0,
      "learning_rate": 0.0009040591747465485,
      "loss": 4.9669,
      "step": 1958
    },
    {
      "epoch": 0.22463020295837632,
      "grad_norm": 0.0,
      "learning_rate": 0.0009039497746780216,
      "loss": 5.1085,
      "step": 1959
    },
    {
      "epoch": 0.224744868707717,
      "grad_norm": 0.0,
      "learning_rate": 0.00090384031889922,
      "loss": 4.9876,
      "step": 1960
    },
    {
      "epoch": 0.22485953445705767,
      "grad_norm": 0.0,
      "learning_rate": 0.0009037308074252408,
      "loss": 5.0858,
      "step": 1961
    },
    {
      "epoch": 0.22497420020639836,
      "grad_norm": 0.0,
      "learning_rate": 0.0009036212402711889,
      "loss": 5.2436,
      "step": 1962
    },
    {
      "epoch": 0.22508886595573901,
      "grad_norm": 0.0,
      "learning_rate": 0.0009035116174521773,
      "loss": 5.2462,
      "step": 1963
    },
    {
      "epoch": 0.2252035317050797,
      "grad_norm": 0.0,
      "learning_rate": 0.0009034019389833263,
      "loss": 5.1152,
      "step": 1964
    },
    {
      "epoch": 0.22531819745442036,
      "grad_norm": 0.0,
      "learning_rate": 0.0009032922048797637,
      "loss": 5.0656,
      "step": 1965
    },
    {
      "epoch": 0.22543286320376105,
      "grad_norm": 0.0,
      "learning_rate": 0.0009031824151566256,
      "loss": 4.9186,
      "step": 1966
    },
    {
      "epoch": 0.2255475289531017,
      "grad_norm": 0.0,
      "learning_rate": 0.0009030725698290551,
      "loss": 4.8622,
      "step": 1967
    },
    {
      "epoch": 0.2256621947024424,
      "grad_norm": 0.0,
      "learning_rate": 0.0009029626689122036,
      "loss": 4.9162,
      "step": 1968
    },
    {
      "epoch": 0.22577686045178305,
      "grad_norm": 0.0,
      "learning_rate": 0.0009028527124212294,
      "loss": 4.8758,
      "step": 1969
    },
    {
      "epoch": 0.22589152620112374,
      "grad_norm": 0.0,
      "learning_rate": 0.0009027427003712994,
      "loss": 5.1667,
      "step": 1970
    },
    {
      "epoch": 0.2260061919504644,
      "grad_norm": 0.0,
      "learning_rate": 0.0009026326327775873,
      "loss": 5.072,
      "step": 1971
    },
    {
      "epoch": 0.22612085769980506,
      "grad_norm": 0.0,
      "learning_rate": 0.0009025225096552748,
      "loss": 5.1046,
      "step": 1972
    },
    {
      "epoch": 0.22623552344914574,
      "grad_norm": 0.0,
      "learning_rate": 0.0009024123310195515,
      "loss": 5.006,
      "step": 1973
    },
    {
      "epoch": 0.2263501891984864,
      "grad_norm": 0.0,
      "learning_rate": 0.0009023020968856144,
      "loss": 5.0097,
      "step": 1974
    },
    {
      "epoch": 0.2264648549478271,
      "grad_norm": 0.0,
      "learning_rate": 0.0009021918072686682,
      "loss": 5.0385,
      "step": 1975
    },
    {
      "epoch": 0.22657952069716775,
      "grad_norm": 0.0,
      "learning_rate": 0.0009020814621839251,
      "loss": 5.1509,
      "step": 1976
    },
    {
      "epoch": 0.22669418644650843,
      "grad_norm": 0.0,
      "learning_rate": 0.0009019710616466054,
      "loss": 4.9686,
      "step": 1977
    },
    {
      "epoch": 0.2268088521958491,
      "grad_norm": 0.0,
      "learning_rate": 0.0009018606056719363,
      "loss": 5.0624,
      "step": 1978
    },
    {
      "epoch": 0.22692351794518978,
      "grad_norm": 0.0,
      "learning_rate": 0.0009017500942751535,
      "loss": 5.2475,
      "step": 1979
    },
    {
      "epoch": 0.22703818369453044,
      "grad_norm": 0.0,
      "learning_rate": 0.0009016395274714998,
      "loss": 4.9156,
      "step": 1980
    },
    {
      "epoch": 0.22715284944387112,
      "grad_norm": 0.0,
      "learning_rate": 0.0009015289052762257,
      "loss": 5.198,
      "step": 1981
    },
    {
      "epoch": 0.22726751519321178,
      "grad_norm": 0.0,
      "learning_rate": 0.0009014182277045896,
      "loss": 5.0688,
      "step": 1982
    },
    {
      "epoch": 0.22738218094255247,
      "grad_norm": 0.0,
      "learning_rate": 0.0009013074947718571,
      "loss": 5.0687,
      "step": 1983
    },
    {
      "epoch": 0.22749684669189313,
      "grad_norm": 0.0,
      "learning_rate": 0.000901196706493302,
      "loss": 4.9409,
      "step": 1984
    },
    {
      "epoch": 0.22761151244123382,
      "grad_norm": 0.0,
      "learning_rate": 0.0009010858628842053,
      "loss": 5.1838,
      "step": 1985
    },
    {
      "epoch": 0.22772617819057447,
      "grad_norm": 0.0,
      "learning_rate": 0.0009009749639598556,
      "loss": 5.1131,
      "step": 1986
    },
    {
      "epoch": 0.22784084393991516,
      "grad_norm": 0.0,
      "learning_rate": 0.0009008640097355496,
      "loss": 5.0032,
      "step": 1987
    },
    {
      "epoch": 0.22795550968925582,
      "grad_norm": 0.0,
      "learning_rate": 0.0009007530002265911,
      "loss": 5.06,
      "step": 1988
    },
    {
      "epoch": 0.22807017543859648,
      "grad_norm": 0.0,
      "learning_rate": 0.0009006419354482918,
      "loss": 4.9285,
      "step": 1989
    },
    {
      "epoch": 0.22818484118793717,
      "grad_norm": 0.0,
      "learning_rate": 0.0009005308154159712,
      "loss": 5.2486,
      "step": 1990
    },
    {
      "epoch": 0.22829950693727782,
      "grad_norm": 0.0,
      "learning_rate": 0.0009004196401449557,
      "loss": 5.3468,
      "step": 1991
    },
    {
      "epoch": 0.2284141726866185,
      "grad_norm": 0.0,
      "learning_rate": 0.0009003084096505801,
      "loss": 5.0379,
      "step": 1992
    },
    {
      "epoch": 0.22852883843595917,
      "grad_norm": 0.0,
      "learning_rate": 0.0009001971239481865,
      "loss": 4.9438,
      "step": 1993
    },
    {
      "epoch": 0.22864350418529986,
      "grad_norm": 0.0,
      "learning_rate": 0.000900085783053125,
      "loss": 4.9816,
      "step": 1994
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 0.0,
      "learning_rate": 0.0008999743869807521,
      "loss": 5.1385,
      "step": 1995
    },
    {
      "epoch": 0.2288728356839812,
      "grad_norm": 0.0,
      "learning_rate": 0.0008998629357464338,
      "loss": 4.9896,
      "step": 1996
    },
    {
      "epoch": 0.22898750143332186,
      "grad_norm": 0.0,
      "learning_rate": 0.0008997514293655416,
      "loss": 5.032,
      "step": 1997
    },
    {
      "epoch": 0.22910216718266255,
      "grad_norm": 0.0,
      "learning_rate": 0.0008996398678534567,
      "loss": 4.8452,
      "step": 1998
    },
    {
      "epoch": 0.2292168329320032,
      "grad_norm": 0.0,
      "learning_rate": 0.000899528251225566,
      "loss": 4.8296,
      "step": 1999
    },
    {
      "epoch": 0.2293314986813439,
      "grad_norm": 0.0,
      "learning_rate": 0.0008994165794972654,
      "loss": 4.9773,
      "step": 2000
    },
    {
      "epoch": 0.22944616443068455,
      "grad_norm": 0.0,
      "learning_rate": 0.000899304852683958,
      "loss": 4.9265,
      "step": 2001
    },
    {
      "epoch": 0.22956083018002524,
      "grad_norm": 0.0,
      "learning_rate": 0.0008991930708010539,
      "loss": 5.4589,
      "step": 2002
    },
    {
      "epoch": 0.2296754959293659,
      "grad_norm": 0.0,
      "learning_rate": 0.0008990812338639715,
      "loss": 5.2918,
      "step": 2003
    },
    {
      "epoch": 0.22979016167870658,
      "grad_norm": 0.0,
      "learning_rate": 0.0008989693418881368,
      "loss": 5.4106,
      "step": 2004
    },
    {
      "epoch": 0.22990482742804724,
      "grad_norm": 0.0,
      "learning_rate": 0.000898857394888983,
      "loss": 5.2244,
      "step": 2005
    },
    {
      "epoch": 0.2300194931773879,
      "grad_norm": 0.0,
      "learning_rate": 0.0008987453928819511,
      "loss": 5.1311,
      "step": 2006
    },
    {
      "epoch": 0.2301341589267286,
      "grad_norm": 0.0,
      "learning_rate": 0.0008986333358824894,
      "loss": 4.9369,
      "step": 2007
    },
    {
      "epoch": 0.23024882467606925,
      "grad_norm": 0.0,
      "learning_rate": 0.0008985212239060542,
      "loss": 4.9161,
      "step": 2008
    },
    {
      "epoch": 0.23036349042540993,
      "grad_norm": 0.0,
      "learning_rate": 0.0008984090569681092,
      "loss": 5.3474,
      "step": 2009
    },
    {
      "epoch": 0.2304781561747506,
      "grad_norm": 0.0,
      "learning_rate": 0.0008982968350841258,
      "loss": 4.9166,
      "step": 2010
    },
    {
      "epoch": 0.23059282192409128,
      "grad_norm": 0.0,
      "learning_rate": 0.0008981845582695828,
      "loss": 4.7073,
      "step": 2011
    },
    {
      "epoch": 0.23070748767343194,
      "grad_norm": 0.0,
      "learning_rate": 0.0008980722265399666,
      "loss": 5.0149,
      "step": 2012
    },
    {
      "epoch": 0.23082215342277262,
      "grad_norm": 0.0,
      "learning_rate": 0.0008979598399107713,
      "loss": 5.2717,
      "step": 2013
    },
    {
      "epoch": 0.23093681917211328,
      "grad_norm": 0.0,
      "learning_rate": 0.0008978473983974983,
      "loss": 4.77,
      "step": 2014
    },
    {
      "epoch": 0.23105148492145397,
      "grad_norm": 0.0,
      "learning_rate": 0.000897734902015657,
      "loss": 5.0524,
      "step": 2015
    },
    {
      "epoch": 0.23116615067079463,
      "grad_norm": 0.0,
      "learning_rate": 0.000897622350780764,
      "loss": 5.0629,
      "step": 2016
    },
    {
      "epoch": 0.23128081642013532,
      "grad_norm": 0.0,
      "learning_rate": 0.0008975097447083436,
      "loss": 5.0251,
      "step": 2017
    },
    {
      "epoch": 0.23139548216947597,
      "grad_norm": 0.0,
      "learning_rate": 0.0008973970838139276,
      "loss": 5.1675,
      "step": 2018
    },
    {
      "epoch": 0.23151014791881666,
      "grad_norm": 0.0,
      "learning_rate": 0.0008972843681130557,
      "loss": 5.1931,
      "step": 2019
    },
    {
      "epoch": 0.23162481366815732,
      "grad_norm": 0.0,
      "learning_rate": 0.0008971715976212746,
      "loss": 5.1796,
      "step": 2020
    },
    {
      "epoch": 0.231739479417498,
      "grad_norm": 0.0,
      "learning_rate": 0.0008970587723541389,
      "loss": 5.006,
      "step": 2021
    },
    {
      "epoch": 0.23185414516683867,
      "grad_norm": 0.0,
      "learning_rate": 0.0008969458923272108,
      "loss": 4.6806,
      "step": 2022
    },
    {
      "epoch": 0.23196881091617932,
      "grad_norm": 0.0,
      "learning_rate": 0.0008968329575560599,
      "loss": 4.6607,
      "step": 2023
    },
    {
      "epoch": 0.23208347666552,
      "grad_norm": 0.0,
      "learning_rate": 0.0008967199680562632,
      "loss": 5.0029,
      "step": 2024
    },
    {
      "epoch": 0.23219814241486067,
      "grad_norm": 0.0,
      "learning_rate": 0.0008966069238434058,
      "loss": 5.0437,
      "step": 2025
    },
    {
      "epoch": 0.23231280816420136,
      "grad_norm": 0.0,
      "learning_rate": 0.0008964938249330798,
      "loss": 5.0273,
      "step": 2026
    },
    {
      "epoch": 0.23242747391354202,
      "grad_norm": 0.0,
      "learning_rate": 0.000896380671340885,
      "loss": 5.1595,
      "step": 2027
    },
    {
      "epoch": 0.2325421396628827,
      "grad_norm": 0.0,
      "learning_rate": 0.0008962674630824288,
      "loss": 4.9621,
      "step": 2028
    },
    {
      "epoch": 0.23265680541222336,
      "grad_norm": 0.0,
      "learning_rate": 0.0008961542001733263,
      "loss": 4.9308,
      "step": 2029
    },
    {
      "epoch": 0.23277147116156405,
      "grad_norm": 0.0,
      "learning_rate": 0.0008960408826291997,
      "loss": 4.7811,
      "step": 2030
    },
    {
      "epoch": 0.2328861369109047,
      "grad_norm": 0.0,
      "learning_rate": 0.0008959275104656792,
      "loss": 5.1718,
      "step": 2031
    },
    {
      "epoch": 0.2330008026602454,
      "grad_norm": 0.0,
      "learning_rate": 0.0008958140836984021,
      "loss": 5.022,
      "step": 2032
    },
    {
      "epoch": 0.23311546840958605,
      "grad_norm": 0.0,
      "learning_rate": 0.0008957006023430137,
      "loss": 5.0914,
      "step": 2033
    },
    {
      "epoch": 0.23323013415892674,
      "grad_norm": 0.0,
      "learning_rate": 0.0008955870664151668,
      "loss": 5.08,
      "step": 2034
    },
    {
      "epoch": 0.2333447999082674,
      "grad_norm": 0.0,
      "learning_rate": 0.0008954734759305207,
      "loss": 4.9604,
      "step": 2035
    },
    {
      "epoch": 0.23345946565760808,
      "grad_norm": 0.0,
      "learning_rate": 0.0008953598309047437,
      "loss": 4.7462,
      "step": 2036
    },
    {
      "epoch": 0.23357413140694874,
      "grad_norm": 0.0,
      "learning_rate": 0.000895246131353511,
      "loss": 4.9975,
      "step": 2037
    },
    {
      "epoch": 0.23368879715628943,
      "grad_norm": 0.0,
      "learning_rate": 0.0008951323772925048,
      "loss": 5.082,
      "step": 2038
    },
    {
      "epoch": 0.2338034629056301,
      "grad_norm": 0.0,
      "learning_rate": 0.0008950185687374158,
      "loss": 5.0648,
      "step": 2039
    },
    {
      "epoch": 0.23391812865497075,
      "grad_norm": 0.0,
      "learning_rate": 0.0008949047057039416,
      "loss": 5.0587,
      "step": 2040
    },
    {
      "epoch": 0.23403279440431143,
      "grad_norm": 0.0,
      "learning_rate": 0.0008947907882077874,
      "loss": 5.2433,
      "step": 2041
    },
    {
      "epoch": 0.2341474601536521,
      "grad_norm": 0.0,
      "learning_rate": 0.0008946768162646658,
      "loss": 5.0983,
      "step": 2042
    },
    {
      "epoch": 0.23426212590299278,
      "grad_norm": 0.0,
      "learning_rate": 0.0008945627898902972,
      "loss": 4.8708,
      "step": 2043
    },
    {
      "epoch": 0.23437679165233344,
      "grad_norm": 0.0,
      "learning_rate": 0.0008944487091004092,
      "loss": 5.0241,
      "step": 2044
    },
    {
      "epoch": 0.23449145740167412,
      "grad_norm": 0.0,
      "learning_rate": 0.0008943345739107374,
      "loss": 4.9483,
      "step": 2045
    },
    {
      "epoch": 0.23460612315101478,
      "grad_norm": 0.0,
      "learning_rate": 0.0008942203843370242,
      "loss": 4.7686,
      "step": 2046
    },
    {
      "epoch": 0.23472078890035547,
      "grad_norm": 0.0,
      "learning_rate": 0.00089410614039502,
      "loss": 5.3336,
      "step": 2047
    },
    {
      "epoch": 0.23483545464969613,
      "grad_norm": 0.0,
      "learning_rate": 0.0008939918421004829,
      "loss": 4.8391,
      "step": 2048
    },
    {
      "epoch": 0.23495012039903682,
      "grad_norm": 0.0,
      "learning_rate": 0.0008938774894691777,
      "loss": 4.8268,
      "step": 2049
    },
    {
      "epoch": 0.23506478614837747,
      "grad_norm": 0.0,
      "learning_rate": 0.0008937630825168774,
      "loss": 4.9955,
      "step": 2050
    },
    {
      "epoch": 0.23517945189771816,
      "grad_norm": 0.0,
      "learning_rate": 0.0008936486212593622,
      "loss": 5.0354,
      "step": 2051
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 0.0,
      "learning_rate": 0.00089353410571242,
      "loss": 5.1578,
      "step": 2052
    },
    {
      "epoch": 0.2354087833963995,
      "grad_norm": 0.0,
      "learning_rate": 0.0008934195358918457,
      "loss": 4.9743,
      "step": 2053
    },
    {
      "epoch": 0.23552344914574017,
      "grad_norm": 0.0,
      "learning_rate": 0.0008933049118134424,
      "loss": 5.0251,
      "step": 2054
    },
    {
      "epoch": 0.23563811489508085,
      "grad_norm": 0.0,
      "learning_rate": 0.00089319023349302,
      "loss": 4.9697,
      "step": 2055
    },
    {
      "epoch": 0.2357527806444215,
      "grad_norm": 0.0,
      "learning_rate": 0.0008930755009463966,
      "loss": 4.9769,
      "step": 2056
    },
    {
      "epoch": 0.23586744639376217,
      "grad_norm": 0.0,
      "learning_rate": 0.0008929607141893967,
      "loss": 5.1359,
      "step": 2057
    },
    {
      "epoch": 0.23598211214310286,
      "grad_norm": 0.0,
      "learning_rate": 0.0008928458732378535,
      "loss": 4.9552,
      "step": 2058
    },
    {
      "epoch": 0.23609677789244352,
      "grad_norm": 0.0,
      "learning_rate": 0.0008927309781076071,
      "loss": 5.0829,
      "step": 2059
    },
    {
      "epoch": 0.2362114436417842,
      "grad_norm": 0.0,
      "learning_rate": 0.0008926160288145048,
      "loss": 4.9402,
      "step": 2060
    },
    {
      "epoch": 0.23632610939112486,
      "grad_norm": 0.0,
      "learning_rate": 0.0008925010253744019,
      "loss": 5.0509,
      "step": 2061
    },
    {
      "epoch": 0.23644077514046555,
      "grad_norm": 0.0,
      "learning_rate": 0.0008923859678031607,
      "loss": 5.0184,
      "step": 2062
    },
    {
      "epoch": 0.2365554408898062,
      "grad_norm": 0.0,
      "learning_rate": 0.0008922708561166513,
      "loss": 4.9999,
      "step": 2063
    },
    {
      "epoch": 0.2366701066391469,
      "grad_norm": 0.0,
      "learning_rate": 0.0008921556903307514,
      "loss": 5.0449,
      "step": 2064
    },
    {
      "epoch": 0.23678477238848755,
      "grad_norm": 0.0,
      "learning_rate": 0.0008920404704613457,
      "loss": 5.1026,
      "step": 2065
    },
    {
      "epoch": 0.23689943813782824,
      "grad_norm": 0.0,
      "learning_rate": 0.0008919251965243268,
      "loss": 5.1684,
      "step": 2066
    },
    {
      "epoch": 0.2370141038871689,
      "grad_norm": 0.0,
      "learning_rate": 0.0008918098685355941,
      "loss": 5.1586,
      "step": 2067
    },
    {
      "epoch": 0.23712876963650958,
      "grad_norm": 0.0,
      "learning_rate": 0.0008916944865110551,
      "loss": 4.9239,
      "step": 2068
    },
    {
      "epoch": 0.23724343538585024,
      "grad_norm": 0.0,
      "learning_rate": 0.0008915790504666247,
      "loss": 4.8906,
      "step": 2069
    },
    {
      "epoch": 0.23735810113519093,
      "grad_norm": 0.0,
      "learning_rate": 0.0008914635604182251,
      "loss": 5.0594,
      "step": 2070
    },
    {
      "epoch": 0.2374727668845316,
      "grad_norm": 0.0,
      "learning_rate": 0.0008913480163817858,
      "loss": 5.1136,
      "step": 2071
    },
    {
      "epoch": 0.23758743263387228,
      "grad_norm": 0.0,
      "learning_rate": 0.000891232418373244,
      "loss": 4.9591,
      "step": 2072
    },
    {
      "epoch": 0.23770209838321293,
      "grad_norm": 0.0,
      "learning_rate": 0.0008911167664085441,
      "loss": 5.2405,
      "step": 2073
    },
    {
      "epoch": 0.2378167641325536,
      "grad_norm": 0.0,
      "learning_rate": 0.0008910010605036381,
      "loss": 5.0958,
      "step": 2074
    },
    {
      "epoch": 0.23793142988189428,
      "grad_norm": 0.0,
      "learning_rate": 0.000890885300674486,
      "loss": 5.0427,
      "step": 2075
    },
    {
      "epoch": 0.23804609563123494,
      "grad_norm": 0.0,
      "learning_rate": 0.0008907694869370536,
      "loss": 5.0982,
      "step": 2076
    },
    {
      "epoch": 0.23816076138057563,
      "grad_norm": 0.0,
      "learning_rate": 0.0008906536193073161,
      "loss": 4.9217,
      "step": 2077
    },
    {
      "epoch": 0.23827542712991628,
      "grad_norm": 0.0,
      "learning_rate": 0.0008905376978012547,
      "loss": 4.9163,
      "step": 2078
    },
    {
      "epoch": 0.23839009287925697,
      "grad_norm": 0.0,
      "learning_rate": 0.0008904217224348589,
      "loss": 5.0763,
      "step": 2079
    },
    {
      "epoch": 0.23850475862859763,
      "grad_norm": 0.0,
      "learning_rate": 0.000890305693224125,
      "loss": 4.6988,
      "step": 2080
    },
    {
      "epoch": 0.23861942437793832,
      "grad_norm": 0.0,
      "learning_rate": 0.0008901896101850573,
      "loss": 5.0758,
      "step": 2081
    },
    {
      "epoch": 0.23873409012727898,
      "grad_norm": 0.0,
      "learning_rate": 0.0008900734733336671,
      "loss": 5.0874,
      "step": 2082
    },
    {
      "epoch": 0.23884875587661966,
      "grad_norm": 0.0,
      "learning_rate": 0.0008899572826859733,
      "loss": 4.8679,
      "step": 2083
    },
    {
      "epoch": 0.23896342162596032,
      "grad_norm": 0.0,
      "learning_rate": 0.0008898410382580021,
      "loss": 4.8962,
      "step": 2084
    },
    {
      "epoch": 0.239078087375301,
      "grad_norm": 0.0,
      "learning_rate": 0.0008897247400657872,
      "loss": 5.0428,
      "step": 2085
    },
    {
      "epoch": 0.23919275312464167,
      "grad_norm": 0.0,
      "learning_rate": 0.00088960838812537,
      "loss": 5.2564,
      "step": 2086
    },
    {
      "epoch": 0.23930741887398235,
      "grad_norm": 0.0,
      "learning_rate": 0.0008894919824527988,
      "loss": 5.0541,
      "step": 2087
    },
    {
      "epoch": 0.239422084623323,
      "grad_norm": 0.0,
      "learning_rate": 0.0008893755230641293,
      "loss": 5.1843,
      "step": 2088
    },
    {
      "epoch": 0.2395367503726637,
      "grad_norm": 0.0,
      "learning_rate": 0.0008892590099754253,
      "loss": 4.8566,
      "step": 2089
    },
    {
      "epoch": 0.23965141612200436,
      "grad_norm": 0.0,
      "learning_rate": 0.0008891424432027573,
      "loss": 5.016,
      "step": 2090
    },
    {
      "epoch": 0.23976608187134502,
      "grad_norm": 0.0,
      "learning_rate": 0.0008890258227622036,
      "loss": 4.8853,
      "step": 2091
    },
    {
      "epoch": 0.2398807476206857,
      "grad_norm": 0.0,
      "learning_rate": 0.0008889091486698498,
      "loss": 4.9588,
      "step": 2092
    },
    {
      "epoch": 0.23999541337002636,
      "grad_norm": 0.0,
      "learning_rate": 0.0008887924209417885,
      "loss": 5.1865,
      "step": 2093
    },
    {
      "epoch": 0.24011007911936705,
      "grad_norm": 0.0,
      "learning_rate": 0.0008886756395941204,
      "loss": 5.1893,
      "step": 2094
    },
    {
      "epoch": 0.2402247448687077,
      "grad_norm": 0.0,
      "learning_rate": 0.0008885588046429534,
      "loss": 5.2077,
      "step": 2095
    },
    {
      "epoch": 0.2403394106180484,
      "grad_norm": 0.0,
      "learning_rate": 0.0008884419161044023,
      "loss": 5.2563,
      "step": 2096
    },
    {
      "epoch": 0.24045407636738905,
      "grad_norm": 0.0,
      "learning_rate": 0.0008883249739945899,
      "loss": 4.9891,
      "step": 2097
    },
    {
      "epoch": 0.24056874211672974,
      "grad_norm": 0.0,
      "learning_rate": 0.0008882079783296459,
      "loss": 5.0149,
      "step": 2098
    },
    {
      "epoch": 0.2406834078660704,
      "grad_norm": 0.0,
      "learning_rate": 0.0008880909291257079,
      "loss": 5.0854,
      "step": 2099
    },
    {
      "epoch": 0.24079807361541108,
      "grad_norm": 0.0,
      "learning_rate": 0.0008879738263989203,
      "loss": 4.9729,
      "step": 2100
    },
    {
      "epoch": 0.24091273936475174,
      "grad_norm": 0.0,
      "learning_rate": 0.0008878566701654353,
      "loss": 4.9675,
      "step": 2101
    },
    {
      "epoch": 0.24102740511409243,
      "grad_norm": 0.0,
      "learning_rate": 0.0008877394604414128,
      "loss": 4.8856,
      "step": 2102
    },
    {
      "epoch": 0.2411420708634331,
      "grad_norm": 0.0,
      "learning_rate": 0.0008876221972430188,
      "loss": 4.9712,
      "step": 2103
    },
    {
      "epoch": 0.24125673661277378,
      "grad_norm": 0.0,
      "learning_rate": 0.0008875048805864282,
      "loss": 4.9857,
      "step": 2104
    },
    {
      "epoch": 0.24137140236211443,
      "grad_norm": 0.0,
      "learning_rate": 0.0008873875104878225,
      "loss": 5.0406,
      "step": 2105
    },
    {
      "epoch": 0.24148606811145512,
      "grad_norm": 0.0,
      "learning_rate": 0.0008872700869633903,
      "loss": 5.2562,
      "step": 2106
    },
    {
      "epoch": 0.24160073386079578,
      "grad_norm": 0.0,
      "learning_rate": 0.0008871526100293284,
      "loss": 5.0232,
      "step": 2107
    },
    {
      "epoch": 0.24171539961013644,
      "grad_norm": 0.0,
      "learning_rate": 0.0008870350797018402,
      "loss": 4.8277,
      "step": 2108
    },
    {
      "epoch": 0.24183006535947713,
      "grad_norm": 0.0,
      "learning_rate": 0.0008869174959971369,
      "loss": 5.1057,
      "step": 2109
    },
    {
      "epoch": 0.24194473110881778,
      "grad_norm": 0.0,
      "learning_rate": 0.0008867998589314369,
      "loss": 4.9845,
      "step": 2110
    },
    {
      "epoch": 0.24205939685815847,
      "grad_norm": 0.0,
      "learning_rate": 0.0008866821685209658,
      "loss": 4.906,
      "step": 2111
    },
    {
      "epoch": 0.24217406260749913,
      "grad_norm": 0.0,
      "learning_rate": 0.0008865644247819572,
      "loss": 4.904,
      "step": 2112
    },
    {
      "epoch": 0.24228872835683982,
      "grad_norm": 0.0,
      "learning_rate": 0.0008864466277306512,
      "loss": 4.941,
      "step": 2113
    },
    {
      "epoch": 0.24240339410618048,
      "grad_norm": 0.0,
      "learning_rate": 0.0008863287773832959,
      "loss": 5.1313,
      "step": 2114
    },
    {
      "epoch": 0.24251805985552116,
      "grad_norm": 0.0,
      "learning_rate": 0.0008862108737561462,
      "loss": 5.085,
      "step": 2115
    },
    {
      "epoch": 0.24263272560486182,
      "grad_norm": 0.0,
      "learning_rate": 0.000886092916865465,
      "loss": 4.8141,
      "step": 2116
    },
    {
      "epoch": 0.2427473913542025,
      "grad_norm": 0.0,
      "learning_rate": 0.0008859749067275222,
      "loss": 4.8486,
      "step": 2117
    },
    {
      "epoch": 0.24286205710354317,
      "grad_norm": 0.0,
      "learning_rate": 0.0008858568433585946,
      "loss": 5.1864,
      "step": 2118
    },
    {
      "epoch": 0.24297672285288385,
      "grad_norm": 0.0,
      "learning_rate": 0.0008857387267749673,
      "loss": 4.9103,
      "step": 2119
    },
    {
      "epoch": 0.2430913886022245,
      "grad_norm": 0.0,
      "learning_rate": 0.0008856205569929321,
      "loss": 4.8572,
      "step": 2120
    },
    {
      "epoch": 0.2432060543515652,
      "grad_norm": 0.0,
      "learning_rate": 0.0008855023340287881,
      "loss": 5.2602,
      "step": 2121
    },
    {
      "epoch": 0.24332072010090586,
      "grad_norm": 0.0,
      "learning_rate": 0.0008853840578988419,
      "loss": 4.88,
      "step": 2122
    },
    {
      "epoch": 0.24343538585024654,
      "grad_norm": 0.0,
      "learning_rate": 0.0008852657286194077,
      "loss": 4.826,
      "step": 2123
    },
    {
      "epoch": 0.2435500515995872,
      "grad_norm": 0.0,
      "learning_rate": 0.0008851473462068066,
      "loss": 5.2058,
      "step": 2124
    },
    {
      "epoch": 0.24366471734892786,
      "grad_norm": 0.0,
      "learning_rate": 0.0008850289106773672,
      "loss": 5.1657,
      "step": 2125
    },
    {
      "epoch": 0.24377938309826855,
      "grad_norm": 0.0,
      "learning_rate": 0.0008849104220474255,
      "loss": 5.2021,
      "step": 2126
    },
    {
      "epoch": 0.2438940488476092,
      "grad_norm": 0.0,
      "learning_rate": 0.0008847918803333247,
      "loss": 4.8779,
      "step": 2127
    },
    {
      "epoch": 0.2440087145969499,
      "grad_norm": 0.0,
      "learning_rate": 0.0008846732855514151,
      "loss": 4.9474,
      "step": 2128
    },
    {
      "epoch": 0.24412338034629055,
      "grad_norm": 0.0,
      "learning_rate": 0.0008845546377180551,
      "loss": 5.2517,
      "step": 2129
    },
    {
      "epoch": 0.24423804609563124,
      "grad_norm": 0.0,
      "learning_rate": 0.0008844359368496096,
      "loss": 4.8635,
      "step": 2130
    },
    {
      "epoch": 0.2443527118449719,
      "grad_norm": 0.0,
      "learning_rate": 0.0008843171829624511,
      "loss": 5.1584,
      "step": 2131
    },
    {
      "epoch": 0.24446737759431258,
      "grad_norm": 0.0,
      "learning_rate": 0.0008841983760729597,
      "loss": 4.8819,
      "step": 2132
    },
    {
      "epoch": 0.24458204334365324,
      "grad_norm": 0.0,
      "learning_rate": 0.0008840795161975222,
      "loss": 4.854,
      "step": 2133
    },
    {
      "epoch": 0.24469670909299393,
      "grad_norm": 0.0,
      "learning_rate": 0.000883960603352533,
      "loss": 5.0073,
      "step": 2134
    },
    {
      "epoch": 0.2448113748423346,
      "grad_norm": 0.0,
      "learning_rate": 0.0008838416375543944,
      "loss": 4.8125,
      "step": 2135
    },
    {
      "epoch": 0.24492604059167528,
      "grad_norm": 0.0,
      "learning_rate": 0.0008837226188195151,
      "loss": 4.9456,
      "step": 2136
    },
    {
      "epoch": 0.24504070634101593,
      "grad_norm": 0.0,
      "learning_rate": 0.0008836035471643114,
      "loss": 4.892,
      "step": 2137
    },
    {
      "epoch": 0.24515537209035662,
      "grad_norm": 0.0,
      "learning_rate": 0.0008834844226052071,
      "loss": 4.8941,
      "step": 2138
    },
    {
      "epoch": 0.24527003783969728,
      "grad_norm": 0.0,
      "learning_rate": 0.0008833652451586332,
      "loss": 5.0214,
      "step": 2139
    },
    {
      "epoch": 0.24538470358903797,
      "grad_norm": 0.0,
      "learning_rate": 0.0008832460148410276,
      "loss": 4.9788,
      "step": 2140
    },
    {
      "epoch": 0.24549936933837863,
      "grad_norm": 0.0,
      "learning_rate": 0.0008831267316688364,
      "loss": 5.1286,
      "step": 2141
    },
    {
      "epoch": 0.24561403508771928,
      "grad_norm": 0.0,
      "learning_rate": 0.000883007395658512,
      "loss": 5.219,
      "step": 2142
    },
    {
      "epoch": 0.24572870083705997,
      "grad_norm": 0.0,
      "learning_rate": 0.0008828880068265149,
      "loss": 5.0854,
      "step": 2143
    },
    {
      "epoch": 0.24584336658640063,
      "grad_norm": 0.0,
      "learning_rate": 0.0008827685651893123,
      "loss": 5.3182,
      "step": 2144
    },
    {
      "epoch": 0.24595803233574132,
      "grad_norm": 0.0,
      "learning_rate": 0.0008826490707633788,
      "loss": 4.9237,
      "step": 2145
    },
    {
      "epoch": 0.24607269808508198,
      "grad_norm": 0.0,
      "learning_rate": 0.0008825295235651965,
      "loss": 5.1938,
      "step": 2146
    },
    {
      "epoch": 0.24618736383442266,
      "grad_norm": 0.0,
      "learning_rate": 0.0008824099236112548,
      "loss": 4.9065,
      "step": 2147
    },
    {
      "epoch": 0.24630202958376332,
      "grad_norm": 0.0,
      "learning_rate": 0.0008822902709180498,
      "loss": 4.8433,
      "step": 2148
    },
    {
      "epoch": 0.246416695333104,
      "grad_norm": 0.0,
      "learning_rate": 0.0008821705655020859,
      "loss": 4.9336,
      "step": 2149
    },
    {
      "epoch": 0.24653136108244467,
      "grad_norm": 0.0,
      "learning_rate": 0.0008820508073798737,
      "loss": 5.0935,
      "step": 2150
    },
    {
      "epoch": 0.24664602683178535,
      "grad_norm": 0.0,
      "learning_rate": 0.0008819309965679316,
      "loss": 5.1789,
      "step": 2151
    },
    {
      "epoch": 0.246760692581126,
      "grad_norm": 0.0,
      "learning_rate": 0.0008818111330827855,
      "loss": 5.0473,
      "step": 2152
    },
    {
      "epoch": 0.2468753583304667,
      "grad_norm": 0.0,
      "learning_rate": 0.000881691216940968,
      "loss": 4.8663,
      "step": 2153
    },
    {
      "epoch": 0.24699002407980736,
      "grad_norm": 0.0,
      "learning_rate": 0.0008815712481590195,
      "loss": 4.9471,
      "step": 2154
    },
    {
      "epoch": 0.24710468982914804,
      "grad_norm": 0.0,
      "learning_rate": 0.0008814512267534873,
      "loss": 4.8479,
      "step": 2155
    },
    {
      "epoch": 0.2472193555784887,
      "grad_norm": 0.0,
      "learning_rate": 0.000881331152740926,
      "loss": 4.9359,
      "step": 2156
    },
    {
      "epoch": 0.2473340213278294,
      "grad_norm": 0.0,
      "learning_rate": 0.0008812110261378975,
      "loss": 4.7708,
      "step": 2157
    },
    {
      "epoch": 0.24744868707717005,
      "grad_norm": 0.0,
      "learning_rate": 0.0008810908469609709,
      "loss": 4.9846,
      "step": 2158
    },
    {
      "epoch": 0.2475633528265107,
      "grad_norm": 0.0,
      "learning_rate": 0.000880970615226723,
      "loss": 5.0615,
      "step": 2159
    },
    {
      "epoch": 0.2476780185758514,
      "grad_norm": 0.0,
      "learning_rate": 0.0008808503309517371,
      "loss": 5.0641,
      "step": 2160
    },
    {
      "epoch": 0.24779268432519205,
      "grad_norm": 0.0,
      "learning_rate": 0.0008807299941526044,
      "loss": 4.982,
      "step": 2161
    },
    {
      "epoch": 0.24790735007453274,
      "grad_norm": 0.0,
      "learning_rate": 0.0008806096048459229,
      "loss": 4.9706,
      "step": 2162
    },
    {
      "epoch": 0.2480220158238734,
      "grad_norm": 0.0,
      "learning_rate": 0.000880489163048298,
      "loss": 4.9723,
      "step": 2163
    },
    {
      "epoch": 0.24813668157321409,
      "grad_norm": 0.0,
      "learning_rate": 0.0008803686687763423,
      "loss": 5.0506,
      "step": 2164
    },
    {
      "epoch": 0.24825134732255474,
      "grad_norm": 0.0,
      "learning_rate": 0.0008802481220466759,
      "loss": 5.0189,
      "step": 2165
    },
    {
      "epoch": 0.24836601307189543,
      "grad_norm": 0.0,
      "learning_rate": 0.0008801275228759257,
      "loss": 5.0655,
      "step": 2166
    },
    {
      "epoch": 0.2484806788212361,
      "grad_norm": 0.0,
      "learning_rate": 0.0008800068712807263,
      "loss": 4.9531,
      "step": 2167
    },
    {
      "epoch": 0.24859534457057678,
      "grad_norm": 0.0,
      "learning_rate": 0.000879886167277719,
      "loss": 4.8599,
      "step": 2168
    },
    {
      "epoch": 0.24871001031991744,
      "grad_norm": 0.0,
      "learning_rate": 0.0008797654108835527,
      "loss": 5.0172,
      "step": 2169
    },
    {
      "epoch": 0.24882467606925812,
      "grad_norm": 0.0,
      "learning_rate": 0.0008796446021148836,
      "loss": 5.1014,
      "step": 2170
    },
    {
      "epoch": 0.24893934181859878,
      "grad_norm": 0.0,
      "learning_rate": 0.0008795237409883749,
      "loss": 4.8801,
      "step": 2171
    },
    {
      "epoch": 0.24905400756793947,
      "grad_norm": 0.0,
      "learning_rate": 0.0008794028275206971,
      "loss": 4.8598,
      "step": 2172
    },
    {
      "epoch": 0.24916867331728013,
      "grad_norm": 0.0,
      "learning_rate": 0.0008792818617285278,
      "loss": 4.9344,
      "step": 2173
    },
    {
      "epoch": 0.2492833390666208,
      "grad_norm": 0.0,
      "learning_rate": 0.0008791608436285519,
      "loss": 5.0582,
      "step": 2174
    },
    {
      "epoch": 0.24939800481596147,
      "grad_norm": 0.0,
      "learning_rate": 0.0008790397732374619,
      "loss": 4.9984,
      "step": 2175
    },
    {
      "epoch": 0.24951267056530213,
      "grad_norm": 0.0,
      "learning_rate": 0.0008789186505719567,
      "loss": 4.8941,
      "step": 2176
    },
    {
      "epoch": 0.24962733631464282,
      "grad_norm": 0.0,
      "learning_rate": 0.000878797475648743,
      "loss": 4.8951,
      "step": 2177
    },
    {
      "epoch": 0.24974200206398348,
      "grad_norm": 0.0,
      "learning_rate": 0.0008786762484845346,
      "loss": 5.1029,
      "step": 2178
    },
    {
      "epoch": 0.24985666781332416,
      "grad_norm": 0.0,
      "learning_rate": 0.0008785549690960527,
      "loss": 4.8129,
      "step": 2179
    },
    {
      "epoch": 0.24997133356266482,
      "grad_norm": 0.0,
      "learning_rate": 0.0008784336375000252,
      "loss": 4.7508,
      "step": 2180
    },
    {
      "epoch": 0.2500859993120055,
      "grad_norm": 0.0,
      "learning_rate": 0.0008783122537131874,
      "loss": 4.9179,
      "step": 2181
    },
    {
      "epoch": 0.2502006650613462,
      "grad_norm": 0.0,
      "learning_rate": 0.0008781908177522821,
      "loss": 4.9644,
      "step": 2182
    },
    {
      "epoch": 0.25031533081068685,
      "grad_norm": 0.0,
      "learning_rate": 0.0008780693296340592,
      "loss": 5.0963,
      "step": 2183
    },
    {
      "epoch": 0.2504299965600275,
      "grad_norm": 0.0,
      "learning_rate": 0.0008779477893752751,
      "loss": 5.2745,
      "step": 2184
    },
    {
      "epoch": 0.25054466230936817,
      "grad_norm": 0.0,
      "learning_rate": 0.0008778261969926946,
      "loss": 4.8577,
      "step": 2185
    },
    {
      "epoch": 0.2506593280587089,
      "grad_norm": 0.0,
      "learning_rate": 0.0008777045525030889,
      "loss": 4.9188,
      "step": 2186
    },
    {
      "epoch": 0.25077399380804954,
      "grad_norm": 0.0,
      "learning_rate": 0.0008775828559232362,
      "loss": 5.0509,
      "step": 2187
    },
    {
      "epoch": 0.2508886595573902,
      "grad_norm": 0.0,
      "learning_rate": 0.0008774611072699226,
      "loss": 5.1377,
      "step": 2188
    },
    {
      "epoch": 0.25100332530673086,
      "grad_norm": 0.0,
      "learning_rate": 0.0008773393065599407,
      "loss": 5.1167,
      "step": 2189
    },
    {
      "epoch": 0.2511179910560716,
      "grad_norm": 0.0,
      "learning_rate": 0.0008772174538100909,
      "loss": 5.0303,
      "step": 2190
    },
    {
      "epoch": 0.25123265680541224,
      "grad_norm": 0.0,
      "learning_rate": 0.0008770955490371803,
      "loss": 5.032,
      "step": 2191
    },
    {
      "epoch": 0.2513473225547529,
      "grad_norm": 0.0,
      "learning_rate": 0.0008769735922580234,
      "loss": 5.0048,
      "step": 2192
    },
    {
      "epoch": 0.25146198830409355,
      "grad_norm": 0.0,
      "learning_rate": 0.0008768515834894417,
      "loss": 4.8488,
      "step": 2193
    },
    {
      "epoch": 0.2515766540534342,
      "grad_norm": 0.0,
      "learning_rate": 0.000876729522748264,
      "loss": 4.924,
      "step": 2194
    },
    {
      "epoch": 0.2516913198027749,
      "grad_norm": 0.0,
      "learning_rate": 0.0008766074100513263,
      "loss": 4.9824,
      "step": 2195
    },
    {
      "epoch": 0.2518059855521156,
      "grad_norm": 0.0,
      "learning_rate": 0.0008764852454154718,
      "loss": 4.977,
      "step": 2196
    },
    {
      "epoch": 0.25192065130145624,
      "grad_norm": 0.0,
      "learning_rate": 0.0008763630288575506,
      "loss": 4.8393,
      "step": 2197
    },
    {
      "epoch": 0.2520353170507969,
      "grad_norm": 0.0,
      "learning_rate": 0.0008762407603944202,
      "loss": 5.2327,
      "step": 2198
    },
    {
      "epoch": 0.2521499828001376,
      "grad_norm": 0.0,
      "learning_rate": 0.0008761184400429455,
      "loss": 5.0276,
      "step": 2199
    },
    {
      "epoch": 0.2522646485494783,
      "grad_norm": 0.0,
      "learning_rate": 0.0008759960678199979,
      "loss": 5.3975,
      "step": 2200
    },
    {
      "epoch": 0.25237931429881894,
      "grad_norm": 0.0,
      "learning_rate": 0.0008758736437424564,
      "loss": 4.9208,
      "step": 2201
    },
    {
      "epoch": 0.2524939800481596,
      "grad_norm": 0.0,
      "learning_rate": 0.0008757511678272071,
      "loss": 5.0851,
      "step": 2202
    },
    {
      "epoch": 0.2526086457975003,
      "grad_norm": 0.0,
      "learning_rate": 0.0008756286400911433,
      "loss": 5.0902,
      "step": 2203
    },
    {
      "epoch": 0.25272331154684097,
      "grad_norm": 0.0,
      "learning_rate": 0.0008755060605511652,
      "loss": 5.022,
      "step": 2204
    },
    {
      "epoch": 0.2528379772961816,
      "grad_norm": 0.0,
      "learning_rate": 0.0008753834292241804,
      "loss": 4.9022,
      "step": 2205
    },
    {
      "epoch": 0.2529526430455223,
      "grad_norm": 0.0,
      "learning_rate": 0.0008752607461271035,
      "loss": 4.9481,
      "step": 2206
    },
    {
      "epoch": 0.253067308794863,
      "grad_norm": 0.0,
      "learning_rate": 0.0008751380112768563,
      "loss": 5.2971,
      "step": 2207
    },
    {
      "epoch": 0.25318197454420366,
      "grad_norm": 0.0,
      "learning_rate": 0.000875015224690368,
      "loss": 4.9814,
      "step": 2208
    },
    {
      "epoch": 0.2532966402935443,
      "grad_norm": 0.0,
      "learning_rate": 0.0008748923863845742,
      "loss": 4.9435,
      "step": 2209
    },
    {
      "epoch": 0.253411306042885,
      "grad_norm": 0.0,
      "learning_rate": 0.0008747694963764183,
      "loss": 4.901,
      "step": 2210
    },
    {
      "epoch": 0.25352597179222564,
      "grad_norm": 0.0,
      "learning_rate": 0.000874646554682851,
      "loss": 5.2195,
      "step": 2211
    },
    {
      "epoch": 0.25364063754156635,
      "grad_norm": 0.0,
      "learning_rate": 0.0008745235613208291,
      "loss": 5.2213,
      "step": 2212
    },
    {
      "epoch": 0.253755303290907,
      "grad_norm": 0.0,
      "learning_rate": 0.0008744005163073176,
      "loss": 4.9688,
      "step": 2213
    },
    {
      "epoch": 0.25386996904024767,
      "grad_norm": 0.0,
      "learning_rate": 0.0008742774196592885,
      "loss": 4.961,
      "step": 2214
    },
    {
      "epoch": 0.2539846347895883,
      "grad_norm": 0.0,
      "learning_rate": 0.0008741542713937199,
      "loss": 5.052,
      "step": 2215
    },
    {
      "epoch": 0.25409930053892904,
      "grad_norm": 0.0,
      "learning_rate": 0.0008740310715275982,
      "loss": 4.9147,
      "step": 2216
    },
    {
      "epoch": 0.2542139662882697,
      "grad_norm": 0.0,
      "learning_rate": 0.0008739078200779164,
      "loss": 5.0289,
      "step": 2217
    },
    {
      "epoch": 0.25432863203761036,
      "grad_norm": 0.0,
      "learning_rate": 0.0008737845170616748,
      "loss": 4.8623,
      "step": 2218
    },
    {
      "epoch": 0.254443297786951,
      "grad_norm": 0.0,
      "learning_rate": 0.0008736611624958805,
      "loss": 4.8689,
      "step": 2219
    },
    {
      "epoch": 0.25455796353629173,
      "grad_norm": 0.0,
      "learning_rate": 0.0008735377563975482,
      "loss": 5.0875,
      "step": 2220
    },
    {
      "epoch": 0.2546726292856324,
      "grad_norm": 0.0,
      "learning_rate": 0.000873414298783699,
      "loss": 5.0647,
      "step": 2221
    },
    {
      "epoch": 0.25478729503497305,
      "grad_norm": 0.0,
      "learning_rate": 0.0008732907896713619,
      "loss": 5.2456,
      "step": 2222
    },
    {
      "epoch": 0.2549019607843137,
      "grad_norm": 0.0,
      "learning_rate": 0.0008731672290775726,
      "loss": 5.1593,
      "step": 2223
    },
    {
      "epoch": 0.2550166265336544,
      "grad_norm": 0.0,
      "learning_rate": 0.0008730436170193735,
      "loss": 4.9132,
      "step": 2224
    },
    {
      "epoch": 0.2551312922829951,
      "grad_norm": 0.0,
      "learning_rate": 0.0008729199535138149,
      "loss": 5.0869,
      "step": 2225
    },
    {
      "epoch": 0.25524595803233574,
      "grad_norm": 0.0,
      "learning_rate": 0.0008727962385779537,
      "loss": 5.0975,
      "step": 2226
    },
    {
      "epoch": 0.2553606237816764,
      "grad_norm": 0.0,
      "learning_rate": 0.0008726724722288543,
      "loss": 5.0358,
      "step": 2227
    },
    {
      "epoch": 0.25547528953101706,
      "grad_norm": 0.0,
      "learning_rate": 0.0008725486544835877,
      "loss": 4.9013,
      "step": 2228
    },
    {
      "epoch": 0.2555899552803578,
      "grad_norm": 0.0,
      "learning_rate": 0.0008724247853592321,
      "loss": 4.7546,
      "step": 2229
    },
    {
      "epoch": 0.25570462102969843,
      "grad_norm": 0.0,
      "learning_rate": 0.000872300864872873,
      "loss": 5.1018,
      "step": 2230
    },
    {
      "epoch": 0.2558192867790391,
      "grad_norm": 0.0,
      "learning_rate": 0.0008721768930416027,
      "loss": 4.6727,
      "step": 2231
    },
    {
      "epoch": 0.25593395252837975,
      "grad_norm": 0.0,
      "learning_rate": 0.0008720528698825211,
      "loss": 5.1056,
      "step": 2232
    },
    {
      "epoch": 0.25604861827772046,
      "grad_norm": 0.0,
      "learning_rate": 0.0008719287954127343,
      "loss": 4.9829,
      "step": 2233
    },
    {
      "epoch": 0.2561632840270611,
      "grad_norm": 0.0,
      "learning_rate": 0.0008718046696493566,
      "loss": 4.9451,
      "step": 2234
    },
    {
      "epoch": 0.2562779497764018,
      "grad_norm": 0.0,
      "learning_rate": 0.0008716804926095084,
      "loss": 4.821,
      "step": 2235
    },
    {
      "epoch": 0.25639261552574244,
      "grad_norm": 0.0,
      "learning_rate": 0.0008715562643103178,
      "loss": 4.7422,
      "step": 2236
    },
    {
      "epoch": 0.25650728127508315,
      "grad_norm": 0.0,
      "learning_rate": 0.0008714319847689195,
      "loss": 4.8611,
      "step": 2237
    },
    {
      "epoch": 0.2566219470244238,
      "grad_norm": 0.0,
      "learning_rate": 0.0008713076540024555,
      "loss": 4.8959,
      "step": 2238
    },
    {
      "epoch": 0.25673661277376447,
      "grad_norm": 0.0,
      "learning_rate": 0.000871183272028075,
      "loss": 5.093,
      "step": 2239
    },
    {
      "epoch": 0.25685127852310513,
      "grad_norm": 0.0,
      "learning_rate": 0.0008710588388629343,
      "loss": 4.8657,
      "step": 2240
    },
    {
      "epoch": 0.25696594427244585,
      "grad_norm": 0.0,
      "learning_rate": 0.000870934354524196,
      "loss": 5.1087,
      "step": 2241
    },
    {
      "epoch": 0.2570806100217865,
      "grad_norm": 0.0,
      "learning_rate": 0.0008708098190290309,
      "loss": 4.7984,
      "step": 2242
    },
    {
      "epoch": 0.25719527577112716,
      "grad_norm": 0.0,
      "learning_rate": 0.000870685232394616,
      "loss": 4.8997,
      "step": 2243
    },
    {
      "epoch": 0.2573099415204678,
      "grad_norm": 0.0,
      "learning_rate": 0.0008705605946381359,
      "loss": 4.8681,
      "step": 2244
    },
    {
      "epoch": 0.2574246072698085,
      "grad_norm": 0.0,
      "learning_rate": 0.0008704359057767815,
      "loss": 4.8591,
      "step": 2245
    },
    {
      "epoch": 0.2575392730191492,
      "grad_norm": 0.0,
      "learning_rate": 0.0008703111658277518,
      "loss": 5.0206,
      "step": 2246
    },
    {
      "epoch": 0.25765393876848985,
      "grad_norm": 0.0,
      "learning_rate": 0.0008701863748082521,
      "loss": 4.9928,
      "step": 2247
    },
    {
      "epoch": 0.2577686045178305,
      "grad_norm": 0.0,
      "learning_rate": 0.000870061532735495,
      "loss": 5.1576,
      "step": 2248
    },
    {
      "epoch": 0.25788327026717117,
      "grad_norm": 0.0,
      "learning_rate": 0.0008699366396267001,
      "loss": 5.1374,
      "step": 2249
    },
    {
      "epoch": 0.2579979360165119,
      "grad_norm": 0.0,
      "learning_rate": 0.0008698116954990937,
      "loss": 4.9063,
      "step": 2250
    },
    {
      "epoch": 0.25811260176585255,
      "grad_norm": 0.0,
      "learning_rate": 0.0008696867003699098,
      "loss": 5.2355,
      "step": 2251
    },
    {
      "epoch": 0.2582272675151932,
      "grad_norm": 0.0,
      "learning_rate": 0.0008695616542563891,
      "loss": 5.127,
      "step": 2252
    },
    {
      "epoch": 0.25834193326453386,
      "grad_norm": 0.0,
      "learning_rate": 0.000869436557175779,
      "loss": 5.1821,
      "step": 2253
    },
    {
      "epoch": 0.2584565990138746,
      "grad_norm": 0.0,
      "learning_rate": 0.0008693114091453347,
      "loss": 5.2282,
      "step": 2254
    },
    {
      "epoch": 0.25857126476321524,
      "grad_norm": 0.0,
      "learning_rate": 0.0008691862101823177,
      "loss": 4.9427,
      "step": 2255
    },
    {
      "epoch": 0.2586859305125559,
      "grad_norm": 0.0,
      "learning_rate": 0.0008690609603039969,
      "loss": 5.1383,
      "step": 2256
    },
    {
      "epoch": 0.25880059626189655,
      "grad_norm": 0.0,
      "learning_rate": 0.0008689356595276479,
      "loss": 4.9623,
      "step": 2257
    },
    {
      "epoch": 0.25891526201123727,
      "grad_norm": 0.0,
      "learning_rate": 0.0008688103078705542,
      "loss": 5.1716,
      "step": 2258
    },
    {
      "epoch": 0.2590299277605779,
      "grad_norm": 0.0,
      "learning_rate": 0.000868684905350005,
      "loss": 4.6987,
      "step": 2259
    },
    {
      "epoch": 0.2591445935099186,
      "grad_norm": 0.0,
      "learning_rate": 0.0008685594519832973,
      "loss": 5.035,
      "step": 2260
    },
    {
      "epoch": 0.25925925925925924,
      "grad_norm": 0.0,
      "learning_rate": 0.0008684339477877353,
      "loss": 5.2614,
      "step": 2261
    },
    {
      "epoch": 0.2593739250085999,
      "grad_norm": 0.0,
      "learning_rate": 0.0008683083927806297,
      "loss": 4.9359,
      "step": 2262
    },
    {
      "epoch": 0.2594885907579406,
      "grad_norm": 0.0,
      "learning_rate": 0.0008681827869792986,
      "loss": 5.1256,
      "step": 2263
    },
    {
      "epoch": 0.2596032565072813,
      "grad_norm": 0.0,
      "learning_rate": 0.0008680571304010665,
      "loss": 5.1452,
      "step": 2264
    },
    {
      "epoch": 0.25971792225662194,
      "grad_norm": 0.0,
      "learning_rate": 0.0008679314230632657,
      "loss": 5.1194,
      "step": 2265
    },
    {
      "epoch": 0.2598325880059626,
      "grad_norm": 0.0,
      "learning_rate": 0.0008678056649832351,
      "loss": 5.0714,
      "step": 2266
    },
    {
      "epoch": 0.2599472537553033,
      "grad_norm": 0.0,
      "learning_rate": 0.0008676798561783207,
      "loss": 4.898,
      "step": 2267
    },
    {
      "epoch": 0.26006191950464397,
      "grad_norm": 0.0,
      "learning_rate": 0.0008675539966658751,
      "loss": 4.8162,
      "step": 2268
    },
    {
      "epoch": 0.2601765852539846,
      "grad_norm": 0.0,
      "learning_rate": 0.0008674280864632586,
      "loss": 4.7264,
      "step": 2269
    },
    {
      "epoch": 0.2602912510033253,
      "grad_norm": 0.0,
      "learning_rate": 0.0008673021255878377,
      "loss": 5.0251,
      "step": 2270
    },
    {
      "epoch": 0.260405916752666,
      "grad_norm": 0.0,
      "learning_rate": 0.0008671761140569867,
      "loss": 4.9477,
      "step": 2271
    },
    {
      "epoch": 0.26052058250200666,
      "grad_norm": 0.0,
      "learning_rate": 0.0008670500518880862,
      "loss": 4.9624,
      "step": 2272
    },
    {
      "epoch": 0.2606352482513473,
      "grad_norm": 0.0,
      "learning_rate": 0.0008669239390985244,
      "loss": 5.1389,
      "step": 2273
    },
    {
      "epoch": 0.260749914000688,
      "grad_norm": 0.0,
      "learning_rate": 0.000866797775705696,
      "loss": 4.7443,
      "step": 2274
    },
    {
      "epoch": 0.2608645797500287,
      "grad_norm": 0.0,
      "learning_rate": 0.0008666715617270025,
      "loss": 5.062,
      "step": 2275
    },
    {
      "epoch": 0.26097924549936935,
      "grad_norm": 0.0,
      "learning_rate": 0.0008665452971798532,
      "loss": 4.9557,
      "step": 2276
    },
    {
      "epoch": 0.26109391124871,
      "grad_norm": 0.0,
      "learning_rate": 0.0008664189820816637,
      "loss": 4.7272,
      "step": 2277
    },
    {
      "epoch": 0.26120857699805067,
      "grad_norm": 0.0,
      "learning_rate": 0.0008662926164498567,
      "loss": 4.9269,
      "step": 2278
    },
    {
      "epoch": 0.2613232427473913,
      "grad_norm": 0.0,
      "learning_rate": 0.000866166200301862,
      "loss": 5.292,
      "step": 2279
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.0,
      "learning_rate": 0.0008660397336551161,
      "loss": 5.0845,
      "step": 2280
    },
    {
      "epoch": 0.2615525742460727,
      "grad_norm": 0.0,
      "learning_rate": 0.000865913216527063,
      "loss": 4.5863,
      "step": 2281
    },
    {
      "epoch": 0.26166723999541336,
      "grad_norm": 0.0,
      "learning_rate": 0.0008657866489351533,
      "loss": 5.1487,
      "step": 2282
    },
    {
      "epoch": 0.261781905744754,
      "grad_norm": 0.0,
      "learning_rate": 0.0008656600308968443,
      "loss": 5.0415,
      "step": 2283
    },
    {
      "epoch": 0.26189657149409473,
      "grad_norm": 0.0,
      "learning_rate": 0.0008655333624296007,
      "loss": 5.1513,
      "step": 2284
    },
    {
      "epoch": 0.2620112372434354,
      "grad_norm": 0.0,
      "learning_rate": 0.000865406643550894,
      "loss": 4.894,
      "step": 2285
    },
    {
      "epoch": 0.26212590299277605,
      "grad_norm": 0.0,
      "learning_rate": 0.0008652798742782026,
      "loss": 4.9429,
      "step": 2286
    },
    {
      "epoch": 0.2622405687421167,
      "grad_norm": 0.0,
      "learning_rate": 0.0008651530546290122,
      "loss": 5.0182,
      "step": 2287
    },
    {
      "epoch": 0.2623552344914574,
      "grad_norm": 0.0,
      "learning_rate": 0.0008650261846208146,
      "loss": 5.2205,
      "step": 2288
    },
    {
      "epoch": 0.2624699002407981,
      "grad_norm": 0.0,
      "learning_rate": 0.0008648992642711097,
      "loss": 4.9775,
      "step": 2289
    },
    {
      "epoch": 0.26258456599013874,
      "grad_norm": 0.0,
      "learning_rate": 0.0008647722935974032,
      "loss": 5.3381,
      "step": 2290
    },
    {
      "epoch": 0.2626992317394794,
      "grad_norm": 0.0,
      "learning_rate": 0.0008646452726172086,
      "loss": 4.9884,
      "step": 2291
    },
    {
      "epoch": 0.2628138974888201,
      "grad_norm": 0.0,
      "learning_rate": 0.0008645182013480461,
      "loss": 5.0338,
      "step": 2292
    },
    {
      "epoch": 0.2629285632381608,
      "grad_norm": 0.0,
      "learning_rate": 0.0008643910798074425,
      "loss": 4.9213,
      "step": 2293
    },
    {
      "epoch": 0.26304322898750143,
      "grad_norm": 0.0,
      "learning_rate": 0.0008642639080129318,
      "loss": 4.8698,
      "step": 2294
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 0.0,
      "learning_rate": 0.0008641366859820552,
      "loss": 5.0658,
      "step": 2295
    },
    {
      "epoch": 0.26327256048618275,
      "grad_norm": 0.0,
      "learning_rate": 0.0008640094137323604,
      "loss": 4.6381,
      "step": 2296
    },
    {
      "epoch": 0.26338722623552346,
      "grad_norm": 0.0,
      "learning_rate": 0.0008638820912814021,
      "loss": 4.901,
      "step": 2297
    },
    {
      "epoch": 0.2635018919848641,
      "grad_norm": 0.0,
      "learning_rate": 0.000863754718646742,
      "loss": 4.876,
      "step": 2298
    },
    {
      "epoch": 0.2636165577342048,
      "grad_norm": 0.0,
      "learning_rate": 0.000863627295845949,
      "loss": 4.96,
      "step": 2299
    },
    {
      "epoch": 0.26373122348354544,
      "grad_norm": 0.0,
      "learning_rate": 0.0008634998228965983,
      "loss": 5.2427,
      "step": 2300
    },
    {
      "epoch": 0.26384588923288615,
      "grad_norm": 0.0,
      "learning_rate": 0.0008633722998162727,
      "loss": 5.074,
      "step": 2301
    },
    {
      "epoch": 0.2639605549822268,
      "grad_norm": 0.0,
      "learning_rate": 0.0008632447266225613,
      "loss": 5.0504,
      "step": 2302
    },
    {
      "epoch": 0.2640752207315675,
      "grad_norm": 0.0,
      "learning_rate": 0.0008631171033330604,
      "loss": 4.8431,
      "step": 2303
    },
    {
      "epoch": 0.26418988648090813,
      "grad_norm": 0.0,
      "learning_rate": 0.0008629894299653733,
      "loss": 4.8415,
      "step": 2304
    },
    {
      "epoch": 0.26430455223024885,
      "grad_norm": 0.0,
      "learning_rate": 0.0008628617065371102,
      "loss": 5.1562,
      "step": 2305
    },
    {
      "epoch": 0.2644192179795895,
      "grad_norm": 0.0,
      "learning_rate": 0.000862733933065888,
      "loss": 5.1931,
      "step": 2306
    },
    {
      "epoch": 0.26453388372893016,
      "grad_norm": 0.0,
      "learning_rate": 0.0008626061095693305,
      "loss": 5.1288,
      "step": 2307
    },
    {
      "epoch": 0.2646485494782708,
      "grad_norm": 0.0,
      "learning_rate": 0.0008624782360650687,
      "loss": 4.974,
      "step": 2308
    },
    {
      "epoch": 0.26476321522761154,
      "grad_norm": 0.0,
      "learning_rate": 0.0008623503125707401,
      "loss": 4.7025,
      "step": 2309
    },
    {
      "epoch": 0.2648778809769522,
      "grad_norm": 0.0,
      "learning_rate": 0.0008622223391039897,
      "loss": 4.9911,
      "step": 2310
    },
    {
      "epoch": 0.26499254672629285,
      "grad_norm": 0.0,
      "learning_rate": 0.0008620943156824687,
      "loss": 5.0882,
      "step": 2311
    },
    {
      "epoch": 0.2651072124756335,
      "grad_norm": 0.0,
      "learning_rate": 0.0008619662423238355,
      "loss": 5.1547,
      "step": 2312
    },
    {
      "epoch": 0.26522187822497423,
      "grad_norm": 0.0,
      "learning_rate": 0.0008618381190457552,
      "loss": 4.9192,
      "step": 2313
    },
    {
      "epoch": 0.2653365439743149,
      "grad_norm": 0.0,
      "learning_rate": 0.0008617099458659006,
      "loss": 5.0732,
      "step": 2314
    },
    {
      "epoch": 0.26545120972365555,
      "grad_norm": 0.0,
      "learning_rate": 0.0008615817228019502,
      "loss": 4.8367,
      "step": 2315
    },
    {
      "epoch": 0.2655658754729962,
      "grad_norm": 0.0,
      "learning_rate": 0.0008614534498715898,
      "loss": 5.169,
      "step": 2316
    },
    {
      "epoch": 0.26568054122233686,
      "grad_norm": 0.0,
      "learning_rate": 0.0008613251270925128,
      "loss": 4.97,
      "step": 2317
    },
    {
      "epoch": 0.2657952069716776,
      "grad_norm": 0.0,
      "learning_rate": 0.0008611967544824183,
      "loss": 4.9506,
      "step": 2318
    },
    {
      "epoch": 0.26590987272101824,
      "grad_norm": 0.0,
      "learning_rate": 0.0008610683320590131,
      "loss": 4.9569,
      "step": 2319
    },
    {
      "epoch": 0.2660245384703589,
      "grad_norm": 0.0,
      "learning_rate": 0.0008609398598400108,
      "loss": 5.0448,
      "step": 2320
    },
    {
      "epoch": 0.26613920421969955,
      "grad_norm": 0.0,
      "learning_rate": 0.0008608113378431316,
      "loss": 4.8396,
      "step": 2321
    },
    {
      "epoch": 0.26625386996904027,
      "grad_norm": 0.0,
      "learning_rate": 0.0008606827660861023,
      "loss": 5.2079,
      "step": 2322
    },
    {
      "epoch": 0.2663685357183809,
      "grad_norm": 0.0,
      "learning_rate": 0.0008605541445866573,
      "loss": 4.9942,
      "step": 2323
    },
    {
      "epoch": 0.2664832014677216,
      "grad_norm": 0.0,
      "learning_rate": 0.0008604254733625375,
      "loss": 5.2868,
      "step": 2324
    },
    {
      "epoch": 0.26659786721706225,
      "grad_norm": 0.0,
      "learning_rate": 0.0008602967524314906,
      "loss": 5.0888,
      "step": 2325
    },
    {
      "epoch": 0.26671253296640296,
      "grad_norm": 0.0,
      "learning_rate": 0.0008601679818112709,
      "loss": 4.8885,
      "step": 2326
    },
    {
      "epoch": 0.2668271987157436,
      "grad_norm": 0.0,
      "learning_rate": 0.0008600391615196403,
      "loss": 5.0084,
      "step": 2327
    },
    {
      "epoch": 0.2669418644650843,
      "grad_norm": 0.0,
      "learning_rate": 0.0008599102915743666,
      "loss": 4.902,
      "step": 2328
    },
    {
      "epoch": 0.26705653021442494,
      "grad_norm": 0.0,
      "learning_rate": 0.0008597813719932255,
      "loss": 5.1879,
      "step": 2329
    },
    {
      "epoch": 0.26717119596376565,
      "grad_norm": 0.0,
      "learning_rate": 0.0008596524027939986,
      "loss": 5.0256,
      "step": 2330
    },
    {
      "epoch": 0.2672858617131063,
      "grad_norm": 0.0,
      "learning_rate": 0.0008595233839944748,
      "loss": 5.0412,
      "step": 2331
    },
    {
      "epoch": 0.26740052746244697,
      "grad_norm": 0.0,
      "learning_rate": 0.0008593943156124502,
      "loss": 4.9319,
      "step": 2332
    },
    {
      "epoch": 0.2675151932117876,
      "grad_norm": 0.0,
      "learning_rate": 0.0008592651976657267,
      "loss": 4.8857,
      "step": 2333
    },
    {
      "epoch": 0.2676298589611283,
      "grad_norm": 0.0,
      "learning_rate": 0.000859136030172114,
      "loss": 5.0554,
      "step": 2334
    },
    {
      "epoch": 0.267744524710469,
      "grad_norm": 0.0,
      "learning_rate": 0.0008590068131494282,
      "loss": 5.1332,
      "step": 2335
    },
    {
      "epoch": 0.26785919045980966,
      "grad_norm": 0.0,
      "learning_rate": 0.0008588775466154924,
      "loss": 5.1377,
      "step": 2336
    },
    {
      "epoch": 0.2679738562091503,
      "grad_norm": 0.0,
      "learning_rate": 0.0008587482305881365,
      "loss": 4.8168,
      "step": 2337
    },
    {
      "epoch": 0.268088521958491,
      "grad_norm": 0.0,
      "learning_rate": 0.000858618865085197,
      "loss": 5.0676,
      "step": 2338
    },
    {
      "epoch": 0.2682031877078317,
      "grad_norm": 0.0,
      "learning_rate": 0.0008584894501245177,
      "loss": 4.8653,
      "step": 2339
    },
    {
      "epoch": 0.26831785345717235,
      "grad_norm": 0.0,
      "learning_rate": 0.0008583599857239485,
      "loss": 4.7638,
      "step": 2340
    },
    {
      "epoch": 0.268432519206513,
      "grad_norm": 0.0,
      "learning_rate": 0.0008582304719013467,
      "loss": 5.0723,
      "step": 2341
    },
    {
      "epoch": 0.26854718495585367,
      "grad_norm": 0.0,
      "learning_rate": 0.0008581009086745767,
      "loss": 4.8441,
      "step": 2342
    },
    {
      "epoch": 0.2686618507051944,
      "grad_norm": 0.0,
      "learning_rate": 0.0008579712960615085,
      "loss": 5.1199,
      "step": 2343
    },
    {
      "epoch": 0.26877651645453504,
      "grad_norm": 0.0,
      "learning_rate": 0.0008578416340800205,
      "loss": 5.0481,
      "step": 2344
    },
    {
      "epoch": 0.2688911822038757,
      "grad_norm": 0.0,
      "learning_rate": 0.0008577119227479964,
      "loss": 5.0558,
      "step": 2345
    },
    {
      "epoch": 0.26900584795321636,
      "grad_norm": 0.0,
      "learning_rate": 0.000857582162083328,
      "loss": 5.1911,
      "step": 2346
    },
    {
      "epoch": 0.2691205137025571,
      "grad_norm": 0.0,
      "learning_rate": 0.0008574523521039128,
      "loss": 5.1154,
      "step": 2347
    },
    {
      "epoch": 0.26923517945189773,
      "grad_norm": 0.0,
      "learning_rate": 0.000857322492827656,
      "loss": 4.804,
      "step": 2348
    },
    {
      "epoch": 0.2693498452012384,
      "grad_norm": 0.0,
      "learning_rate": 0.0008571925842724688,
      "loss": 5.2426,
      "step": 2349
    },
    {
      "epoch": 0.26946451095057905,
      "grad_norm": 0.0,
      "learning_rate": 0.0008570626264562701,
      "loss": 5.1263,
      "step": 2350
    },
    {
      "epoch": 0.2695791766999197,
      "grad_norm": 0.0,
      "learning_rate": 0.0008569326193969848,
      "loss": 5.0224,
      "step": 2351
    },
    {
      "epoch": 0.2696938424492604,
      "grad_norm": 0.0,
      "learning_rate": 0.0008568025631125449,
      "loss": 4.9033,
      "step": 2352
    },
    {
      "epoch": 0.2698085081986011,
      "grad_norm": 0.0,
      "learning_rate": 0.0008566724576208894,
      "loss": 5.0857,
      "step": 2353
    },
    {
      "epoch": 0.26992317394794174,
      "grad_norm": 0.0,
      "learning_rate": 0.0008565423029399633,
      "loss": 5.0288,
      "step": 2354
    },
    {
      "epoch": 0.2700378396972824,
      "grad_norm": 0.0,
      "learning_rate": 0.0008564120990877198,
      "loss": 5.1502,
      "step": 2355
    },
    {
      "epoch": 0.2701525054466231,
      "grad_norm": 0.0,
      "learning_rate": 0.0008562818460821174,
      "loss": 5.1321,
      "step": 2356
    },
    {
      "epoch": 0.2702671711959638,
      "grad_norm": 0.0,
      "learning_rate": 0.0008561515439411224,
      "loss": 5.1446,
      "step": 2357
    },
    {
      "epoch": 0.27038183694530443,
      "grad_norm": 0.0,
      "learning_rate": 0.0008560211926827072,
      "loss": 4.9342,
      "step": 2358
    },
    {
      "epoch": 0.2704965026946451,
      "grad_norm": 0.0,
      "learning_rate": 0.0008558907923248514,
      "loss": 4.9959,
      "step": 2359
    },
    {
      "epoch": 0.2706111684439858,
      "grad_norm": 0.0,
      "learning_rate": 0.0008557603428855413,
      "loss": 5.0951,
      "step": 2360
    },
    {
      "epoch": 0.27072583419332646,
      "grad_norm": 0.0,
      "learning_rate": 0.0008556298443827698,
      "loss": 4.9861,
      "step": 2361
    },
    {
      "epoch": 0.2708404999426671,
      "grad_norm": 0.0,
      "learning_rate": 0.0008554992968345368,
      "loss": 5.0257,
      "step": 2362
    },
    {
      "epoch": 0.2709551656920078,
      "grad_norm": 0.0,
      "learning_rate": 0.0008553687002588486,
      "loss": 4.8303,
      "step": 2363
    },
    {
      "epoch": 0.2710698314413485,
      "grad_norm": 0.0,
      "learning_rate": 0.0008552380546737189,
      "loss": 5.125,
      "step": 2364
    },
    {
      "epoch": 0.27118449719068916,
      "grad_norm": 0.0,
      "learning_rate": 0.0008551073600971674,
      "loss": 5.047,
      "step": 2365
    },
    {
      "epoch": 0.2712991629400298,
      "grad_norm": 0.0,
      "learning_rate": 0.0008549766165472213,
      "loss": 5.0494,
      "step": 2366
    },
    {
      "epoch": 0.2714138286893705,
      "grad_norm": 0.0,
      "learning_rate": 0.0008548458240419138,
      "loss": 5.1309,
      "step": 2367
    },
    {
      "epoch": 0.27152849443871113,
      "grad_norm": 0.0,
      "learning_rate": 0.0008547149825992854,
      "loss": 5.0947,
      "step": 2368
    },
    {
      "epoch": 0.27164316018805185,
      "grad_norm": 0.0,
      "learning_rate": 0.0008545840922373832,
      "loss": 5.0073,
      "step": 2369
    },
    {
      "epoch": 0.2717578259373925,
      "grad_norm": 0.0,
      "learning_rate": 0.0008544531529742611,
      "loss": 4.8861,
      "step": 2370
    },
    {
      "epoch": 0.27187249168673316,
      "grad_norm": 0.0,
      "learning_rate": 0.0008543221648279794,
      "loss": 5.0778,
      "step": 2371
    },
    {
      "epoch": 0.2719871574360738,
      "grad_norm": 0.0,
      "learning_rate": 0.0008541911278166058,
      "loss": 4.847,
      "step": 2372
    },
    {
      "epoch": 0.27210182318541454,
      "grad_norm": 0.0,
      "learning_rate": 0.000854060041958214,
      "loss": 5.16,
      "step": 2373
    },
    {
      "epoch": 0.2722164889347552,
      "grad_norm": 0.0,
      "learning_rate": 0.000853928907270885,
      "loss": 4.9521,
      "step": 2374
    },
    {
      "epoch": 0.27233115468409586,
      "grad_norm": 0.0,
      "learning_rate": 0.0008537977237727064,
      "loss": 5.1848,
      "step": 2375
    },
    {
      "epoch": 0.2724458204334365,
      "grad_norm": 0.0,
      "learning_rate": 0.0008536664914817723,
      "loss": 4.6575,
      "step": 2376
    },
    {
      "epoch": 0.27256048618277723,
      "grad_norm": 0.0,
      "learning_rate": 0.0008535352104161836,
      "loss": 5.0319,
      "step": 2377
    },
    {
      "epoch": 0.2726751519321179,
      "grad_norm": 0.0,
      "learning_rate": 0.0008534038805940483,
      "loss": 5.2687,
      "step": 2378
    },
    {
      "epoch": 0.27278981768145855,
      "grad_norm": 0.0,
      "learning_rate": 0.0008532725020334806,
      "loss": 4.9063,
      "step": 2379
    },
    {
      "epoch": 0.2729044834307992,
      "grad_norm": 0.0,
      "learning_rate": 0.000853141074752602,
      "loss": 5.2497,
      "step": 2380
    },
    {
      "epoch": 0.2730191491801399,
      "grad_norm": 0.0,
      "learning_rate": 0.0008530095987695399,
      "loss": 4.6042,
      "step": 2381
    },
    {
      "epoch": 0.2731338149294806,
      "grad_norm": 0.0,
      "learning_rate": 0.0008528780741024293,
      "loss": 5.1885,
      "step": 2382
    },
    {
      "epoch": 0.27324848067882124,
      "grad_norm": 0.0,
      "learning_rate": 0.0008527465007694114,
      "loss": 4.8319,
      "step": 2383
    },
    {
      "epoch": 0.2733631464281619,
      "grad_norm": 0.0,
      "learning_rate": 0.0008526148787886343,
      "loss": 5.1412,
      "step": 2384
    },
    {
      "epoch": 0.27347781217750256,
      "grad_norm": 0.0,
      "learning_rate": 0.0008524832081782525,
      "loss": 4.9675,
      "step": 2385
    },
    {
      "epoch": 0.27359247792684327,
      "grad_norm": 0.0,
      "learning_rate": 0.0008523514889564278,
      "loss": 4.8594,
      "step": 2386
    },
    {
      "epoch": 0.27370714367618393,
      "grad_norm": 0.0,
      "learning_rate": 0.0008522197211413281,
      "loss": 4.9198,
      "step": 2387
    },
    {
      "epoch": 0.2738218094255246,
      "grad_norm": 0.0,
      "learning_rate": 0.0008520879047511281,
      "loss": 5.0329,
      "step": 2388
    },
    {
      "epoch": 0.27393647517486525,
      "grad_norm": 0.0,
      "learning_rate": 0.00085195603980401,
      "loss": 5.0855,
      "step": 2389
    },
    {
      "epoch": 0.27405114092420596,
      "grad_norm": 0.0,
      "learning_rate": 0.0008518241263181614,
      "loss": 4.9618,
      "step": 2390
    },
    {
      "epoch": 0.2741658066735466,
      "grad_norm": 0.0,
      "learning_rate": 0.0008516921643117775,
      "loss": 4.7114,
      "step": 2391
    },
    {
      "epoch": 0.2742804724228873,
      "grad_norm": 0.0,
      "learning_rate": 0.00085156015380306,
      "loss": 5.084,
      "step": 2392
    },
    {
      "epoch": 0.27439513817222794,
      "grad_norm": 0.0,
      "learning_rate": 0.0008514280948102172,
      "loss": 5.0865,
      "step": 2393
    },
    {
      "epoch": 0.27450980392156865,
      "grad_norm": 0.0,
      "learning_rate": 0.0008512959873514642,
      "loss": 4.9965,
      "step": 2394
    },
    {
      "epoch": 0.2746244696709093,
      "grad_norm": 0.0,
      "learning_rate": 0.0008511638314450224,
      "loss": 4.7665,
      "step": 2395
    },
    {
      "epoch": 0.27473913542024997,
      "grad_norm": 0.0,
      "learning_rate": 0.0008510316271091204,
      "loss": 4.9505,
      "step": 2396
    },
    {
      "epoch": 0.27485380116959063,
      "grad_norm": 0.0,
      "learning_rate": 0.0008508993743619932,
      "loss": 5.1433,
      "step": 2397
    },
    {
      "epoch": 0.27496846691893134,
      "grad_norm": 0.0,
      "learning_rate": 0.0008507670732218829,
      "loss": 4.9154,
      "step": 2398
    },
    {
      "epoch": 0.275083132668272,
      "grad_norm": 0.0,
      "learning_rate": 0.0008506347237070374,
      "loss": 4.9433,
      "step": 2399
    },
    {
      "epoch": 0.27519779841761266,
      "grad_norm": 0.0,
      "learning_rate": 0.0008505023258357121,
      "loss": 5.1507,
      "step": 2400
    },
    {
      "epoch": 0.2753124641669533,
      "grad_norm": 0.0,
      "learning_rate": 0.0008503698796261686,
      "loss": 5.2156,
      "step": 2401
    },
    {
      "epoch": 0.275427129916294,
      "grad_norm": 0.0,
      "learning_rate": 0.0008502373850966755,
      "loss": 4.8802,
      "step": 2402
    },
    {
      "epoch": 0.2755417956656347,
      "grad_norm": 0.0,
      "learning_rate": 0.0008501048422655076,
      "loss": 5.0412,
      "step": 2403
    },
    {
      "epoch": 0.27565646141497535,
      "grad_norm": 0.0,
      "learning_rate": 0.0008499722511509471,
      "loss": 4.8057,
      "step": 2404
    },
    {
      "epoch": 0.275771127164316,
      "grad_norm": 0.0,
      "learning_rate": 0.0008498396117712822,
      "loss": 5.0466,
      "step": 2405
    },
    {
      "epoch": 0.27588579291365667,
      "grad_norm": 0.0,
      "learning_rate": 0.0008497069241448078,
      "loss": 5.1323,
      "step": 2406
    },
    {
      "epoch": 0.2760004586629974,
      "grad_norm": 0.0,
      "learning_rate": 0.0008495741882898259,
      "loss": 4.973,
      "step": 2407
    },
    {
      "epoch": 0.27611512441233804,
      "grad_norm": 0.0,
      "learning_rate": 0.0008494414042246447,
      "loss": 5.056,
      "step": 2408
    },
    {
      "epoch": 0.2762297901616787,
      "grad_norm": 0.0,
      "learning_rate": 0.0008493085719675793,
      "loss": 5.319,
      "step": 2409
    },
    {
      "epoch": 0.27634445591101936,
      "grad_norm": 0.0,
      "learning_rate": 0.0008491756915369513,
      "loss": 5.094,
      "step": 2410
    },
    {
      "epoch": 0.2764591216603601,
      "grad_norm": 0.0,
      "learning_rate": 0.0008490427629510892,
      "loss": 4.9916,
      "step": 2411
    },
    {
      "epoch": 0.27657378740970073,
      "grad_norm": 0.0,
      "learning_rate": 0.0008489097862283278,
      "loss": 4.9739,
      "step": 2412
    },
    {
      "epoch": 0.2766884531590414,
      "grad_norm": 0.0,
      "learning_rate": 0.0008487767613870088,
      "loss": 5.3031,
      "step": 2413
    },
    {
      "epoch": 0.27680311890838205,
      "grad_norm": 0.0,
      "learning_rate": 0.0008486436884454804,
      "loss": 5.0695,
      "step": 2414
    },
    {
      "epoch": 0.27691778465772277,
      "grad_norm": 0.0,
      "learning_rate": 0.0008485105674220973,
      "loss": 4.9779,
      "step": 2415
    },
    {
      "epoch": 0.2770324504070634,
      "grad_norm": 0.0,
      "learning_rate": 0.0008483773983352215,
      "loss": 4.9514,
      "step": 2416
    },
    {
      "epoch": 0.2771471161564041,
      "grad_norm": 0.0,
      "learning_rate": 0.0008482441812032207,
      "loss": 5.1367,
      "step": 2417
    },
    {
      "epoch": 0.27726178190574474,
      "grad_norm": 0.0,
      "learning_rate": 0.0008481109160444697,
      "loss": 5.2404,
      "step": 2418
    },
    {
      "epoch": 0.2773764476550854,
      "grad_norm": 0.0,
      "learning_rate": 0.00084797760287735,
      "loss": 5.0168,
      "step": 2419
    },
    {
      "epoch": 0.2774911134044261,
      "grad_norm": 0.0,
      "learning_rate": 0.0008478442417202497,
      "loss": 5.0176,
      "step": 2420
    },
    {
      "epoch": 0.2776057791537668,
      "grad_norm": 0.0,
      "learning_rate": 0.0008477108325915631,
      "loss": 5.1703,
      "step": 2421
    },
    {
      "epoch": 0.27772044490310743,
      "grad_norm": 0.0,
      "learning_rate": 0.000847577375509692,
      "loss": 5.0273,
      "step": 2422
    },
    {
      "epoch": 0.2778351106524481,
      "grad_norm": 0.0,
      "learning_rate": 0.0008474438704930436,
      "loss": 4.8649,
      "step": 2423
    },
    {
      "epoch": 0.2779497764017888,
      "grad_norm": 0.0,
      "learning_rate": 0.0008473103175600328,
      "loss": 5.2985,
      "step": 2424
    },
    {
      "epoch": 0.27806444215112947,
      "grad_norm": 0.0,
      "learning_rate": 0.0008471767167290805,
      "loss": 5.2188,
      "step": 2425
    },
    {
      "epoch": 0.2781791079004701,
      "grad_norm": 0.0,
      "learning_rate": 0.0008470430680186146,
      "loss": 4.8976,
      "step": 2426
    },
    {
      "epoch": 0.2782937736498108,
      "grad_norm": 0.0,
      "learning_rate": 0.0008469093714470694,
      "loss": 5.0856,
      "step": 2427
    },
    {
      "epoch": 0.2784084393991515,
      "grad_norm": 0.0,
      "learning_rate": 0.0008467756270328854,
      "loss": 5.1824,
      "step": 2428
    },
    {
      "epoch": 0.27852310514849216,
      "grad_norm": 0.0,
      "learning_rate": 0.0008466418347945104,
      "loss": 4.9677,
      "step": 2429
    },
    {
      "epoch": 0.2786377708978328,
      "grad_norm": 0.0,
      "learning_rate": 0.0008465079947503985,
      "loss": 4.9411,
      "step": 2430
    },
    {
      "epoch": 0.2787524366471735,
      "grad_norm": 0.0,
      "learning_rate": 0.0008463741069190102,
      "loss": 5.0554,
      "step": 2431
    },
    {
      "epoch": 0.2788671023965142,
      "grad_norm": 0.0,
      "learning_rate": 0.0008462401713188129,
      "loss": 4.9504,
      "step": 2432
    },
    {
      "epoch": 0.27898176814585485,
      "grad_norm": 0.0,
      "learning_rate": 0.0008461061879682806,
      "loss": 5.1271,
      "step": 2433
    },
    {
      "epoch": 0.2790964338951955,
      "grad_norm": 0.0,
      "learning_rate": 0.0008459721568858934,
      "loss": 5.0413,
      "step": 2434
    },
    {
      "epoch": 0.27921109964453616,
      "grad_norm": 0.0,
      "learning_rate": 0.0008458380780901386,
      "loss": 5.159,
      "step": 2435
    },
    {
      "epoch": 0.2793257653938768,
      "grad_norm": 0.0,
      "learning_rate": 0.0008457039515995099,
      "loss": 4.9025,
      "step": 2436
    },
    {
      "epoch": 0.27944043114321754,
      "grad_norm": 0.0,
      "learning_rate": 0.0008455697774325072,
      "loss": 5.0345,
      "step": 2437
    },
    {
      "epoch": 0.2795550968925582,
      "grad_norm": 0.0,
      "learning_rate": 0.0008454355556076374,
      "loss": 4.9375,
      "step": 2438
    },
    {
      "epoch": 0.27966976264189886,
      "grad_norm": 0.0,
      "learning_rate": 0.0008453012861434139,
      "loss": 5.2011,
      "step": 2439
    },
    {
      "epoch": 0.2797844283912395,
      "grad_norm": 0.0,
      "learning_rate": 0.0008451669690583564,
      "loss": 5.2156,
      "step": 2440
    },
    {
      "epoch": 0.27989909414058023,
      "grad_norm": 0.0,
      "learning_rate": 0.0008450326043709917,
      "loss": 5.2054,
      "step": 2441
    },
    {
      "epoch": 0.2800137598899209,
      "grad_norm": 0.0,
      "learning_rate": 0.0008448981920998527,
      "loss": 4.7779,
      "step": 2442
    },
    {
      "epoch": 0.28012842563926155,
      "grad_norm": 0.0,
      "learning_rate": 0.000844763732263479,
      "loss": 4.7673,
      "step": 2443
    },
    {
      "epoch": 0.2802430913886022,
      "grad_norm": 0.0,
      "learning_rate": 0.0008446292248804168,
      "loss": 5.1056,
      "step": 2444
    },
    {
      "epoch": 0.2803577571379429,
      "grad_norm": 0.0,
      "learning_rate": 0.0008444946699692188,
      "loss": 4.896,
      "step": 2445
    },
    {
      "epoch": 0.2804724228872836,
      "grad_norm": 0.0,
      "learning_rate": 0.0008443600675484441,
      "loss": 4.8172,
      "step": 2446
    },
    {
      "epoch": 0.28058708863662424,
      "grad_norm": 0.0,
      "learning_rate": 0.000844225417636659,
      "loss": 4.9421,
      "step": 2447
    },
    {
      "epoch": 0.2807017543859649,
      "grad_norm": 0.0,
      "learning_rate": 0.0008440907202524356,
      "loss": 5.1084,
      "step": 2448
    },
    {
      "epoch": 0.2808164201353056,
      "grad_norm": 0.0,
      "learning_rate": 0.0008439559754143527,
      "loss": 4.8467,
      "step": 2449
    },
    {
      "epoch": 0.28093108588464627,
      "grad_norm": 0.0,
      "learning_rate": 0.000843821183140996,
      "loss": 4.893,
      "step": 2450
    },
    {
      "epoch": 0.28104575163398693,
      "grad_norm": 0.0,
      "learning_rate": 0.0008436863434509574,
      "loss": 5.1992,
      "step": 2451
    },
    {
      "epoch": 0.2811604173833276,
      "grad_norm": 0.0,
      "learning_rate": 0.0008435514563628357,
      "loss": 5.0647,
      "step": 2452
    },
    {
      "epoch": 0.28127508313266825,
      "grad_norm": 0.0,
      "learning_rate": 0.0008434165218952355,
      "loss": 4.8286,
      "step": 2453
    },
    {
      "epoch": 0.28138974888200896,
      "grad_norm": 0.0,
      "learning_rate": 0.0008432815400667691,
      "loss": 5.1244,
      "step": 2454
    },
    {
      "epoch": 0.2815044146313496,
      "grad_norm": 0.0,
      "learning_rate": 0.0008431465108960542,
      "loss": 4.9478,
      "step": 2455
    },
    {
      "epoch": 0.2816190803806903,
      "grad_norm": 0.0,
      "learning_rate": 0.0008430114344017156,
      "loss": 4.8232,
      "step": 2456
    },
    {
      "epoch": 0.28173374613003094,
      "grad_norm": 0.0,
      "learning_rate": 0.0008428763106023846,
      "loss": 5.145,
      "step": 2457
    },
    {
      "epoch": 0.28184841187937165,
      "grad_norm": 0.0,
      "learning_rate": 0.000842741139516699,
      "loss": 4.9005,
      "step": 2458
    },
    {
      "epoch": 0.2819630776287123,
      "grad_norm": 0.0,
      "learning_rate": 0.0008426059211633029,
      "loss": 4.8658,
      "step": 2459
    },
    {
      "epoch": 0.28207774337805297,
      "grad_norm": 0.0,
      "learning_rate": 0.0008424706555608473,
      "loss": 5.0785,
      "step": 2460
    },
    {
      "epoch": 0.28219240912739363,
      "grad_norm": 0.0,
      "learning_rate": 0.0008423353427279892,
      "loss": 5.16,
      "step": 2461
    },
    {
      "epoch": 0.28230707487673434,
      "grad_norm": 0.0,
      "learning_rate": 0.0008421999826833928,
      "loss": 4.8569,
      "step": 2462
    },
    {
      "epoch": 0.282421740626075,
      "grad_norm": 0.0,
      "learning_rate": 0.0008420645754457281,
      "loss": 4.7801,
      "step": 2463
    },
    {
      "epoch": 0.28253640637541566,
      "grad_norm": 0.0,
      "learning_rate": 0.0008419291210336723,
      "loss": 4.6728,
      "step": 2464
    },
    {
      "epoch": 0.2826510721247563,
      "grad_norm": 0.0,
      "learning_rate": 0.0008417936194659082,
      "loss": 4.9853,
      "step": 2465
    },
    {
      "epoch": 0.28276573787409703,
      "grad_norm": 0.0,
      "learning_rate": 0.0008416580707611265,
      "loss": 5.0966,
      "step": 2466
    },
    {
      "epoch": 0.2828804036234377,
      "grad_norm": 0.0,
      "learning_rate": 0.0008415224749380227,
      "loss": 5.1222,
      "step": 2467
    },
    {
      "epoch": 0.28299506937277835,
      "grad_norm": 0.0,
      "learning_rate": 0.0008413868320153003,
      "loss": 5.1507,
      "step": 2468
    },
    {
      "epoch": 0.283109735122119,
      "grad_norm": 0.0,
      "learning_rate": 0.0008412511420116683,
      "loss": 5.0332,
      "step": 2469
    },
    {
      "epoch": 0.28322440087145967,
      "grad_norm": 0.0,
      "learning_rate": 0.0008411154049458426,
      "loss": 4.9687,
      "step": 2470
    },
    {
      "epoch": 0.2833390666208004,
      "grad_norm": 0.0,
      "learning_rate": 0.0008409796208365456,
      "loss": 5.0124,
      "step": 2471
    },
    {
      "epoch": 0.28345373237014104,
      "grad_norm": 0.0,
      "learning_rate": 0.0008408437897025062,
      "loss": 5.0273,
      "step": 2472
    },
    {
      "epoch": 0.2835683981194817,
      "grad_norm": 0.0,
      "learning_rate": 0.0008407079115624595,
      "loss": 5.1572,
      "step": 2473
    },
    {
      "epoch": 0.28368306386882236,
      "grad_norm": 0.0,
      "learning_rate": 0.0008405719864351477,
      "loss": 4.9515,
      "step": 2474
    },
    {
      "epoch": 0.2837977296181631,
      "grad_norm": 0.0,
      "learning_rate": 0.0008404360143393185,
      "loss": 4.9849,
      "step": 2475
    },
    {
      "epoch": 0.28391239536750373,
      "grad_norm": 0.0,
      "learning_rate": 0.0008402999952937271,
      "loss": 4.8772,
      "step": 2476
    },
    {
      "epoch": 0.2840270611168444,
      "grad_norm": 0.0,
      "learning_rate": 0.0008401639293171346,
      "loss": 5.0907,
      "step": 2477
    },
    {
      "epoch": 0.28414172686618505,
      "grad_norm": 0.0,
      "learning_rate": 0.0008400278164283088,
      "loss": 4.9522,
      "step": 2478
    },
    {
      "epoch": 0.28425639261552577,
      "grad_norm": 0.0,
      "learning_rate": 0.0008398916566460234,
      "loss": 4.9086,
      "step": 2479
    },
    {
      "epoch": 0.2843710583648664,
      "grad_norm": 0.0,
      "learning_rate": 0.00083975544998906,
      "loss": 5.0672,
      "step": 2480
    },
    {
      "epoch": 0.2844857241142071,
      "grad_norm": 0.0,
      "learning_rate": 0.0008396191964762047,
      "loss": 5.1971,
      "step": 2481
    },
    {
      "epoch": 0.28460038986354774,
      "grad_norm": 0.0,
      "learning_rate": 0.0008394828961262518,
      "loss": 5.0036,
      "step": 2482
    },
    {
      "epoch": 0.28471505561288846,
      "grad_norm": 0.0,
      "learning_rate": 0.0008393465489580008,
      "loss": 5.0781,
      "step": 2483
    },
    {
      "epoch": 0.2848297213622291,
      "grad_norm": 0.0,
      "learning_rate": 0.0008392101549902586,
      "loss": 4.944,
      "step": 2484
    },
    {
      "epoch": 0.2849443871115698,
      "grad_norm": 0.0,
      "learning_rate": 0.0008390737142418381,
      "loss": 4.9798,
      "step": 2485
    },
    {
      "epoch": 0.28505905286091043,
      "grad_norm": 0.0,
      "learning_rate": 0.0008389372267315585,
      "loss": 4.6758,
      "step": 2486
    },
    {
      "epoch": 0.2851737186102511,
      "grad_norm": 0.0,
      "learning_rate": 0.0008388006924782456,
      "loss": 4.9098,
      "step": 2487
    },
    {
      "epoch": 0.2852883843595918,
      "grad_norm": 0.0,
      "learning_rate": 0.0008386641115007323,
      "loss": 4.8667,
      "step": 2488
    },
    {
      "epoch": 0.28540305010893247,
      "grad_norm": 0.0,
      "learning_rate": 0.0008385274838178565,
      "loss": 5.0251,
      "step": 2489
    },
    {
      "epoch": 0.2855177158582731,
      "grad_norm": 0.0,
      "learning_rate": 0.0008383908094484638,
      "loss": 5.0774,
      "step": 2490
    },
    {
      "epoch": 0.2856323816076138,
      "grad_norm": 0.0,
      "learning_rate": 0.0008382540884114059,
      "loss": 5.1128,
      "step": 2491
    },
    {
      "epoch": 0.2857470473569545,
      "grad_norm": 0.0,
      "learning_rate": 0.0008381173207255407,
      "loss": 5.2341,
      "step": 2492
    },
    {
      "epoch": 0.28586171310629516,
      "grad_norm": 0.0,
      "learning_rate": 0.0008379805064097328,
      "loss": 5.2915,
      "step": 2493
    },
    {
      "epoch": 0.2859763788556358,
      "grad_norm": 0.0,
      "learning_rate": 0.000837843645482853,
      "loss": 5.1197,
      "step": 2494
    },
    {
      "epoch": 0.2860910446049765,
      "grad_norm": 0.0,
      "learning_rate": 0.000837706737963779,
      "loss": 4.8715,
      "step": 2495
    },
    {
      "epoch": 0.2862057103543172,
      "grad_norm": 0.0,
      "learning_rate": 0.000837569783871394,
      "loss": 5.0481,
      "step": 2496
    },
    {
      "epoch": 0.28632037610365785,
      "grad_norm": 0.0,
      "learning_rate": 0.0008374327832245887,
      "loss": 4.8953,
      "step": 2497
    },
    {
      "epoch": 0.2864350418529985,
      "grad_norm": 0.0,
      "learning_rate": 0.0008372957360422594,
      "loss": 5.2429,
      "step": 2498
    },
    {
      "epoch": 0.28654970760233917,
      "grad_norm": 0.0,
      "learning_rate": 0.0008371586423433095,
      "loss": 5.2445,
      "step": 2499
    },
    {
      "epoch": 0.2866643733516799,
      "grad_norm": 0.0,
      "learning_rate": 0.0008370215021466482,
      "loss": 4.836,
      "step": 2500
    },
    {
      "epoch": 0.28677903910102054,
      "grad_norm": 0.0,
      "learning_rate": 0.0008368843154711915,
      "loss": 5.1582,
      "step": 2501
    },
    {
      "epoch": 0.2868937048503612,
      "grad_norm": 0.0,
      "learning_rate": 0.0008367470823358614,
      "loss": 5.1834,
      "step": 2502
    },
    {
      "epoch": 0.28700837059970186,
      "grad_norm": 0.0,
      "learning_rate": 0.000836609802759587,
      "loss": 5.2554,
      "step": 2503
    },
    {
      "epoch": 0.2871230363490425,
      "grad_norm": 0.0,
      "learning_rate": 0.0008364724767613031,
      "loss": 4.9077,
      "step": 2504
    },
    {
      "epoch": 0.28723770209838323,
      "grad_norm": 0.0,
      "learning_rate": 0.0008363351043599516,
      "loss": 5.1234,
      "step": 2505
    },
    {
      "epoch": 0.2873523678477239,
      "grad_norm": 0.0,
      "learning_rate": 0.0008361976855744797,
      "loss": 5.1294,
      "step": 2506
    },
    {
      "epoch": 0.28746703359706455,
      "grad_norm": 0.0,
      "learning_rate": 0.0008360602204238425,
      "loss": 4.9155,
      "step": 2507
    },
    {
      "epoch": 0.2875816993464052,
      "grad_norm": 0.0,
      "learning_rate": 0.0008359227089270003,
      "loss": 4.8769,
      "step": 2508
    },
    {
      "epoch": 0.2876963650957459,
      "grad_norm": 0.0,
      "learning_rate": 0.00083578515110292,
      "loss": 4.863,
      "step": 2509
    },
    {
      "epoch": 0.2878110308450866,
      "grad_norm": 0.0,
      "learning_rate": 0.0008356475469705755,
      "loss": 5.1351,
      "step": 2510
    },
    {
      "epoch": 0.28792569659442724,
      "grad_norm": 0.0,
      "learning_rate": 0.0008355098965489464,
      "loss": 4.9574,
      "step": 2511
    },
    {
      "epoch": 0.2880403623437679,
      "grad_norm": 0.0,
      "learning_rate": 0.0008353721998570191,
      "loss": 4.9844,
      "step": 2512
    },
    {
      "epoch": 0.2881550280931086,
      "grad_norm": 0.0,
      "learning_rate": 0.000835234456913786,
      "loss": 4.9989,
      "step": 2513
    },
    {
      "epoch": 0.28826969384244927,
      "grad_norm": 0.0,
      "learning_rate": 0.0008350966677382463,
      "loss": 5.0491,
      "step": 2514
    },
    {
      "epoch": 0.28838435959178993,
      "grad_norm": 0.0,
      "learning_rate": 0.0008349588323494054,
      "loss": 4.7886,
      "step": 2515
    },
    {
      "epoch": 0.2884990253411306,
      "grad_norm": 0.0,
      "learning_rate": 0.000834820950766275,
      "loss": 4.8767,
      "step": 2516
    },
    {
      "epoch": 0.2886136910904713,
      "grad_norm": 0.0,
      "learning_rate": 0.0008346830230078733,
      "loss": 4.956,
      "step": 2517
    },
    {
      "epoch": 0.28872835683981196,
      "grad_norm": 0.0,
      "learning_rate": 0.0008345450490932247,
      "loss": 5.1265,
      "step": 2518
    },
    {
      "epoch": 0.2888430225891526,
      "grad_norm": 0.0,
      "learning_rate": 0.0008344070290413601,
      "loss": 4.8653,
      "step": 2519
    },
    {
      "epoch": 0.2889576883384933,
      "grad_norm": 0.0,
      "learning_rate": 0.0008342689628713168,
      "loss": 4.8884,
      "step": 2520
    },
    {
      "epoch": 0.28907235408783394,
      "grad_norm": 0.0,
      "learning_rate": 0.0008341308506021384,
      "loss": 4.8767,
      "step": 2521
    },
    {
      "epoch": 0.28918701983717465,
      "grad_norm": 0.0,
      "learning_rate": 0.0008339926922528749,
      "loss": 4.8286,
      "step": 2522
    },
    {
      "epoch": 0.2893016855865153,
      "grad_norm": 0.0,
      "learning_rate": 0.0008338544878425825,
      "loss": 4.9577,
      "step": 2523
    },
    {
      "epoch": 0.28941635133585597,
      "grad_norm": 0.0,
      "learning_rate": 0.0008337162373903237,
      "loss": 4.8525,
      "step": 2524
    },
    {
      "epoch": 0.28953101708519663,
      "grad_norm": 0.0,
      "learning_rate": 0.0008335779409151679,
      "loss": 5.1878,
      "step": 2525
    },
    {
      "epoch": 0.28964568283453734,
      "grad_norm": 0.0,
      "learning_rate": 0.0008334395984361901,
      "loss": 4.8389,
      "step": 2526
    },
    {
      "epoch": 0.289760348583878,
      "grad_norm": 0.0,
      "learning_rate": 0.0008333012099724724,
      "loss": 5.0971,
      "step": 2527
    },
    {
      "epoch": 0.28987501433321866,
      "grad_norm": 0.0,
      "learning_rate": 0.0008331627755431025,
      "loss": 4.9317,
      "step": 2528
    },
    {
      "epoch": 0.2899896800825593,
      "grad_norm": 0.0,
      "learning_rate": 0.000833024295167175,
      "loss": 5.0499,
      "step": 2529
    },
    {
      "epoch": 0.29010434583190003,
      "grad_norm": 0.0,
      "learning_rate": 0.0008328857688637906,
      "loss": 5.1238,
      "step": 2530
    },
    {
      "epoch": 0.2902190115812407,
      "grad_norm": 0.0,
      "learning_rate": 0.0008327471966520561,
      "loss": 4.9384,
      "step": 2531
    },
    {
      "epoch": 0.29033367733058135,
      "grad_norm": 0.0,
      "learning_rate": 0.0008326085785510852,
      "loss": 4.8475,
      "step": 2532
    },
    {
      "epoch": 0.290448343079922,
      "grad_norm": 0.0,
      "learning_rate": 0.0008324699145799975,
      "loss": 5.2886,
      "step": 2533
    },
    {
      "epoch": 0.2905630088292627,
      "grad_norm": 0.0,
      "learning_rate": 0.0008323312047579192,
      "loss": 5.0659,
      "step": 2534
    },
    {
      "epoch": 0.2906776745786034,
      "grad_norm": 0.0,
      "learning_rate": 0.0008321924491039823,
      "loss": 4.9754,
      "step": 2535
    },
    {
      "epoch": 0.29079234032794404,
      "grad_norm": 0.0,
      "learning_rate": 0.0008320536476373261,
      "loss": 5.0833,
      "step": 2536
    },
    {
      "epoch": 0.2909070060772847,
      "grad_norm": 0.0,
      "learning_rate": 0.0008319148003770952,
      "loss": 5.0334,
      "step": 2537
    },
    {
      "epoch": 0.29102167182662536,
      "grad_norm": 0.0,
      "learning_rate": 0.0008317759073424409,
      "loss": 4.9386,
      "step": 2538
    },
    {
      "epoch": 0.2911363375759661,
      "grad_norm": 0.0,
      "learning_rate": 0.0008316369685525209,
      "loss": 4.965,
      "step": 2539
    },
    {
      "epoch": 0.29125100332530673,
      "grad_norm": 0.0,
      "learning_rate": 0.0008314979840264993,
      "loss": 4.8738,
      "step": 2540
    },
    {
      "epoch": 0.2913656690746474,
      "grad_norm": 0.0,
      "learning_rate": 0.0008313589537835463,
      "loss": 5.1287,
      "step": 2541
    },
    {
      "epoch": 0.29148033482398805,
      "grad_norm": 0.0,
      "learning_rate": 0.0008312198778428385,
      "loss": 5.0118,
      "step": 2542
    },
    {
      "epoch": 0.29159500057332877,
      "grad_norm": 0.0,
      "learning_rate": 0.0008310807562235586,
      "loss": 5.0546,
      "step": 2543
    },
    {
      "epoch": 0.2917096663226694,
      "grad_norm": 0.0,
      "learning_rate": 0.0008309415889448959,
      "loss": 4.9922,
      "step": 2544
    },
    {
      "epoch": 0.2918243320720101,
      "grad_norm": 0.0,
      "learning_rate": 0.0008308023760260459,
      "loss": 4.9933,
      "step": 2545
    },
    {
      "epoch": 0.29193899782135074,
      "grad_norm": 0.0,
      "learning_rate": 0.0008306631174862105,
      "loss": 4.8068,
      "step": 2546
    },
    {
      "epoch": 0.29205366357069146,
      "grad_norm": 0.0,
      "learning_rate": 0.0008305238133445974,
      "loss": 4.9089,
      "step": 2547
    },
    {
      "epoch": 0.2921683293200321,
      "grad_norm": 0.0,
      "learning_rate": 0.0008303844636204211,
      "loss": 5.2633,
      "step": 2548
    },
    {
      "epoch": 0.2922829950693728,
      "grad_norm": 0.0,
      "learning_rate": 0.0008302450683329025,
      "loss": 4.9074,
      "step": 2549
    },
    {
      "epoch": 0.29239766081871343,
      "grad_norm": 0.0,
      "learning_rate": 0.0008301056275012683,
      "loss": 4.9544,
      "step": 2550
    },
    {
      "epoch": 0.29251232656805415,
      "grad_norm": 0.0,
      "learning_rate": 0.0008299661411447514,
      "loss": 5.0446,
      "step": 2551
    },
    {
      "epoch": 0.2926269923173948,
      "grad_norm": 0.0,
      "learning_rate": 0.0008298266092825919,
      "loss": 4.8429,
      "step": 2552
    },
    {
      "epoch": 0.29274165806673547,
      "grad_norm": 0.0,
      "learning_rate": 0.0008296870319340352,
      "loss": 5.1243,
      "step": 2553
    },
    {
      "epoch": 0.2928563238160761,
      "grad_norm": 0.0,
      "learning_rate": 0.0008295474091183335,
      "loss": 4.9867,
      "step": 2554
    },
    {
      "epoch": 0.2929709895654168,
      "grad_norm": 0.0,
      "learning_rate": 0.0008294077408547448,
      "loss": 4.9707,
      "step": 2555
    },
    {
      "epoch": 0.2930856553147575,
      "grad_norm": 0.0,
      "learning_rate": 0.000829268027162534,
      "loss": 5.0536,
      "step": 2556
    },
    {
      "epoch": 0.29320032106409816,
      "grad_norm": 0.0,
      "learning_rate": 0.0008291282680609718,
      "loss": 4.9698,
      "step": 2557
    },
    {
      "epoch": 0.2933149868134388,
      "grad_norm": 0.0,
      "learning_rate": 0.0008289884635693353,
      "loss": 5.0653,
      "step": 2558
    },
    {
      "epoch": 0.2934296525627795,
      "grad_norm": 0.0,
      "learning_rate": 0.000828848613706908,
      "loss": 4.9335,
      "step": 2559
    },
    {
      "epoch": 0.2935443183121202,
      "grad_norm": 0.0,
      "learning_rate": 0.0008287087184929792,
      "loss": 5.0412,
      "step": 2560
    },
    {
      "epoch": 0.29365898406146085,
      "grad_norm": 0.0,
      "learning_rate": 0.0008285687779468453,
      "loss": 4.8823,
      "step": 2561
    },
    {
      "epoch": 0.2937736498108015,
      "grad_norm": 0.0,
      "learning_rate": 0.0008284287920878079,
      "loss": 5.1871,
      "step": 2562
    },
    {
      "epoch": 0.29388831556014217,
      "grad_norm": 0.0,
      "learning_rate": 0.0008282887609351757,
      "loss": 5.0563,
      "step": 2563
    },
    {
      "epoch": 0.2940029813094829,
      "grad_norm": 0.0,
      "learning_rate": 0.0008281486845082631,
      "loss": 5.3503,
      "step": 2564
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.0,
      "learning_rate": 0.0008280085628263912,
      "loss": 4.9981,
      "step": 2565
    },
    {
      "epoch": 0.2942323128081642,
      "grad_norm": 0.0,
      "learning_rate": 0.000827868395908887,
      "loss": 5.1306,
      "step": 2566
    },
    {
      "epoch": 0.29434697855750486,
      "grad_norm": 0.0,
      "learning_rate": 0.0008277281837750837,
      "loss": 4.9867,
      "step": 2567
    },
    {
      "epoch": 0.29446164430684557,
      "grad_norm": 0.0,
      "learning_rate": 0.0008275879264443214,
      "loss": 4.6892,
      "step": 2568
    },
    {
      "epoch": 0.29457631005618623,
      "grad_norm": 0.0,
      "learning_rate": 0.0008274476239359453,
      "loss": 5.0544,
      "step": 2569
    },
    {
      "epoch": 0.2946909758055269,
      "grad_norm": 0.0,
      "learning_rate": 0.0008273072762693079,
      "loss": 4.7433,
      "step": 2570
    },
    {
      "epoch": 0.29480564155486755,
      "grad_norm": 0.0,
      "learning_rate": 0.0008271668834637673,
      "loss": 4.9789,
      "step": 2571
    },
    {
      "epoch": 0.2949203073042082,
      "grad_norm": 0.0,
      "learning_rate": 0.0008270264455386879,
      "loss": 5.0595,
      "step": 2572
    },
    {
      "epoch": 0.2950349730535489,
      "grad_norm": 0.0,
      "learning_rate": 0.0008268859625134408,
      "loss": 4.8255,
      "step": 2573
    },
    {
      "epoch": 0.2951496388028896,
      "grad_norm": 0.0,
      "learning_rate": 0.0008267454344074026,
      "loss": 5.0661,
      "step": 2574
    },
    {
      "epoch": 0.29526430455223024,
      "grad_norm": 0.0,
      "learning_rate": 0.0008266048612399566,
      "loss": 5.1034,
      "step": 2575
    },
    {
      "epoch": 0.2953789703015709,
      "grad_norm": 0.0,
      "learning_rate": 0.0008264642430304922,
      "loss": 5.2501,
      "step": 2576
    },
    {
      "epoch": 0.2954936360509116,
      "grad_norm": 0.0,
      "learning_rate": 0.000826323579798405,
      "loss": 5.0801,
      "step": 2577
    },
    {
      "epoch": 0.29560830180025227,
      "grad_norm": 0.0,
      "learning_rate": 0.0008261828715630969,
      "loss": 5.06,
      "step": 2578
    },
    {
      "epoch": 0.29572296754959293,
      "grad_norm": 0.0,
      "learning_rate": 0.0008260421183439758,
      "loss": 5.0053,
      "step": 2579
    },
    {
      "epoch": 0.2958376332989336,
      "grad_norm": 0.0,
      "learning_rate": 0.0008259013201604559,
      "loss": 5.0637,
      "step": 2580
    },
    {
      "epoch": 0.2959522990482743,
      "grad_norm": 0.0,
      "learning_rate": 0.0008257604770319577,
      "loss": 5.0621,
      "step": 2581
    },
    {
      "epoch": 0.29606696479761496,
      "grad_norm": 0.0,
      "learning_rate": 0.0008256195889779077,
      "loss": 4.8581,
      "step": 2582
    },
    {
      "epoch": 0.2961816305469556,
      "grad_norm": 0.0,
      "learning_rate": 0.0008254786560177389,
      "loss": 4.997,
      "step": 2583
    },
    {
      "epoch": 0.2962962962962963,
      "grad_norm": 0.0,
      "learning_rate": 0.0008253376781708903,
      "loss": 4.7558,
      "step": 2584
    },
    {
      "epoch": 0.296410962045637,
      "grad_norm": 0.0,
      "learning_rate": 0.0008251966554568069,
      "loss": 4.9509,
      "step": 2585
    },
    {
      "epoch": 0.29652562779497765,
      "grad_norm": 0.0,
      "learning_rate": 0.0008250555878949403,
      "loss": 4.9226,
      "step": 2586
    },
    {
      "epoch": 0.2966402935443183,
      "grad_norm": 0.0,
      "learning_rate": 0.000824914475504748,
      "loss": 5.2376,
      "step": 2587
    },
    {
      "epoch": 0.29675495929365897,
      "grad_norm": 0.0,
      "learning_rate": 0.0008247733183056939,
      "loss": 4.9209,
      "step": 2588
    },
    {
      "epoch": 0.29686962504299963,
      "grad_norm": 0.0,
      "learning_rate": 0.0008246321163172478,
      "loss": 5.0619,
      "step": 2589
    },
    {
      "epoch": 0.29698429079234034,
      "grad_norm": 0.0,
      "learning_rate": 0.0008244908695588858,
      "loss": 4.9264,
      "step": 2590
    },
    {
      "epoch": 0.297098956541681,
      "grad_norm": 0.0,
      "learning_rate": 0.0008243495780500903,
      "loss": 5.0475,
      "step": 2591
    },
    {
      "epoch": 0.29721362229102166,
      "grad_norm": 0.0,
      "learning_rate": 0.0008242082418103496,
      "loss": 5.0775,
      "step": 2592
    },
    {
      "epoch": 0.2973282880403623,
      "grad_norm": 0.0,
      "learning_rate": 0.0008240668608591585,
      "loss": 5.1452,
      "step": 2593
    },
    {
      "epoch": 0.29744295378970304,
      "grad_norm": 0.0,
      "learning_rate": 0.0008239254352160178,
      "loss": 5.1791,
      "step": 2594
    },
    {
      "epoch": 0.2975576195390437,
      "grad_norm": 0.0,
      "learning_rate": 0.0008237839649004345,
      "loss": 4.7625,
      "step": 2595
    },
    {
      "epoch": 0.29767228528838435,
      "grad_norm": 0.0,
      "learning_rate": 0.0008236424499319217,
      "loss": 5.3804,
      "step": 2596
    },
    {
      "epoch": 0.297786951037725,
      "grad_norm": 0.0,
      "learning_rate": 0.0008235008903299985,
      "loss": 4.9245,
      "step": 2597
    },
    {
      "epoch": 0.2979016167870657,
      "grad_norm": 0.0,
      "learning_rate": 0.0008233592861141906,
      "loss": 5.2052,
      "step": 2598
    },
    {
      "epoch": 0.2980162825364064,
      "grad_norm": 0.0,
      "learning_rate": 0.0008232176373040295,
      "loss": 5.03,
      "step": 2599
    },
    {
      "epoch": 0.29813094828574704,
      "grad_norm": 0.0,
      "learning_rate": 0.000823075943919053,
      "loss": 5.0362,
      "step": 2600
    },
    {
      "epoch": 0.2982456140350877,
      "grad_norm": 0.0,
      "learning_rate": 0.000822934205978805,
      "loss": 5.0214,
      "step": 2601
    },
    {
      "epoch": 0.2983602797844284,
      "grad_norm": 0.0,
      "learning_rate": 0.0008227924235028355,
      "loss": 5.094,
      "step": 2602
    },
    {
      "epoch": 0.2984749455337691,
      "grad_norm": 0.0,
      "learning_rate": 0.0008226505965107004,
      "loss": 4.9653,
      "step": 2603
    },
    {
      "epoch": 0.29858961128310973,
      "grad_norm": 0.0,
      "learning_rate": 0.0008225087250219627,
      "loss": 5.028,
      "step": 2604
    },
    {
      "epoch": 0.2987042770324504,
      "grad_norm": 0.0,
      "learning_rate": 0.0008223668090561905,
      "loss": 4.99,
      "step": 2605
    },
    {
      "epoch": 0.29881894278179105,
      "grad_norm": 0.0,
      "learning_rate": 0.0008222248486329585,
      "loss": 4.8501,
      "step": 2606
    },
    {
      "epoch": 0.29893360853113177,
      "grad_norm": 0.0,
      "learning_rate": 0.000822082843771847,
      "loss": 5.0291,
      "step": 2607
    },
    {
      "epoch": 0.2990482742804724,
      "grad_norm": 0.0,
      "learning_rate": 0.0008219407944924433,
      "loss": 5.1566,
      "step": 2608
    },
    {
      "epoch": 0.2991629400298131,
      "grad_norm": 0.0,
      "learning_rate": 0.0008217987008143405,
      "loss": 5.0458,
      "step": 2609
    },
    {
      "epoch": 0.29927760577915374,
      "grad_norm": 0.0,
      "learning_rate": 0.0008216565627571373,
      "loss": 5.0375,
      "step": 2610
    },
    {
      "epoch": 0.29939227152849446,
      "grad_norm": 0.0,
      "learning_rate": 0.0008215143803404392,
      "loss": 4.8819,
      "step": 2611
    },
    {
      "epoch": 0.2995069372778351,
      "grad_norm": 0.0,
      "learning_rate": 0.0008213721535838577,
      "loss": 4.7985,
      "step": 2612
    },
    {
      "epoch": 0.2996216030271758,
      "grad_norm": 0.0,
      "learning_rate": 0.0008212298825070097,
      "loss": 5.0256,
      "step": 2613
    },
    {
      "epoch": 0.29973626877651643,
      "grad_norm": 0.0,
      "learning_rate": 0.0008210875671295194,
      "loss": 4.9369,
      "step": 2614
    },
    {
      "epoch": 0.29985093452585715,
      "grad_norm": 0.0,
      "learning_rate": 0.0008209452074710163,
      "loss": 4.7249,
      "step": 2615
    },
    {
      "epoch": 0.2999656002751978,
      "grad_norm": 0.0,
      "learning_rate": 0.000820802803551136,
      "loss": 4.8483,
      "step": 2616
    },
    {
      "epoch": 0.30008026602453847,
      "grad_norm": 0.0,
      "learning_rate": 0.0008206603553895206,
      "loss": 5.2537,
      "step": 2617
    },
    {
      "epoch": 0.3001949317738791,
      "grad_norm": 0.0,
      "learning_rate": 0.0008205178630058181,
      "loss": 5.2717,
      "step": 2618
    },
    {
      "epoch": 0.30030959752321984,
      "grad_norm": 0.0,
      "learning_rate": 0.0008203753264196825,
      "loss": 5.0742,
      "step": 2619
    },
    {
      "epoch": 0.3004242632725605,
      "grad_norm": 0.0,
      "learning_rate": 0.0008202327456507741,
      "loss": 4.956,
      "step": 2620
    },
    {
      "epoch": 0.30053892902190116,
      "grad_norm": 0.0,
      "learning_rate": 0.0008200901207187592,
      "loss": 4.9835,
      "step": 2621
    },
    {
      "epoch": 0.3006535947712418,
      "grad_norm": 0.0,
      "learning_rate": 0.0008199474516433102,
      "loss": 4.9173,
      "step": 2622
    },
    {
      "epoch": 0.3007682605205825,
      "grad_norm": 0.0,
      "learning_rate": 0.0008198047384441055,
      "loss": 5.2605,
      "step": 2623
    },
    {
      "epoch": 0.3008829262699232,
      "grad_norm": 0.0,
      "learning_rate": 0.0008196619811408297,
      "loss": 5.0507,
      "step": 2624
    },
    {
      "epoch": 0.30099759201926385,
      "grad_norm": 0.0,
      "learning_rate": 0.0008195191797531735,
      "loss": 4.497,
      "step": 2625
    },
    {
      "epoch": 0.3011122577686045,
      "grad_norm": 0.0,
      "learning_rate": 0.0008193763343008336,
      "loss": 4.9623,
      "step": 2626
    },
    {
      "epoch": 0.30122692351794517,
      "grad_norm": 0.0,
      "learning_rate": 0.0008192334448035126,
      "loss": 5.0831,
      "step": 2627
    },
    {
      "epoch": 0.3013415892672859,
      "grad_norm": 0.0,
      "learning_rate": 0.0008190905112809199,
      "loss": 5.0829,
      "step": 2628
    },
    {
      "epoch": 0.30145625501662654,
      "grad_norm": 0.0,
      "learning_rate": 0.0008189475337527698,
      "loss": 4.9851,
      "step": 2629
    },
    {
      "epoch": 0.3015709207659672,
      "grad_norm": 0.0,
      "learning_rate": 0.0008188045122387841,
      "loss": 4.9928,
      "step": 2630
    },
    {
      "epoch": 0.30168558651530786,
      "grad_norm": 0.0,
      "learning_rate": 0.0008186614467586891,
      "loss": 4.8159,
      "step": 2631
    },
    {
      "epoch": 0.30180025226464857,
      "grad_norm": 0.0,
      "learning_rate": 0.0008185183373322183,
      "loss": 5.0951,
      "step": 2632
    },
    {
      "epoch": 0.30191491801398923,
      "grad_norm": 0.0,
      "learning_rate": 0.0008183751839791111,
      "loss": 5.1943,
      "step": 2633
    },
    {
      "epoch": 0.3020295837633299,
      "grad_norm": 0.0,
      "learning_rate": 0.0008182319867191124,
      "loss": 5.0061,
      "step": 2634
    },
    {
      "epoch": 0.30214424951267055,
      "grad_norm": 0.0,
      "learning_rate": 0.000818088745571974,
      "loss": 5.2585,
      "step": 2635
    },
    {
      "epoch": 0.30225891526201126,
      "grad_norm": 0.0,
      "learning_rate": 0.0008179454605574529,
      "loss": 4.9902,
      "step": 2636
    },
    {
      "epoch": 0.3023735810113519,
      "grad_norm": 0.0,
      "learning_rate": 0.0008178021316953126,
      "loss": 5.3197,
      "step": 2637
    },
    {
      "epoch": 0.3024882467606926,
      "grad_norm": 0.0,
      "learning_rate": 0.0008176587590053228,
      "loss": 5.0862,
      "step": 2638
    },
    {
      "epoch": 0.30260291251003324,
      "grad_norm": 0.0,
      "learning_rate": 0.0008175153425072587,
      "loss": 4.7039,
      "step": 2639
    },
    {
      "epoch": 0.3027175782593739,
      "grad_norm": 0.0,
      "learning_rate": 0.000817371882220902,
      "loss": 5.15,
      "step": 2640
    },
    {
      "epoch": 0.3028322440087146,
      "grad_norm": 0.0,
      "learning_rate": 0.0008172283781660405,
      "loss": 5.2452,
      "step": 2641
    },
    {
      "epoch": 0.30294690975805527,
      "grad_norm": 0.0,
      "learning_rate": 0.0008170848303624675,
      "loss": 4.8426,
      "step": 2642
    },
    {
      "epoch": 0.30306157550739593,
      "grad_norm": 0.0,
      "learning_rate": 0.0008169412388299831,
      "loss": 4.8934,
      "step": 2643
    },
    {
      "epoch": 0.3031762412567366,
      "grad_norm": 0.0,
      "learning_rate": 0.0008167976035883927,
      "loss": 5.0954,
      "step": 2644
    },
    {
      "epoch": 0.3032909070060773,
      "grad_norm": 0.0,
      "learning_rate": 0.000816653924657508,
      "loss": 4.7473,
      "step": 2645
    },
    {
      "epoch": 0.30340557275541796,
      "grad_norm": 0.0,
      "learning_rate": 0.0008165102020571472,
      "loss": 4.858,
      "step": 2646
    },
    {
      "epoch": 0.3035202385047586,
      "grad_norm": 0.0,
      "learning_rate": 0.0008163664358071337,
      "loss": 5.309,
      "step": 2647
    },
    {
      "epoch": 0.3036349042540993,
      "grad_norm": 0.0,
      "learning_rate": 0.0008162226259272973,
      "loss": 4.9908,
      "step": 2648
    },
    {
      "epoch": 0.30374957000344,
      "grad_norm": 0.0,
      "learning_rate": 0.0008160787724374739,
      "loss": 5.0213,
      "step": 2649
    },
    {
      "epoch": 0.30386423575278065,
      "grad_norm": 0.0,
      "learning_rate": 0.0008159348753575058,
      "loss": 4.9722,
      "step": 2650
    },
    {
      "epoch": 0.3039789015021213,
      "grad_norm": 0.0,
      "learning_rate": 0.0008157909347072401,
      "loss": 4.9053,
      "step": 2651
    },
    {
      "epoch": 0.30409356725146197,
      "grad_norm": 0.0,
      "learning_rate": 0.0008156469505065312,
      "loss": 4.9959,
      "step": 2652
    },
    {
      "epoch": 0.3042082330008027,
      "grad_norm": 0.0,
      "learning_rate": 0.0008155029227752388,
      "loss": 4.7807,
      "step": 2653
    },
    {
      "epoch": 0.30432289875014334,
      "grad_norm": 0.0,
      "learning_rate": 0.0008153588515332287,
      "loss": 5.1665,
      "step": 2654
    },
    {
      "epoch": 0.304437564499484,
      "grad_norm": 0.0,
      "learning_rate": 0.0008152147368003728,
      "loss": 4.7704,
      "step": 2655
    },
    {
      "epoch": 0.30455223024882466,
      "grad_norm": 0.0,
      "learning_rate": 0.0008150705785965492,
      "loss": 5.0458,
      "step": 2656
    },
    {
      "epoch": 0.3046668959981653,
      "grad_norm": 0.0,
      "learning_rate": 0.0008149263769416414,
      "loss": 5.1291,
      "step": 2657
    },
    {
      "epoch": 0.30478156174750604,
      "grad_norm": 0.0,
      "learning_rate": 0.0008147821318555397,
      "loss": 4.9234,
      "step": 2658
    },
    {
      "epoch": 0.3048962274968467,
      "grad_norm": 0.0,
      "learning_rate": 0.0008146378433581397,
      "loss": 5.0115,
      "step": 2659
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 0.0,
      "learning_rate": 0.0008144935114693432,
      "loss": 5.0,
      "step": 2660
    },
    {
      "epoch": 0.305125558995528,
      "grad_norm": 0.0,
      "learning_rate": 0.0008143491362090585,
      "loss": 5.2084,
      "step": 2661
    },
    {
      "epoch": 0.3052402247448687,
      "grad_norm": 0.0,
      "learning_rate": 0.0008142047175971986,
      "loss": 4.7398,
      "step": 2662
    },
    {
      "epoch": 0.3053548904942094,
      "grad_norm": 0.0,
      "learning_rate": 0.0008140602556536838,
      "loss": 5.1553,
      "step": 2663
    },
    {
      "epoch": 0.30546955624355004,
      "grad_norm": 0.0,
      "learning_rate": 0.00081391575039844,
      "loss": 4.8524,
      "step": 2664
    },
    {
      "epoch": 0.3055842219928907,
      "grad_norm": 0.0,
      "learning_rate": 0.0008137712018513988,
      "loss": 4.7613,
      "step": 2665
    },
    {
      "epoch": 0.3056988877422314,
      "grad_norm": 0.0,
      "learning_rate": 0.0008136266100324977,
      "loss": 5.0423,
      "step": 2666
    },
    {
      "epoch": 0.3058135534915721,
      "grad_norm": 0.0,
      "learning_rate": 0.0008134819749616806,
      "loss": 4.933,
      "step": 2667
    },
    {
      "epoch": 0.30592821924091274,
      "grad_norm": 0.0,
      "learning_rate": 0.0008133372966588971,
      "loss": 5.052,
      "step": 2668
    },
    {
      "epoch": 0.3060428849902534,
      "grad_norm": 0.0,
      "learning_rate": 0.0008131925751441028,
      "loss": 5.0209,
      "step": 2669
    },
    {
      "epoch": 0.3061575507395941,
      "grad_norm": 0.0,
      "learning_rate": 0.0008130478104372594,
      "loss": 4.7789,
      "step": 2670
    },
    {
      "epoch": 0.30627221648893477,
      "grad_norm": 0.0,
      "learning_rate": 0.0008129030025583343,
      "loss": 5.1625,
      "step": 2671
    },
    {
      "epoch": 0.3063868822382754,
      "grad_norm": 0.0,
      "learning_rate": 0.000812758151527301,
      "loss": 4.9243,
      "step": 2672
    },
    {
      "epoch": 0.3065015479876161,
      "grad_norm": 0.0,
      "learning_rate": 0.0008126132573641389,
      "loss": 5.1096,
      "step": 2673
    },
    {
      "epoch": 0.30661621373695674,
      "grad_norm": 0.0,
      "learning_rate": 0.0008124683200888336,
      "loss": 5.0282,
      "step": 2674
    },
    {
      "epoch": 0.30673087948629746,
      "grad_norm": 0.0,
      "learning_rate": 0.0008123233397213761,
      "loss": 4.8056,
      "step": 2675
    },
    {
      "epoch": 0.3068455452356381,
      "grad_norm": 0.0,
      "learning_rate": 0.000812178316281764,
      "loss": 4.9946,
      "step": 2676
    },
    {
      "epoch": 0.3069602109849788,
      "grad_norm": 0.0,
      "learning_rate": 0.0008120332497900003,
      "loss": 4.9603,
      "step": 2677
    },
    {
      "epoch": 0.30707487673431944,
      "grad_norm": 0.0,
      "learning_rate": 0.0008118881402660943,
      "loss": 5.0949,
      "step": 2678
    },
    {
      "epoch": 0.30718954248366015,
      "grad_norm": 0.0,
      "learning_rate": 0.0008117429877300608,
      "loss": 4.5955,
      "step": 2679
    },
    {
      "epoch": 0.3073042082330008,
      "grad_norm": 0.0,
      "learning_rate": 0.0008115977922019212,
      "loss": 5.14,
      "step": 2680
    },
    {
      "epoch": 0.30741887398234147,
      "grad_norm": 0.0,
      "learning_rate": 0.0008114525537017025,
      "loss": 4.89,
      "step": 2681
    },
    {
      "epoch": 0.3075335397316821,
      "grad_norm": 0.0,
      "learning_rate": 0.0008113072722494371,
      "loss": 5.0549,
      "step": 2682
    },
    {
      "epoch": 0.30764820548102284,
      "grad_norm": 0.0,
      "learning_rate": 0.0008111619478651642,
      "loss": 5.119,
      "step": 2683
    },
    {
      "epoch": 0.3077628712303635,
      "grad_norm": 0.0,
      "learning_rate": 0.0008110165805689285,
      "loss": 4.9236,
      "step": 2684
    },
    {
      "epoch": 0.30787753697970416,
      "grad_norm": 0.0,
      "learning_rate": 0.0008108711703807805,
      "loss": 5.0646,
      "step": 2685
    },
    {
      "epoch": 0.3079922027290448,
      "grad_norm": 0.0,
      "learning_rate": 0.000810725717320777,
      "loss": 4.9854,
      "step": 2686
    },
    {
      "epoch": 0.30810686847838553,
      "grad_norm": 0.0,
      "learning_rate": 0.00081058022140898,
      "loss": 5.1981,
      "step": 2687
    },
    {
      "epoch": 0.3082215342277262,
      "grad_norm": 0.0,
      "learning_rate": 0.0008104346826654583,
      "loss": 5.0147,
      "step": 2688
    },
    {
      "epoch": 0.30833619997706685,
      "grad_norm": 0.0,
      "learning_rate": 0.0008102891011102862,
      "loss": 5.0037,
      "step": 2689
    },
    {
      "epoch": 0.3084508657264075,
      "grad_norm": 0.0,
      "learning_rate": 0.0008101434767635438,
      "loss": 5.0225,
      "step": 2690
    },
    {
      "epoch": 0.30856553147574817,
      "grad_norm": 0.0,
      "learning_rate": 0.0008099978096453172,
      "loss": 4.9274,
      "step": 2691
    },
    {
      "epoch": 0.3086801972250889,
      "grad_norm": 0.0,
      "learning_rate": 0.0008098520997756982,
      "loss": 4.7891,
      "step": 2692
    },
    {
      "epoch": 0.30879486297442954,
      "grad_norm": 0.0,
      "learning_rate": 0.0008097063471747852,
      "loss": 4.6811,
      "step": 2693
    },
    {
      "epoch": 0.3089095287237702,
      "grad_norm": 0.0,
      "learning_rate": 0.0008095605518626816,
      "loss": 4.8269,
      "step": 2694
    },
    {
      "epoch": 0.30902419447311086,
      "grad_norm": 0.0,
      "learning_rate": 0.000809414713859497,
      "loss": 4.8841,
      "step": 2695
    },
    {
      "epoch": 0.3091388602224516,
      "grad_norm": 0.0,
      "learning_rate": 0.0008092688331853474,
      "loss": 5.032,
      "step": 2696
    },
    {
      "epoch": 0.30925352597179223,
      "grad_norm": 0.0,
      "learning_rate": 0.000809122909860354,
      "loss": 4.765,
      "step": 2697
    },
    {
      "epoch": 0.3093681917211329,
      "grad_norm": 0.0,
      "learning_rate": 0.0008089769439046439,
      "loss": 4.865,
      "step": 2698
    },
    {
      "epoch": 0.30948285747047355,
      "grad_norm": 0.0,
      "learning_rate": 0.0008088309353383507,
      "loss": 4.8798,
      "step": 2699
    },
    {
      "epoch": 0.30959752321981426,
      "grad_norm": 0.0,
      "learning_rate": 0.0008086848841816134,
      "loss": 5.1296,
      "step": 2700
    },
    {
      "epoch": 0.3097121889691549,
      "grad_norm": 0.0,
      "learning_rate": 0.0008085387904545769,
      "loss": 5.1343,
      "step": 2701
    },
    {
      "epoch": 0.3098268547184956,
      "grad_norm": 0.0,
      "learning_rate": 0.0008083926541773922,
      "loss": 4.8108,
      "step": 2702
    },
    {
      "epoch": 0.30994152046783624,
      "grad_norm": 0.0,
      "learning_rate": 0.0008082464753702158,
      "loss": 4.9543,
      "step": 2703
    },
    {
      "epoch": 0.31005618621717695,
      "grad_norm": 0.0,
      "learning_rate": 0.0008081002540532104,
      "loss": 4.7926,
      "step": 2704
    },
    {
      "epoch": 0.3101708519665176,
      "grad_norm": 0.0,
      "learning_rate": 0.0008079539902465443,
      "loss": 5.113,
      "step": 2705
    },
    {
      "epoch": 0.31028551771585827,
      "grad_norm": 0.0,
      "learning_rate": 0.0008078076839703922,
      "loss": 4.8843,
      "step": 2706
    },
    {
      "epoch": 0.31040018346519893,
      "grad_norm": 0.0,
      "learning_rate": 0.0008076613352449337,
      "loss": 4.9695,
      "step": 2707
    },
    {
      "epoch": 0.3105148492145396,
      "grad_norm": 0.0,
      "learning_rate": 0.0008075149440903553,
      "loss": 5.2776,
      "step": 2708
    },
    {
      "epoch": 0.3106295149638803,
      "grad_norm": 0.0,
      "learning_rate": 0.0008073685105268487,
      "loss": 4.8749,
      "step": 2709
    },
    {
      "epoch": 0.31074418071322096,
      "grad_norm": 0.0,
      "learning_rate": 0.0008072220345746114,
      "loss": 4.9842,
      "step": 2710
    },
    {
      "epoch": 0.3108588464625616,
      "grad_norm": 0.0,
      "learning_rate": 0.0008070755162538473,
      "loss": 4.8757,
      "step": 2711
    },
    {
      "epoch": 0.3109735122119023,
      "grad_norm": 0.0,
      "learning_rate": 0.0008069289555847658,
      "loss": 5.1388,
      "step": 2712
    },
    {
      "epoch": 0.311088177961243,
      "grad_norm": 0.0,
      "learning_rate": 0.0008067823525875818,
      "loss": 4.994,
      "step": 2713
    },
    {
      "epoch": 0.31120284371058365,
      "grad_norm": 0.0,
      "learning_rate": 0.0008066357072825167,
      "loss": 5.0264,
      "step": 2714
    },
    {
      "epoch": 0.3113175094599243,
      "grad_norm": 0.0,
      "learning_rate": 0.0008064890196897974,
      "loss": 4.727,
      "step": 2715
    },
    {
      "epoch": 0.31143217520926497,
      "grad_norm": 0.0,
      "learning_rate": 0.0008063422898296564,
      "loss": 4.9027,
      "step": 2716
    },
    {
      "epoch": 0.3115468409586057,
      "grad_norm": 0.0,
      "learning_rate": 0.0008061955177223327,
      "loss": 4.9757,
      "step": 2717
    },
    {
      "epoch": 0.31166150670794635,
      "grad_norm": 0.0,
      "learning_rate": 0.0008060487033880704,
      "loss": 5.0855,
      "step": 2718
    },
    {
      "epoch": 0.311776172457287,
      "grad_norm": 0.0,
      "learning_rate": 0.0008059018468471198,
      "loss": 4.8422,
      "step": 2719
    },
    {
      "epoch": 0.31189083820662766,
      "grad_norm": 0.0,
      "learning_rate": 0.000805754948119737,
      "loss": 5.0372,
      "step": 2720
    },
    {
      "epoch": 0.3120055039559684,
      "grad_norm": 0.0,
      "learning_rate": 0.0008056080072261839,
      "loss": 4.8339,
      "step": 2721
    },
    {
      "epoch": 0.31212016970530904,
      "grad_norm": 0.0,
      "learning_rate": 0.0008054610241867282,
      "loss": 5.1452,
      "step": 2722
    },
    {
      "epoch": 0.3122348354546497,
      "grad_norm": 0.0,
      "learning_rate": 0.0008053139990216434,
      "loss": 5.0277,
      "step": 2723
    },
    {
      "epoch": 0.31234950120399035,
      "grad_norm": 0.0,
      "learning_rate": 0.0008051669317512087,
      "loss": 5.0494,
      "step": 2724
    },
    {
      "epoch": 0.312464166953331,
      "grad_norm": 0.0,
      "learning_rate": 0.0008050198223957093,
      "loss": 4.9859,
      "step": 2725
    },
    {
      "epoch": 0.3125788327026717,
      "grad_norm": 0.0,
      "learning_rate": 0.0008048726709754362,
      "loss": 5.2312,
      "step": 2726
    },
    {
      "epoch": 0.3126934984520124,
      "grad_norm": 0.0,
      "learning_rate": 0.0008047254775106862,
      "loss": 5.0594,
      "step": 2727
    },
    {
      "epoch": 0.31280816420135305,
      "grad_norm": 0.0,
      "learning_rate": 0.0008045782420217617,
      "loss": 5.3394,
      "step": 2728
    },
    {
      "epoch": 0.3129228299506937,
      "grad_norm": 0.0,
      "learning_rate": 0.0008044309645289709,
      "loss": 4.8479,
      "step": 2729
    },
    {
      "epoch": 0.3130374957000344,
      "grad_norm": 0.0,
      "learning_rate": 0.0008042836450526281,
      "loss": 5.1549,
      "step": 2730
    },
    {
      "epoch": 0.3131521614493751,
      "grad_norm": 0.0,
      "learning_rate": 0.0008041362836130534,
      "loss": 5.0299,
      "step": 2731
    },
    {
      "epoch": 0.31326682719871574,
      "grad_norm": 0.0,
      "learning_rate": 0.0008039888802305721,
      "loss": 5.0937,
      "step": 2732
    },
    {
      "epoch": 0.3133814929480564,
      "grad_norm": 0.0,
      "learning_rate": 0.0008038414349255158,
      "loss": 4.996,
      "step": 2733
    },
    {
      "epoch": 0.3134961586973971,
      "grad_norm": 0.0,
      "learning_rate": 0.0008036939477182219,
      "loss": 4.8408,
      "step": 2734
    },
    {
      "epoch": 0.31361082444673777,
      "grad_norm": 0.0,
      "learning_rate": 0.0008035464186290335,
      "loss": 5.1648,
      "step": 2735
    },
    {
      "epoch": 0.3137254901960784,
      "grad_norm": 0.0,
      "learning_rate": 0.0008033988476782992,
      "loss": 4.9148,
      "step": 2736
    },
    {
      "epoch": 0.3138401559454191,
      "grad_norm": 0.0,
      "learning_rate": 0.0008032512348863739,
      "loss": 4.9313,
      "step": 2737
    },
    {
      "epoch": 0.3139548216947598,
      "grad_norm": 0.0,
      "learning_rate": 0.0008031035802736177,
      "loss": 4.9451,
      "step": 2738
    },
    {
      "epoch": 0.31406948744410046,
      "grad_norm": 0.0,
      "learning_rate": 0.0008029558838603967,
      "loss": 5.2731,
      "step": 2739
    },
    {
      "epoch": 0.3141841531934411,
      "grad_norm": 0.0,
      "learning_rate": 0.0008028081456670828,
      "loss": 5.0003,
      "step": 2740
    },
    {
      "epoch": 0.3142988189427818,
      "grad_norm": 0.0,
      "learning_rate": 0.0008026603657140542,
      "loss": 4.9205,
      "step": 2741
    },
    {
      "epoch": 0.31441348469212244,
      "grad_norm": 0.0,
      "learning_rate": 0.0008025125440216936,
      "loss": 4.9152,
      "step": 2742
    },
    {
      "epoch": 0.31452815044146315,
      "grad_norm": 0.0,
      "learning_rate": 0.0008023646806103907,
      "loss": 5.127,
      "step": 2743
    },
    {
      "epoch": 0.3146428161908038,
      "grad_norm": 0.0,
      "learning_rate": 0.0008022167755005403,
      "loss": 4.9581,
      "step": 2744
    },
    {
      "epoch": 0.31475748194014447,
      "grad_norm": 0.0,
      "learning_rate": 0.0008020688287125429,
      "loss": 4.702,
      "step": 2745
    },
    {
      "epoch": 0.3148721476894851,
      "grad_norm": 0.0,
      "learning_rate": 0.0008019208402668053,
      "loss": 4.8451,
      "step": 2746
    },
    {
      "epoch": 0.31498681343882584,
      "grad_norm": 0.0,
      "learning_rate": 0.0008017728101837392,
      "loss": 4.992,
      "step": 2747
    },
    {
      "epoch": 0.3151014791881665,
      "grad_norm": 0.0,
      "learning_rate": 0.0008016247384837629,
      "loss": 5.0549,
      "step": 2748
    },
    {
      "epoch": 0.31521614493750716,
      "grad_norm": 0.0,
      "learning_rate": 0.0008014766251872998,
      "loss": 4.9689,
      "step": 2749
    },
    {
      "epoch": 0.3153308106868478,
      "grad_norm": 0.0,
      "learning_rate": 0.0008013284703147798,
      "loss": 4.978,
      "step": 2750
    },
    {
      "epoch": 0.31544547643618853,
      "grad_norm": 0.0,
      "learning_rate": 0.0008011802738866375,
      "loss": 4.8424,
      "step": 2751
    },
    {
      "epoch": 0.3155601421855292,
      "grad_norm": 0.0,
      "learning_rate": 0.000801032035923314,
      "loss": 5.1441,
      "step": 2752
    },
    {
      "epoch": 0.31567480793486985,
      "grad_norm": 0.0,
      "learning_rate": 0.000800883756445256,
      "loss": 4.8866,
      "step": 2753
    },
    {
      "epoch": 0.3157894736842105,
      "grad_norm": 0.0,
      "learning_rate": 0.0008007354354729156,
      "loss": 4.9682,
      "step": 2754
    },
    {
      "epoch": 0.3159041394335512,
      "grad_norm": 0.0,
      "learning_rate": 0.0008005870730267509,
      "loss": 5.219,
      "step": 2755
    },
    {
      "epoch": 0.3160188051828919,
      "grad_norm": 0.0,
      "learning_rate": 0.0008004386691272258,
      "loss": 5.2126,
      "step": 2756
    },
    {
      "epoch": 0.31613347093223254,
      "grad_norm": 0.0,
      "learning_rate": 0.0008002902237948098,
      "loss": 5.187,
      "step": 2757
    },
    {
      "epoch": 0.3162481366815732,
      "grad_norm": 0.0,
      "learning_rate": 0.000800141737049978,
      "loss": 4.8996,
      "step": 2758
    },
    {
      "epoch": 0.31636280243091386,
      "grad_norm": 0.0,
      "learning_rate": 0.0007999932089132112,
      "loss": 4.9603,
      "step": 2759
    },
    {
      "epoch": 0.3164774681802546,
      "grad_norm": 0.0,
      "learning_rate": 0.0007998446394049963,
      "loss": 5.1161,
      "step": 2760
    },
    {
      "epoch": 0.31659213392959523,
      "grad_norm": 0.0,
      "learning_rate": 0.0007996960285458256,
      "loss": 5.1174,
      "step": 2761
    },
    {
      "epoch": 0.3167067996789359,
      "grad_norm": 0.0,
      "learning_rate": 0.0007995473763561967,
      "loss": 5.4645,
      "step": 2762
    },
    {
      "epoch": 0.31682146542827655,
      "grad_norm": 0.0,
      "learning_rate": 0.0007993986828566141,
      "loss": 5.1655,
      "step": 2763
    },
    {
      "epoch": 0.31693613117761726,
      "grad_norm": 0.0,
      "learning_rate": 0.0007992499480675865,
      "loss": 5.1807,
      "step": 2764
    },
    {
      "epoch": 0.3170507969269579,
      "grad_norm": 0.0,
      "learning_rate": 0.0007991011720096294,
      "loss": 4.9704,
      "step": 2765
    },
    {
      "epoch": 0.3171654626762986,
      "grad_norm": 0.0,
      "learning_rate": 0.0007989523547032635,
      "loss": 4.8907,
      "step": 2766
    },
    {
      "epoch": 0.31728012842563924,
      "grad_norm": 0.0,
      "learning_rate": 0.0007988034961690154,
      "loss": 4.9969,
      "step": 2767
    },
    {
      "epoch": 0.31739479417497996,
      "grad_norm": 0.0,
      "learning_rate": 0.0007986545964274174,
      "loss": 4.9787,
      "step": 2768
    },
    {
      "epoch": 0.3175094599243206,
      "grad_norm": 0.0,
      "learning_rate": 0.0007985056554990072,
      "loss": 4.9497,
      "step": 2769
    },
    {
      "epoch": 0.3176241256736613,
      "grad_norm": 0.0,
      "learning_rate": 0.0007983566734043284,
      "loss": 5.071,
      "step": 2770
    },
    {
      "epoch": 0.31773879142300193,
      "grad_norm": 0.0,
      "learning_rate": 0.0007982076501639301,
      "loss": 4.8896,
      "step": 2771
    },
    {
      "epoch": 0.31785345717234265,
      "grad_norm": 0.0,
      "learning_rate": 0.0007980585857983674,
      "loss": 4.9195,
      "step": 2772
    },
    {
      "epoch": 0.3179681229216833,
      "grad_norm": 0.0,
      "learning_rate": 0.000797909480328201,
      "loss": 4.9205,
      "step": 2773
    },
    {
      "epoch": 0.31808278867102396,
      "grad_norm": 0.0,
      "learning_rate": 0.0007977603337739969,
      "loss": 4.7788,
      "step": 2774
    },
    {
      "epoch": 0.3181974544203646,
      "grad_norm": 0.0,
      "learning_rate": 0.0007976111461563271,
      "loss": 4.8514,
      "step": 2775
    },
    {
      "epoch": 0.3183121201697053,
      "grad_norm": 0.0,
      "learning_rate": 0.0007974619174957693,
      "loss": 4.9398,
      "step": 2776
    },
    {
      "epoch": 0.318426785919046,
      "grad_norm": 0.0,
      "learning_rate": 0.0007973126478129067,
      "loss": 4.6956,
      "step": 2777
    },
    {
      "epoch": 0.31854145166838665,
      "grad_norm": 0.0,
      "learning_rate": 0.0007971633371283281,
      "loss": 5.0441,
      "step": 2778
    },
    {
      "epoch": 0.3186561174177273,
      "grad_norm": 0.0,
      "learning_rate": 0.0007970139854626281,
      "loss": 4.9036,
      "step": 2779
    },
    {
      "epoch": 0.318770783167068,
      "grad_norm": 0.0,
      "learning_rate": 0.0007968645928364071,
      "loss": 5.0533,
      "step": 2780
    },
    {
      "epoch": 0.3188854489164087,
      "grad_norm": 0.0,
      "learning_rate": 0.0007967151592702706,
      "loss": 4.9616,
      "step": 2781
    },
    {
      "epoch": 0.31900011466574935,
      "grad_norm": 0.0,
      "learning_rate": 0.0007965656847848305,
      "loss": 5.195,
      "step": 2782
    },
    {
      "epoch": 0.31911478041509,
      "grad_norm": 0.0,
      "learning_rate": 0.0007964161694007037,
      "loss": 4.9131,
      "step": 2783
    },
    {
      "epoch": 0.31922944616443066,
      "grad_norm": 0.0,
      "learning_rate": 0.0007962666131385133,
      "loss": 4.7107,
      "step": 2784
    },
    {
      "epoch": 0.3193441119137714,
      "grad_norm": 0.0,
      "learning_rate": 0.0007961170160188873,
      "loss": 5.0564,
      "step": 2785
    },
    {
      "epoch": 0.31945877766311204,
      "grad_norm": 0.0,
      "learning_rate": 0.00079596737806246,
      "loss": 5.1231,
      "step": 2786
    },
    {
      "epoch": 0.3195734434124527,
      "grad_norm": 0.0,
      "learning_rate": 0.0007958176992898711,
      "loss": 5.0453,
      "step": 2787
    },
    {
      "epoch": 0.31968810916179335,
      "grad_norm": 0.0,
      "learning_rate": 0.0007956679797217661,
      "loss": 4.9727,
      "step": 2788
    },
    {
      "epoch": 0.31980277491113407,
      "grad_norm": 0.0,
      "learning_rate": 0.0007955182193787956,
      "loss": 5.2439,
      "step": 2789
    },
    {
      "epoch": 0.31991744066047473,
      "grad_norm": 0.0,
      "learning_rate": 0.0007953684182816164,
      "loss": 4.9309,
      "step": 2790
    },
    {
      "epoch": 0.3200321064098154,
      "grad_norm": 0.0,
      "learning_rate": 0.0007952185764508907,
      "loss": 5.1194,
      "step": 2791
    },
    {
      "epoch": 0.32014677215915605,
      "grad_norm": 0.0,
      "learning_rate": 0.0007950686939072862,
      "loss": 4.792,
      "step": 2792
    },
    {
      "epoch": 0.3202614379084967,
      "grad_norm": 0.0,
      "learning_rate": 0.0007949187706714765,
      "loss": 5.116,
      "step": 2793
    },
    {
      "epoch": 0.3203761036578374,
      "grad_norm": 0.0,
      "learning_rate": 0.0007947688067641409,
      "loss": 4.8438,
      "step": 2794
    },
    {
      "epoch": 0.3204907694071781,
      "grad_norm": 0.0,
      "learning_rate": 0.0007946188022059634,
      "loss": 5.1151,
      "step": 2795
    },
    {
      "epoch": 0.32060543515651874,
      "grad_norm": 0.0,
      "learning_rate": 0.0007944687570176348,
      "loss": 4.8032,
      "step": 2796
    },
    {
      "epoch": 0.3207201009058594,
      "grad_norm": 0.0,
      "learning_rate": 0.0007943186712198507,
      "loss": 4.9455,
      "step": 2797
    },
    {
      "epoch": 0.3208347666552001,
      "grad_norm": 0.0,
      "learning_rate": 0.0007941685448333126,
      "loss": 4.9203,
      "step": 2798
    },
    {
      "epoch": 0.32094943240454077,
      "grad_norm": 0.0,
      "learning_rate": 0.0007940183778787278,
      "loss": 5.325,
      "step": 2799
    },
    {
      "epoch": 0.3210640981538814,
      "grad_norm": 0.0,
      "learning_rate": 0.0007938681703768088,
      "loss": 4.9979,
      "step": 2800
    },
    {
      "epoch": 0.3211787639032221,
      "grad_norm": 0.0,
      "learning_rate": 0.0007937179223482739,
      "loss": 4.7724,
      "step": 2801
    },
    {
      "epoch": 0.3212934296525628,
      "grad_norm": 0.0,
      "learning_rate": 0.0007935676338138469,
      "loss": 4.8987,
      "step": 2802
    },
    {
      "epoch": 0.32140809540190346,
      "grad_norm": 0.0,
      "learning_rate": 0.0007934173047942573,
      "loss": 5.1366,
      "step": 2803
    },
    {
      "epoch": 0.3215227611512441,
      "grad_norm": 0.0,
      "learning_rate": 0.00079326693531024,
      "loss": 4.9537,
      "step": 2804
    },
    {
      "epoch": 0.3216374269005848,
      "grad_norm": 0.0,
      "learning_rate": 0.0007931165253825357,
      "loss": 5.2248,
      "step": 2805
    },
    {
      "epoch": 0.3217520926499255,
      "grad_norm": 0.0,
      "learning_rate": 0.0007929660750318906,
      "loss": 4.8549,
      "step": 2806
    },
    {
      "epoch": 0.32186675839926615,
      "grad_norm": 0.0,
      "learning_rate": 0.0007928155842790566,
      "loss": 5.163,
      "step": 2807
    },
    {
      "epoch": 0.3219814241486068,
      "grad_norm": 0.0,
      "learning_rate": 0.0007926650531447907,
      "loss": 5.0444,
      "step": 2808
    },
    {
      "epoch": 0.32209608989794747,
      "grad_norm": 0.0,
      "learning_rate": 0.000792514481649856,
      "loss": 4.9494,
      "step": 2809
    },
    {
      "epoch": 0.3222107556472881,
      "grad_norm": 0.0,
      "learning_rate": 0.0007923638698150208,
      "loss": 5.1491,
      "step": 2810
    },
    {
      "epoch": 0.32232542139662884,
      "grad_norm": 0.0,
      "learning_rate": 0.0007922132176610595,
      "loss": 4.9927,
      "step": 2811
    },
    {
      "epoch": 0.3224400871459695,
      "grad_norm": 0.0,
      "learning_rate": 0.0007920625252087513,
      "loss": 5.1058,
      "step": 2812
    },
    {
      "epoch": 0.32255475289531016,
      "grad_norm": 0.0,
      "learning_rate": 0.0007919117924788816,
      "loss": 5.0801,
      "step": 2813
    },
    {
      "epoch": 0.3226694186446508,
      "grad_norm": 0.0,
      "learning_rate": 0.000791761019492241,
      "loss": 5.2109,
      "step": 2814
    },
    {
      "epoch": 0.32278408439399153,
      "grad_norm": 0.0,
      "learning_rate": 0.0007916102062696259,
      "loss": 4.7603,
      "step": 2815
    },
    {
      "epoch": 0.3228987501433322,
      "grad_norm": 0.0,
      "learning_rate": 0.0007914593528318379,
      "loss": 4.9889,
      "step": 2816
    },
    {
      "epoch": 0.32301341589267285,
      "grad_norm": 0.0,
      "learning_rate": 0.0007913084591996845,
      "loss": 5.1004,
      "step": 2817
    },
    {
      "epoch": 0.3231280816420135,
      "grad_norm": 0.0,
      "learning_rate": 0.0007911575253939783,
      "loss": 4.9251,
      "step": 2818
    },
    {
      "epoch": 0.3232427473913542,
      "grad_norm": 0.0,
      "learning_rate": 0.0007910065514355382,
      "loss": 4.8255,
      "step": 2819
    },
    {
      "epoch": 0.3233574131406949,
      "grad_norm": 0.0,
      "learning_rate": 0.0007908555373451878,
      "loss": 5.1551,
      "step": 2820
    },
    {
      "epoch": 0.32347207889003554,
      "grad_norm": 0.0,
      "learning_rate": 0.0007907044831437569,
      "loss": 5.0685,
      "step": 2821
    },
    {
      "epoch": 0.3235867446393762,
      "grad_norm": 0.0,
      "learning_rate": 0.0007905533888520804,
      "loss": 5.0802,
      "step": 2822
    },
    {
      "epoch": 0.3237014103887169,
      "grad_norm": 0.0,
      "learning_rate": 0.000790402254490999,
      "loss": 4.7532,
      "step": 2823
    },
    {
      "epoch": 0.3238160761380576,
      "grad_norm": 0.0,
      "learning_rate": 0.0007902510800813587,
      "loss": 5.0451,
      "step": 2824
    },
    {
      "epoch": 0.32393074188739823,
      "grad_norm": 0.0,
      "learning_rate": 0.0007900998656440111,
      "loss": 4.823,
      "step": 2825
    },
    {
      "epoch": 0.3240454076367389,
      "grad_norm": 0.0,
      "learning_rate": 0.0007899486111998132,
      "loss": 4.9101,
      "step": 2826
    },
    {
      "epoch": 0.3241600733860796,
      "grad_norm": 0.0,
      "learning_rate": 0.0007897973167696282,
      "loss": 4.9388,
      "step": 2827
    },
    {
      "epoch": 0.32427473913542026,
      "grad_norm": 0.0,
      "learning_rate": 0.0007896459823743237,
      "loss": 5.1556,
      "step": 2828
    },
    {
      "epoch": 0.3243894048847609,
      "grad_norm": 0.0,
      "learning_rate": 0.0007894946080347736,
      "loss": 5.0153,
      "step": 2829
    },
    {
      "epoch": 0.3245040706341016,
      "grad_norm": 0.0,
      "learning_rate": 0.0007893431937718574,
      "loss": 4.9388,
      "step": 2830
    },
    {
      "epoch": 0.32461873638344224,
      "grad_norm": 0.0,
      "learning_rate": 0.0007891917396064593,
      "loss": 4.7748,
      "step": 2831
    },
    {
      "epoch": 0.32473340213278296,
      "grad_norm": 0.0,
      "learning_rate": 0.0007890402455594698,
      "loss": 5.0309,
      "step": 2832
    },
    {
      "epoch": 0.3248480678821236,
      "grad_norm": 0.0,
      "learning_rate": 0.0007888887116517847,
      "loss": 4.9079,
      "step": 2833
    },
    {
      "epoch": 0.3249627336314643,
      "grad_norm": 0.0,
      "learning_rate": 0.0007887371379043049,
      "loss": 4.8432,
      "step": 2834
    },
    {
      "epoch": 0.32507739938080493,
      "grad_norm": 0.0,
      "learning_rate": 0.0007885855243379375,
      "loss": 5.0138,
      "step": 2835
    },
    {
      "epoch": 0.32519206513014565,
      "grad_norm": 0.0,
      "learning_rate": 0.0007884338709735944,
      "loss": 4.8655,
      "step": 2836
    },
    {
      "epoch": 0.3253067308794863,
      "grad_norm": 0.0,
      "learning_rate": 0.0007882821778321935,
      "loss": 5.1554,
      "step": 2837
    },
    {
      "epoch": 0.32542139662882696,
      "grad_norm": 0.0,
      "learning_rate": 0.0007881304449346576,
      "loss": 5.1488,
      "step": 2838
    },
    {
      "epoch": 0.3255360623781676,
      "grad_norm": 0.0,
      "learning_rate": 0.000787978672301916,
      "loss": 4.7682,
      "step": 2839
    },
    {
      "epoch": 0.32565072812750834,
      "grad_norm": 0.0,
      "learning_rate": 0.0007878268599549024,
      "loss": 5.0561,
      "step": 2840
    },
    {
      "epoch": 0.325765393876849,
      "grad_norm": 0.0,
      "learning_rate": 0.0007876750079145562,
      "loss": 4.9499,
      "step": 2841
    },
    {
      "epoch": 0.32588005962618966,
      "grad_norm": 0.0,
      "learning_rate": 0.0007875231162018231,
      "loss": 5.1353,
      "step": 2842
    },
    {
      "epoch": 0.3259947253755303,
      "grad_norm": 0.0,
      "learning_rate": 0.0007873711848376531,
      "loss": 4.9962,
      "step": 2843
    },
    {
      "epoch": 0.32610939112487103,
      "grad_norm": 0.0,
      "learning_rate": 0.0007872192138430028,
      "loss": 4.7078,
      "step": 2844
    },
    {
      "epoch": 0.3262240568742117,
      "grad_norm": 0.0,
      "learning_rate": 0.0007870672032388332,
      "loss": 4.934,
      "step": 2845
    },
    {
      "epoch": 0.32633872262355235,
      "grad_norm": 0.0,
      "learning_rate": 0.0007869151530461115,
      "loss": 5.1796,
      "step": 2846
    },
    {
      "epoch": 0.326453388372893,
      "grad_norm": 0.0,
      "learning_rate": 0.0007867630632858101,
      "loss": 4.7177,
      "step": 2847
    },
    {
      "epoch": 0.32656805412223366,
      "grad_norm": 0.0,
      "learning_rate": 0.0007866109339789067,
      "loss": 4.7542,
      "step": 2848
    },
    {
      "epoch": 0.3266827198715744,
      "grad_norm": 0.0,
      "learning_rate": 0.0007864587651463851,
      "loss": 4.896,
      "step": 2849
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.0,
      "learning_rate": 0.0007863065568092336,
      "loss": 5.021,
      "step": 2850
    },
    {
      "epoch": 0.3269120513702557,
      "grad_norm": 0.0,
      "learning_rate": 0.0007861543089884468,
      "loss": 5.2039,
      "step": 2851
    },
    {
      "epoch": 0.32702671711959636,
      "grad_norm": 0.0,
      "learning_rate": 0.000786002021705024,
      "loss": 4.9141,
      "step": 2852
    },
    {
      "epoch": 0.32714138286893707,
      "grad_norm": 0.0,
      "learning_rate": 0.0007858496949799706,
      "loss": 5.1078,
      "step": 2853
    },
    {
      "epoch": 0.32725604861827773,
      "grad_norm": 0.0,
      "learning_rate": 0.0007856973288342973,
      "loss": 4.9308,
      "step": 2854
    },
    {
      "epoch": 0.3273707143676184,
      "grad_norm": 0.0,
      "learning_rate": 0.0007855449232890197,
      "loss": 5.2214,
      "step": 2855
    },
    {
      "epoch": 0.32748538011695905,
      "grad_norm": 0.0,
      "learning_rate": 0.0007853924783651594,
      "loss": 5.2131,
      "step": 2856
    },
    {
      "epoch": 0.32760004586629976,
      "grad_norm": 0.0,
      "learning_rate": 0.0007852399940837436,
      "loss": 4.8667,
      "step": 2857
    },
    {
      "epoch": 0.3277147116156404,
      "grad_norm": 0.0,
      "learning_rate": 0.0007850874704658041,
      "loss": 4.9645,
      "step": 2858
    },
    {
      "epoch": 0.3278293773649811,
      "grad_norm": 0.0,
      "learning_rate": 0.000784934907532379,
      "loss": 4.8565,
      "step": 2859
    },
    {
      "epoch": 0.32794404311432174,
      "grad_norm": 0.0,
      "learning_rate": 0.0007847823053045113,
      "loss": 4.8991,
      "step": 2860
    },
    {
      "epoch": 0.32805870886366245,
      "grad_norm": 0.0,
      "learning_rate": 0.0007846296638032495,
      "loss": 5.1462,
      "step": 2861
    },
    {
      "epoch": 0.3281733746130031,
      "grad_norm": 0.0,
      "learning_rate": 0.0007844769830496476,
      "loss": 5.0785,
      "step": 2862
    },
    {
      "epoch": 0.32828804036234377,
      "grad_norm": 0.0,
      "learning_rate": 0.0007843242630647654,
      "loss": 5.1432,
      "step": 2863
    },
    {
      "epoch": 0.32840270611168443,
      "grad_norm": 0.0,
      "learning_rate": 0.0007841715038696672,
      "loss": 4.892,
      "step": 2864
    },
    {
      "epoch": 0.3285173718610251,
      "grad_norm": 0.0,
      "learning_rate": 0.0007840187054854232,
      "loss": 5.1308,
      "step": 2865
    },
    {
      "epoch": 0.3286320376103658,
      "grad_norm": 0.0,
      "learning_rate": 0.0007838658679331093,
      "loss": 5.2078,
      "step": 2866
    },
    {
      "epoch": 0.32874670335970646,
      "grad_norm": 0.0,
      "learning_rate": 0.0007837129912338065,
      "loss": 5.1326,
      "step": 2867
    },
    {
      "epoch": 0.3288613691090471,
      "grad_norm": 0.0,
      "learning_rate": 0.0007835600754086012,
      "loss": 4.8496,
      "step": 2868
    },
    {
      "epoch": 0.3289760348583878,
      "grad_norm": 0.0,
      "learning_rate": 0.0007834071204785851,
      "loss": 5.2625,
      "step": 2869
    },
    {
      "epoch": 0.3290907006077285,
      "grad_norm": 0.0,
      "learning_rate": 0.0007832541264648557,
      "loss": 4.9474,
      "step": 2870
    },
    {
      "epoch": 0.32920536635706915,
      "grad_norm": 0.0,
      "learning_rate": 0.000783101093388515,
      "loss": 5.0725,
      "step": 2871
    },
    {
      "epoch": 0.3293200321064098,
      "grad_norm": 0.0,
      "learning_rate": 0.0007829480212706717,
      "loss": 5.1948,
      "step": 2872
    },
    {
      "epoch": 0.32943469785575047,
      "grad_norm": 0.0,
      "learning_rate": 0.000782794910132439,
      "loss": 5.0759,
      "step": 2873
    },
    {
      "epoch": 0.3295493636050912,
      "grad_norm": 0.0,
      "learning_rate": 0.0007826417599949354,
      "loss": 4.9231,
      "step": 2874
    },
    {
      "epoch": 0.32966402935443184,
      "grad_norm": 0.0,
      "learning_rate": 0.0007824885708792854,
      "loss": 4.8502,
      "step": 2875
    },
    {
      "epoch": 0.3297786951037725,
      "grad_norm": 0.0,
      "learning_rate": 0.000782335342806618,
      "loss": 5.0227,
      "step": 2876
    },
    {
      "epoch": 0.32989336085311316,
      "grad_norm": 0.0,
      "learning_rate": 0.0007821820757980685,
      "loss": 5.0793,
      "step": 2877
    },
    {
      "epoch": 0.3300080266024539,
      "grad_norm": 0.0,
      "learning_rate": 0.000782028769874777,
      "loss": 4.8304,
      "step": 2878
    },
    {
      "epoch": 0.33012269235179453,
      "grad_norm": 0.0,
      "learning_rate": 0.0007818754250578894,
      "loss": 5.164,
      "step": 2879
    },
    {
      "epoch": 0.3302373581011352,
      "grad_norm": 0.0,
      "learning_rate": 0.0007817220413685565,
      "loss": 5.1016,
      "step": 2880
    },
    {
      "epoch": 0.33035202385047585,
      "grad_norm": 0.0,
      "learning_rate": 0.0007815686188279345,
      "loss": 4.9968,
      "step": 2881
    },
    {
      "epoch": 0.3304666895998165,
      "grad_norm": 0.0,
      "learning_rate": 0.0007814151574571852,
      "loss": 4.9075,
      "step": 2882
    },
    {
      "epoch": 0.3305813553491572,
      "grad_norm": 0.0,
      "learning_rate": 0.000781261657277476,
      "loss": 5.2445,
      "step": 2883
    },
    {
      "epoch": 0.3306960210984979,
      "grad_norm": 0.0,
      "learning_rate": 0.0007811081183099789,
      "loss": 4.7548,
      "step": 2884
    },
    {
      "epoch": 0.33081068684783854,
      "grad_norm": 0.0,
      "learning_rate": 0.0007809545405758718,
      "loss": 4.8288,
      "step": 2885
    },
    {
      "epoch": 0.3309253525971792,
      "grad_norm": 0.0,
      "learning_rate": 0.0007808009240963381,
      "loss": 5.1348,
      "step": 2886
    },
    {
      "epoch": 0.3310400183465199,
      "grad_norm": 0.0,
      "learning_rate": 0.0007806472688925657,
      "loss": 4.9616,
      "step": 2887
    },
    {
      "epoch": 0.3311546840958606,
      "grad_norm": 0.0,
      "learning_rate": 0.000780493574985749,
      "loss": 5.0577,
      "step": 2888
    },
    {
      "epoch": 0.33126934984520123,
      "grad_norm": 0.0,
      "learning_rate": 0.0007803398423970866,
      "loss": 4.9226,
      "step": 2889
    },
    {
      "epoch": 0.3313840155945419,
      "grad_norm": 0.0,
      "learning_rate": 0.0007801860711477834,
      "loss": 5.0326,
      "step": 2890
    },
    {
      "epoch": 0.3314986813438826,
      "grad_norm": 0.0,
      "learning_rate": 0.0007800322612590491,
      "loss": 5.1705,
      "step": 2891
    },
    {
      "epoch": 0.33161334709322327,
      "grad_norm": 0.0,
      "learning_rate": 0.0007798784127520988,
      "loss": 4.8671,
      "step": 2892
    },
    {
      "epoch": 0.3317280128425639,
      "grad_norm": 0.0,
      "learning_rate": 0.0007797245256481528,
      "loss": 5.1584,
      "step": 2893
    },
    {
      "epoch": 0.3318426785919046,
      "grad_norm": 0.0,
      "learning_rate": 0.0007795705999684373,
      "loss": 5.0245,
      "step": 2894
    },
    {
      "epoch": 0.3319573443412453,
      "grad_norm": 0.0,
      "learning_rate": 0.000779416635734183,
      "loss": 5.2947,
      "step": 2895
    },
    {
      "epoch": 0.33207201009058596,
      "grad_norm": 0.0,
      "learning_rate": 0.0007792626329666267,
      "loss": 5.0477,
      "step": 2896
    },
    {
      "epoch": 0.3321866758399266,
      "grad_norm": 0.0,
      "learning_rate": 0.0007791085916870099,
      "loss": 5.123,
      "step": 2897
    },
    {
      "epoch": 0.3323013415892673,
      "grad_norm": 0.0,
      "learning_rate": 0.0007789545119165795,
      "loss": 5.2535,
      "step": 2898
    },
    {
      "epoch": 0.33241600733860793,
      "grad_norm": 0.0,
      "learning_rate": 0.0007788003936765881,
      "loss": 4.9119,
      "step": 2899
    },
    {
      "epoch": 0.33253067308794865,
      "grad_norm": 0.0,
      "learning_rate": 0.0007786462369882937,
      "loss": 5.0845,
      "step": 2900
    },
    {
      "epoch": 0.3326453388372893,
      "grad_norm": 0.0,
      "learning_rate": 0.0007784920418729588,
      "loss": 5.0609,
      "step": 2901
    },
    {
      "epoch": 0.33276000458662996,
      "grad_norm": 0.0,
      "learning_rate": 0.0007783378083518517,
      "loss": 4.8964,
      "step": 2902
    },
    {
      "epoch": 0.3328746703359706,
      "grad_norm": 0.0,
      "learning_rate": 0.0007781835364462461,
      "loss": 5.1813,
      "step": 2903
    },
    {
      "epoch": 0.33298933608531134,
      "grad_norm": 0.0,
      "learning_rate": 0.0007780292261774209,
      "loss": 4.8994,
      "step": 2904
    },
    {
      "epoch": 0.333104001834652,
      "grad_norm": 0.0,
      "learning_rate": 0.0007778748775666603,
      "loss": 5.0967,
      "step": 2905
    },
    {
      "epoch": 0.33321866758399266,
      "grad_norm": 0.0,
      "learning_rate": 0.0007777204906352535,
      "loss": 4.9437,
      "step": 2906
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.0,
      "learning_rate": 0.0007775660654044954,
      "loss": 4.9104,
      "step": 2907
    },
    {
      "epoch": 0.33344799908267403,
      "grad_norm": 0.0,
      "learning_rate": 0.0007774116018956863,
      "loss": 5.2134,
      "step": 2908
    },
    {
      "epoch": 0.3335626648320147,
      "grad_norm": 0.0,
      "learning_rate": 0.0007772571001301309,
      "loss": 4.8364,
      "step": 2909
    },
    {
      "epoch": 0.33367733058135535,
      "grad_norm": 0.0,
      "learning_rate": 0.0007771025601291402,
      "loss": 4.7893,
      "step": 2910
    },
    {
      "epoch": 0.333791996330696,
      "grad_norm": 0.0,
      "learning_rate": 0.00077694798191403,
      "loss": 5.1995,
      "step": 2911
    },
    {
      "epoch": 0.3339066620800367,
      "grad_norm": 0.0,
      "learning_rate": 0.0007767933655061213,
      "loss": 4.7051,
      "step": 2912
    },
    {
      "epoch": 0.3340213278293774,
      "grad_norm": 0.0,
      "learning_rate": 0.0007766387109267404,
      "loss": 4.964,
      "step": 2913
    },
    {
      "epoch": 0.33413599357871804,
      "grad_norm": 0.0,
      "learning_rate": 0.0007764840181972193,
      "loss": 5.0605,
      "step": 2914
    },
    {
      "epoch": 0.3342506593280587,
      "grad_norm": 0.0,
      "learning_rate": 0.0007763292873388945,
      "loss": 4.8413,
      "step": 2915
    },
    {
      "epoch": 0.33436532507739936,
      "grad_norm": 0.0,
      "learning_rate": 0.0007761745183731086,
      "loss": 4.8768,
      "step": 2916
    },
    {
      "epoch": 0.33447999082674007,
      "grad_norm": 0.0,
      "learning_rate": 0.0007760197113212085,
      "loss": 4.9677,
      "step": 2917
    },
    {
      "epoch": 0.33459465657608073,
      "grad_norm": 0.0,
      "learning_rate": 0.0007758648662045473,
      "loss": 4.8866,
      "step": 2918
    },
    {
      "epoch": 0.3347093223254214,
      "grad_norm": 0.0,
      "learning_rate": 0.000775709983044483,
      "loss": 4.9454,
      "step": 2919
    },
    {
      "epoch": 0.33482398807476205,
      "grad_norm": 0.0,
      "learning_rate": 0.0007755550618623784,
      "loss": 4.7881,
      "step": 2920
    },
    {
      "epoch": 0.33493865382410276,
      "grad_norm": 0.0,
      "learning_rate": 0.0007754001026796022,
      "loss": 5.0615,
      "step": 2921
    },
    {
      "epoch": 0.3350533195734434,
      "grad_norm": 0.0,
      "learning_rate": 0.000775245105517528,
      "loss": 5.239,
      "step": 2922
    },
    {
      "epoch": 0.3351679853227841,
      "grad_norm": 0.0,
      "learning_rate": 0.0007750900703975347,
      "loss": 5.2401,
      "step": 2923
    },
    {
      "epoch": 0.33528265107212474,
      "grad_norm": 0.0,
      "learning_rate": 0.0007749349973410063,
      "loss": 5.0435,
      "step": 2924
    },
    {
      "epoch": 0.33539731682146545,
      "grad_norm": 0.0,
      "learning_rate": 0.0007747798863693325,
      "loss": 5.0036,
      "step": 2925
    },
    {
      "epoch": 0.3355119825708061,
      "grad_norm": 0.0,
      "learning_rate": 0.0007746247375039076,
      "loss": 4.7587,
      "step": 2926
    },
    {
      "epoch": 0.33562664832014677,
      "grad_norm": 0.0,
      "learning_rate": 0.0007744695507661316,
      "loss": 4.9731,
      "step": 2927
    },
    {
      "epoch": 0.33574131406948743,
      "grad_norm": 0.0,
      "learning_rate": 0.0007743143261774094,
      "loss": 4.9839,
      "step": 2928
    },
    {
      "epoch": 0.33585597981882814,
      "grad_norm": 0.0,
      "learning_rate": 0.0007741590637591512,
      "loss": 5.126,
      "step": 2929
    },
    {
      "epoch": 0.3359706455681688,
      "grad_norm": 0.0,
      "learning_rate": 0.0007740037635327729,
      "loss": 5.0249,
      "step": 2930
    },
    {
      "epoch": 0.33608531131750946,
      "grad_norm": 0.0,
      "learning_rate": 0.0007738484255196949,
      "loss": 5.1145,
      "step": 2931
    },
    {
      "epoch": 0.3361999770668501,
      "grad_norm": 0.0,
      "learning_rate": 0.0007736930497413432,
      "loss": 4.7916,
      "step": 2932
    },
    {
      "epoch": 0.3363146428161908,
      "grad_norm": 0.0,
      "learning_rate": 0.0007735376362191489,
      "loss": 5.0713,
      "step": 2933
    },
    {
      "epoch": 0.3364293085655315,
      "grad_norm": 0.0,
      "learning_rate": 0.0007733821849745481,
      "loss": 5.0586,
      "step": 2934
    },
    {
      "epoch": 0.33654397431487215,
      "grad_norm": 0.0,
      "learning_rate": 0.0007732266960289828,
      "loss": 4.9206,
      "step": 2935
    },
    {
      "epoch": 0.3366586400642128,
      "grad_norm": 0.0,
      "learning_rate": 0.0007730711694038996,
      "loss": 5.1577,
      "step": 2936
    },
    {
      "epoch": 0.33677330581355347,
      "grad_norm": 0.0,
      "learning_rate": 0.00077291560512075,
      "loss": 4.892,
      "step": 2937
    },
    {
      "epoch": 0.3368879715628942,
      "grad_norm": 0.0,
      "learning_rate": 0.0007727600032009918,
      "loss": 5.1424,
      "step": 2938
    },
    {
      "epoch": 0.33700263731223484,
      "grad_norm": 0.0,
      "learning_rate": 0.0007726043636660868,
      "loss": 5.1857,
      "step": 2939
    },
    {
      "epoch": 0.3371173030615755,
      "grad_norm": 0.0,
      "learning_rate": 0.0007724486865375028,
      "loss": 4.7127,
      "step": 2940
    },
    {
      "epoch": 0.33723196881091616,
      "grad_norm": 0.0,
      "learning_rate": 0.0007722929718367123,
      "loss": 4.9687,
      "step": 2941
    },
    {
      "epoch": 0.3373466345602569,
      "grad_norm": 0.0,
      "learning_rate": 0.0007721372195851933,
      "loss": 4.7287,
      "step": 2942
    },
    {
      "epoch": 0.33746130030959753,
      "grad_norm": 0.0,
      "learning_rate": 0.0007719814298044287,
      "loss": 5.0573,
      "step": 2943
    },
    {
      "epoch": 0.3375759660589382,
      "grad_norm": 0.0,
      "learning_rate": 0.0007718256025159069,
      "loss": 4.8305,
      "step": 2944
    },
    {
      "epoch": 0.33769063180827885,
      "grad_norm": 0.0,
      "learning_rate": 0.0007716697377411213,
      "loss": 5.1571,
      "step": 2945
    },
    {
      "epoch": 0.33780529755761957,
      "grad_norm": 0.0,
      "learning_rate": 0.0007715138355015705,
      "loss": 5.0215,
      "step": 2946
    },
    {
      "epoch": 0.3379199633069602,
      "grad_norm": 0.0,
      "learning_rate": 0.0007713578958187581,
      "loss": 5.056,
      "step": 2947
    },
    {
      "epoch": 0.3380346290563009,
      "grad_norm": 0.0,
      "learning_rate": 0.0007712019187141929,
      "loss": 5.0857,
      "step": 2948
    },
    {
      "epoch": 0.33814929480564154,
      "grad_norm": 0.0,
      "learning_rate": 0.0007710459042093894,
      "loss": 4.9111,
      "step": 2949
    },
    {
      "epoch": 0.3382639605549822,
      "grad_norm": 0.0,
      "learning_rate": 0.0007708898523258664,
      "loss": 4.9157,
      "step": 2950
    },
    {
      "epoch": 0.3383786263043229,
      "grad_norm": 0.0,
      "learning_rate": 0.0007707337630851486,
      "loss": 4.9883,
      "step": 2951
    },
    {
      "epoch": 0.3384932920536636,
      "grad_norm": 0.0,
      "learning_rate": 0.0007705776365087652,
      "loss": 5.0711,
      "step": 2952
    },
    {
      "epoch": 0.33860795780300423,
      "grad_norm": 0.0,
      "learning_rate": 0.0007704214726182512,
      "loss": 4.6506,
      "step": 2953
    },
    {
      "epoch": 0.3387226235523449,
      "grad_norm": 0.0,
      "learning_rate": 0.0007702652714351462,
      "loss": 4.9567,
      "step": 2954
    },
    {
      "epoch": 0.3388372893016856,
      "grad_norm": 0.0,
      "learning_rate": 0.0007701090329809954,
      "loss": 5.2644,
      "step": 2955
    },
    {
      "epoch": 0.33895195505102627,
      "grad_norm": 0.0,
      "learning_rate": 0.0007699527572773485,
      "loss": 4.958,
      "step": 2956
    },
    {
      "epoch": 0.3390666208003669,
      "grad_norm": 0.0,
      "learning_rate": 0.0007697964443457614,
      "loss": 4.9904,
      "step": 2957
    },
    {
      "epoch": 0.3391812865497076,
      "grad_norm": 0.0,
      "learning_rate": 0.000769640094207794,
      "loss": 4.8808,
      "step": 2958
    },
    {
      "epoch": 0.3392959522990483,
      "grad_norm": 0.0,
      "learning_rate": 0.000769483706885012,
      "loss": 5.5959,
      "step": 2959
    },
    {
      "epoch": 0.33941061804838896,
      "grad_norm": 0.0,
      "learning_rate": 0.0007693272823989859,
      "loss": 5.16,
      "step": 2960
    },
    {
      "epoch": 0.3395252837977296,
      "grad_norm": 0.0,
      "learning_rate": 0.0007691708207712917,
      "loss": 4.9195,
      "step": 2961
    },
    {
      "epoch": 0.3396399495470703,
      "grad_norm": 0.0,
      "learning_rate": 0.00076901432202351,
      "loss": 5.0474,
      "step": 2962
    },
    {
      "epoch": 0.339754615296411,
      "grad_norm": 0.0,
      "learning_rate": 0.0007688577861772272,
      "loss": 4.8334,
      "step": 2963
    },
    {
      "epoch": 0.33986928104575165,
      "grad_norm": 0.0,
      "learning_rate": 0.0007687012132540343,
      "loss": 5.107,
      "step": 2964
    },
    {
      "epoch": 0.3399839467950923,
      "grad_norm": 0.0,
      "learning_rate": 0.0007685446032755272,
      "loss": 5.0353,
      "step": 2965
    },
    {
      "epoch": 0.34009861254443297,
      "grad_norm": 0.0,
      "learning_rate": 0.0007683879562633078,
      "loss": 5.1374,
      "step": 2966
    },
    {
      "epoch": 0.3402132782937736,
      "grad_norm": 0.0,
      "learning_rate": 0.0007682312722389823,
      "loss": 5.0969,
      "step": 2967
    },
    {
      "epoch": 0.34032794404311434,
      "grad_norm": 0.0,
      "learning_rate": 0.0007680745512241621,
      "loss": 5.0006,
      "step": 2968
    },
    {
      "epoch": 0.340442609792455,
      "grad_norm": 0.0,
      "learning_rate": 0.0007679177932404644,
      "loss": 5.0602,
      "step": 2969
    },
    {
      "epoch": 0.34055727554179566,
      "grad_norm": 0.0,
      "learning_rate": 0.0007677609983095102,
      "loss": 5.2121,
      "step": 2970
    },
    {
      "epoch": 0.3406719412911363,
      "grad_norm": 0.0,
      "learning_rate": 0.0007676041664529271,
      "loss": 4.9166,
      "step": 2971
    },
    {
      "epoch": 0.34078660704047703,
      "grad_norm": 0.0,
      "learning_rate": 0.0007674472976923467,
      "loss": 5.0357,
      "step": 2972
    },
    {
      "epoch": 0.3409012727898177,
      "grad_norm": 0.0,
      "learning_rate": 0.0007672903920494063,
      "loss": 4.9515,
      "step": 2973
    },
    {
      "epoch": 0.34101593853915835,
      "grad_norm": 0.0,
      "learning_rate": 0.0007671334495457478,
      "loss": 5.2308,
      "step": 2974
    },
    {
      "epoch": 0.341130604288499,
      "grad_norm": 0.0,
      "learning_rate": 0.0007669764702030185,
      "loss": 4.8264,
      "step": 2975
    },
    {
      "epoch": 0.3412452700378397,
      "grad_norm": 0.0,
      "learning_rate": 0.0007668194540428706,
      "loss": 5.207,
      "step": 2976
    },
    {
      "epoch": 0.3413599357871804,
      "grad_norm": 0.0,
      "learning_rate": 0.0007666624010869618,
      "loss": 4.8181,
      "step": 2977
    },
    {
      "epoch": 0.34147460153652104,
      "grad_norm": 0.0,
      "learning_rate": 0.0007665053113569542,
      "loss": 4.9362,
      "step": 2978
    },
    {
      "epoch": 0.3415892672858617,
      "grad_norm": 0.0,
      "learning_rate": 0.0007663481848745158,
      "loss": 5.0864,
      "step": 2979
    },
    {
      "epoch": 0.3417039330352024,
      "grad_norm": 0.0,
      "learning_rate": 0.0007661910216613185,
      "loss": 5.2105,
      "step": 2980
    },
    {
      "epoch": 0.34181859878454307,
      "grad_norm": 0.0,
      "learning_rate": 0.0007660338217390406,
      "loss": 5.1518,
      "step": 2981
    },
    {
      "epoch": 0.34193326453388373,
      "grad_norm": 0.0,
      "learning_rate": 0.0007658765851293644,
      "loss": 4.9255,
      "step": 2982
    },
    {
      "epoch": 0.3420479302832244,
      "grad_norm": 0.0,
      "learning_rate": 0.0007657193118539782,
      "loss": 5.0398,
      "step": 2983
    },
    {
      "epoch": 0.34216259603256505,
      "grad_norm": 0.0,
      "learning_rate": 0.0007655620019345744,
      "loss": 4.8994,
      "step": 2984
    },
    {
      "epoch": 0.34227726178190576,
      "grad_norm": 0.0,
      "learning_rate": 0.0007654046553928511,
      "loss": 4.9538,
      "step": 2985
    },
    {
      "epoch": 0.3423919275312464,
      "grad_norm": 0.0,
      "learning_rate": 0.0007652472722505111,
      "loss": 4.8392,
      "step": 2986
    },
    {
      "epoch": 0.3425065932805871,
      "grad_norm": 0.0,
      "learning_rate": 0.0007650898525292625,
      "loss": 5.0106,
      "step": 2987
    },
    {
      "epoch": 0.34262125902992774,
      "grad_norm": 0.0,
      "learning_rate": 0.0007649323962508185,
      "loss": 4.947,
      "step": 2988
    },
    {
      "epoch": 0.34273592477926845,
      "grad_norm": 0.0,
      "learning_rate": 0.000764774903436897,
      "loss": 4.8886,
      "step": 2989
    },
    {
      "epoch": 0.3428505905286091,
      "grad_norm": 0.0,
      "learning_rate": 0.0007646173741092211,
      "loss": 5.0022,
      "step": 2990
    },
    {
      "epoch": 0.34296525627794977,
      "grad_norm": 0.0,
      "learning_rate": 0.0007644598082895192,
      "loss": 4.9672,
      "step": 2991
    },
    {
      "epoch": 0.34307992202729043,
      "grad_norm": 0.0,
      "learning_rate": 0.0007643022059995243,
      "loss": 5.0102,
      "step": 2992
    },
    {
      "epoch": 0.34319458777663114,
      "grad_norm": 0.0,
      "learning_rate": 0.0007641445672609745,
      "loss": 4.9585,
      "step": 2993
    },
    {
      "epoch": 0.3433092535259718,
      "grad_norm": 0.0,
      "learning_rate": 0.0007639868920956136,
      "loss": 4.9829,
      "step": 2994
    },
    {
      "epoch": 0.34342391927531246,
      "grad_norm": 0.0,
      "learning_rate": 0.0007638291805251892,
      "loss": 5.1373,
      "step": 2995
    },
    {
      "epoch": 0.3435385850246531,
      "grad_norm": 0.0,
      "learning_rate": 0.0007636714325714552,
      "loss": 4.7279,
      "step": 2996
    },
    {
      "epoch": 0.34365325077399383,
      "grad_norm": 0.0,
      "learning_rate": 0.0007635136482561695,
      "loss": 5.1014,
      "step": 2997
    },
    {
      "epoch": 0.3437679165233345,
      "grad_norm": 0.0,
      "learning_rate": 0.0007633558276010957,
      "loss": 5.0212,
      "step": 2998
    },
    {
      "epoch": 0.34388258227267515,
      "grad_norm": 0.0,
      "learning_rate": 0.0007631979706280019,
      "loss": 5.0738,
      "step": 2999
    },
    {
      "epoch": 0.3439972480220158,
      "grad_norm": 0.0,
      "learning_rate": 0.0007630400773586618,
      "loss": 5.1093,
      "step": 3000
    },
    {
      "epoch": 0.34411191377135647,
      "grad_norm": 0.0,
      "learning_rate": 0.0007628821478148533,
      "loss": 4.9736,
      "step": 3001
    },
    {
      "epoch": 0.3442265795206972,
      "grad_norm": 0.0,
      "learning_rate": 0.0007627241820183602,
      "loss": 5.0833,
      "step": 3002
    },
    {
      "epoch": 0.34434124527003784,
      "grad_norm": 0.0,
      "learning_rate": 0.0007625661799909709,
      "loss": 4.9425,
      "step": 3003
    },
    {
      "epoch": 0.3444559110193785,
      "grad_norm": 0.0,
      "learning_rate": 0.0007624081417544784,
      "loss": 5.0321,
      "step": 3004
    },
    {
      "epoch": 0.34457057676871916,
      "grad_norm": 0.0,
      "learning_rate": 0.0007622500673306813,
      "loss": 5.0411,
      "step": 3005
    },
    {
      "epoch": 0.3446852425180599,
      "grad_norm": 0.0,
      "learning_rate": 0.0007620919567413827,
      "loss": 5.0755,
      "step": 3006
    },
    {
      "epoch": 0.34479990826740053,
      "grad_norm": 0.0,
      "learning_rate": 0.0007619338100083914,
      "loss": 5.0698,
      "step": 3007
    },
    {
      "epoch": 0.3449145740167412,
      "grad_norm": 0.0,
      "learning_rate": 0.0007617756271535203,
      "loss": 4.9982,
      "step": 3008
    },
    {
      "epoch": 0.34502923976608185,
      "grad_norm": 0.0,
      "learning_rate": 0.000761617408198588,
      "loss": 4.9148,
      "step": 3009
    },
    {
      "epoch": 0.34514390551542257,
      "grad_norm": 0.0,
      "learning_rate": 0.0007614591531654176,
      "loss": 5.0978,
      "step": 3010
    },
    {
      "epoch": 0.3452585712647632,
      "grad_norm": 0.0,
      "learning_rate": 0.0007613008620758374,
      "loss": 4.8615,
      "step": 3011
    },
    {
      "epoch": 0.3453732370141039,
      "grad_norm": 0.0,
      "learning_rate": 0.0007611425349516809,
      "loss": 4.9417,
      "step": 3012
    },
    {
      "epoch": 0.34548790276344454,
      "grad_norm": 0.0,
      "learning_rate": 0.0007609841718147857,
      "loss": 4.6965,
      "step": 3013
    },
    {
      "epoch": 0.34560256851278526,
      "grad_norm": 0.0,
      "learning_rate": 0.0007608257726869956,
      "loss": 4.9894,
      "step": 3014
    },
    {
      "epoch": 0.3457172342621259,
      "grad_norm": 0.0,
      "learning_rate": 0.0007606673375901587,
      "loss": 5.2894,
      "step": 3015
    },
    {
      "epoch": 0.3458319000114666,
      "grad_norm": 0.0,
      "learning_rate": 0.0007605088665461274,
      "loss": 5.2587,
      "step": 3016
    },
    {
      "epoch": 0.34594656576080723,
      "grad_norm": 0.0,
      "learning_rate": 0.0007603503595767605,
      "loss": 5.1469,
      "step": 3017
    },
    {
      "epoch": 0.3460612315101479,
      "grad_norm": 0.0,
      "learning_rate": 0.0007601918167039209,
      "loss": 4.9164,
      "step": 3018
    },
    {
      "epoch": 0.3461758972594886,
      "grad_norm": 0.0,
      "learning_rate": 0.0007600332379494762,
      "loss": 4.8437,
      "step": 3019
    },
    {
      "epoch": 0.34629056300882927,
      "grad_norm": 0.0,
      "learning_rate": 0.0007598746233352997,
      "loss": 4.9707,
      "step": 3020
    },
    {
      "epoch": 0.3464052287581699,
      "grad_norm": 0.0,
      "learning_rate": 0.0007597159728832691,
      "loss": 4.9898,
      "step": 3021
    },
    {
      "epoch": 0.3465198945075106,
      "grad_norm": 0.0,
      "learning_rate": 0.0007595572866152672,
      "loss": 5.1285,
      "step": 3022
    },
    {
      "epoch": 0.3466345602568513,
      "grad_norm": 0.0,
      "learning_rate": 0.0007593985645531819,
      "loss": 4.8025,
      "step": 3023
    },
    {
      "epoch": 0.34674922600619196,
      "grad_norm": 0.0,
      "learning_rate": 0.0007592398067189054,
      "loss": 4.9926,
      "step": 3024
    },
    {
      "epoch": 0.3468638917555326,
      "grad_norm": 0.0,
      "learning_rate": 0.0007590810131343362,
      "loss": 5.2821,
      "step": 3025
    },
    {
      "epoch": 0.3469785575048733,
      "grad_norm": 0.0,
      "learning_rate": 0.000758922183821376,
      "loss": 5.3584,
      "step": 3026
    },
    {
      "epoch": 0.347093223254214,
      "grad_norm": 0.0,
      "learning_rate": 0.0007587633188019325,
      "loss": 4.9153,
      "step": 3027
    },
    {
      "epoch": 0.34720788900355465,
      "grad_norm": 0.0,
      "learning_rate": 0.0007586044180979183,
      "loss": 4.8422,
      "step": 3028
    },
    {
      "epoch": 0.3473225547528953,
      "grad_norm": 0.0,
      "learning_rate": 0.0007584454817312509,
      "loss": 4.6976,
      "step": 3029
    },
    {
      "epoch": 0.34743722050223597,
      "grad_norm": 0.0,
      "learning_rate": 0.0007582865097238519,
      "loss": 4.9029,
      "step": 3030
    },
    {
      "epoch": 0.3475518862515767,
      "grad_norm": 0.0,
      "learning_rate": 0.0007581275020976488,
      "loss": 5.3625,
      "step": 3031
    },
    {
      "epoch": 0.34766655200091734,
      "grad_norm": 0.0,
      "learning_rate": 0.0007579684588745738,
      "loss": 4.9712,
      "step": 3032
    },
    {
      "epoch": 0.347781217750258,
      "grad_norm": 0.0,
      "learning_rate": 0.0007578093800765638,
      "loss": 4.9898,
      "step": 3033
    },
    {
      "epoch": 0.34789588349959866,
      "grad_norm": 0.0,
      "learning_rate": 0.0007576502657255607,
      "loss": 5.1141,
      "step": 3034
    },
    {
      "epoch": 0.3480105492489393,
      "grad_norm": 0.0,
      "learning_rate": 0.0007574911158435112,
      "loss": 5.119,
      "step": 3035
    },
    {
      "epoch": 0.34812521499828003,
      "grad_norm": 0.0,
      "learning_rate": 0.000757331930452367,
      "loss": 5.1857,
      "step": 3036
    },
    {
      "epoch": 0.3482398807476207,
      "grad_norm": 0.0,
      "learning_rate": 0.0007571727095740849,
      "loss": 5.1052,
      "step": 3037
    },
    {
      "epoch": 0.34835454649696135,
      "grad_norm": 0.0,
      "learning_rate": 0.000757013453230626,
      "loss": 5.0515,
      "step": 3038
    },
    {
      "epoch": 0.348469212246302,
      "grad_norm": 0.0,
      "learning_rate": 0.000756854161443957,
      "loss": 4.9537,
      "step": 3039
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 0.0,
      "learning_rate": 0.000756694834236049,
      "loss": 4.9454,
      "step": 3040
    },
    {
      "epoch": 0.3486985437449834,
      "grad_norm": 0.0,
      "learning_rate": 0.0007565354716288782,
      "loss": 4.7464,
      "step": 3041
    },
    {
      "epoch": 0.34881320949432404,
      "grad_norm": 0.0,
      "learning_rate": 0.0007563760736444259,
      "loss": 5.1594,
      "step": 3042
    },
    {
      "epoch": 0.3489278752436647,
      "grad_norm": 0.0,
      "learning_rate": 0.0007562166403046775,
      "loss": 4.9783,
      "step": 3043
    },
    {
      "epoch": 0.3490425409930054,
      "grad_norm": 0.0,
      "learning_rate": 0.000756057171631624,
      "loss": 4.8579,
      "step": 3044
    },
    {
      "epoch": 0.34915720674234607,
      "grad_norm": 0.0,
      "learning_rate": 0.0007558976676472614,
      "loss": 5.3223,
      "step": 3045
    },
    {
      "epoch": 0.34927187249168673,
      "grad_norm": 0.0,
      "learning_rate": 0.0007557381283735897,
      "loss": 4.8896,
      "step": 3046
    },
    {
      "epoch": 0.3493865382410274,
      "grad_norm": 0.0,
      "learning_rate": 0.0007555785538326147,
      "loss": 4.7733,
      "step": 3047
    },
    {
      "epoch": 0.3495012039903681,
      "grad_norm": 0.0,
      "learning_rate": 0.0007554189440463464,
      "loss": 4.9212,
      "step": 3048
    },
    {
      "epoch": 0.34961586973970876,
      "grad_norm": 0.0,
      "learning_rate": 0.0007552592990368,
      "loss": 5.1941,
      "step": 3049
    },
    {
      "epoch": 0.3497305354890494,
      "grad_norm": 0.0,
      "learning_rate": 0.0007550996188259956,
      "loss": 5.0555,
      "step": 3050
    },
    {
      "epoch": 0.3498452012383901,
      "grad_norm": 0.0,
      "learning_rate": 0.0007549399034359582,
      "loss": 5.2125,
      "step": 3051
    },
    {
      "epoch": 0.34995986698773074,
      "grad_norm": 0.0,
      "learning_rate": 0.0007547801528887169,
      "loss": 5.1408,
      "step": 3052
    },
    {
      "epoch": 0.35007453273707145,
      "grad_norm": 0.0,
      "learning_rate": 0.0007546203672063068,
      "loss": 4.9693,
      "step": 3053
    },
    {
      "epoch": 0.3501891984864121,
      "grad_norm": 0.0,
      "learning_rate": 0.0007544605464107669,
      "loss": 5.0109,
      "step": 3054
    },
    {
      "epoch": 0.35030386423575277,
      "grad_norm": 0.0,
      "learning_rate": 0.000754300690524142,
      "loss": 5.1478,
      "step": 3055
    },
    {
      "epoch": 0.35041852998509343,
      "grad_norm": 0.0,
      "learning_rate": 0.0007541407995684807,
      "loss": 5.0324,
      "step": 3056
    },
    {
      "epoch": 0.35053319573443414,
      "grad_norm": 0.0,
      "learning_rate": 0.0007539808735658368,
      "loss": 5.1106,
      "step": 3057
    },
    {
      "epoch": 0.3506478614837748,
      "grad_norm": 0.0,
      "learning_rate": 0.0007538209125382693,
      "loss": 5.1062,
      "step": 3058
    },
    {
      "epoch": 0.35076252723311546,
      "grad_norm": 0.0,
      "learning_rate": 0.0007536609165078418,
      "loss": 5.1129,
      "step": 3059
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 0.0,
      "learning_rate": 0.0007535008854966226,
      "loss": 4.9457,
      "step": 3060
    },
    {
      "epoch": 0.35099185873179684,
      "grad_norm": 0.0,
      "learning_rate": 0.0007533408195266849,
      "loss": 5.1503,
      "step": 3061
    },
    {
      "epoch": 0.3511065244811375,
      "grad_norm": 0.0,
      "learning_rate": 0.000753180718620107,
      "loss": 4.8878,
      "step": 3062
    },
    {
      "epoch": 0.35122119023047815,
      "grad_norm": 0.0,
      "learning_rate": 0.0007530205827989714,
      "loss": 5.0362,
      "step": 3063
    },
    {
      "epoch": 0.3513358559798188,
      "grad_norm": 0.0,
      "learning_rate": 0.000752860412085366,
      "loss": 5.1771,
      "step": 3064
    },
    {
      "epoch": 0.3514505217291595,
      "grad_norm": 0.0,
      "learning_rate": 0.0007527002065013834,
      "loss": 4.9282,
      "step": 3065
    },
    {
      "epoch": 0.3515651874785002,
      "grad_norm": 0.0,
      "learning_rate": 0.0007525399660691204,
      "loss": 5.0267,
      "step": 3066
    },
    {
      "epoch": 0.35167985322784084,
      "grad_norm": 0.0,
      "learning_rate": 0.0007523796908106799,
      "loss": 4.8457,
      "step": 3067
    },
    {
      "epoch": 0.3517945189771815,
      "grad_norm": 0.0,
      "learning_rate": 0.0007522193807481682,
      "loss": 4.9658,
      "step": 3068
    },
    {
      "epoch": 0.35190918472652216,
      "grad_norm": 0.0,
      "learning_rate": 0.0007520590359036972,
      "loss": 5.0459,
      "step": 3069
    },
    {
      "epoch": 0.3520238504758629,
      "grad_norm": 0.0,
      "learning_rate": 0.0007518986562993834,
      "loss": 5.0506,
      "step": 3070
    },
    {
      "epoch": 0.35213851622520354,
      "grad_norm": 0.0,
      "learning_rate": 0.0007517382419573482,
      "loss": 5.0148,
      "step": 3071
    },
    {
      "epoch": 0.3522531819745442,
      "grad_norm": 0.0,
      "learning_rate": 0.0007515777928997176,
      "loss": 5.2017,
      "step": 3072
    },
    {
      "epoch": 0.35236784772388485,
      "grad_norm": 0.0,
      "learning_rate": 0.0007514173091486226,
      "loss": 4.8889,
      "step": 3073
    },
    {
      "epoch": 0.35248251347322557,
      "grad_norm": 0.0,
      "learning_rate": 0.0007512567907261987,
      "loss": 4.9848,
      "step": 3074
    },
    {
      "epoch": 0.3525971792225662,
      "grad_norm": 0.0,
      "learning_rate": 0.0007510962376545867,
      "loss": 4.9346,
      "step": 3075
    },
    {
      "epoch": 0.3527118449719069,
      "grad_norm": 0.0,
      "learning_rate": 0.0007509356499559312,
      "loss": 4.8391,
      "step": 3076
    },
    {
      "epoch": 0.35282651072124754,
      "grad_norm": 0.0,
      "learning_rate": 0.0007507750276523828,
      "loss": 5.2394,
      "step": 3077
    },
    {
      "epoch": 0.35294117647058826,
      "grad_norm": 0.0,
      "learning_rate": 0.0007506143707660962,
      "loss": 5.0031,
      "step": 3078
    },
    {
      "epoch": 0.3530558422199289,
      "grad_norm": 0.0,
      "learning_rate": 0.0007504536793192307,
      "loss": 5.1142,
      "step": 3079
    },
    {
      "epoch": 0.3531705079692696,
      "grad_norm": 0.0,
      "learning_rate": 0.0007502929533339509,
      "loss": 4.8815,
      "step": 3080
    },
    {
      "epoch": 0.35328517371861023,
      "grad_norm": 0.0,
      "learning_rate": 0.0007501321928324254,
      "loss": 4.9846,
      "step": 3081
    },
    {
      "epoch": 0.35339983946795095,
      "grad_norm": 0.0,
      "learning_rate": 0.0007499713978368287,
      "loss": 5.2906,
      "step": 3082
    },
    {
      "epoch": 0.3535145052172916,
      "grad_norm": 0.0,
      "learning_rate": 0.0007498105683693391,
      "loss": 4.955,
      "step": 3083
    },
    {
      "epoch": 0.35362917096663227,
      "grad_norm": 0.0,
      "learning_rate": 0.0007496497044521399,
      "loss": 4.911,
      "step": 3084
    },
    {
      "epoch": 0.3537438367159729,
      "grad_norm": 0.0,
      "learning_rate": 0.0007494888061074193,
      "loss": 5.0035,
      "step": 3085
    },
    {
      "epoch": 0.3538585024653136,
      "grad_norm": 0.0,
      "learning_rate": 0.0007493278733573703,
      "loss": 5.2295,
      "step": 3086
    },
    {
      "epoch": 0.3539731682146543,
      "grad_norm": 0.0,
      "learning_rate": 0.00074916690622419,
      "loss": 5.0257,
      "step": 3087
    },
    {
      "epoch": 0.35408783396399496,
      "grad_norm": 0.0,
      "learning_rate": 0.0007490059047300813,
      "loss": 4.9539,
      "step": 3088
    },
    {
      "epoch": 0.3542024997133356,
      "grad_norm": 0.0,
      "learning_rate": 0.000748844868897251,
      "loss": 4.8351,
      "step": 3089
    },
    {
      "epoch": 0.3543171654626763,
      "grad_norm": 0.0,
      "learning_rate": 0.000748683798747911,
      "loss": 5.0534,
      "step": 3090
    },
    {
      "epoch": 0.354431831212017,
      "grad_norm": 0.0,
      "learning_rate": 0.000748522694304278,
      "loss": 5.1918,
      "step": 3091
    },
    {
      "epoch": 0.35454649696135765,
      "grad_norm": 0.0,
      "learning_rate": 0.000748361555588573,
      "loss": 5.2808,
      "step": 3092
    },
    {
      "epoch": 0.3546611627106983,
      "grad_norm": 0.0,
      "learning_rate": 0.0007482003826230221,
      "loss": 4.9712,
      "step": 3093
    },
    {
      "epoch": 0.35477582846003897,
      "grad_norm": 0.0,
      "learning_rate": 0.0007480391754298561,
      "loss": 4.9185,
      "step": 3094
    },
    {
      "epoch": 0.3548904942093797,
      "grad_norm": 0.0,
      "learning_rate": 0.0007478779340313106,
      "loss": 4.7924,
      "step": 3095
    },
    {
      "epoch": 0.35500515995872034,
      "grad_norm": 0.0,
      "learning_rate": 0.0007477166584496256,
      "loss": 5.0361,
      "step": 3096
    },
    {
      "epoch": 0.355119825708061,
      "grad_norm": 0.0,
      "learning_rate": 0.000747555348707046,
      "loss": 5.1537,
      "step": 3097
    },
    {
      "epoch": 0.35523449145740166,
      "grad_norm": 0.0,
      "learning_rate": 0.0007473940048258213,
      "loss": 5.0693,
      "step": 3098
    },
    {
      "epoch": 0.35534915720674237,
      "grad_norm": 0.0,
      "learning_rate": 0.000747232626828206,
      "loss": 5.0142,
      "step": 3099
    },
    {
      "epoch": 0.35546382295608303,
      "grad_norm": 0.0,
      "learning_rate": 0.0007470712147364592,
      "loss": 5.0555,
      "step": 3100
    },
    {
      "epoch": 0.3555784887054237,
      "grad_norm": 0.0,
      "learning_rate": 0.0007469097685728444,
      "loss": 4.8175,
      "step": 3101
    },
    {
      "epoch": 0.35569315445476435,
      "grad_norm": 0.0,
      "learning_rate": 0.0007467482883596299,
      "loss": 5.0847,
      "step": 3102
    },
    {
      "epoch": 0.355807820204105,
      "grad_norm": 0.0,
      "learning_rate": 0.0007465867741190894,
      "loss": 4.927,
      "step": 3103
    },
    {
      "epoch": 0.3559224859534457,
      "grad_norm": 0.0,
      "learning_rate": 0.0007464252258735,
      "loss": 5.097,
      "step": 3104
    },
    {
      "epoch": 0.3560371517027864,
      "grad_norm": 0.0,
      "learning_rate": 0.0007462636436451446,
      "loss": 4.9148,
      "step": 3105
    },
    {
      "epoch": 0.35615181745212704,
      "grad_norm": 0.0,
      "learning_rate": 0.0007461020274563107,
      "loss": 5.127,
      "step": 3106
    },
    {
      "epoch": 0.3562664832014677,
      "grad_norm": 0.0,
      "learning_rate": 0.0007459403773292893,
      "loss": 4.9443,
      "step": 3107
    },
    {
      "epoch": 0.3563811489508084,
      "grad_norm": 0.0,
      "learning_rate": 0.0007457786932863776,
      "loss": 5.1844,
      "step": 3108
    },
    {
      "epoch": 0.35649581470014907,
      "grad_norm": 0.0,
      "learning_rate": 0.0007456169753498768,
      "loss": 5.0945,
      "step": 3109
    },
    {
      "epoch": 0.35661048044948973,
      "grad_norm": 0.0,
      "learning_rate": 0.0007454552235420924,
      "loss": 5.158,
      "step": 3110
    },
    {
      "epoch": 0.3567251461988304,
      "grad_norm": 0.0,
      "learning_rate": 0.0007452934378853355,
      "loss": 4.9734,
      "step": 3111
    },
    {
      "epoch": 0.3568398119481711,
      "grad_norm": 0.0,
      "learning_rate": 0.000745131618401921,
      "loss": 4.7771,
      "step": 3112
    },
    {
      "epoch": 0.35695447769751176,
      "grad_norm": 0.0,
      "learning_rate": 0.000744969765114169,
      "loss": 5.1181,
      "step": 3113
    },
    {
      "epoch": 0.3570691434468524,
      "grad_norm": 0.0,
      "learning_rate": 0.0007448078780444039,
      "loss": 5.3287,
      "step": 3114
    },
    {
      "epoch": 0.3571838091961931,
      "grad_norm": 0.0,
      "learning_rate": 0.0007446459572149551,
      "loss": 4.7186,
      "step": 3115
    },
    {
      "epoch": 0.3572984749455338,
      "grad_norm": 0.0,
      "learning_rate": 0.0007444840026481564,
      "loss": 4.7713,
      "step": 3116
    },
    {
      "epoch": 0.35741314069487445,
      "grad_norm": 0.0,
      "learning_rate": 0.0007443220143663465,
      "loss": 4.9876,
      "step": 3117
    },
    {
      "epoch": 0.3575278064442151,
      "grad_norm": 0.0,
      "learning_rate": 0.0007441599923918682,
      "loss": 5.0896,
      "step": 3118
    },
    {
      "epoch": 0.35764247219355577,
      "grad_norm": 0.0,
      "learning_rate": 0.0007439979367470698,
      "loss": 5.1263,
      "step": 3119
    },
    {
      "epoch": 0.35775713794289643,
      "grad_norm": 0.0,
      "learning_rate": 0.0007438358474543035,
      "loss": 5.0167,
      "step": 3120
    },
    {
      "epoch": 0.35787180369223714,
      "grad_norm": 0.0,
      "learning_rate": 0.0007436737245359266,
      "loss": 4.9944,
      "step": 3121
    },
    {
      "epoch": 0.3579864694415778,
      "grad_norm": 0.0,
      "learning_rate": 0.0007435115680143008,
      "loss": 5.1565,
      "step": 3122
    },
    {
      "epoch": 0.35810113519091846,
      "grad_norm": 0.0,
      "learning_rate": 0.0007433493779117926,
      "loss": 5.0018,
      "step": 3123
    },
    {
      "epoch": 0.3582158009402591,
      "grad_norm": 0.0,
      "learning_rate": 0.0007431871542507726,
      "loss": 5.1835,
      "step": 3124
    },
    {
      "epoch": 0.35833046668959984,
      "grad_norm": 0.0,
      "learning_rate": 0.000743024897053617,
      "loss": 5.067,
      "step": 3125
    },
    {
      "epoch": 0.3584451324389405,
      "grad_norm": 0.0,
      "learning_rate": 0.0007428626063427059,
      "loss": 5.0504,
      "step": 3126
    },
    {
      "epoch": 0.35855979818828115,
      "grad_norm": 0.0,
      "learning_rate": 0.0007427002821404242,
      "loss": 4.9832,
      "step": 3127
    },
    {
      "epoch": 0.3586744639376218,
      "grad_norm": 0.0,
      "learning_rate": 0.0007425379244691614,
      "loss": 4.9922,
      "step": 3128
    },
    {
      "epoch": 0.3587891296869625,
      "grad_norm": 0.0,
      "learning_rate": 0.0007423755333513116,
      "loss": 4.899,
      "step": 3129
    },
    {
      "epoch": 0.3589037954363032,
      "grad_norm": 0.0,
      "learning_rate": 0.0007422131088092736,
      "loss": 5.1382,
      "step": 3130
    },
    {
      "epoch": 0.35901846118564384,
      "grad_norm": 0.0,
      "learning_rate": 0.0007420506508654508,
      "loss": 5.1224,
      "step": 3131
    },
    {
      "epoch": 0.3591331269349845,
      "grad_norm": 0.0,
      "learning_rate": 0.0007418881595422512,
      "loss": 4.9783,
      "step": 3132
    },
    {
      "epoch": 0.3592477926843252,
      "grad_norm": 0.0,
      "learning_rate": 0.0007417256348620872,
      "loss": 5.067,
      "step": 3133
    },
    {
      "epoch": 0.3593624584336659,
      "grad_norm": 0.0,
      "learning_rate": 0.0007415630768473763,
      "loss": 5.1535,
      "step": 3134
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 0.0,
      "learning_rate": 0.0007414004855205401,
      "loss": 5.4948,
      "step": 3135
    },
    {
      "epoch": 0.3595917899323472,
      "grad_norm": 0.0,
      "learning_rate": 0.000741237860904005,
      "loss": 5.1457,
      "step": 3136
    },
    {
      "epoch": 0.35970645568168785,
      "grad_norm": 0.0,
      "learning_rate": 0.0007410752030202019,
      "loss": 5.1169,
      "step": 3137
    },
    {
      "epoch": 0.35982112143102857,
      "grad_norm": 0.0,
      "learning_rate": 0.0007409125118915663,
      "loss": 5.0231,
      "step": 3138
    },
    {
      "epoch": 0.3599357871803692,
      "grad_norm": 0.0,
      "learning_rate": 0.0007407497875405387,
      "loss": 4.8542,
      "step": 3139
    },
    {
      "epoch": 0.3600504529297099,
      "grad_norm": 0.0,
      "learning_rate": 0.0007405870299895634,
      "loss": 5.1018,
      "step": 3140
    },
    {
      "epoch": 0.36016511867905054,
      "grad_norm": 0.0,
      "learning_rate": 0.0007404242392610898,
      "loss": 4.9581,
      "step": 3141
    },
    {
      "epoch": 0.36027978442839126,
      "grad_norm": 0.0,
      "learning_rate": 0.0007402614153775718,
      "loss": 4.9291,
      "step": 3142
    },
    {
      "epoch": 0.3603944501777319,
      "grad_norm": 0.0,
      "learning_rate": 0.000740098558361468,
      "loss": 4.8804,
      "step": 3143
    },
    {
      "epoch": 0.3605091159270726,
      "grad_norm": 0.0,
      "learning_rate": 0.0007399356682352414,
      "loss": 4.9197,
      "step": 3144
    },
    {
      "epoch": 0.36062378167641324,
      "grad_norm": 0.0,
      "learning_rate": 0.0007397727450213594,
      "loss": 4.9225,
      "step": 3145
    },
    {
      "epoch": 0.36073844742575395,
      "grad_norm": 0.0,
      "learning_rate": 0.0007396097887422944,
      "loss": 5.2088,
      "step": 3146
    },
    {
      "epoch": 0.3608531131750946,
      "grad_norm": 0.0,
      "learning_rate": 0.0007394467994205229,
      "loss": 4.9792,
      "step": 3147
    },
    {
      "epoch": 0.36096777892443527,
      "grad_norm": 0.0,
      "learning_rate": 0.0007392837770785261,
      "loss": 5.1023,
      "step": 3148
    },
    {
      "epoch": 0.3610824446737759,
      "grad_norm": 0.0,
      "learning_rate": 0.0007391207217387901,
      "loss": 5.0125,
      "step": 3149
    },
    {
      "epoch": 0.36119711042311664,
      "grad_norm": 0.0,
      "learning_rate": 0.0007389576334238051,
      "loss": 5.1034,
      "step": 3150
    },
    {
      "epoch": 0.3613117761724573,
      "grad_norm": 0.0,
      "learning_rate": 0.000738794512156066,
      "loss": 5.1187,
      "step": 3151
    },
    {
      "epoch": 0.36142644192179796,
      "grad_norm": 0.0,
      "learning_rate": 0.0007386313579580724,
      "loss": 4.9556,
      "step": 3152
    },
    {
      "epoch": 0.3615411076711386,
      "grad_norm": 0.0,
      "learning_rate": 0.0007384681708523282,
      "loss": 5.1656,
      "step": 3153
    },
    {
      "epoch": 0.3616557734204793,
      "grad_norm": 0.0,
      "learning_rate": 0.000738304950861342,
      "loss": 5.0151,
      "step": 3154
    },
    {
      "epoch": 0.36177043916982,
      "grad_norm": 0.0,
      "learning_rate": 0.0007381416980076268,
      "loss": 4.9812,
      "step": 3155
    },
    {
      "epoch": 0.36188510491916065,
      "grad_norm": 0.0,
      "learning_rate": 0.0007379784123137006,
      "loss": 5.1254,
      "step": 3156
    },
    {
      "epoch": 0.3619997706685013,
      "grad_norm": 0.0,
      "learning_rate": 0.0007378150938020851,
      "loss": 5.0294,
      "step": 3157
    },
    {
      "epoch": 0.36211443641784197,
      "grad_norm": 0.0,
      "learning_rate": 0.000737651742495307,
      "loss": 5.2217,
      "step": 3158
    },
    {
      "epoch": 0.3622291021671827,
      "grad_norm": 0.0,
      "learning_rate": 0.0007374883584158977,
      "loss": 5.015,
      "step": 3159
    },
    {
      "epoch": 0.36234376791652334,
      "grad_norm": 0.0,
      "learning_rate": 0.0007373249415863928,
      "loss": 5.0742,
      "step": 3160
    },
    {
      "epoch": 0.362458433665864,
      "grad_norm": 0.0,
      "learning_rate": 0.0007371614920293327,
      "loss": 5.0729,
      "step": 3161
    },
    {
      "epoch": 0.36257309941520466,
      "grad_norm": 0.0,
      "learning_rate": 0.000736998009767262,
      "loss": 5.1075,
      "step": 3162
    },
    {
      "epoch": 0.3626877651645454,
      "grad_norm": 0.0,
      "learning_rate": 0.0007368344948227299,
      "loss": 5.1056,
      "step": 3163
    },
    {
      "epoch": 0.36280243091388603,
      "grad_norm": 0.0,
      "learning_rate": 0.0007366709472182902,
      "loss": 5.076,
      "step": 3164
    },
    {
      "epoch": 0.3629170966632267,
      "grad_norm": 0.0,
      "learning_rate": 0.0007365073669765013,
      "loss": 4.7592,
      "step": 3165
    },
    {
      "epoch": 0.36303176241256735,
      "grad_norm": 0.0,
      "learning_rate": 0.0007363437541199259,
      "loss": 5.2076,
      "step": 3166
    },
    {
      "epoch": 0.36314642816190806,
      "grad_norm": 0.0,
      "learning_rate": 0.0007361801086711316,
      "loss": 5.3358,
      "step": 3167
    },
    {
      "epoch": 0.3632610939112487,
      "grad_norm": 0.0,
      "learning_rate": 0.0007360164306526897,
      "loss": 4.9426,
      "step": 3168
    },
    {
      "epoch": 0.3633757596605894,
      "grad_norm": 0.0,
      "learning_rate": 0.0007358527200871764,
      "loss": 5.0313,
      "step": 3169
    },
    {
      "epoch": 0.36349042540993004,
      "grad_norm": 0.0,
      "learning_rate": 0.0007356889769971727,
      "loss": 4.9585,
      "step": 3170
    },
    {
      "epoch": 0.3636050911592707,
      "grad_norm": 0.0,
      "learning_rate": 0.000735525201405264,
      "loss": 5.4234,
      "step": 3171
    },
    {
      "epoch": 0.3637197569086114,
      "grad_norm": 0.0,
      "learning_rate": 0.0007353613933340397,
      "loss": 5.0227,
      "step": 3172
    },
    {
      "epoch": 0.3638344226579521,
      "grad_norm": 0.0,
      "learning_rate": 0.0007351975528060942,
      "loss": 5.3083,
      "step": 3173
    },
    {
      "epoch": 0.36394908840729273,
      "grad_norm": 0.0,
      "learning_rate": 0.0007350336798440261,
      "loss": 5.0378,
      "step": 3174
    },
    {
      "epoch": 0.3640637541566334,
      "grad_norm": 0.0,
      "learning_rate": 0.0007348697744704385,
      "loss": 4.9263,
      "step": 3175
    },
    {
      "epoch": 0.3641784199059741,
      "grad_norm": 0.0,
      "learning_rate": 0.0007347058367079391,
      "loss": 5.0688,
      "step": 3176
    },
    {
      "epoch": 0.36429308565531476,
      "grad_norm": 0.0,
      "learning_rate": 0.0007345418665791402,
      "loss": 4.96,
      "step": 3177
    },
    {
      "epoch": 0.3644077514046554,
      "grad_norm": 0.0,
      "learning_rate": 0.0007343778641066579,
      "loss": 4.9879,
      "step": 3178
    },
    {
      "epoch": 0.3645224171539961,
      "grad_norm": 0.0,
      "learning_rate": 0.0007342138293131135,
      "loss": 4.8842,
      "step": 3179
    },
    {
      "epoch": 0.3646370829033368,
      "grad_norm": 0.0,
      "learning_rate": 0.0007340497622211324,
      "loss": 4.9808,
      "step": 3180
    },
    {
      "epoch": 0.36475174865267745,
      "grad_norm": 0.0,
      "learning_rate": 0.0007338856628533444,
      "loss": 4.9083,
      "step": 3181
    },
    {
      "epoch": 0.3648664144020181,
      "grad_norm": 0.0,
      "learning_rate": 0.0007337215312323841,
      "loss": 5.0004,
      "step": 3182
    },
    {
      "epoch": 0.36498108015135877,
      "grad_norm": 0.0,
      "learning_rate": 0.0007335573673808904,
      "loss": 4.7669,
      "step": 3183
    },
    {
      "epoch": 0.3650957459006995,
      "grad_norm": 0.0,
      "learning_rate": 0.0007333931713215063,
      "loss": 4.9677,
      "step": 3184
    },
    {
      "epoch": 0.36521041165004015,
      "grad_norm": 0.0,
      "learning_rate": 0.0007332289430768797,
      "loss": 4.8648,
      "step": 3185
    },
    {
      "epoch": 0.3653250773993808,
      "grad_norm": 0.0,
      "learning_rate": 0.0007330646826696626,
      "loss": 4.9576,
      "step": 3186
    },
    {
      "epoch": 0.36543974314872146,
      "grad_norm": 0.0,
      "learning_rate": 0.0007329003901225119,
      "loss": 5.0247,
      "step": 3187
    },
    {
      "epoch": 0.3655544088980621,
      "grad_norm": 0.0,
      "learning_rate": 0.0007327360654580883,
      "loss": 5.2236,
      "step": 3188
    },
    {
      "epoch": 0.36566907464740284,
      "grad_norm": 0.0,
      "learning_rate": 0.0007325717086990573,
      "loss": 4.9151,
      "step": 3189
    },
    {
      "epoch": 0.3657837403967435,
      "grad_norm": 0.0,
      "learning_rate": 0.0007324073198680889,
      "loss": 4.9225,
      "step": 3190
    },
    {
      "epoch": 0.36589840614608415,
      "grad_norm": 0.0,
      "learning_rate": 0.0007322428989878573,
      "loss": 4.7406,
      "step": 3191
    },
    {
      "epoch": 0.3660130718954248,
      "grad_norm": 0.0,
      "learning_rate": 0.0007320784460810412,
      "loss": 4.8241,
      "step": 3192
    },
    {
      "epoch": 0.3661277376447655,
      "grad_norm": 0.0,
      "learning_rate": 0.000731913961170324,
      "loss": 5.0984,
      "step": 3193
    },
    {
      "epoch": 0.3662424033941062,
      "grad_norm": 0.0,
      "learning_rate": 0.0007317494442783932,
      "loss": 4.8206,
      "step": 3194
    },
    {
      "epoch": 0.36635706914344685,
      "grad_norm": 0.0,
      "learning_rate": 0.0007315848954279404,
      "loss": 5.0107,
      "step": 3195
    },
    {
      "epoch": 0.3664717348927875,
      "grad_norm": 0.0,
      "learning_rate": 0.0007314203146416623,
      "loss": 5.0218,
      "step": 3196
    },
    {
      "epoch": 0.3665864006421282,
      "grad_norm": 0.0,
      "learning_rate": 0.0007312557019422597,
      "loss": 5.1136,
      "step": 3197
    },
    {
      "epoch": 0.3667010663914689,
      "grad_norm": 0.0,
      "learning_rate": 0.0007310910573524377,
      "loss": 5.1054,
      "step": 3198
    },
    {
      "epoch": 0.36681573214080954,
      "grad_norm": 0.0,
      "learning_rate": 0.0007309263808949058,
      "loss": 5.1225,
      "step": 3199
    },
    {
      "epoch": 0.3669303978901502,
      "grad_norm": 0.0,
      "learning_rate": 0.0007307616725923782,
      "loss": 5.1493,
      "step": 3200
    },
    {
      "epoch": 0.3670450636394909,
      "grad_norm": 0.0,
      "learning_rate": 0.000730596932467573,
      "loss": 5.1093,
      "step": 3201
    },
    {
      "epoch": 0.36715972938883157,
      "grad_norm": 0.0,
      "learning_rate": 0.000730432160543213,
      "loss": 5.0503,
      "step": 3202
    },
    {
      "epoch": 0.3672743951381722,
      "grad_norm": 0.0,
      "learning_rate": 0.0007302673568420257,
      "loss": 5.0833,
      "step": 3203
    },
    {
      "epoch": 0.3673890608875129,
      "grad_norm": 0.0,
      "learning_rate": 0.0007301025213867422,
      "loss": 4.9881,
      "step": 3204
    },
    {
      "epoch": 0.36750372663685354,
      "grad_norm": 0.0,
      "learning_rate": 0.0007299376542000987,
      "loss": 5.0483,
      "step": 3205
    },
    {
      "epoch": 0.36761839238619426,
      "grad_norm": 0.0,
      "learning_rate": 0.0007297727553048351,
      "loss": 5.027,
      "step": 3206
    },
    {
      "epoch": 0.3677330581355349,
      "grad_norm": 0.0,
      "learning_rate": 0.0007296078247236965,
      "loss": 5.0889,
      "step": 3207
    },
    {
      "epoch": 0.3678477238848756,
      "grad_norm": 0.0,
      "learning_rate": 0.0007294428624794318,
      "loss": 5.0331,
      "step": 3208
    },
    {
      "epoch": 0.36796238963421624,
      "grad_norm": 0.0,
      "learning_rate": 0.0007292778685947941,
      "loss": 4.9423,
      "step": 3209
    },
    {
      "epoch": 0.36807705538355695,
      "grad_norm": 0.0,
      "learning_rate": 0.0007291128430925417,
      "loss": 5.243,
      "step": 3210
    },
    {
      "epoch": 0.3681917211328976,
      "grad_norm": 0.0,
      "learning_rate": 0.0007289477859954364,
      "loss": 4.9907,
      "step": 3211
    },
    {
      "epoch": 0.36830638688223827,
      "grad_norm": 0.0,
      "learning_rate": 0.0007287826973262446,
      "loss": 5.0316,
      "step": 3212
    },
    {
      "epoch": 0.3684210526315789,
      "grad_norm": 0.0,
      "learning_rate": 0.0007286175771077371,
      "loss": 5.0951,
      "step": 3213
    },
    {
      "epoch": 0.36853571838091964,
      "grad_norm": 0.0,
      "learning_rate": 0.0007284524253626894,
      "loss": 4.7852,
      "step": 3214
    },
    {
      "epoch": 0.3686503841302603,
      "grad_norm": 0.0,
      "learning_rate": 0.0007282872421138809,
      "loss": 5.0199,
      "step": 3215
    },
    {
      "epoch": 0.36876504987960096,
      "grad_norm": 0.0,
      "learning_rate": 0.0007281220273840954,
      "loss": 4.7381,
      "step": 3216
    },
    {
      "epoch": 0.3688797156289416,
      "grad_norm": 0.0,
      "learning_rate": 0.0007279567811961212,
      "loss": 4.9,
      "step": 3217
    },
    {
      "epoch": 0.36899438137828233,
      "grad_norm": 0.0,
      "learning_rate": 0.0007277915035727509,
      "loss": 4.7947,
      "step": 3218
    },
    {
      "epoch": 0.369109047127623,
      "grad_norm": 0.0,
      "learning_rate": 0.0007276261945367812,
      "loss": 4.883,
      "step": 3219
    },
    {
      "epoch": 0.36922371287696365,
      "grad_norm": 0.0,
      "learning_rate": 0.0007274608541110134,
      "loss": 4.8979,
      "step": 3220
    },
    {
      "epoch": 0.3693383786263043,
      "grad_norm": 0.0,
      "learning_rate": 0.0007272954823182532,
      "loss": 5.3102,
      "step": 3221
    },
    {
      "epoch": 0.36945304437564497,
      "grad_norm": 0.0,
      "learning_rate": 0.0007271300791813106,
      "loss": 5.059,
      "step": 3222
    },
    {
      "epoch": 0.3695677101249857,
      "grad_norm": 0.0,
      "learning_rate": 0.0007269646447229994,
      "loss": 4.8462,
      "step": 3223
    },
    {
      "epoch": 0.36968237587432634,
      "grad_norm": 0.0,
      "learning_rate": 0.0007267991789661383,
      "loss": 4.8851,
      "step": 3224
    },
    {
      "epoch": 0.369797041623667,
      "grad_norm": 0.0,
      "learning_rate": 0.0007266336819335503,
      "loss": 4.9789,
      "step": 3225
    },
    {
      "epoch": 0.36991170737300766,
      "grad_norm": 0.0,
      "learning_rate": 0.0007264681536480625,
      "loss": 4.9503,
      "step": 3226
    },
    {
      "epoch": 0.3700263731223484,
      "grad_norm": 0.0,
      "learning_rate": 0.0007263025941325063,
      "loss": 4.7741,
      "step": 3227
    },
    {
      "epoch": 0.37014103887168903,
      "grad_norm": 0.0,
      "learning_rate": 0.0007261370034097176,
      "loss": 4.8793,
      "step": 3228
    },
    {
      "epoch": 0.3702557046210297,
      "grad_norm": 0.0,
      "learning_rate": 0.0007259713815025362,
      "loss": 5.0482,
      "step": 3229
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.0,
      "learning_rate": 0.0007258057284338068,
      "loss": 5.0337,
      "step": 3230
    },
    {
      "epoch": 0.37048503611971106,
      "grad_norm": 0.0,
      "learning_rate": 0.0007256400442263778,
      "loss": 4.8737,
      "step": 3231
    },
    {
      "epoch": 0.3705997018690517,
      "grad_norm": 0.0,
      "learning_rate": 0.0007254743289031024,
      "loss": 5.0828,
      "step": 3232
    },
    {
      "epoch": 0.3707143676183924,
      "grad_norm": 0.0,
      "learning_rate": 0.000725308582486838,
      "loss": 5.0054,
      "step": 3233
    },
    {
      "epoch": 0.37082903336773304,
      "grad_norm": 0.0,
      "learning_rate": 0.0007251428050004458,
      "loss": 5.0552,
      "step": 3234
    },
    {
      "epoch": 0.37094369911707376,
      "grad_norm": 0.0,
      "learning_rate": 0.0007249769964667916,
      "loss": 5.0547,
      "step": 3235
    },
    {
      "epoch": 0.3710583648664144,
      "grad_norm": 0.0,
      "learning_rate": 0.000724811156908746,
      "loss": 4.8554,
      "step": 3236
    },
    {
      "epoch": 0.3711730306157551,
      "grad_norm": 0.0,
      "learning_rate": 0.0007246452863491832,
      "loss": 5.1091,
      "step": 3237
    },
    {
      "epoch": 0.37128769636509573,
      "grad_norm": 0.0,
      "learning_rate": 0.0007244793848109818,
      "loss": 5.2201,
      "step": 3238
    },
    {
      "epoch": 0.3714023621144364,
      "grad_norm": 0.0,
      "learning_rate": 0.0007243134523170246,
      "loss": 5.0062,
      "step": 3239
    },
    {
      "epoch": 0.3715170278637771,
      "grad_norm": 0.0,
      "learning_rate": 0.0007241474888901992,
      "loss": 5.0629,
      "step": 3240
    },
    {
      "epoch": 0.37163169361311776,
      "grad_norm": 0.0,
      "learning_rate": 0.0007239814945533967,
      "loss": 4.8046,
      "step": 3241
    },
    {
      "epoch": 0.3717463593624584,
      "grad_norm": 0.0,
      "learning_rate": 0.000723815469329513,
      "loss": 4.9628,
      "step": 3242
    },
    {
      "epoch": 0.3718610251117991,
      "grad_norm": 0.0,
      "learning_rate": 0.0007236494132414484,
      "loss": 4.8574,
      "step": 3243
    },
    {
      "epoch": 0.3719756908611398,
      "grad_norm": 0.0,
      "learning_rate": 0.0007234833263121069,
      "loss": 4.9038,
      "step": 3244
    },
    {
      "epoch": 0.37209035661048045,
      "grad_norm": 0.0,
      "learning_rate": 0.0007233172085643971,
      "loss": 4.7783,
      "step": 3245
    },
    {
      "epoch": 0.3722050223598211,
      "grad_norm": 0.0,
      "learning_rate": 0.0007231510600212316,
      "loss": 4.8464,
      "step": 3246
    },
    {
      "epoch": 0.3723196881091618,
      "grad_norm": 0.0,
      "learning_rate": 0.0007229848807055275,
      "loss": 5.0444,
      "step": 3247
    },
    {
      "epoch": 0.3724343538585025,
      "grad_norm": 0.0,
      "learning_rate": 0.0007228186706402063,
      "loss": 5.3998,
      "step": 3248
    },
    {
      "epoch": 0.37254901960784315,
      "grad_norm": 0.0,
      "learning_rate": 0.0007226524298481933,
      "loss": 5.1069,
      "step": 3249
    },
    {
      "epoch": 0.3726636853571838,
      "grad_norm": 0.0,
      "learning_rate": 0.0007224861583524182,
      "loss": 4.6581,
      "step": 3250
    },
    {
      "epoch": 0.37277835110652446,
      "grad_norm": 0.0,
      "learning_rate": 0.0007223198561758153,
      "loss": 5.244,
      "step": 3251
    },
    {
      "epoch": 0.3728930168558652,
      "grad_norm": 0.0,
      "learning_rate": 0.0007221535233413223,
      "loss": 4.9598,
      "step": 3252
    },
    {
      "epoch": 0.37300768260520584,
      "grad_norm": 0.0,
      "learning_rate": 0.0007219871598718821,
      "loss": 4.9439,
      "step": 3253
    },
    {
      "epoch": 0.3731223483545465,
      "grad_norm": 0.0,
      "learning_rate": 0.0007218207657904411,
      "loss": 5.2227,
      "step": 3254
    },
    {
      "epoch": 0.37323701410388715,
      "grad_norm": 0.0,
      "learning_rate": 0.0007216543411199505,
      "loss": 4.971,
      "step": 3255
    },
    {
      "epoch": 0.3733516798532278,
      "grad_norm": 0.0,
      "learning_rate": 0.0007214878858833651,
      "loss": 5.0161,
      "step": 3256
    },
    {
      "epoch": 0.37346634560256853,
      "grad_norm": 0.0,
      "learning_rate": 0.0007213214001036443,
      "loss": 4.8109,
      "step": 3257
    },
    {
      "epoch": 0.3735810113519092,
      "grad_norm": 0.0,
      "learning_rate": 0.0007211548838037518,
      "loss": 4.9651,
      "step": 3258
    },
    {
      "epoch": 0.37369567710124985,
      "grad_norm": 0.0,
      "learning_rate": 0.000720988337006655,
      "loss": 4.82,
      "step": 3259
    },
    {
      "epoch": 0.3738103428505905,
      "grad_norm": 0.0,
      "learning_rate": 0.0007208217597353262,
      "loss": 5.1616,
      "step": 3260
    },
    {
      "epoch": 0.3739250085999312,
      "grad_norm": 0.0,
      "learning_rate": 0.0007206551520127413,
      "loss": 4.9272,
      "step": 3261
    },
    {
      "epoch": 0.3740396743492719,
      "grad_norm": 0.0,
      "learning_rate": 0.000720488513861881,
      "loss": 5.0996,
      "step": 3262
    },
    {
      "epoch": 0.37415434009861254,
      "grad_norm": 0.0,
      "learning_rate": 0.0007203218453057295,
      "loss": 5.1026,
      "step": 3263
    },
    {
      "epoch": 0.3742690058479532,
      "grad_norm": 0.0,
      "learning_rate": 0.0007201551463672758,
      "loss": 4.7671,
      "step": 3264
    },
    {
      "epoch": 0.3743836715972939,
      "grad_norm": 0.0,
      "learning_rate": 0.0007199884170695127,
      "loss": 4.7079,
      "step": 3265
    },
    {
      "epoch": 0.37449833734663457,
      "grad_norm": 0.0,
      "learning_rate": 0.0007198216574354375,
      "loss": 5.0696,
      "step": 3266
    },
    {
      "epoch": 0.3746130030959752,
      "grad_norm": 0.0,
      "learning_rate": 0.0007196548674880511,
      "loss": 5.1096,
      "step": 3267
    },
    {
      "epoch": 0.3747276688453159,
      "grad_norm": 0.0,
      "learning_rate": 0.0007194880472503596,
      "loss": 5.1097,
      "step": 3268
    },
    {
      "epoch": 0.3748423345946566,
      "grad_norm": 0.0,
      "learning_rate": 0.0007193211967453723,
      "loss": 5.1104,
      "step": 3269
    },
    {
      "epoch": 0.37495700034399726,
      "grad_norm": 0.0,
      "learning_rate": 0.0007191543159961029,
      "loss": 5.1825,
      "step": 3270
    },
    {
      "epoch": 0.3750716660933379,
      "grad_norm": 0.0,
      "learning_rate": 0.0007189874050255696,
      "loss": 5.0138,
      "step": 3271
    },
    {
      "epoch": 0.3751863318426786,
      "grad_norm": 0.0,
      "learning_rate": 0.0007188204638567949,
      "loss": 5.0369,
      "step": 3272
    },
    {
      "epoch": 0.37530099759201924,
      "grad_norm": 0.0,
      "learning_rate": 0.0007186534925128045,
      "loss": 5.0672,
      "step": 3273
    },
    {
      "epoch": 0.37541566334135995,
      "grad_norm": 0.0,
      "learning_rate": 0.0007184864910166295,
      "loss": 5.2023,
      "step": 3274
    },
    {
      "epoch": 0.3755303290907006,
      "grad_norm": 0.0,
      "learning_rate": 0.0007183194593913043,
      "loss": 5.251,
      "step": 3275
    },
    {
      "epoch": 0.37564499484004127,
      "grad_norm": 0.0,
      "learning_rate": 0.0007181523976598677,
      "loss": 5.2711,
      "step": 3276
    },
    {
      "epoch": 0.3757596605893819,
      "grad_norm": 0.0,
      "learning_rate": 0.0007179853058453628,
      "loss": 4.9725,
      "step": 3277
    },
    {
      "epoch": 0.37587432633872264,
      "grad_norm": 0.0,
      "learning_rate": 0.0007178181839708368,
      "loss": 4.8189,
      "step": 3278
    },
    {
      "epoch": 0.3759889920880633,
      "grad_norm": 0.0,
      "learning_rate": 0.0007176510320593408,
      "loss": 4.9509,
      "step": 3279
    },
    {
      "epoch": 0.37610365783740396,
      "grad_norm": 0.0,
      "learning_rate": 0.0007174838501339303,
      "loss": 4.8451,
      "step": 3280
    },
    {
      "epoch": 0.3762183235867446,
      "grad_norm": 0.0,
      "learning_rate": 0.0007173166382176645,
      "loss": 4.7326,
      "step": 3281
    },
    {
      "epoch": 0.37633298933608533,
      "grad_norm": 0.0,
      "learning_rate": 0.000717149396333608,
      "loss": 5.0424,
      "step": 3282
    },
    {
      "epoch": 0.376447655085426,
      "grad_norm": 0.0,
      "learning_rate": 0.0007169821245048277,
      "loss": 4.9534,
      "step": 3283
    },
    {
      "epoch": 0.37656232083476665,
      "grad_norm": 0.0,
      "learning_rate": 0.000716814822754396,
      "loss": 5.0908,
      "step": 3284
    },
    {
      "epoch": 0.3766769865841073,
      "grad_norm": 0.0,
      "learning_rate": 0.0007166474911053888,
      "loss": 5.0186,
      "step": 3285
    },
    {
      "epoch": 0.376791652333448,
      "grad_norm": 0.0,
      "learning_rate": 0.0007164801295808866,
      "loss": 4.7957,
      "step": 3286
    },
    {
      "epoch": 0.3769063180827887,
      "grad_norm": 0.0,
      "learning_rate": 0.0007163127382039735,
      "loss": 4.8794,
      "step": 3287
    },
    {
      "epoch": 0.37702098383212934,
      "grad_norm": 0.0,
      "learning_rate": 0.000716145316997738,
      "loss": 4.9354,
      "step": 3288
    },
    {
      "epoch": 0.37713564958147,
      "grad_norm": 0.0,
      "learning_rate": 0.0007159778659852728,
      "loss": 4.8616,
      "step": 3289
    },
    {
      "epoch": 0.37725031533081066,
      "grad_norm": 0.0,
      "learning_rate": 0.0007158103851896743,
      "loss": 4.9864,
      "step": 3290
    },
    {
      "epoch": 0.3773649810801514,
      "grad_norm": 0.0,
      "learning_rate": 0.0007156428746340435,
      "loss": 5.2081,
      "step": 3291
    },
    {
      "epoch": 0.37747964682949203,
      "grad_norm": 0.0,
      "learning_rate": 0.0007154753343414852,
      "loss": 4.8642,
      "step": 3292
    },
    {
      "epoch": 0.3775943125788327,
      "grad_norm": 0.0,
      "learning_rate": 0.0007153077643351084,
      "loss": 4.8147,
      "step": 3293
    },
    {
      "epoch": 0.37770897832817335,
      "grad_norm": 0.0,
      "learning_rate": 0.0007151401646380262,
      "loss": 5.1654,
      "step": 3294
    },
    {
      "epoch": 0.37782364407751406,
      "grad_norm": 0.0,
      "learning_rate": 0.0007149725352733557,
      "loss": 4.9103,
      "step": 3295
    },
    {
      "epoch": 0.3779383098268547,
      "grad_norm": 0.0,
      "learning_rate": 0.0007148048762642183,
      "loss": 4.9724,
      "step": 3296
    },
    {
      "epoch": 0.3780529755761954,
      "grad_norm": 0.0,
      "learning_rate": 0.0007146371876337393,
      "loss": 5.1598,
      "step": 3297
    },
    {
      "epoch": 0.37816764132553604,
      "grad_norm": 0.0,
      "learning_rate": 0.0007144694694050482,
      "loss": 4.8516,
      "step": 3298
    },
    {
      "epoch": 0.37828230707487676,
      "grad_norm": 0.0,
      "learning_rate": 0.0007143017216012786,
      "loss": 5.0244,
      "step": 3299
    },
    {
      "epoch": 0.3783969728242174,
      "grad_norm": 0.0,
      "learning_rate": 0.000714133944245568,
      "loss": 5.1513,
      "step": 3300
    },
    {
      "epoch": 0.3785116385735581,
      "grad_norm": 0.0,
      "learning_rate": 0.000713966137361058,
      "loss": 5.1484,
      "step": 3301
    },
    {
      "epoch": 0.37862630432289873,
      "grad_norm": 0.0,
      "learning_rate": 0.0007137983009708943,
      "loss": 4.9789,
      "step": 3302
    },
    {
      "epoch": 0.37874097007223945,
      "grad_norm": 0.0,
      "learning_rate": 0.0007136304350982271,
      "loss": 4.9583,
      "step": 3303
    },
    {
      "epoch": 0.3788556358215801,
      "grad_norm": 0.0,
      "learning_rate": 0.0007134625397662102,
      "loss": 4.9042,
      "step": 3304
    },
    {
      "epoch": 0.37897030157092076,
      "grad_norm": 0.0,
      "learning_rate": 0.0007132946149980013,
      "loss": 4.836,
      "step": 3305
    },
    {
      "epoch": 0.3790849673202614,
      "grad_norm": 0.0,
      "learning_rate": 0.0007131266608167627,
      "loss": 5.0635,
      "step": 3306
    },
    {
      "epoch": 0.3791996330696021,
      "grad_norm": 0.0,
      "learning_rate": 0.0007129586772456602,
      "loss": 4.9094,
      "step": 3307
    },
    {
      "epoch": 0.3793142988189428,
      "grad_norm": 0.0,
      "learning_rate": 0.000712790664307864,
      "loss": 5.1837,
      "step": 3308
    },
    {
      "epoch": 0.37942896456828346,
      "grad_norm": 0.0,
      "learning_rate": 0.0007126226220265488,
      "loss": 5.091,
      "step": 3309
    },
    {
      "epoch": 0.3795436303176241,
      "grad_norm": 0.0,
      "learning_rate": 0.000712454550424892,
      "loss": 4.8271,
      "step": 3310
    },
    {
      "epoch": 0.3796582960669648,
      "grad_norm": 0.0,
      "learning_rate": 0.0007122864495260763,
      "loss": 4.8779,
      "step": 3311
    },
    {
      "epoch": 0.3797729618163055,
      "grad_norm": 0.0,
      "learning_rate": 0.000712118319353288,
      "loss": 4.8704,
      "step": 3312
    },
    {
      "epoch": 0.37988762756564615,
      "grad_norm": 0.0,
      "learning_rate": 0.0007119501599297176,
      "loss": 4.9583,
      "step": 3313
    },
    {
      "epoch": 0.3800022933149868,
      "grad_norm": 0.0,
      "learning_rate": 0.0007117819712785592,
      "loss": 5.0444,
      "step": 3314
    },
    {
      "epoch": 0.38011695906432746,
      "grad_norm": 0.0,
      "learning_rate": 0.0007116137534230114,
      "loss": 5.0381,
      "step": 3315
    },
    {
      "epoch": 0.3802316248136682,
      "grad_norm": 0.0,
      "learning_rate": 0.0007114455063862763,
      "loss": 5.1371,
      "step": 3316
    },
    {
      "epoch": 0.38034629056300884,
      "grad_norm": 0.0,
      "learning_rate": 0.0007112772301915611,
      "loss": 4.8679,
      "step": 3317
    },
    {
      "epoch": 0.3804609563123495,
      "grad_norm": 0.0,
      "learning_rate": 0.0007111089248620755,
      "loss": 5.0914,
      "step": 3318
    },
    {
      "epoch": 0.38057562206169016,
      "grad_norm": 0.0,
      "learning_rate": 0.0007109405904210345,
      "loss": 5.1359,
      "step": 3319
    },
    {
      "epoch": 0.38069028781103087,
      "grad_norm": 0.0,
      "learning_rate": 0.0007107722268916565,
      "loss": 5.2988,
      "step": 3320
    },
    {
      "epoch": 0.38080495356037153,
      "grad_norm": 0.0,
      "learning_rate": 0.0007106038342971642,
      "loss": 5.1179,
      "step": 3321
    },
    {
      "epoch": 0.3809196193097122,
      "grad_norm": 0.0,
      "learning_rate": 0.0007104354126607838,
      "loss": 4.9472,
      "step": 3322
    },
    {
      "epoch": 0.38103428505905285,
      "grad_norm": 0.0,
      "learning_rate": 0.000710266962005746,
      "loss": 5.0867,
      "step": 3323
    },
    {
      "epoch": 0.3811489508083935,
      "grad_norm": 0.0,
      "learning_rate": 0.0007100984823552855,
      "loss": 4.9308,
      "step": 3324
    },
    {
      "epoch": 0.3812636165577342,
      "grad_norm": 0.0,
      "learning_rate": 0.0007099299737326406,
      "loss": 5.0341,
      "step": 3325
    },
    {
      "epoch": 0.3813782823070749,
      "grad_norm": 0.0,
      "learning_rate": 0.0007097614361610542,
      "loss": 4.9814,
      "step": 3326
    },
    {
      "epoch": 0.38149294805641554,
      "grad_norm": 0.0,
      "learning_rate": 0.0007095928696637723,
      "loss": 5.2754,
      "step": 3327
    },
    {
      "epoch": 0.3816076138057562,
      "grad_norm": 0.0,
      "learning_rate": 0.0007094242742640462,
      "loss": 4.9227,
      "step": 3328
    },
    {
      "epoch": 0.3817222795550969,
      "grad_norm": 0.0,
      "learning_rate": 0.0007092556499851296,
      "loss": 5.1349,
      "step": 3329
    },
    {
      "epoch": 0.38183694530443757,
      "grad_norm": 0.0,
      "learning_rate": 0.0007090869968502817,
      "loss": 4.8416,
      "step": 3330
    },
    {
      "epoch": 0.38195161105377823,
      "grad_norm": 0.0,
      "learning_rate": 0.0007089183148827646,
      "loss": 5.3188,
      "step": 3331
    },
    {
      "epoch": 0.3820662768031189,
      "grad_norm": 0.0,
      "learning_rate": 0.0007087496041058449,
      "loss": 5.0364,
      "step": 3332
    },
    {
      "epoch": 0.3821809425524596,
      "grad_norm": 0.0,
      "learning_rate": 0.000708580864542793,
      "loss": 5.1423,
      "step": 3333
    },
    {
      "epoch": 0.38229560830180026,
      "grad_norm": 0.0,
      "learning_rate": 0.0007084120962168833,
      "loss": 5.4288,
      "step": 3334
    },
    {
      "epoch": 0.3824102740511409,
      "grad_norm": 0.0,
      "learning_rate": 0.0007082432991513941,
      "loss": 4.9943,
      "step": 3335
    },
    {
      "epoch": 0.3825249398004816,
      "grad_norm": 0.0,
      "learning_rate": 0.0007080744733696078,
      "loss": 4.8832,
      "step": 3336
    },
    {
      "epoch": 0.3826396055498223,
      "grad_norm": 0.0,
      "learning_rate": 0.0007079056188948108,
      "loss": 4.7734,
      "step": 3337
    },
    {
      "epoch": 0.38275427129916295,
      "grad_norm": 0.0,
      "learning_rate": 0.0007077367357502932,
      "loss": 5.0327,
      "step": 3338
    },
    {
      "epoch": 0.3828689370485036,
      "grad_norm": 0.0,
      "learning_rate": 0.0007075678239593493,
      "loss": 4.8828,
      "step": 3339
    },
    {
      "epoch": 0.38298360279784427,
      "grad_norm": 0.0,
      "learning_rate": 0.0007073988835452771,
      "loss": 5.0083,
      "step": 3340
    },
    {
      "epoch": 0.383098268547185,
      "grad_norm": 0.0,
      "learning_rate": 0.0007072299145313791,
      "loss": 4.9778,
      "step": 3341
    },
    {
      "epoch": 0.38321293429652564,
      "grad_norm": 0.0,
      "learning_rate": 0.0007070609169409608,
      "loss": 5.254,
      "step": 3342
    },
    {
      "epoch": 0.3833276000458663,
      "grad_norm": 0.0,
      "learning_rate": 0.0007068918907973328,
      "loss": 5.2334,
      "step": 3343
    },
    {
      "epoch": 0.38344226579520696,
      "grad_norm": 0.0,
      "learning_rate": 0.0007067228361238086,
      "loss": 5.1744,
      "step": 3344
    },
    {
      "epoch": 0.3835569315445476,
      "grad_norm": 0.0,
      "learning_rate": 0.000706553752943706,
      "loss": 4.9896,
      "step": 3345
    },
    {
      "epoch": 0.38367159729388833,
      "grad_norm": 0.0,
      "learning_rate": 0.0007063846412803471,
      "loss": 4.751,
      "step": 3346
    },
    {
      "epoch": 0.383786263043229,
      "grad_norm": 0.0,
      "learning_rate": 0.0007062155011570576,
      "loss": 5.1867,
      "step": 3347
    },
    {
      "epoch": 0.38390092879256965,
      "grad_norm": 0.0,
      "learning_rate": 0.0007060463325971671,
      "loss": 5.1174,
      "step": 3348
    },
    {
      "epoch": 0.3840155945419103,
      "grad_norm": 0.0,
      "learning_rate": 0.0007058771356240092,
      "loss": 5.0966,
      "step": 3349
    },
    {
      "epoch": 0.384130260291251,
      "grad_norm": 0.0,
      "learning_rate": 0.0007057079102609214,
      "loss": 4.841,
      "step": 3350
    },
    {
      "epoch": 0.3842449260405917,
      "grad_norm": 0.0,
      "learning_rate": 0.0007055386565312451,
      "loss": 4.9833,
      "step": 3351
    },
    {
      "epoch": 0.38435959178993234,
      "grad_norm": 0.0,
      "learning_rate": 0.0007053693744583254,
      "loss": 4.9053,
      "step": 3352
    },
    {
      "epoch": 0.384474257539273,
      "grad_norm": 0.0,
      "learning_rate": 0.0007052000640655117,
      "loss": 5.1036,
      "step": 3353
    },
    {
      "epoch": 0.3845889232886137,
      "grad_norm": 0.0,
      "learning_rate": 0.0007050307253761574,
      "loss": 4.9905,
      "step": 3354
    },
    {
      "epoch": 0.3847035890379544,
      "grad_norm": 0.0,
      "learning_rate": 0.0007048613584136192,
      "loss": 5.0669,
      "step": 3355
    },
    {
      "epoch": 0.38481825478729503,
      "grad_norm": 0.0,
      "learning_rate": 0.0007046919632012582,
      "loss": 5.1233,
      "step": 3356
    },
    {
      "epoch": 0.3849329205366357,
      "grad_norm": 0.0,
      "learning_rate": 0.0007045225397624393,
      "loss": 5.0959,
      "step": 3357
    },
    {
      "epoch": 0.3850475862859764,
      "grad_norm": 0.0,
      "learning_rate": 0.0007043530881205308,
      "loss": 5.2849,
      "step": 3358
    },
    {
      "epoch": 0.38516225203531707,
      "grad_norm": 0.0,
      "learning_rate": 0.0007041836082989062,
      "loss": 5.0264,
      "step": 3359
    },
    {
      "epoch": 0.3852769177846577,
      "grad_norm": 0.0,
      "learning_rate": 0.0007040141003209411,
      "loss": 4.8664,
      "step": 3360
    },
    {
      "epoch": 0.3853915835339984,
      "grad_norm": 0.0,
      "learning_rate": 0.0007038445642100163,
      "loss": 4.8314,
      "step": 3361
    },
    {
      "epoch": 0.38550624928333904,
      "grad_norm": 0.0,
      "learning_rate": 0.0007036749999895163,
      "loss": 4.9108,
      "step": 3362
    },
    {
      "epoch": 0.38562091503267976,
      "grad_norm": 0.0,
      "learning_rate": 0.0007035054076828287,
      "loss": 5.1763,
      "step": 3363
    },
    {
      "epoch": 0.3857355807820204,
      "grad_norm": 0.0,
      "learning_rate": 0.0007033357873133458,
      "loss": 5.3621,
      "step": 3364
    },
    {
      "epoch": 0.3858502465313611,
      "grad_norm": 0.0,
      "learning_rate": 0.0007031661389044637,
      "loss": 5.1333,
      "step": 3365
    },
    {
      "epoch": 0.38596491228070173,
      "grad_norm": 0.0,
      "learning_rate": 0.0007029964624795821,
      "loss": 4.9828,
      "step": 3366
    },
    {
      "epoch": 0.38607957803004245,
      "grad_norm": 0.0,
      "learning_rate": 0.0007028267580621041,
      "loss": 4.8819,
      "step": 3367
    },
    {
      "epoch": 0.3861942437793831,
      "grad_norm": 0.0,
      "learning_rate": 0.0007026570256754379,
      "loss": 5.3079,
      "step": 3368
    },
    {
      "epoch": 0.38630890952872377,
      "grad_norm": 0.0,
      "learning_rate": 0.0007024872653429944,
      "loss": 5.0161,
      "step": 3369
    },
    {
      "epoch": 0.3864235752780644,
      "grad_norm": 0.0,
      "learning_rate": 0.0007023174770881893,
      "loss": 5.0798,
      "step": 3370
    },
    {
      "epoch": 0.38653824102740514,
      "grad_norm": 0.0,
      "learning_rate": 0.000702147660934441,
      "loss": 5.0595,
      "step": 3371
    },
    {
      "epoch": 0.3866529067767458,
      "grad_norm": 0.0,
      "learning_rate": 0.0007019778169051727,
      "loss": 4.9176,
      "step": 3372
    },
    {
      "epoch": 0.38676757252608646,
      "grad_norm": 0.0,
      "learning_rate": 0.0007018079450238113,
      "loss": 5.0433,
      "step": 3373
    },
    {
      "epoch": 0.3868822382754271,
      "grad_norm": 0.0,
      "learning_rate": 0.0007016380453137871,
      "loss": 5.0447,
      "step": 3374
    },
    {
      "epoch": 0.38699690402476783,
      "grad_norm": 0.0,
      "learning_rate": 0.0007014681177985346,
      "loss": 4.8817,
      "step": 3375
    },
    {
      "epoch": 0.3871115697741085,
      "grad_norm": 0.0,
      "learning_rate": 0.0007012981625014923,
      "loss": 5.1323,
      "step": 3376
    },
    {
      "epoch": 0.38722623552344915,
      "grad_norm": 0.0,
      "learning_rate": 0.000701128179446102,
      "loss": 4.8721,
      "step": 3377
    },
    {
      "epoch": 0.3873409012727898,
      "grad_norm": 0.0,
      "learning_rate": 0.0007009581686558098,
      "loss": 4.7963,
      "step": 3378
    },
    {
      "epoch": 0.38745556702213046,
      "grad_norm": 0.0,
      "learning_rate": 0.0007007881301540654,
      "loss": 5.0341,
      "step": 3379
    },
    {
      "epoch": 0.3875702327714712,
      "grad_norm": 0.0,
      "learning_rate": 0.0007006180639643225,
      "loss": 5.0348,
      "step": 3380
    },
    {
      "epoch": 0.38768489852081184,
      "grad_norm": 0.0,
      "learning_rate": 0.0007004479701100383,
      "loss": 5.0763,
      "step": 3381
    },
    {
      "epoch": 0.3877995642701525,
      "grad_norm": 0.0,
      "learning_rate": 0.0007002778486146739,
      "loss": 5.0351,
      "step": 3382
    },
    {
      "epoch": 0.38791423001949316,
      "grad_norm": 0.0,
      "learning_rate": 0.0007001076995016946,
      "loss": 4.8423,
      "step": 3383
    },
    {
      "epoch": 0.38802889576883387,
      "grad_norm": 0.0,
      "learning_rate": 0.0006999375227945689,
      "loss": 4.8953,
      "step": 3384
    },
    {
      "epoch": 0.38814356151817453,
      "grad_norm": 0.0,
      "learning_rate": 0.0006997673185167698,
      "loss": 5.0544,
      "step": 3385
    },
    {
      "epoch": 0.3882582272675152,
      "grad_norm": 0.0,
      "learning_rate": 0.0006995970866917735,
      "loss": 4.8924,
      "step": 3386
    },
    {
      "epoch": 0.38837289301685585,
      "grad_norm": 0.0,
      "learning_rate": 0.0006994268273430604,
      "loss": 4.8753,
      "step": 3387
    },
    {
      "epoch": 0.38848755876619656,
      "grad_norm": 0.0,
      "learning_rate": 0.0006992565404941144,
      "loss": 4.8288,
      "step": 3388
    },
    {
      "epoch": 0.3886022245155372,
      "grad_norm": 0.0,
      "learning_rate": 0.0006990862261684233,
      "loss": 4.9204,
      "step": 3389
    },
    {
      "epoch": 0.3887168902648779,
      "grad_norm": 0.0,
      "learning_rate": 0.0006989158843894788,
      "loss": 5.2442,
      "step": 3390
    },
    {
      "epoch": 0.38883155601421854,
      "grad_norm": 0.0,
      "learning_rate": 0.0006987455151807765,
      "loss": 5.0808,
      "step": 3391
    },
    {
      "epoch": 0.38894622176355925,
      "grad_norm": 0.0,
      "learning_rate": 0.0006985751185658152,
      "loss": 5.3379,
      "step": 3392
    },
    {
      "epoch": 0.3890608875128999,
      "grad_norm": 0.0,
      "learning_rate": 0.0006984046945680978,
      "loss": 5.2123,
      "step": 3393
    },
    {
      "epoch": 0.38917555326224057,
      "grad_norm": 0.0,
      "learning_rate": 0.0006982342432111315,
      "loss": 5.1038,
      "step": 3394
    },
    {
      "epoch": 0.38929021901158123,
      "grad_norm": 0.0,
      "learning_rate": 0.0006980637645184266,
      "loss": 5.0783,
      "step": 3395
    },
    {
      "epoch": 0.3894048847609219,
      "grad_norm": 0.0,
      "learning_rate": 0.0006978932585134972,
      "loss": 5.1459,
      "step": 3396
    },
    {
      "epoch": 0.3895195505102626,
      "grad_norm": 0.0,
      "learning_rate": 0.0006977227252198617,
      "loss": 5.1571,
      "step": 3397
    },
    {
      "epoch": 0.38963421625960326,
      "grad_norm": 0.0,
      "learning_rate": 0.0006975521646610417,
      "loss": 5.0816,
      "step": 3398
    },
    {
      "epoch": 0.3897488820089439,
      "grad_norm": 0.0,
      "learning_rate": 0.0006973815768605629,
      "loss": 5.1731,
      "step": 3399
    },
    {
      "epoch": 0.3898635477582846,
      "grad_norm": 0.0,
      "learning_rate": 0.0006972109618419544,
      "loss": 5.0608,
      "step": 3400
    },
    {
      "epoch": 0.3899782135076253,
      "grad_norm": 0.0,
      "learning_rate": 0.0006970403196287495,
      "loss": 5.1625,
      "step": 3401
    },
    {
      "epoch": 0.39009287925696595,
      "grad_norm": 0.0,
      "learning_rate": 0.0006968696502444849,
      "loss": 5.098,
      "step": 3402
    },
    {
      "epoch": 0.3902075450063066,
      "grad_norm": 0.0,
      "learning_rate": 0.0006966989537127014,
      "loss": 5.1735,
      "step": 3403
    },
    {
      "epoch": 0.39032221075564727,
      "grad_norm": 0.0,
      "learning_rate": 0.0006965282300569431,
      "loss": 5.0218,
      "step": 3404
    },
    {
      "epoch": 0.390436876504988,
      "grad_norm": 0.0,
      "learning_rate": 0.0006963574793007582,
      "loss": 5.1633,
      "step": 3405
    },
    {
      "epoch": 0.39055154225432864,
      "grad_norm": 0.0,
      "learning_rate": 0.0006961867014676986,
      "loss": 5.0685,
      "step": 3406
    },
    {
      "epoch": 0.3906662080036693,
      "grad_norm": 0.0,
      "learning_rate": 0.0006960158965813196,
      "loss": 5.0443,
      "step": 3407
    },
    {
      "epoch": 0.39078087375300996,
      "grad_norm": 0.0,
      "learning_rate": 0.0006958450646651806,
      "loss": 4.7961,
      "step": 3408
    },
    {
      "epoch": 0.3908955395023507,
      "grad_norm": 0.0,
      "learning_rate": 0.0006956742057428448,
      "loss": 4.921,
      "step": 3409
    },
    {
      "epoch": 0.39101020525169133,
      "grad_norm": 0.0,
      "learning_rate": 0.0006955033198378786,
      "loss": 4.9001,
      "step": 3410
    },
    {
      "epoch": 0.391124871001032,
      "grad_norm": 0.0,
      "learning_rate": 0.0006953324069738527,
      "loss": 5.0674,
      "step": 3411
    },
    {
      "epoch": 0.39123953675037265,
      "grad_norm": 0.0,
      "learning_rate": 0.0006951614671743411,
      "loss": 4.7242,
      "step": 3412
    },
    {
      "epoch": 0.3913542024997133,
      "grad_norm": 0.0,
      "learning_rate": 0.0006949905004629219,
      "loss": 5.3563,
      "step": 3413
    },
    {
      "epoch": 0.391468868249054,
      "grad_norm": 0.0,
      "learning_rate": 0.0006948195068631765,
      "loss": 4.962,
      "step": 3414
    },
    {
      "epoch": 0.3915835339983947,
      "grad_norm": 0.0,
      "learning_rate": 0.0006946484863986902,
      "loss": 4.8179,
      "step": 3415
    },
    {
      "epoch": 0.39169819974773534,
      "grad_norm": 0.0,
      "learning_rate": 0.0006944774390930522,
      "loss": 4.9913,
      "step": 3416
    },
    {
      "epoch": 0.391812865497076,
      "grad_norm": 0.0,
      "learning_rate": 0.000694306364969855,
      "loss": 5.159,
      "step": 3417
    },
    {
      "epoch": 0.3919275312464167,
      "grad_norm": 0.0,
      "learning_rate": 0.0006941352640526951,
      "loss": 4.8755,
      "step": 3418
    },
    {
      "epoch": 0.3920421969957574,
      "grad_norm": 0.0,
      "learning_rate": 0.0006939641363651726,
      "loss": 4.8942,
      "step": 3419
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.0,
      "learning_rate": 0.0006937929819308915,
      "loss": 4.913,
      "step": 3420
    },
    {
      "epoch": 0.3922715284944387,
      "grad_norm": 0.0,
      "learning_rate": 0.0006936218007734591,
      "loss": 4.8518,
      "step": 3421
    },
    {
      "epoch": 0.3923861942437794,
      "grad_norm": 0.0,
      "learning_rate": 0.0006934505929164865,
      "loss": 4.757,
      "step": 3422
    },
    {
      "epoch": 0.39250085999312007,
      "grad_norm": 0.0,
      "learning_rate": 0.0006932793583835885,
      "loss": 4.8525,
      "step": 3423
    },
    {
      "epoch": 0.3926155257424607,
      "grad_norm": 0.0,
      "learning_rate": 0.0006931080971983841,
      "loss": 4.9211,
      "step": 3424
    },
    {
      "epoch": 0.3927301914918014,
      "grad_norm": 0.0,
      "learning_rate": 0.0006929368093844951,
      "loss": 4.9811,
      "step": 3425
    },
    {
      "epoch": 0.3928448572411421,
      "grad_norm": 0.0,
      "learning_rate": 0.0006927654949655475,
      "loss": 4.9476,
      "step": 3426
    },
    {
      "epoch": 0.39295952299048276,
      "grad_norm": 0.0,
      "learning_rate": 0.0006925941539651708,
      "loss": 5.0995,
      "step": 3427
    },
    {
      "epoch": 0.3930741887398234,
      "grad_norm": 0.0,
      "learning_rate": 0.0006924227864069984,
      "loss": 5.0699,
      "step": 3428
    },
    {
      "epoch": 0.3931888544891641,
      "grad_norm": 0.0,
      "learning_rate": 0.000692251392314667,
      "loss": 5.1446,
      "step": 3429
    },
    {
      "epoch": 0.39330352023850473,
      "grad_norm": 0.0,
      "learning_rate": 0.0006920799717118171,
      "loss": 4.8286,
      "step": 3430
    },
    {
      "epoch": 0.39341818598784545,
      "grad_norm": 0.0,
      "learning_rate": 0.0006919085246220934,
      "loss": 4.7822,
      "step": 3431
    },
    {
      "epoch": 0.3935328517371861,
      "grad_norm": 0.0,
      "learning_rate": 0.000691737051069143,
      "loss": 5.0482,
      "step": 3432
    },
    {
      "epoch": 0.39364751748652677,
      "grad_norm": 0.0,
      "learning_rate": 0.0006915655510766181,
      "loss": 5.3443,
      "step": 3433
    },
    {
      "epoch": 0.3937621832358674,
      "grad_norm": 0.0,
      "learning_rate": 0.0006913940246681733,
      "loss": 4.9944,
      "step": 3434
    },
    {
      "epoch": 0.39387684898520814,
      "grad_norm": 0.0,
      "learning_rate": 0.0006912224718674676,
      "loss": 4.8241,
      "step": 3435
    },
    {
      "epoch": 0.3939915147345488,
      "grad_norm": 0.0,
      "learning_rate": 0.0006910508926981639,
      "loss": 5.0077,
      "step": 3436
    },
    {
      "epoch": 0.39410618048388946,
      "grad_norm": 0.0,
      "learning_rate": 0.0006908792871839275,
      "loss": 4.9872,
      "step": 3437
    },
    {
      "epoch": 0.3942208462332301,
      "grad_norm": 0.0,
      "learning_rate": 0.0006907076553484285,
      "loss": 5.0524,
      "step": 3438
    },
    {
      "epoch": 0.39433551198257083,
      "grad_norm": 0.0,
      "learning_rate": 0.0006905359972153402,
      "loss": 5.1438,
      "step": 3439
    },
    {
      "epoch": 0.3944501777319115,
      "grad_norm": 0.0,
      "learning_rate": 0.0006903643128083396,
      "loss": 5.0144,
      "step": 3440
    },
    {
      "epoch": 0.39456484348125215,
      "grad_norm": 0.0,
      "learning_rate": 0.0006901926021511074,
      "loss": 5.1115,
      "step": 3441
    },
    {
      "epoch": 0.3946795092305928,
      "grad_norm": 0.0,
      "learning_rate": 0.0006900208652673278,
      "loss": 5.5121,
      "step": 3442
    },
    {
      "epoch": 0.3947941749799335,
      "grad_norm": 0.0,
      "learning_rate": 0.0006898491021806881,
      "loss": 5.1807,
      "step": 3443
    },
    {
      "epoch": 0.3949088407292742,
      "grad_norm": 0.0,
      "learning_rate": 0.0006896773129148803,
      "loss": 4.8567,
      "step": 3444
    },
    {
      "epoch": 0.39502350647861484,
      "grad_norm": 0.0,
      "learning_rate": 0.0006895054974935994,
      "loss": 5.0425,
      "step": 3445
    },
    {
      "epoch": 0.3951381722279555,
      "grad_norm": 0.0,
      "learning_rate": 0.0006893336559405439,
      "loss": 5.0752,
      "step": 3446
    },
    {
      "epoch": 0.39525283797729616,
      "grad_norm": 0.0,
      "learning_rate": 0.0006891617882794163,
      "loss": 5.1709,
      "step": 3447
    },
    {
      "epoch": 0.39536750372663687,
      "grad_norm": 0.0,
      "learning_rate": 0.0006889898945339222,
      "loss": 5.0237,
      "step": 3448
    },
    {
      "epoch": 0.39548216947597753,
      "grad_norm": 0.0,
      "learning_rate": 0.0006888179747277709,
      "loss": 5.0453,
      "step": 3449
    },
    {
      "epoch": 0.3955968352253182,
      "grad_norm": 0.0,
      "learning_rate": 0.0006886460288846761,
      "loss": 5.0046,
      "step": 3450
    },
    {
      "epoch": 0.39571150097465885,
      "grad_norm": 0.0,
      "learning_rate": 0.0006884740570283538,
      "loss": 5.2281,
      "step": 3451
    },
    {
      "epoch": 0.39582616672399956,
      "grad_norm": 0.0,
      "learning_rate": 0.0006883020591825249,
      "loss": 4.8082,
      "step": 3452
    },
    {
      "epoch": 0.3959408324733402,
      "grad_norm": 0.0,
      "learning_rate": 0.0006881300353709127,
      "loss": 4.7275,
      "step": 3453
    },
    {
      "epoch": 0.3960554982226809,
      "grad_norm": 0.0,
      "learning_rate": 0.0006879579856172446,
      "loss": 4.8546,
      "step": 3454
    },
    {
      "epoch": 0.39617016397202154,
      "grad_norm": 0.0,
      "learning_rate": 0.000687785909945252,
      "loss": 4.9941,
      "step": 3455
    },
    {
      "epoch": 0.39628482972136225,
      "grad_norm": 0.0,
      "learning_rate": 0.0006876138083786688,
      "loss": 4.898,
      "step": 3456
    },
    {
      "epoch": 0.3963994954707029,
      "grad_norm": 0.0,
      "learning_rate": 0.0006874416809412337,
      "loss": 4.9304,
      "step": 3457
    },
    {
      "epoch": 0.39651416122004357,
      "grad_norm": 0.0,
      "learning_rate": 0.0006872695276566883,
      "loss": 5.2285,
      "step": 3458
    },
    {
      "epoch": 0.39662882696938423,
      "grad_norm": 0.0,
      "learning_rate": 0.0006870973485487779,
      "loss": 4.7755,
      "step": 3459
    },
    {
      "epoch": 0.39674349271872494,
      "grad_norm": 0.0,
      "learning_rate": 0.0006869251436412509,
      "loss": 5.1349,
      "step": 3460
    },
    {
      "epoch": 0.3968581584680656,
      "grad_norm": 0.0,
      "learning_rate": 0.0006867529129578602,
      "loss": 5.0385,
      "step": 3461
    },
    {
      "epoch": 0.39697282421740626,
      "grad_norm": 0.0,
      "learning_rate": 0.0006865806565223614,
      "loss": 5.2286,
      "step": 3462
    },
    {
      "epoch": 0.3970874899667469,
      "grad_norm": 0.0,
      "learning_rate": 0.0006864083743585145,
      "loss": 4.8721,
      "step": 3463
    },
    {
      "epoch": 0.3972021557160876,
      "grad_norm": 0.0,
      "learning_rate": 0.0006862360664900819,
      "loss": 4.8572,
      "step": 3464
    },
    {
      "epoch": 0.3973168214654283,
      "grad_norm": 0.0,
      "learning_rate": 0.0006860637329408303,
      "loss": 4.8209,
      "step": 3465
    },
    {
      "epoch": 0.39743148721476895,
      "grad_norm": 0.0,
      "learning_rate": 0.0006858913737345303,
      "loss": 4.85,
      "step": 3466
    },
    {
      "epoch": 0.3975461529641096,
      "grad_norm": 0.0,
      "learning_rate": 0.0006857189888949548,
      "loss": 5.1112,
      "step": 3467
    },
    {
      "epoch": 0.39766081871345027,
      "grad_norm": 0.0,
      "learning_rate": 0.0006855465784458819,
      "loss": 5.1374,
      "step": 3468
    },
    {
      "epoch": 0.397775484462791,
      "grad_norm": 0.0,
      "learning_rate": 0.0006853741424110919,
      "loss": 4.9813,
      "step": 3469
    },
    {
      "epoch": 0.39789015021213164,
      "grad_norm": 0.0,
      "learning_rate": 0.0006852016808143688,
      "loss": 4.8801,
      "step": 3470
    },
    {
      "epoch": 0.3980048159614723,
      "grad_norm": 0.0,
      "learning_rate": 0.0006850291936795007,
      "loss": 5.1608,
      "step": 3471
    },
    {
      "epoch": 0.39811948171081296,
      "grad_norm": 0.0,
      "learning_rate": 0.000684856681030279,
      "loss": 4.9974,
      "step": 3472
    },
    {
      "epoch": 0.3982341474601537,
      "grad_norm": 0.0,
      "learning_rate": 0.0006846841428904982,
      "loss": 4.7406,
      "step": 3473
    },
    {
      "epoch": 0.39834881320949433,
      "grad_norm": 0.0,
      "learning_rate": 0.0006845115792839569,
      "loss": 5.0268,
      "step": 3474
    },
    {
      "epoch": 0.398463478958835,
      "grad_norm": 0.0,
      "learning_rate": 0.0006843389902344571,
      "loss": 4.899,
      "step": 3475
    },
    {
      "epoch": 0.39857814470817565,
      "grad_norm": 0.0,
      "learning_rate": 0.0006841663757658036,
      "loss": 5.0559,
      "step": 3476
    },
    {
      "epoch": 0.39869281045751637,
      "grad_norm": 0.0,
      "learning_rate": 0.0006839937359018058,
      "loss": 4.8165,
      "step": 3477
    },
    {
      "epoch": 0.398807476206857,
      "grad_norm": 0.0,
      "learning_rate": 0.0006838210706662759,
      "loss": 4.906,
      "step": 3478
    },
    {
      "epoch": 0.3989221419561977,
      "grad_norm": 0.0,
      "learning_rate": 0.00068364838008303,
      "loss": 4.7301,
      "step": 3479
    },
    {
      "epoch": 0.39903680770553834,
      "grad_norm": 0.0,
      "learning_rate": 0.000683475664175887,
      "loss": 5.007,
      "step": 3480
    },
    {
      "epoch": 0.399151473454879,
      "grad_norm": 0.0,
      "learning_rate": 0.0006833029229686701,
      "loss": 4.7315,
      "step": 3481
    },
    {
      "epoch": 0.3992661392042197,
      "grad_norm": 0.0,
      "learning_rate": 0.0006831301564852059,
      "loss": 5.0637,
      "step": 3482
    },
    {
      "epoch": 0.3993808049535604,
      "grad_norm": 0.0,
      "learning_rate": 0.0006829573647493236,
      "loss": 5.128,
      "step": 3483
    },
    {
      "epoch": 0.39949547070290103,
      "grad_norm": 0.0,
      "learning_rate": 0.0006827845477848568,
      "loss": 5.0799,
      "step": 3484
    },
    {
      "epoch": 0.3996101364522417,
      "grad_norm": 0.0,
      "learning_rate": 0.0006826117056156426,
      "loss": 5.0253,
      "step": 3485
    },
    {
      "epoch": 0.3997248022015824,
      "grad_norm": 0.0,
      "learning_rate": 0.000682438838265521,
      "loss": 4.9085,
      "step": 3486
    },
    {
      "epoch": 0.39983946795092307,
      "grad_norm": 0.0,
      "learning_rate": 0.0006822659457583357,
      "loss": 5.3542,
      "step": 3487
    },
    {
      "epoch": 0.3999541337002637,
      "grad_norm": 0.0,
      "learning_rate": 0.000682093028117934,
      "loss": 5.1362,
      "step": 3488
    },
    {
      "epoch": 0.4000687994496044,
      "grad_norm": 0.0,
      "learning_rate": 0.0006819200853681669,
      "loss": 4.894,
      "step": 3489
    },
    {
      "epoch": 0.4001834651989451,
      "grad_norm": 0.0,
      "learning_rate": 0.0006817471175328881,
      "loss": 4.9495,
      "step": 3490
    },
    {
      "epoch": 0.40029813094828576,
      "grad_norm": 0.0,
      "learning_rate": 0.0006815741246359553,
      "loss": 5.0265,
      "step": 3491
    },
    {
      "epoch": 0.4004127966976264,
      "grad_norm": 0.0,
      "learning_rate": 0.0006814011067012299,
      "loss": 5.1213,
      "step": 3492
    },
    {
      "epoch": 0.4005274624469671,
      "grad_norm": 0.0,
      "learning_rate": 0.0006812280637525762,
      "loss": 4.9685,
      "step": 3493
    },
    {
      "epoch": 0.4006421281963078,
      "grad_norm": 0.0,
      "learning_rate": 0.000681054995813862,
      "loss": 5.1316,
      "step": 3494
    },
    {
      "epoch": 0.40075679394564845,
      "grad_norm": 0.0,
      "learning_rate": 0.0006808819029089589,
      "loss": 4.8923,
      "step": 3495
    },
    {
      "epoch": 0.4008714596949891,
      "grad_norm": 0.0,
      "learning_rate": 0.0006807087850617419,
      "loss": 5.0361,
      "step": 3496
    },
    {
      "epoch": 0.40098612544432977,
      "grad_norm": 0.0,
      "learning_rate": 0.0006805356422960892,
      "loss": 5.0263,
      "step": 3497
    },
    {
      "epoch": 0.4011007911936704,
      "grad_norm": 0.0,
      "learning_rate": 0.0006803624746358822,
      "loss": 5.3803,
      "step": 3498
    },
    {
      "epoch": 0.40121545694301114,
      "grad_norm": 0.0,
      "learning_rate": 0.0006801892821050067,
      "loss": 4.9482,
      "step": 3499
    },
    {
      "epoch": 0.4013301226923518,
      "grad_norm": 0.0,
      "learning_rate": 0.0006800160647273508,
      "loss": 4.9728,
      "step": 3500
    },
    {
      "epoch": 0.40144478844169246,
      "grad_norm": 0.0,
      "learning_rate": 0.0006798428225268068,
      "loss": 4.8828,
      "step": 3501
    },
    {
      "epoch": 0.4015594541910331,
      "grad_norm": 0.0,
      "learning_rate": 0.0006796695555272703,
      "loss": 5.0135,
      "step": 3502
    },
    {
      "epoch": 0.40167411994037383,
      "grad_norm": 0.0,
      "learning_rate": 0.0006794962637526399,
      "loss": 5.052,
      "step": 3503
    },
    {
      "epoch": 0.4017887856897145,
      "grad_norm": 0.0,
      "learning_rate": 0.0006793229472268177,
      "loss": 5.1179,
      "step": 3504
    },
    {
      "epoch": 0.40190345143905515,
      "grad_norm": 0.0,
      "learning_rate": 0.0006791496059737099,
      "loss": 5.1554,
      "step": 3505
    },
    {
      "epoch": 0.4020181171883958,
      "grad_norm": 0.0,
      "learning_rate": 0.0006789762400172254,
      "loss": 5.139,
      "step": 3506
    },
    {
      "epoch": 0.4021327829377365,
      "grad_norm": 0.0,
      "learning_rate": 0.0006788028493812765,
      "loss": 5.1936,
      "step": 3507
    },
    {
      "epoch": 0.4022474486870772,
      "grad_norm": 0.0,
      "learning_rate": 0.0006786294340897797,
      "loss": 5.1338,
      "step": 3508
    },
    {
      "epoch": 0.40236211443641784,
      "grad_norm": 0.0,
      "learning_rate": 0.000678455994166654,
      "loss": 5.088,
      "step": 3509
    },
    {
      "epoch": 0.4024767801857585,
      "grad_norm": 0.0,
      "learning_rate": 0.000678282529635822,
      "loss": 4.9936,
      "step": 3510
    },
    {
      "epoch": 0.4025914459350992,
      "grad_norm": 0.0,
      "learning_rate": 0.0006781090405212099,
      "loss": 5.1072,
      "step": 3511
    },
    {
      "epoch": 0.40270611168443987,
      "grad_norm": 0.0,
      "learning_rate": 0.0006779355268467471,
      "loss": 5.0757,
      "step": 3512
    },
    {
      "epoch": 0.40282077743378053,
      "grad_norm": 0.0,
      "learning_rate": 0.0006777619886363671,
      "loss": 5.1836,
      "step": 3513
    },
    {
      "epoch": 0.4029354431831212,
      "grad_norm": 0.0,
      "learning_rate": 0.0006775884259140057,
      "loss": 5.2265,
      "step": 3514
    },
    {
      "epoch": 0.40305010893246185,
      "grad_norm": 0.0,
      "learning_rate": 0.0006774148387036024,
      "loss": 5.0718,
      "step": 3515
    },
    {
      "epoch": 0.40316477468180256,
      "grad_norm": 0.0,
      "learning_rate": 0.0006772412270291006,
      "loss": 5.0424,
      "step": 3516
    },
    {
      "epoch": 0.4032794404311432,
      "grad_norm": 0.0,
      "learning_rate": 0.0006770675909144464,
      "loss": 4.9194,
      "step": 3517
    },
    {
      "epoch": 0.4033941061804839,
      "grad_norm": 0.0,
      "learning_rate": 0.0006768939303835902,
      "loss": 4.7986,
      "step": 3518
    },
    {
      "epoch": 0.40350877192982454,
      "grad_norm": 0.0,
      "learning_rate": 0.0006767202454604846,
      "loss": 4.9375,
      "step": 3519
    },
    {
      "epoch": 0.40362343767916525,
      "grad_norm": 0.0,
      "learning_rate": 0.0006765465361690861,
      "loss": 4.9856,
      "step": 3520
    },
    {
      "epoch": 0.4037381034285059,
      "grad_norm": 0.0,
      "learning_rate": 0.0006763728025333548,
      "loss": 4.8755,
      "step": 3521
    },
    {
      "epoch": 0.40385276917784657,
      "grad_norm": 0.0,
      "learning_rate": 0.0006761990445772542,
      "loss": 4.9031,
      "step": 3522
    },
    {
      "epoch": 0.40396743492718723,
      "grad_norm": 0.0,
      "learning_rate": 0.0006760252623247504,
      "loss": 5.2314,
      "step": 3523
    },
    {
      "epoch": 0.40408210067652794,
      "grad_norm": 0.0,
      "learning_rate": 0.0006758514557998137,
      "loss": 5.1722,
      "step": 3524
    },
    {
      "epoch": 0.4041967664258686,
      "grad_norm": 0.0,
      "learning_rate": 0.0006756776250264171,
      "loss": 5.2153,
      "step": 3525
    },
    {
      "epoch": 0.40431143217520926,
      "grad_norm": 0.0,
      "learning_rate": 0.0006755037700285374,
      "loss": 4.675,
      "step": 3526
    },
    {
      "epoch": 0.4044260979245499,
      "grad_norm": 0.0,
      "learning_rate": 0.0006753298908301543,
      "loss": 4.7775,
      "step": 3527
    },
    {
      "epoch": 0.40454076367389064,
      "grad_norm": 0.0,
      "learning_rate": 0.0006751559874552519,
      "loss": 5.1114,
      "step": 3528
    },
    {
      "epoch": 0.4046554294232313,
      "grad_norm": 0.0,
      "learning_rate": 0.0006749820599278162,
      "loss": 5.3613,
      "step": 3529
    },
    {
      "epoch": 0.40477009517257195,
      "grad_norm": 0.0,
      "learning_rate": 0.0006748081082718373,
      "loss": 5.389,
      "step": 3530
    },
    {
      "epoch": 0.4048847609219126,
      "grad_norm": 0.0,
      "learning_rate": 0.0006746341325113085,
      "loss": 5.1513,
      "step": 3531
    },
    {
      "epoch": 0.40499942667125327,
      "grad_norm": 0.0,
      "learning_rate": 0.0006744601326702265,
      "loss": 5.1224,
      "step": 3532
    },
    {
      "epoch": 0.405114092420594,
      "grad_norm": 0.0,
      "learning_rate": 0.0006742861087725913,
      "loss": 5.1148,
      "step": 3533
    },
    {
      "epoch": 0.40522875816993464,
      "grad_norm": 0.0,
      "learning_rate": 0.0006741120608424061,
      "loss": 4.9716,
      "step": 3534
    },
    {
      "epoch": 0.4053434239192753,
      "grad_norm": 0.0,
      "learning_rate": 0.0006739379889036778,
      "loss": 5.4009,
      "step": 3535
    },
    {
      "epoch": 0.40545808966861596,
      "grad_norm": 0.0,
      "learning_rate": 0.0006737638929804156,
      "loss": 4.9785,
      "step": 3536
    },
    {
      "epoch": 0.4055727554179567,
      "grad_norm": 0.0,
      "learning_rate": 0.0006735897730966334,
      "loss": 4.9637,
      "step": 3537
    },
    {
      "epoch": 0.40568742116729734,
      "grad_norm": 0.0,
      "learning_rate": 0.0006734156292763474,
      "loss": 4.8823,
      "step": 3538
    },
    {
      "epoch": 0.405802086916638,
      "grad_norm": 0.0,
      "learning_rate": 0.0006732414615435774,
      "loss": 5.0394,
      "step": 3539
    },
    {
      "epoch": 0.40591675266597865,
      "grad_norm": 0.0,
      "learning_rate": 0.0006730672699223468,
      "loss": 5.1367,
      "step": 3540
    },
    {
      "epoch": 0.40603141841531937,
      "grad_norm": 0.0,
      "learning_rate": 0.0006728930544366818,
      "loss": 4.9326,
      "step": 3541
    },
    {
      "epoch": 0.40614608416466,
      "grad_norm": 0.0,
      "learning_rate": 0.0006727188151106119,
      "loss": 4.8597,
      "step": 3542
    },
    {
      "epoch": 0.4062607499140007,
      "grad_norm": 0.0,
      "learning_rate": 0.0006725445519681708,
      "loss": 4.7923,
      "step": 3543
    },
    {
      "epoch": 0.40637541566334134,
      "grad_norm": 0.0,
      "learning_rate": 0.0006723702650333939,
      "loss": 4.8945,
      "step": 3544
    },
    {
      "epoch": 0.40649008141268206,
      "grad_norm": 0.0,
      "learning_rate": 0.0006721959543303213,
      "loss": 5.1248,
      "step": 3545
    },
    {
      "epoch": 0.4066047471620227,
      "grad_norm": 0.0,
      "learning_rate": 0.0006720216198829957,
      "loss": 5.1702,
      "step": 3546
    },
    {
      "epoch": 0.4067194129113634,
      "grad_norm": 0.0,
      "learning_rate": 0.000671847261715463,
      "loss": 5.0298,
      "step": 3547
    },
    {
      "epoch": 0.40683407866070403,
      "grad_norm": 0.0,
      "learning_rate": 0.0006716728798517731,
      "loss": 5.2796,
      "step": 3548
    },
    {
      "epoch": 0.4069487444100447,
      "grad_norm": 0.0,
      "learning_rate": 0.0006714984743159781,
      "loss": 4.9434,
      "step": 3549
    },
    {
      "epoch": 0.4070634101593854,
      "grad_norm": 0.0,
      "learning_rate": 0.0006713240451321344,
      "loss": 5.0372,
      "step": 3550
    },
    {
      "epoch": 0.40717807590872607,
      "grad_norm": 0.0,
      "learning_rate": 0.0006711495923243008,
      "loss": 5.1514,
      "step": 3551
    },
    {
      "epoch": 0.4072927416580667,
      "grad_norm": 0.0,
      "learning_rate": 0.00067097511591654,
      "loss": 5.2191,
      "step": 3552
    },
    {
      "epoch": 0.4074074074074074,
      "grad_norm": 0.0,
      "learning_rate": 0.0006708006159329176,
      "loss": 5.0427,
      "step": 3553
    },
    {
      "epoch": 0.4075220731567481,
      "grad_norm": 0.0,
      "learning_rate": 0.0006706260923975025,
      "loss": 5.1782,
      "step": 3554
    },
    {
      "epoch": 0.40763673890608876,
      "grad_norm": 0.0,
      "learning_rate": 0.0006704515453343668,
      "loss": 5.2795,
      "step": 3555
    },
    {
      "epoch": 0.4077514046554294,
      "grad_norm": 0.0,
      "learning_rate": 0.0006702769747675861,
      "loss": 5.0394,
      "step": 3556
    },
    {
      "epoch": 0.4078660704047701,
      "grad_norm": 0.0,
      "learning_rate": 0.0006701023807212392,
      "loss": 4.9469,
      "step": 3557
    },
    {
      "epoch": 0.4079807361541108,
      "grad_norm": 0.0,
      "learning_rate": 0.0006699277632194079,
      "loss": 5.014,
      "step": 3558
    },
    {
      "epoch": 0.40809540190345145,
      "grad_norm": 0.0,
      "learning_rate": 0.0006697531222861772,
      "loss": 5.1854,
      "step": 3559
    },
    {
      "epoch": 0.4082100676527921,
      "grad_norm": 0.0,
      "learning_rate": 0.0006695784579456355,
      "loss": 4.9591,
      "step": 3560
    },
    {
      "epoch": 0.40832473340213277,
      "grad_norm": 0.0,
      "learning_rate": 0.0006694037702218748,
      "loss": 4.7876,
      "step": 3561
    },
    {
      "epoch": 0.4084393991514735,
      "grad_norm": 0.0,
      "learning_rate": 0.0006692290591389894,
      "loss": 5.1679,
      "step": 3562
    },
    {
      "epoch": 0.40855406490081414,
      "grad_norm": 0.0,
      "learning_rate": 0.0006690543247210779,
      "loss": 4.9116,
      "step": 3563
    },
    {
      "epoch": 0.4086687306501548,
      "grad_norm": 0.0,
      "learning_rate": 0.0006688795669922414,
      "loss": 4.9464,
      "step": 3564
    },
    {
      "epoch": 0.40878339639949546,
      "grad_norm": 0.0,
      "learning_rate": 0.0006687047859765841,
      "loss": 4.8617,
      "step": 3565
    },
    {
      "epoch": 0.4088980621488361,
      "grad_norm": 0.0,
      "learning_rate": 0.0006685299816982139,
      "loss": 4.8393,
      "step": 3566
    },
    {
      "epoch": 0.40901272789817683,
      "grad_norm": 0.0,
      "learning_rate": 0.0006683551541812417,
      "loss": 5.258,
      "step": 3567
    },
    {
      "epoch": 0.4091273936475175,
      "grad_norm": 0.0,
      "learning_rate": 0.0006681803034497819,
      "loss": 4.9727,
      "step": 3568
    },
    {
      "epoch": 0.40924205939685815,
      "grad_norm": 0.0,
      "learning_rate": 0.0006680054295279515,
      "loss": 4.8034,
      "step": 3569
    },
    {
      "epoch": 0.4093567251461988,
      "grad_norm": 0.0,
      "learning_rate": 0.0006678305324398711,
      "loss": 5.0309,
      "step": 3570
    },
    {
      "epoch": 0.4094713908955395,
      "grad_norm": 0.0,
      "learning_rate": 0.0006676556122096643,
      "loss": 4.9396,
      "step": 3571
    },
    {
      "epoch": 0.4095860566448802,
      "grad_norm": 0.0,
      "learning_rate": 0.0006674806688614582,
      "loss": 4.8753,
      "step": 3572
    },
    {
      "epoch": 0.40970072239422084,
      "grad_norm": 0.0,
      "learning_rate": 0.000667305702419383,
      "loss": 5.0269,
      "step": 3573
    },
    {
      "epoch": 0.4098153881435615,
      "grad_norm": 0.0,
      "learning_rate": 0.0006671307129075719,
      "loss": 5.0004,
      "step": 3574
    },
    {
      "epoch": 0.4099300538929022,
      "grad_norm": 0.0,
      "learning_rate": 0.0006669557003501611,
      "loss": 5.0676,
      "step": 3575
    },
    {
      "epoch": 0.41004471964224287,
      "grad_norm": 0.0,
      "learning_rate": 0.0006667806647712905,
      "loss": 4.9232,
      "step": 3576
    },
    {
      "epoch": 0.41015938539158353,
      "grad_norm": 0.0,
      "learning_rate": 0.0006666056061951028,
      "loss": 5.2521,
      "step": 3577
    },
    {
      "epoch": 0.4102740511409242,
      "grad_norm": 0.0,
      "learning_rate": 0.0006664305246457441,
      "loss": 5.1938,
      "step": 3578
    },
    {
      "epoch": 0.4103887168902649,
      "grad_norm": 0.0,
      "learning_rate": 0.0006662554201473637,
      "loss": 5.0428,
      "step": 3579
    },
    {
      "epoch": 0.41050338263960556,
      "grad_norm": 0.0,
      "learning_rate": 0.0006660802927241135,
      "loss": 5.1739,
      "step": 3580
    },
    {
      "epoch": 0.4106180483889462,
      "grad_norm": 0.0,
      "learning_rate": 0.0006659051424001495,
      "loss": 4.8748,
      "step": 3581
    },
    {
      "epoch": 0.4107327141382869,
      "grad_norm": 0.0,
      "learning_rate": 0.0006657299691996299,
      "loss": 4.6431,
      "step": 3582
    },
    {
      "epoch": 0.41084737988762754,
      "grad_norm": 0.0,
      "learning_rate": 0.0006655547731467166,
      "loss": 5.1063,
      "step": 3583
    },
    {
      "epoch": 0.41096204563696825,
      "grad_norm": 0.0,
      "learning_rate": 0.0006653795542655751,
      "loss": 4.8641,
      "step": 3584
    },
    {
      "epoch": 0.4110767113863089,
      "grad_norm": 0.0,
      "learning_rate": 0.0006652043125803726,
      "loss": 5.2008,
      "step": 3585
    },
    {
      "epoch": 0.41119137713564957,
      "grad_norm": 0.0,
      "learning_rate": 0.000665029048115281,
      "loss": 5.0743,
      "step": 3586
    },
    {
      "epoch": 0.41130604288499023,
      "grad_norm": 0.0,
      "learning_rate": 0.0006648537608944746,
      "loss": 5.1005,
      "step": 3587
    },
    {
      "epoch": 0.41142070863433094,
      "grad_norm": 0.0,
      "learning_rate": 0.0006646784509421306,
      "loss": 5.0765,
      "step": 3588
    },
    {
      "epoch": 0.4115353743836716,
      "grad_norm": 0.0,
      "learning_rate": 0.00066450311828243,
      "loss": 4.9078,
      "step": 3589
    },
    {
      "epoch": 0.41165004013301226,
      "grad_norm": 0.0,
      "learning_rate": 0.0006643277629395564,
      "loss": 5.1036,
      "step": 3590
    },
    {
      "epoch": 0.4117647058823529,
      "grad_norm": 0.0,
      "learning_rate": 0.000664152384937697,
      "loss": 4.9986,
      "step": 3591
    },
    {
      "epoch": 0.41187937163169364,
      "grad_norm": 0.0,
      "learning_rate": 0.0006639769843010414,
      "loss": 5.012,
      "step": 3592
    },
    {
      "epoch": 0.4119940373810343,
      "grad_norm": 0.0,
      "learning_rate": 0.0006638015610537833,
      "loss": 4.8923,
      "step": 3593
    },
    {
      "epoch": 0.41210870313037495,
      "grad_norm": 0.0,
      "learning_rate": 0.0006636261152201188,
      "loss": 4.8918,
      "step": 3594
    },
    {
      "epoch": 0.4122233688797156,
      "grad_norm": 0.0,
      "learning_rate": 0.000663450646824247,
      "loss": 4.8338,
      "step": 3595
    },
    {
      "epoch": 0.4123380346290563,
      "grad_norm": 0.0,
      "learning_rate": 0.000663275155890371,
      "loss": 5.0208,
      "step": 3596
    },
    {
      "epoch": 0.412452700378397,
      "grad_norm": 0.0,
      "learning_rate": 0.0006630996424426959,
      "loss": 4.6768,
      "step": 3597
    },
    {
      "epoch": 0.41256736612773764,
      "grad_norm": 0.0,
      "learning_rate": 0.0006629241065054304,
      "loss": 5.0829,
      "step": 3598
    },
    {
      "epoch": 0.4126820318770783,
      "grad_norm": 0.0,
      "learning_rate": 0.0006627485481027869,
      "loss": 5.1154,
      "step": 3599
    },
    {
      "epoch": 0.41279669762641896,
      "grad_norm": 0.0,
      "learning_rate": 0.0006625729672589799,
      "loss": 5.2647,
      "step": 3600
    },
    {
      "epoch": 0.4129113633757597,
      "grad_norm": 0.0,
      "learning_rate": 0.0006623973639982276,
      "loss": 5.3187,
      "step": 3601
    },
    {
      "epoch": 0.41302602912510034,
      "grad_norm": 0.0,
      "learning_rate": 0.000662221738344751,
      "loss": 5.0615,
      "step": 3602
    },
    {
      "epoch": 0.413140694874441,
      "grad_norm": 0.0,
      "learning_rate": 0.0006620460903227743,
      "loss": 5.1808,
      "step": 3603
    },
    {
      "epoch": 0.41325536062378165,
      "grad_norm": 0.0,
      "learning_rate": 0.000661870419956525,
      "loss": 4.9403,
      "step": 3604
    },
    {
      "epoch": 0.41337002637312237,
      "grad_norm": 0.0,
      "learning_rate": 0.0006616947272702333,
      "loss": 4.8881,
      "step": 3605
    },
    {
      "epoch": 0.413484692122463,
      "grad_norm": 0.0,
      "learning_rate": 0.0006615190122881326,
      "loss": 5.119,
      "step": 3606
    },
    {
      "epoch": 0.4135993578718037,
      "grad_norm": 0.0,
      "learning_rate": 0.0006613432750344598,
      "loss": 5.0301,
      "step": 3607
    },
    {
      "epoch": 0.41371402362114434,
      "grad_norm": 0.0,
      "learning_rate": 0.000661167515533454,
      "loss": 5.1209,
      "step": 3608
    },
    {
      "epoch": 0.41382868937048506,
      "grad_norm": 0.0,
      "learning_rate": 0.0006609917338093581,
      "loss": 4.8616,
      "step": 3609
    },
    {
      "epoch": 0.4139433551198257,
      "grad_norm": 0.0,
      "learning_rate": 0.0006608159298864179,
      "loss": 4.9358,
      "step": 3610
    },
    {
      "epoch": 0.4140580208691664,
      "grad_norm": 0.0,
      "learning_rate": 0.0006606401037888822,
      "loss": 4.9324,
      "step": 3611
    },
    {
      "epoch": 0.41417268661850704,
      "grad_norm": 0.0,
      "learning_rate": 0.0006604642555410027,
      "loss": 4.7828,
      "step": 3612
    },
    {
      "epoch": 0.41428735236784775,
      "grad_norm": 0.0,
      "learning_rate": 0.0006602883851670346,
      "loss": 5.1271,
      "step": 3613
    },
    {
      "epoch": 0.4144020181171884,
      "grad_norm": 0.0,
      "learning_rate": 0.0006601124926912355,
      "loss": 5.1518,
      "step": 3614
    },
    {
      "epoch": 0.41451668386652907,
      "grad_norm": 0.0,
      "learning_rate": 0.0006599365781378668,
      "loss": 5.2544,
      "step": 3615
    },
    {
      "epoch": 0.4146313496158697,
      "grad_norm": 0.0,
      "learning_rate": 0.0006597606415311922,
      "loss": 4.9044,
      "step": 3616
    },
    {
      "epoch": 0.4147460153652104,
      "grad_norm": 0.0,
      "learning_rate": 0.000659584682895479,
      "loss": 4.9955,
      "step": 3617
    },
    {
      "epoch": 0.4148606811145511,
      "grad_norm": 0.0,
      "learning_rate": 0.0006594087022549974,
      "loss": 4.9057,
      "step": 3618
    },
    {
      "epoch": 0.41497534686389176,
      "grad_norm": 0.0,
      "learning_rate": 0.0006592326996340204,
      "loss": 4.9484,
      "step": 3619
    },
    {
      "epoch": 0.4150900126132324,
      "grad_norm": 0.0,
      "learning_rate": 0.0006590566750568242,
      "loss": 4.9765,
      "step": 3620
    },
    {
      "epoch": 0.4152046783625731,
      "grad_norm": 0.0,
      "learning_rate": 0.0006588806285476881,
      "loss": 4.8615,
      "step": 3621
    },
    {
      "epoch": 0.4153193441119138,
      "grad_norm": 0.0,
      "learning_rate": 0.0006587045601308945,
      "loss": 5.0878,
      "step": 3622
    },
    {
      "epoch": 0.41543400986125445,
      "grad_norm": 0.0,
      "learning_rate": 0.0006585284698307286,
      "loss": 4.9777,
      "step": 3623
    },
    {
      "epoch": 0.4155486756105951,
      "grad_norm": 0.0,
      "learning_rate": 0.0006583523576714787,
      "loss": 4.9615,
      "step": 3624
    },
    {
      "epoch": 0.41566334135993577,
      "grad_norm": 0.0,
      "learning_rate": 0.000658176223677436,
      "loss": 4.9691,
      "step": 3625
    },
    {
      "epoch": 0.4157780071092765,
      "grad_norm": 0.0,
      "learning_rate": 0.0006580000678728948,
      "loss": 4.8819,
      "step": 3626
    },
    {
      "epoch": 0.41589267285861714,
      "grad_norm": 0.0,
      "learning_rate": 0.0006578238902821526,
      "loss": 4.8928,
      "step": 3627
    },
    {
      "epoch": 0.4160073386079578,
      "grad_norm": 0.0,
      "learning_rate": 0.0006576476909295096,
      "loss": 5.0295,
      "step": 3628
    },
    {
      "epoch": 0.41612200435729846,
      "grad_norm": 0.0,
      "learning_rate": 0.0006574714698392695,
      "loss": 5.1358,
      "step": 3629
    },
    {
      "epoch": 0.4162366701066392,
      "grad_norm": 0.0,
      "learning_rate": 0.0006572952270357381,
      "loss": 4.8843,
      "step": 3630
    },
    {
      "epoch": 0.41635133585597983,
      "grad_norm": 0.0,
      "learning_rate": 0.000657118962543225,
      "loss": 5.3478,
      "step": 3631
    },
    {
      "epoch": 0.4164660016053205,
      "grad_norm": 0.0,
      "learning_rate": 0.0006569426763860426,
      "loss": 5.2689,
      "step": 3632
    },
    {
      "epoch": 0.41658066735466115,
      "grad_norm": 0.0,
      "learning_rate": 0.0006567663685885061,
      "loss": 4.9345,
      "step": 3633
    },
    {
      "epoch": 0.4166953331040018,
      "grad_norm": 0.0,
      "learning_rate": 0.0006565900391749338,
      "loss": 4.9934,
      "step": 3634
    },
    {
      "epoch": 0.4168099988533425,
      "grad_norm": 0.0,
      "learning_rate": 0.0006564136881696475,
      "loss": 5.1516,
      "step": 3635
    },
    {
      "epoch": 0.4169246646026832,
      "grad_norm": 0.0,
      "learning_rate": 0.0006562373155969704,
      "loss": 4.9185,
      "step": 3636
    },
    {
      "epoch": 0.41703933035202384,
      "grad_norm": 0.0,
      "learning_rate": 0.0006560609214812304,
      "loss": 4.9319,
      "step": 3637
    },
    {
      "epoch": 0.4171539961013645,
      "grad_norm": 0.0,
      "learning_rate": 0.0006558845058467577,
      "loss": 5.1565,
      "step": 3638
    },
    {
      "epoch": 0.4172686618507052,
      "grad_norm": 0.0,
      "learning_rate": 0.0006557080687178854,
      "loss": 5.1652,
      "step": 3639
    },
    {
      "epoch": 0.4173833276000459,
      "grad_norm": 0.0,
      "learning_rate": 0.0006555316101189497,
      "loss": 5.1347,
      "step": 3640
    },
    {
      "epoch": 0.41749799334938653,
      "grad_norm": 0.0,
      "learning_rate": 0.0006553551300742896,
      "loss": 5.0508,
      "step": 3641
    },
    {
      "epoch": 0.4176126590987272,
      "grad_norm": 0.0,
      "learning_rate": 0.000655178628608247,
      "loss": 5.2987,
      "step": 3642
    },
    {
      "epoch": 0.4177273248480679,
      "grad_norm": 0.0,
      "learning_rate": 0.0006550021057451673,
      "loss": 5.3764,
      "step": 3643
    },
    {
      "epoch": 0.41784199059740856,
      "grad_norm": 0.0,
      "learning_rate": 0.0006548255615093983,
      "loss": 4.9332,
      "step": 3644
    },
    {
      "epoch": 0.4179566563467492,
      "grad_norm": 0.0,
      "learning_rate": 0.0006546489959252909,
      "loss": 5.1288,
      "step": 3645
    },
    {
      "epoch": 0.4180713220960899,
      "grad_norm": 0.0,
      "learning_rate": 0.0006544724090171988,
      "loss": 4.8142,
      "step": 3646
    },
    {
      "epoch": 0.4181859878454306,
      "grad_norm": 0.0,
      "learning_rate": 0.000654295800809479,
      "loss": 5.051,
      "step": 3647
    },
    {
      "epoch": 0.41830065359477125,
      "grad_norm": 0.0,
      "learning_rate": 0.0006541191713264913,
      "loss": 4.956,
      "step": 3648
    },
    {
      "epoch": 0.4184153193441119,
      "grad_norm": 0.0,
      "learning_rate": 0.0006539425205925979,
      "loss": 5.0559,
      "step": 3649
    },
    {
      "epoch": 0.4185299850934526,
      "grad_norm": 0.0,
      "learning_rate": 0.0006537658486321649,
      "loss": 4.9354,
      "step": 3650
    },
    {
      "epoch": 0.41864465084279323,
      "grad_norm": 0.0,
      "learning_rate": 0.0006535891554695607,
      "loss": 5.1445,
      "step": 3651
    },
    {
      "epoch": 0.41875931659213395,
      "grad_norm": 0.0,
      "learning_rate": 0.0006534124411291568,
      "loss": 5.0568,
      "step": 3652
    },
    {
      "epoch": 0.4188739823414746,
      "grad_norm": 0.0,
      "learning_rate": 0.0006532357056353276,
      "loss": 4.9779,
      "step": 3653
    },
    {
      "epoch": 0.41898864809081526,
      "grad_norm": 0.0,
      "learning_rate": 0.0006530589490124499,
      "loss": 4.9983,
      "step": 3654
    },
    {
      "epoch": 0.4191033138401559,
      "grad_norm": 0.0,
      "learning_rate": 0.0006528821712849047,
      "loss": 4.9912,
      "step": 3655
    },
    {
      "epoch": 0.41921797958949664,
      "grad_norm": 0.0,
      "learning_rate": 0.0006527053724770746,
      "loss": 4.9599,
      "step": 3656
    },
    {
      "epoch": 0.4193326453388373,
      "grad_norm": 0.0,
      "learning_rate": 0.0006525285526133457,
      "loss": 5.2325,
      "step": 3657
    },
    {
      "epoch": 0.41944731108817795,
      "grad_norm": 0.0,
      "learning_rate": 0.0006523517117181069,
      "loss": 5.075,
      "step": 3658
    },
    {
      "epoch": 0.4195619768375186,
      "grad_norm": 0.0,
      "learning_rate": 0.0006521748498157503,
      "loss": 4.7786,
      "step": 3659
    },
    {
      "epoch": 0.4196766425868593,
      "grad_norm": 0.0,
      "learning_rate": 0.0006519979669306702,
      "loss": 5.0651,
      "step": 3660
    },
    {
      "epoch": 0.4197913083362,
      "grad_norm": 0.0,
      "learning_rate": 0.0006518210630872645,
      "loss": 5.0812,
      "step": 3661
    },
    {
      "epoch": 0.41990597408554065,
      "grad_norm": 0.0,
      "learning_rate": 0.0006516441383099339,
      "loss": 5.1205,
      "step": 3662
    },
    {
      "epoch": 0.4200206398348813,
      "grad_norm": 0.0,
      "learning_rate": 0.0006514671926230813,
      "loss": 4.7954,
      "step": 3663
    },
    {
      "epoch": 0.420135305584222,
      "grad_norm": 0.0,
      "learning_rate": 0.0006512902260511132,
      "loss": 5.3028,
      "step": 3664
    },
    {
      "epoch": 0.4202499713335627,
      "grad_norm": 0.0,
      "learning_rate": 0.0006511132386184391,
      "loss": 5.27,
      "step": 3665
    },
    {
      "epoch": 0.42036463708290334,
      "grad_norm": 0.0,
      "learning_rate": 0.0006509362303494706,
      "loss": 5.0698,
      "step": 3666
    },
    {
      "epoch": 0.420479302832244,
      "grad_norm": 0.0,
      "learning_rate": 0.0006507592012686226,
      "loss": 5.0276,
      "step": 3667
    },
    {
      "epoch": 0.42059396858158465,
      "grad_norm": 0.0,
      "learning_rate": 0.0006505821514003134,
      "loss": 5.1704,
      "step": 3668
    },
    {
      "epoch": 0.42070863433092537,
      "grad_norm": 0.0,
      "learning_rate": 0.0006504050807689632,
      "loss": 4.9849,
      "step": 3669
    },
    {
      "epoch": 0.420823300080266,
      "grad_norm": 0.0,
      "learning_rate": 0.0006502279893989955,
      "loss": 5.174,
      "step": 3670
    },
    {
      "epoch": 0.4209379658296067,
      "grad_norm": 0.0,
      "learning_rate": 0.000650050877314837,
      "loss": 5.0009,
      "step": 3671
    },
    {
      "epoch": 0.42105263157894735,
      "grad_norm": 0.0,
      "learning_rate": 0.0006498737445409166,
      "loss": 4.7298,
      "step": 3672
    },
    {
      "epoch": 0.42116729732828806,
      "grad_norm": 0.0,
      "learning_rate": 0.0006496965911016668,
      "loss": 4.7127,
      "step": 3673
    },
    {
      "epoch": 0.4212819630776287,
      "grad_norm": 0.0,
      "learning_rate": 0.0006495194170215219,
      "loss": 5.0983,
      "step": 3674
    },
    {
      "epoch": 0.4213966288269694,
      "grad_norm": 0.0,
      "learning_rate": 0.0006493422223249203,
      "loss": 5.0112,
      "step": 3675
    },
    {
      "epoch": 0.42151129457631004,
      "grad_norm": 0.0,
      "learning_rate": 0.0006491650070363026,
      "loss": 4.9577,
      "step": 3676
    },
    {
      "epoch": 0.42162596032565075,
      "grad_norm": 0.0,
      "learning_rate": 0.0006489877711801118,
      "loss": 5.1954,
      "step": 3677
    },
    {
      "epoch": 0.4217406260749914,
      "grad_norm": 0.0,
      "learning_rate": 0.0006488105147807944,
      "loss": 5.1909,
      "step": 3678
    },
    {
      "epoch": 0.42185529182433207,
      "grad_norm": 0.0,
      "learning_rate": 0.0006486332378627998,
      "loss": 5.0389,
      "step": 3679
    },
    {
      "epoch": 0.4219699575736727,
      "grad_norm": 0.0,
      "learning_rate": 0.0006484559404505798,
      "loss": 5.1055,
      "step": 3680
    },
    {
      "epoch": 0.42208462332301344,
      "grad_norm": 0.0,
      "learning_rate": 0.000648278622568589,
      "loss": 4.91,
      "step": 3681
    },
    {
      "epoch": 0.4221992890723541,
      "grad_norm": 0.0,
      "learning_rate": 0.0006481012842412853,
      "loss": 4.9676,
      "step": 3682
    },
    {
      "epoch": 0.42231395482169476,
      "grad_norm": 0.0,
      "learning_rate": 0.0006479239254931291,
      "loss": 5.2446,
      "step": 3683
    },
    {
      "epoch": 0.4224286205710354,
      "grad_norm": 0.0,
      "learning_rate": 0.0006477465463485835,
      "loss": 4.8099,
      "step": 3684
    },
    {
      "epoch": 0.4225432863203761,
      "grad_norm": 0.0,
      "learning_rate": 0.0006475691468321149,
      "loss": 5.0216,
      "step": 3685
    },
    {
      "epoch": 0.4226579520697168,
      "grad_norm": 0.0,
      "learning_rate": 0.0006473917269681919,
      "loss": 4.8512,
      "step": 3686
    },
    {
      "epoch": 0.42277261781905745,
      "grad_norm": 0.0,
      "learning_rate": 0.0006472142867812861,
      "loss": 4.8558,
      "step": 3687
    },
    {
      "epoch": 0.4228872835683981,
      "grad_norm": 0.0,
      "learning_rate": 0.0006470368262958724,
      "loss": 5.0675,
      "step": 3688
    },
    {
      "epoch": 0.42300194931773877,
      "grad_norm": 0.0,
      "learning_rate": 0.0006468593455364275,
      "loss": 4.9512,
      "step": 3689
    },
    {
      "epoch": 0.4231166150670795,
      "grad_norm": 0.0,
      "learning_rate": 0.0006466818445274321,
      "loss": 4.9429,
      "step": 3690
    },
    {
      "epoch": 0.42323128081642014,
      "grad_norm": 0.0,
      "learning_rate": 0.0006465043232933686,
      "loss": 5.0275,
      "step": 3691
    },
    {
      "epoch": 0.4233459465657608,
      "grad_norm": 0.0,
      "learning_rate": 0.0006463267818587231,
      "loss": 4.7851,
      "step": 3692
    },
    {
      "epoch": 0.42346061231510146,
      "grad_norm": 0.0,
      "learning_rate": 0.0006461492202479835,
      "loss": 4.8982,
      "step": 3693
    },
    {
      "epoch": 0.4235752780644422,
      "grad_norm": 0.0,
      "learning_rate": 0.0006459716384856417,
      "loss": 4.9819,
      "step": 3694
    },
    {
      "epoch": 0.42368994381378283,
      "grad_norm": 0.0,
      "learning_rate": 0.0006457940365961913,
      "loss": 5.367,
      "step": 3695
    },
    {
      "epoch": 0.4238046095631235,
      "grad_norm": 0.0,
      "learning_rate": 0.0006456164146041292,
      "loss": 4.8897,
      "step": 3696
    },
    {
      "epoch": 0.42391927531246415,
      "grad_norm": 0.0,
      "learning_rate": 0.0006454387725339549,
      "loss": 4.9495,
      "step": 3697
    },
    {
      "epoch": 0.42403394106180486,
      "grad_norm": 0.0,
      "learning_rate": 0.0006452611104101708,
      "loss": 4.9684,
      "step": 3698
    },
    {
      "epoch": 0.4241486068111455,
      "grad_norm": 0.0,
      "learning_rate": 0.0006450834282572819,
      "loss": 5.0483,
      "step": 3699
    },
    {
      "epoch": 0.4242632725604862,
      "grad_norm": 0.0,
      "learning_rate": 0.0006449057260997963,
      "loss": 4.7844,
      "step": 3700
    },
    {
      "epoch": 0.42437793830982684,
      "grad_norm": 0.0,
      "learning_rate": 0.0006447280039622245,
      "loss": 4.8779,
      "step": 3701
    },
    {
      "epoch": 0.4244926040591675,
      "grad_norm": 0.0,
      "learning_rate": 0.0006445502618690798,
      "loss": 4.7887,
      "step": 3702
    },
    {
      "epoch": 0.4246072698085082,
      "grad_norm": 0.0,
      "learning_rate": 0.0006443724998448783,
      "loss": 5.4934,
      "step": 3703
    },
    {
      "epoch": 0.4247219355578489,
      "grad_norm": 0.0,
      "learning_rate": 0.0006441947179141391,
      "loss": 4.8977,
      "step": 3704
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.0,
      "learning_rate": 0.0006440169161013838,
      "loss": 4.9269,
      "step": 3705
    },
    {
      "epoch": 0.4249512670565302,
      "grad_norm": 0.0,
      "learning_rate": 0.0006438390944311367,
      "loss": 5.0672,
      "step": 3706
    },
    {
      "epoch": 0.4250659328058709,
      "grad_norm": 0.0,
      "learning_rate": 0.0006436612529279247,
      "loss": 4.9306,
      "step": 3707
    },
    {
      "epoch": 0.42518059855521156,
      "grad_norm": 0.0,
      "learning_rate": 0.0006434833916162778,
      "loss": 5.1438,
      "step": 3708
    },
    {
      "epoch": 0.4252952643045522,
      "grad_norm": 0.0,
      "learning_rate": 0.0006433055105207288,
      "loss": 5.0612,
      "step": 3709
    },
    {
      "epoch": 0.4254099300538929,
      "grad_norm": 0.0,
      "learning_rate": 0.0006431276096658128,
      "loss": 5.23,
      "step": 3710
    },
    {
      "epoch": 0.4255245958032336,
      "grad_norm": 0.0,
      "learning_rate": 0.0006429496890760678,
      "loss": 4.9549,
      "step": 3711
    },
    {
      "epoch": 0.42563926155257426,
      "grad_norm": 0.0,
      "learning_rate": 0.0006427717487760348,
      "loss": 4.8981,
      "step": 3712
    },
    {
      "epoch": 0.4257539273019149,
      "grad_norm": 0.0,
      "learning_rate": 0.0006425937887902567,
      "loss": 4.6993,
      "step": 3713
    },
    {
      "epoch": 0.4258685930512556,
      "grad_norm": 0.0,
      "learning_rate": 0.0006424158091432803,
      "loss": 4.815,
      "step": 3714
    },
    {
      "epoch": 0.4259832588005963,
      "grad_norm": 0.0,
      "learning_rate": 0.0006422378098596542,
      "loss": 4.8984,
      "step": 3715
    },
    {
      "epoch": 0.42609792454993695,
      "grad_norm": 0.0,
      "learning_rate": 0.0006420597909639301,
      "loss": 5.1326,
      "step": 3716
    },
    {
      "epoch": 0.4262125902992776,
      "grad_norm": 0.0,
      "learning_rate": 0.0006418817524806625,
      "loss": 4.9036,
      "step": 3717
    },
    {
      "epoch": 0.42632725604861826,
      "grad_norm": 0.0,
      "learning_rate": 0.0006417036944344079,
      "loss": 5.1933,
      "step": 3718
    },
    {
      "epoch": 0.4264419217979589,
      "grad_norm": 0.0,
      "learning_rate": 0.0006415256168497265,
      "loss": 5.1887,
      "step": 3719
    },
    {
      "epoch": 0.42655658754729964,
      "grad_norm": 0.0,
      "learning_rate": 0.0006413475197511804,
      "loss": 5.019,
      "step": 3720
    },
    {
      "epoch": 0.4266712532966403,
      "grad_norm": 0.0,
      "learning_rate": 0.0006411694031633349,
      "loss": 4.9104,
      "step": 3721
    },
    {
      "epoch": 0.42678591904598095,
      "grad_norm": 0.0,
      "learning_rate": 0.0006409912671107575,
      "loss": 5.2431,
      "step": 3722
    },
    {
      "epoch": 0.4269005847953216,
      "grad_norm": 0.0,
      "learning_rate": 0.0006408131116180192,
      "loss": 5.0982,
      "step": 3723
    },
    {
      "epoch": 0.42701525054466233,
      "grad_norm": 0.0,
      "learning_rate": 0.0006406349367096926,
      "loss": 4.8713,
      "step": 3724
    },
    {
      "epoch": 0.427129916294003,
      "grad_norm": 0.0,
      "learning_rate": 0.0006404567424103539,
      "loss": 5.3808,
      "step": 3725
    },
    {
      "epoch": 0.42724458204334365,
      "grad_norm": 0.0,
      "learning_rate": 0.0006402785287445817,
      "loss": 5.2001,
      "step": 3726
    },
    {
      "epoch": 0.4273592477926843,
      "grad_norm": 0.0,
      "learning_rate": 0.0006401002957369566,
      "loss": 4.9808,
      "step": 3727
    },
    {
      "epoch": 0.427473913542025,
      "grad_norm": 0.0,
      "learning_rate": 0.000639922043412063,
      "loss": 5.1217,
      "step": 3728
    },
    {
      "epoch": 0.4275885792913657,
      "grad_norm": 0.0,
      "learning_rate": 0.0006397437717944872,
      "loss": 4.8153,
      "step": 3729
    },
    {
      "epoch": 0.42770324504070634,
      "grad_norm": 0.0,
      "learning_rate": 0.0006395654809088182,
      "loss": 5.0522,
      "step": 3730
    },
    {
      "epoch": 0.427817910790047,
      "grad_norm": 0.0,
      "learning_rate": 0.0006393871707796483,
      "loss": 4.9922,
      "step": 3731
    },
    {
      "epoch": 0.4279325765393877,
      "grad_norm": 0.0,
      "learning_rate": 0.0006392088414315714,
      "loss": 4.7695,
      "step": 3732
    },
    {
      "epoch": 0.42804724228872837,
      "grad_norm": 0.0,
      "learning_rate": 0.0006390304928891852,
      "loss": 4.9403,
      "step": 3733
    },
    {
      "epoch": 0.42816190803806903,
      "grad_norm": 0.0,
      "learning_rate": 0.0006388521251770892,
      "loss": 4.9601,
      "step": 3734
    },
    {
      "epoch": 0.4282765737874097,
      "grad_norm": 0.0,
      "learning_rate": 0.0006386737383198857,
      "loss": 5.0293,
      "step": 3735
    },
    {
      "epoch": 0.42839123953675035,
      "grad_norm": 0.0,
      "learning_rate": 0.0006384953323421797,
      "loss": 5.048,
      "step": 3736
    },
    {
      "epoch": 0.42850590528609106,
      "grad_norm": 0.0,
      "learning_rate": 0.0006383169072685795,
      "loss": 5.1117,
      "step": 3737
    },
    {
      "epoch": 0.4286205710354317,
      "grad_norm": 0.0,
      "learning_rate": 0.0006381384631236948,
      "loss": 4.9696,
      "step": 3738
    },
    {
      "epoch": 0.4287352367847724,
      "grad_norm": 0.0,
      "learning_rate": 0.0006379599999321392,
      "loss": 5.153,
      "step": 3739
    },
    {
      "epoch": 0.42884990253411304,
      "grad_norm": 0.0,
      "learning_rate": 0.0006377815177185276,
      "loss": 4.9035,
      "step": 3740
    },
    {
      "epoch": 0.42896456828345375,
      "grad_norm": 0.0,
      "learning_rate": 0.0006376030165074785,
      "loss": 4.8287,
      "step": 3741
    },
    {
      "epoch": 0.4290792340327944,
      "grad_norm": 0.0,
      "learning_rate": 0.0006374244963236128,
      "loss": 5.1691,
      "step": 3742
    },
    {
      "epoch": 0.42919389978213507,
      "grad_norm": 0.0,
      "learning_rate": 0.000637245957191554,
      "loss": 4.949,
      "step": 3743
    },
    {
      "epoch": 0.4293085655314757,
      "grad_norm": 0.0,
      "learning_rate": 0.0006370673991359279,
      "loss": 5.0255,
      "step": 3744
    },
    {
      "epoch": 0.42942323128081644,
      "grad_norm": 0.0,
      "learning_rate": 0.0006368888221813637,
      "loss": 4.9334,
      "step": 3745
    },
    {
      "epoch": 0.4295378970301571,
      "grad_norm": 0.0,
      "learning_rate": 0.0006367102263524922,
      "loss": 4.9812,
      "step": 3746
    },
    {
      "epoch": 0.42965256277949776,
      "grad_norm": 0.0,
      "learning_rate": 0.0006365316116739476,
      "loss": 5.0981,
      "step": 3747
    },
    {
      "epoch": 0.4297672285288384,
      "grad_norm": 0.0,
      "learning_rate": 0.0006363529781703661,
      "loss": 4.8969,
      "step": 3748
    },
    {
      "epoch": 0.42988189427817913,
      "grad_norm": 0.0,
      "learning_rate": 0.0006361743258663869,
      "loss": 4.9617,
      "step": 3749
    },
    {
      "epoch": 0.4299965600275198,
      "grad_norm": 0.0,
      "learning_rate": 0.0006359956547866518,
      "loss": 4.9371,
      "step": 3750
    },
    {
      "epoch": 0.43011122577686045,
      "grad_norm": 0.0,
      "learning_rate": 0.000635816964955805,
      "loss": 4.9457,
      "step": 3751
    },
    {
      "epoch": 0.4302258915262011,
      "grad_norm": 0.0,
      "learning_rate": 0.0006356382563984932,
      "loss": 5.0297,
      "step": 3752
    },
    {
      "epoch": 0.43034055727554177,
      "grad_norm": 0.0,
      "learning_rate": 0.000635459529139366,
      "loss": 4.9766,
      "step": 3753
    },
    {
      "epoch": 0.4304552230248825,
      "grad_norm": 0.0,
      "learning_rate": 0.0006352807832030753,
      "loss": 5.1441,
      "step": 3754
    },
    {
      "epoch": 0.43056988877422314,
      "grad_norm": 0.0,
      "learning_rate": 0.000635102018614276,
      "loss": 5.0848,
      "step": 3755
    },
    {
      "epoch": 0.4306845545235638,
      "grad_norm": 0.0,
      "learning_rate": 0.0006349232353976251,
      "loss": 5.1062,
      "step": 3756
    },
    {
      "epoch": 0.43079922027290446,
      "grad_norm": 0.0,
      "learning_rate": 0.0006347444335777823,
      "loss": 4.9871,
      "step": 3757
    },
    {
      "epoch": 0.4309138860222452,
      "grad_norm": 0.0,
      "learning_rate": 0.0006345656131794097,
      "loss": 4.9425,
      "step": 3758
    },
    {
      "epoch": 0.43102855177158583,
      "grad_norm": 0.0,
      "learning_rate": 0.0006343867742271725,
      "loss": 4.9635,
      "step": 3759
    },
    {
      "epoch": 0.4311432175209265,
      "grad_norm": 0.0,
      "learning_rate": 0.0006342079167457379,
      "loss": 4.9576,
      "step": 3760
    },
    {
      "epoch": 0.43125788327026715,
      "grad_norm": 0.0,
      "learning_rate": 0.0006340290407597762,
      "loss": 5.0316,
      "step": 3761
    },
    {
      "epoch": 0.43137254901960786,
      "grad_norm": 0.0,
      "learning_rate": 0.0006338501462939594,
      "loss": 4.9643,
      "step": 3762
    },
    {
      "epoch": 0.4314872147689485,
      "grad_norm": 0.0,
      "learning_rate": 0.0006336712333729629,
      "loss": 5.0339,
      "step": 3763
    },
    {
      "epoch": 0.4316018805182892,
      "grad_norm": 0.0,
      "learning_rate": 0.0006334923020214644,
      "loss": 5.1211,
      "step": 3764
    },
    {
      "epoch": 0.43171654626762984,
      "grad_norm": 0.0,
      "learning_rate": 0.000633313352264144,
      "loss": 5.066,
      "step": 3765
    },
    {
      "epoch": 0.43183121201697056,
      "grad_norm": 0.0,
      "learning_rate": 0.0006331343841256843,
      "loss": 4.9131,
      "step": 3766
    },
    {
      "epoch": 0.4319458777663112,
      "grad_norm": 0.0,
      "learning_rate": 0.0006329553976307709,
      "loss": 5.2513,
      "step": 3767
    },
    {
      "epoch": 0.4320605435156519,
      "grad_norm": 0.0,
      "learning_rate": 0.0006327763928040912,
      "loss": 5.0256,
      "step": 3768
    },
    {
      "epoch": 0.43217520926499253,
      "grad_norm": 0.0,
      "learning_rate": 0.0006325973696703353,
      "loss": 4.9579,
      "step": 3769
    },
    {
      "epoch": 0.4322898750143332,
      "grad_norm": 0.0,
      "learning_rate": 0.0006324183282541965,
      "loss": 4.8158,
      "step": 3770
    },
    {
      "epoch": 0.4324045407636739,
      "grad_norm": 0.0,
      "learning_rate": 0.00063223926858037,
      "loss": 4.8983,
      "step": 3771
    },
    {
      "epoch": 0.43251920651301456,
      "grad_norm": 0.0,
      "learning_rate": 0.0006320601906735539,
      "loss": 4.7141,
      "step": 3772
    },
    {
      "epoch": 0.4326338722623552,
      "grad_norm": 0.0,
      "learning_rate": 0.000631881094558448,
      "loss": 5.2226,
      "step": 3773
    },
    {
      "epoch": 0.4327485380116959,
      "grad_norm": 0.0,
      "learning_rate": 0.0006317019802597558,
      "loss": 4.8447,
      "step": 3774
    },
    {
      "epoch": 0.4328632037610366,
      "grad_norm": 0.0,
      "learning_rate": 0.0006315228478021821,
      "loss": 4.8748,
      "step": 3775
    },
    {
      "epoch": 0.43297786951037726,
      "grad_norm": 0.0,
      "learning_rate": 0.0006313436972104354,
      "loss": 4.7209,
      "step": 3776
    },
    {
      "epoch": 0.4330925352597179,
      "grad_norm": 0.0,
      "learning_rate": 0.0006311645285092259,
      "loss": 4.9221,
      "step": 3777
    },
    {
      "epoch": 0.4332072010090586,
      "grad_norm": 0.0,
      "learning_rate": 0.0006309853417232665,
      "loss": 4.9905,
      "step": 3778
    },
    {
      "epoch": 0.4333218667583993,
      "grad_norm": 0.0,
      "learning_rate": 0.0006308061368772722,
      "loss": 4.6943,
      "step": 3779
    },
    {
      "epoch": 0.43343653250773995,
      "grad_norm": 0.0,
      "learning_rate": 0.0006306269139959616,
      "loss": 4.9626,
      "step": 3780
    },
    {
      "epoch": 0.4335511982570806,
      "grad_norm": 0.0,
      "learning_rate": 0.0006304476731040546,
      "loss": 4.9634,
      "step": 3781
    },
    {
      "epoch": 0.43366586400642126,
      "grad_norm": 0.0,
      "learning_rate": 0.0006302684142262742,
      "loss": 5.2414,
      "step": 3782
    },
    {
      "epoch": 0.433780529755762,
      "grad_norm": 0.0,
      "learning_rate": 0.0006300891373873458,
      "loss": 4.8144,
      "step": 3783
    },
    {
      "epoch": 0.43389519550510264,
      "grad_norm": 0.0,
      "learning_rate": 0.0006299098426119971,
      "loss": 4.7572,
      "step": 3784
    },
    {
      "epoch": 0.4340098612544433,
      "grad_norm": 0.0,
      "learning_rate": 0.0006297305299249585,
      "loss": 5.3248,
      "step": 3785
    },
    {
      "epoch": 0.43412452700378396,
      "grad_norm": 0.0,
      "learning_rate": 0.0006295511993509627,
      "loss": 4.8973,
      "step": 3786
    },
    {
      "epoch": 0.4342391927531246,
      "grad_norm": 0.0,
      "learning_rate": 0.000629371850914745,
      "loss": 4.774,
      "step": 3787
    },
    {
      "epoch": 0.43435385850246533,
      "grad_norm": 0.0,
      "learning_rate": 0.0006291924846410431,
      "loss": 5.3164,
      "step": 3788
    },
    {
      "epoch": 0.434468524251806,
      "grad_norm": 0.0,
      "learning_rate": 0.0006290131005545972,
      "loss": 4.9431,
      "step": 3789
    },
    {
      "epoch": 0.43458319000114665,
      "grad_norm": 0.0,
      "learning_rate": 0.0006288336986801496,
      "loss": 5.0838,
      "step": 3790
    },
    {
      "epoch": 0.4346978557504873,
      "grad_norm": 0.0,
      "learning_rate": 0.0006286542790424458,
      "loss": 4.9851,
      "step": 3791
    },
    {
      "epoch": 0.434812521499828,
      "grad_norm": 0.0,
      "learning_rate": 0.000628474841666233,
      "loss": 5.2635,
      "step": 3792
    },
    {
      "epoch": 0.4349271872491687,
      "grad_norm": 0.0,
      "learning_rate": 0.0006282953865762614,
      "loss": 4.9147,
      "step": 3793
    },
    {
      "epoch": 0.43504185299850934,
      "grad_norm": 0.0,
      "learning_rate": 0.0006281159137972832,
      "loss": 4.9112,
      "step": 3794
    },
    {
      "epoch": 0.43515651874785,
      "grad_norm": 0.0,
      "learning_rate": 0.0006279364233540535,
      "loss": 4.6353,
      "step": 3795
    },
    {
      "epoch": 0.4352711844971907,
      "grad_norm": 0.0,
      "learning_rate": 0.0006277569152713294,
      "loss": 5.0083,
      "step": 3796
    },
    {
      "epoch": 0.43538585024653137,
      "grad_norm": 0.0,
      "learning_rate": 0.0006275773895738705,
      "loss": 5.1219,
      "step": 3797
    },
    {
      "epoch": 0.43550051599587203,
      "grad_norm": 0.0,
      "learning_rate": 0.0006273978462864393,
      "loss": 4.8855,
      "step": 3798
    },
    {
      "epoch": 0.4356151817452127,
      "grad_norm": 0.0,
      "learning_rate": 0.0006272182854338,
      "loss": 5.0639,
      "step": 3799
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 0.0,
      "learning_rate": 0.0006270387070407198,
      "loss": 4.8353,
      "step": 3800
    },
    {
      "epoch": 0.43584451324389406,
      "grad_norm": 0.0,
      "learning_rate": 0.0006268591111319682,
      "loss": 5.0298,
      "step": 3801
    },
    {
      "epoch": 0.4359591789932347,
      "grad_norm": 0.0,
      "learning_rate": 0.0006266794977323168,
      "loss": 5.0237,
      "step": 3802
    },
    {
      "epoch": 0.4360738447425754,
      "grad_norm": 0.0,
      "learning_rate": 0.00062649986686654,
      "loss": 4.9485,
      "step": 3803
    },
    {
      "epoch": 0.43618851049191604,
      "grad_norm": 0.0,
      "learning_rate": 0.0006263202185594145,
      "loss": 4.8841,
      "step": 3804
    },
    {
      "epoch": 0.43630317624125675,
      "grad_norm": 0.0,
      "learning_rate": 0.0006261405528357192,
      "loss": 5.1095,
      "step": 3805
    },
    {
      "epoch": 0.4364178419905974,
      "grad_norm": 0.0,
      "learning_rate": 0.0006259608697202357,
      "loss": 5.0285,
      "step": 3806
    },
    {
      "epoch": 0.43653250773993807,
      "grad_norm": 0.0,
      "learning_rate": 0.0006257811692377478,
      "loss": 4.7138,
      "step": 3807
    },
    {
      "epoch": 0.43664717348927873,
      "grad_norm": 0.0,
      "learning_rate": 0.0006256014514130419,
      "loss": 5.1624,
      "step": 3808
    },
    {
      "epoch": 0.43676183923861944,
      "grad_norm": 0.0,
      "learning_rate": 0.000625421716270906,
      "loss": 5.1758,
      "step": 3809
    },
    {
      "epoch": 0.4368765049879601,
      "grad_norm": 0.0,
      "learning_rate": 0.0006252419638361321,
      "loss": 5.0565,
      "step": 3810
    },
    {
      "epoch": 0.43699117073730076,
      "grad_norm": 0.0,
      "learning_rate": 0.0006250621941335131,
      "loss": 4.9769,
      "step": 3811
    },
    {
      "epoch": 0.4371058364866414,
      "grad_norm": 0.0,
      "learning_rate": 0.0006248824071878447,
      "loss": 5.0567,
      "step": 3812
    },
    {
      "epoch": 0.43722050223598213,
      "grad_norm": 0.0,
      "learning_rate": 0.0006247026030239254,
      "loss": 4.9111,
      "step": 3813
    },
    {
      "epoch": 0.4373351679853228,
      "grad_norm": 0.0,
      "learning_rate": 0.0006245227816665556,
      "loss": 5.0764,
      "step": 3814
    },
    {
      "epoch": 0.43744983373466345,
      "grad_norm": 0.0,
      "learning_rate": 0.0006243429431405381,
      "loss": 5.0787,
      "step": 3815
    },
    {
      "epoch": 0.4375644994840041,
      "grad_norm": 0.0,
      "learning_rate": 0.0006241630874706785,
      "loss": 5.1952,
      "step": 3816
    },
    {
      "epoch": 0.4376791652333448,
      "grad_norm": 0.0,
      "learning_rate": 0.0006239832146817842,
      "loss": 5.2071,
      "step": 3817
    },
    {
      "epoch": 0.4377938309826855,
      "grad_norm": 0.0,
      "learning_rate": 0.0006238033247986654,
      "loss": 4.8731,
      "step": 3818
    },
    {
      "epoch": 0.43790849673202614,
      "grad_norm": 0.0,
      "learning_rate": 0.0006236234178461343,
      "loss": 5.1602,
      "step": 3819
    },
    {
      "epoch": 0.4380231624813668,
      "grad_norm": 0.0,
      "learning_rate": 0.0006234434938490057,
      "loss": 5.1834,
      "step": 3820
    },
    {
      "epoch": 0.43813782823070746,
      "grad_norm": 0.0,
      "learning_rate": 0.0006232635528320969,
      "loss": 5.0659,
      "step": 3821
    },
    {
      "epoch": 0.4382524939800482,
      "grad_norm": 0.0,
      "learning_rate": 0.000623083594820227,
      "loss": 4.9743,
      "step": 3822
    },
    {
      "epoch": 0.43836715972938883,
      "grad_norm": 0.0,
      "learning_rate": 0.0006229036198382179,
      "loss": 4.9548,
      "step": 3823
    },
    {
      "epoch": 0.4384818254787295,
      "grad_norm": 0.0,
      "learning_rate": 0.0006227236279108939,
      "loss": 4.827,
      "step": 3824
    },
    {
      "epoch": 0.43859649122807015,
      "grad_norm": 0.0,
      "learning_rate": 0.0006225436190630812,
      "loss": 4.7281,
      "step": 3825
    },
    {
      "epoch": 0.43871115697741087,
      "grad_norm": 0.0,
      "learning_rate": 0.0006223635933196086,
      "loss": 5.2329,
      "step": 3826
    },
    {
      "epoch": 0.4388258227267515,
      "grad_norm": 0.0,
      "learning_rate": 0.0006221835507053074,
      "loss": 5.3597,
      "step": 3827
    },
    {
      "epoch": 0.4389404884760922,
      "grad_norm": 0.0,
      "learning_rate": 0.0006220034912450112,
      "loss": 4.8201,
      "step": 3828
    },
    {
      "epoch": 0.43905515422543284,
      "grad_norm": 0.0,
      "learning_rate": 0.0006218234149635552,
      "loss": 5.008,
      "step": 3829
    },
    {
      "epoch": 0.43916981997477356,
      "grad_norm": 0.0,
      "learning_rate": 0.000621643321885778,
      "loss": 4.8797,
      "step": 3830
    },
    {
      "epoch": 0.4392844857241142,
      "grad_norm": 0.0,
      "learning_rate": 0.0006214632120365196,
      "loss": 4.9343,
      "step": 3831
    },
    {
      "epoch": 0.4393991514734549,
      "grad_norm": 0.0,
      "learning_rate": 0.000621283085440623,
      "loss": 5.2028,
      "step": 3832
    },
    {
      "epoch": 0.43951381722279553,
      "grad_norm": 0.0,
      "learning_rate": 0.0006211029421229334,
      "loss": 5.0304,
      "step": 3833
    },
    {
      "epoch": 0.43962848297213625,
      "grad_norm": 0.0,
      "learning_rate": 0.0006209227821082978,
      "loss": 4.7908,
      "step": 3834
    },
    {
      "epoch": 0.4397431487214769,
      "grad_norm": 0.0,
      "learning_rate": 0.0006207426054215659,
      "loss": 4.9861,
      "step": 3835
    },
    {
      "epoch": 0.43985781447081757,
      "grad_norm": 0.0,
      "learning_rate": 0.0006205624120875897,
      "loss": 5.168,
      "step": 3836
    },
    {
      "epoch": 0.4399724802201582,
      "grad_norm": 0.0,
      "learning_rate": 0.0006203822021312234,
      "loss": 5.0642,
      "step": 3837
    },
    {
      "epoch": 0.4400871459694989,
      "grad_norm": 0.0,
      "learning_rate": 0.0006202019755773237,
      "loss": 5.1522,
      "step": 3838
    },
    {
      "epoch": 0.4402018117188396,
      "grad_norm": 0.0,
      "learning_rate": 0.0006200217324507493,
      "loss": 5.0398,
      "step": 3839
    },
    {
      "epoch": 0.44031647746818026,
      "grad_norm": 0.0,
      "learning_rate": 0.0006198414727763611,
      "loss": 5.2768,
      "step": 3840
    },
    {
      "epoch": 0.4404311432175209,
      "grad_norm": 0.0,
      "learning_rate": 0.0006196611965790227,
      "loss": 5.0342,
      "step": 3841
    },
    {
      "epoch": 0.4405458089668616,
      "grad_norm": 0.0,
      "learning_rate": 0.0006194809038835996,
      "loss": 5.1815,
      "step": 3842
    },
    {
      "epoch": 0.4406604747162023,
      "grad_norm": 0.0,
      "learning_rate": 0.0006193005947149601,
      "loss": 4.975,
      "step": 3843
    },
    {
      "epoch": 0.44077514046554295,
      "grad_norm": 0.0,
      "learning_rate": 0.0006191202690979743,
      "loss": 5.0807,
      "step": 3844
    },
    {
      "epoch": 0.4408898062148836,
      "grad_norm": 0.0,
      "learning_rate": 0.0006189399270575143,
      "loss": 4.9311,
      "step": 3845
    },
    {
      "epoch": 0.44100447196422426,
      "grad_norm": 0.0,
      "learning_rate": 0.000618759568618455,
      "loss": 5.1223,
      "step": 3846
    },
    {
      "epoch": 0.441119137713565,
      "grad_norm": 0.0,
      "learning_rate": 0.0006185791938056737,
      "loss": 5.0952,
      "step": 3847
    },
    {
      "epoch": 0.44123380346290564,
      "grad_norm": 0.0,
      "learning_rate": 0.0006183988026440497,
      "loss": 4.8188,
      "step": 3848
    },
    {
      "epoch": 0.4413484692122463,
      "grad_norm": 0.0,
      "learning_rate": 0.0006182183951584641,
      "loss": 5.1423,
      "step": 3849
    },
    {
      "epoch": 0.44146313496158696,
      "grad_norm": 0.0,
      "learning_rate": 0.0006180379713738009,
      "loss": 4.757,
      "step": 3850
    },
    {
      "epoch": 0.44157780071092767,
      "grad_norm": 0.0,
      "learning_rate": 0.0006178575313149459,
      "loss": 5.0215,
      "step": 3851
    },
    {
      "epoch": 0.44169246646026833,
      "grad_norm": 0.0,
      "learning_rate": 0.000617677075006788,
      "loss": 4.961,
      "step": 3852
    },
    {
      "epoch": 0.441807132209609,
      "grad_norm": 0.0,
      "learning_rate": 0.0006174966024742169,
      "loss": 4.956,
      "step": 3853
    },
    {
      "epoch": 0.44192179795894965,
      "grad_norm": 0.0,
      "learning_rate": 0.0006173161137421258,
      "loss": 4.9627,
      "step": 3854
    },
    {
      "epoch": 0.44203646370829036,
      "grad_norm": 0.0,
      "learning_rate": 0.0006171356088354097,
      "loss": 5.0414,
      "step": 3855
    },
    {
      "epoch": 0.442151129457631,
      "grad_norm": 0.0,
      "learning_rate": 0.0006169550877789657,
      "loss": 4.7883,
      "step": 3856
    },
    {
      "epoch": 0.4422657952069717,
      "grad_norm": 0.0,
      "learning_rate": 0.0006167745505976931,
      "loss": 5.2272,
      "step": 3857
    },
    {
      "epoch": 0.44238046095631234,
      "grad_norm": 0.0,
      "learning_rate": 0.000616593997316494,
      "loss": 4.8921,
      "step": 3858
    },
    {
      "epoch": 0.442495126705653,
      "grad_norm": 0.0,
      "learning_rate": 0.0006164134279602719,
      "loss": 4.9365,
      "step": 3859
    },
    {
      "epoch": 0.4426097924549937,
      "grad_norm": 0.0,
      "learning_rate": 0.000616232842553933,
      "loss": 4.9695,
      "step": 3860
    },
    {
      "epoch": 0.44272445820433437,
      "grad_norm": 0.0,
      "learning_rate": 0.0006160522411223855,
      "loss": 4.9199,
      "step": 3861
    },
    {
      "epoch": 0.44283912395367503,
      "grad_norm": 0.0,
      "learning_rate": 0.00061587162369054,
      "loss": 5.1096,
      "step": 3862
    },
    {
      "epoch": 0.4429537897030157,
      "grad_norm": 0.0,
      "learning_rate": 0.0006156909902833095,
      "loss": 5.1897,
      "step": 3863
    },
    {
      "epoch": 0.4430684554523564,
      "grad_norm": 0.0,
      "learning_rate": 0.0006155103409256084,
      "loss": 5.1031,
      "step": 3864
    },
    {
      "epoch": 0.44318312120169706,
      "grad_norm": 0.0,
      "learning_rate": 0.0006153296756423544,
      "loss": 5.0851,
      "step": 3865
    },
    {
      "epoch": 0.4432977869510377,
      "grad_norm": 0.0,
      "learning_rate": 0.0006151489944584666,
      "loss": 5.0775,
      "step": 3866
    },
    {
      "epoch": 0.4434124527003784,
      "grad_norm": 0.0,
      "learning_rate": 0.0006149682973988664,
      "loss": 5.1859,
      "step": 3867
    },
    {
      "epoch": 0.4435271184497191,
      "grad_norm": 0.0,
      "learning_rate": 0.0006147875844884775,
      "loss": 4.9301,
      "step": 3868
    },
    {
      "epoch": 0.44364178419905975,
      "grad_norm": 0.0,
      "learning_rate": 0.0006146068557522262,
      "loss": 4.9601,
      "step": 3869
    },
    {
      "epoch": 0.4437564499484004,
      "grad_norm": 0.0,
      "learning_rate": 0.0006144261112150401,
      "loss": 4.9198,
      "step": 3870
    },
    {
      "epoch": 0.44387111569774107,
      "grad_norm": 0.0,
      "learning_rate": 0.0006142453509018498,
      "loss": 4.9431,
      "step": 3871
    },
    {
      "epoch": 0.4439857814470818,
      "grad_norm": 0.0,
      "learning_rate": 0.0006140645748375874,
      "loss": 4.9762,
      "step": 3872
    },
    {
      "epoch": 0.44410044719642244,
      "grad_norm": 0.0,
      "learning_rate": 0.0006138837830471878,
      "loss": 4.6704,
      "step": 3873
    },
    {
      "epoch": 0.4442151129457631,
      "grad_norm": 0.0,
      "learning_rate": 0.0006137029755555877,
      "loss": 5.0098,
      "step": 3874
    },
    {
      "epoch": 0.44432977869510376,
      "grad_norm": 0.0,
      "learning_rate": 0.0006135221523877262,
      "loss": 5.0989,
      "step": 3875
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.0,
      "learning_rate": 0.0006133413135685441,
      "loss": 5.1119,
      "step": 3876
    },
    {
      "epoch": 0.44455911019378513,
      "grad_norm": 0.0,
      "learning_rate": 0.0006131604591229848,
      "loss": 5.1052,
      "step": 3877
    },
    {
      "epoch": 0.4446737759431258,
      "grad_norm": 0.0,
      "learning_rate": 0.0006129795890759938,
      "loss": 4.7868,
      "step": 3878
    },
    {
      "epoch": 0.44478844169246645,
      "grad_norm": 0.0,
      "learning_rate": 0.0006127987034525187,
      "loss": 5.0739,
      "step": 3879
    },
    {
      "epoch": 0.4449031074418071,
      "grad_norm": 0.0,
      "learning_rate": 0.0006126178022775091,
      "loss": 5.1291,
      "step": 3880
    },
    {
      "epoch": 0.4450177731911478,
      "grad_norm": 0.0,
      "learning_rate": 0.0006124368855759168,
      "loss": 5.1518,
      "step": 3881
    },
    {
      "epoch": 0.4451324389404885,
      "grad_norm": 0.0,
      "learning_rate": 0.000612255953372696,
      "loss": 4.9127,
      "step": 3882
    },
    {
      "epoch": 0.44524710468982914,
      "grad_norm": 0.0,
      "learning_rate": 0.0006120750056928028,
      "loss": 5.1296,
      "step": 3883
    },
    {
      "epoch": 0.4453617704391698,
      "grad_norm": 0.0,
      "learning_rate": 0.0006118940425611953,
      "loss": 4.9879,
      "step": 3884
    },
    {
      "epoch": 0.4454764361885105,
      "grad_norm": 0.0,
      "learning_rate": 0.0006117130640028343,
      "loss": 5.2285,
      "step": 3885
    },
    {
      "epoch": 0.4455911019378512,
      "grad_norm": 0.0,
      "learning_rate": 0.000611532070042682,
      "loss": 4.9079,
      "step": 3886
    },
    {
      "epoch": 0.44570576768719183,
      "grad_norm": 0.0,
      "learning_rate": 0.0006113510607057032,
      "loss": 5.047,
      "step": 3887
    },
    {
      "epoch": 0.4458204334365325,
      "grad_norm": 0.0,
      "learning_rate": 0.0006111700360168646,
      "loss": 4.9304,
      "step": 3888
    },
    {
      "epoch": 0.4459350991858732,
      "grad_norm": 0.0,
      "learning_rate": 0.0006109889960011353,
      "loss": 5.1756,
      "step": 3889
    },
    {
      "epoch": 0.44604976493521387,
      "grad_norm": 0.0,
      "learning_rate": 0.0006108079406834861,
      "loss": 5.1422,
      "step": 3890
    },
    {
      "epoch": 0.4461644306845545,
      "grad_norm": 0.0,
      "learning_rate": 0.0006106268700888902,
      "loss": 5.0173,
      "step": 3891
    },
    {
      "epoch": 0.4462790964338952,
      "grad_norm": 0.0,
      "learning_rate": 0.0006104457842423229,
      "loss": 4.9202,
      "step": 3892
    },
    {
      "epoch": 0.44639376218323584,
      "grad_norm": 0.0,
      "learning_rate": 0.0006102646831687615,
      "loss": 4.6708,
      "step": 3893
    },
    {
      "epoch": 0.44650842793257656,
      "grad_norm": 0.0,
      "learning_rate": 0.0006100835668931856,
      "loss": 5.1921,
      "step": 3894
    },
    {
      "epoch": 0.4466230936819172,
      "grad_norm": 0.0,
      "learning_rate": 0.0006099024354405763,
      "loss": 5.0585,
      "step": 3895
    },
    {
      "epoch": 0.4467377594312579,
      "grad_norm": 0.0,
      "learning_rate": 0.0006097212888359176,
      "loss": 4.9007,
      "step": 3896
    },
    {
      "epoch": 0.44685242518059853,
      "grad_norm": 0.0,
      "learning_rate": 0.000609540127104195,
      "loss": 4.9984,
      "step": 3897
    },
    {
      "epoch": 0.44696709092993925,
      "grad_norm": 0.0,
      "learning_rate": 0.0006093589502703966,
      "loss": 4.8256,
      "step": 3898
    },
    {
      "epoch": 0.4470817566792799,
      "grad_norm": 0.0,
      "learning_rate": 0.0006091777583595123,
      "loss": 4.8457,
      "step": 3899
    },
    {
      "epoch": 0.44719642242862057,
      "grad_norm": 0.0,
      "learning_rate": 0.0006089965513965337,
      "loss": 4.8804,
      "step": 3900
    },
    {
      "epoch": 0.4473110881779612,
      "grad_norm": 0.0,
      "learning_rate": 0.000608815329406455,
      "loss": 5.0283,
      "step": 3901
    },
    {
      "epoch": 0.44742575392730194,
      "grad_norm": 0.0,
      "learning_rate": 0.0006086340924142723,
      "loss": 4.8925,
      "step": 3902
    },
    {
      "epoch": 0.4475404196766426,
      "grad_norm": 0.0,
      "learning_rate": 0.0006084528404449841,
      "loss": 4.5915,
      "step": 3903
    },
    {
      "epoch": 0.44765508542598326,
      "grad_norm": 0.0,
      "learning_rate": 0.0006082715735235905,
      "loss": 4.9371,
      "step": 3904
    },
    {
      "epoch": 0.4477697511753239,
      "grad_norm": 0.0,
      "learning_rate": 0.0006080902916750934,
      "loss": 4.9792,
      "step": 3905
    },
    {
      "epoch": 0.44788441692466463,
      "grad_norm": 0.0,
      "learning_rate": 0.0006079089949244976,
      "loss": 4.9209,
      "step": 3906
    },
    {
      "epoch": 0.4479990826740053,
      "grad_norm": 0.0,
      "learning_rate": 0.0006077276832968093,
      "loss": 4.9303,
      "step": 3907
    },
    {
      "epoch": 0.44811374842334595,
      "grad_norm": 0.0,
      "learning_rate": 0.0006075463568170373,
      "loss": 4.998,
      "step": 3908
    },
    {
      "epoch": 0.4482284141726866,
      "grad_norm": 0.0,
      "learning_rate": 0.0006073650155101919,
      "loss": 4.8389,
      "step": 3909
    },
    {
      "epoch": 0.44834307992202727,
      "grad_norm": 0.0,
      "learning_rate": 0.0006071836594012858,
      "loss": 4.7699,
      "step": 3910
    },
    {
      "epoch": 0.448457745671368,
      "grad_norm": 0.0,
      "learning_rate": 0.0006070022885153334,
      "loss": 4.8519,
      "step": 3911
    },
    {
      "epoch": 0.44857241142070864,
      "grad_norm": 0.0,
      "learning_rate": 0.0006068209028773515,
      "loss": 4.7831,
      "step": 3912
    },
    {
      "epoch": 0.4486870771700493,
      "grad_norm": 0.0,
      "learning_rate": 0.0006066395025123588,
      "loss": 5.0671,
      "step": 3913
    },
    {
      "epoch": 0.44880174291938996,
      "grad_norm": 0.0,
      "learning_rate": 0.000606458087445376,
      "loss": 5.2544,
      "step": 3914
    },
    {
      "epoch": 0.44891640866873067,
      "grad_norm": 0.0,
      "learning_rate": 0.0006062766577014261,
      "loss": 5.0685,
      "step": 3915
    },
    {
      "epoch": 0.44903107441807133,
      "grad_norm": 0.0,
      "learning_rate": 0.0006060952133055335,
      "loss": 5.1745,
      "step": 3916
    },
    {
      "epoch": 0.449145740167412,
      "grad_norm": 0.0,
      "learning_rate": 0.0006059137542827248,
      "loss": 5.006,
      "step": 3917
    },
    {
      "epoch": 0.44926040591675265,
      "grad_norm": 0.0,
      "learning_rate": 0.0006057322806580295,
      "loss": 4.9802,
      "step": 3918
    },
    {
      "epoch": 0.44937507166609336,
      "grad_norm": 0.0,
      "learning_rate": 0.0006055507924564779,
      "loss": 4.8037,
      "step": 3919
    },
    {
      "epoch": 0.449489737415434,
      "grad_norm": 0.0,
      "learning_rate": 0.0006053692897031032,
      "loss": 5.0867,
      "step": 3920
    },
    {
      "epoch": 0.4496044031647747,
      "grad_norm": 0.0,
      "learning_rate": 0.00060518777242294,
      "loss": 5.2142,
      "step": 3921
    },
    {
      "epoch": 0.44971906891411534,
      "grad_norm": 0.0,
      "learning_rate": 0.0006050062406410252,
      "loss": 4.7994,
      "step": 3922
    },
    {
      "epoch": 0.44983373466345605,
      "grad_norm": 0.0,
      "learning_rate": 0.0006048246943823975,
      "loss": 5.1164,
      "step": 3923
    },
    {
      "epoch": 0.4499484004127967,
      "grad_norm": 0.0,
      "learning_rate": 0.000604643133672098,
      "loss": 4.8285,
      "step": 3924
    },
    {
      "epoch": 0.45006306616213737,
      "grad_norm": 0.0,
      "learning_rate": 0.0006044615585351693,
      "loss": 4.731,
      "step": 3925
    },
    {
      "epoch": 0.45017773191147803,
      "grad_norm": 0.0,
      "learning_rate": 0.0006042799689966566,
      "loss": 5.0081,
      "step": 3926
    },
    {
      "epoch": 0.4502923976608187,
      "grad_norm": 0.0,
      "learning_rate": 0.0006040983650816064,
      "loss": 4.8882,
      "step": 3927
    },
    {
      "epoch": 0.4504070634101594,
      "grad_norm": 0.0,
      "learning_rate": 0.0006039167468150676,
      "loss": 4.8527,
      "step": 3928
    },
    {
      "epoch": 0.45052172915950006,
      "grad_norm": 0.0,
      "learning_rate": 0.0006037351142220909,
      "loss": 5.314,
      "step": 3929
    },
    {
      "epoch": 0.4506363949088407,
      "grad_norm": 0.0,
      "learning_rate": 0.0006035534673277291,
      "loss": 5.227,
      "step": 3930
    },
    {
      "epoch": 0.4507510606581814,
      "grad_norm": 0.0,
      "learning_rate": 0.000603371806157037,
      "loss": 5.1904,
      "step": 3931
    },
    {
      "epoch": 0.4508657264075221,
      "grad_norm": 0.0,
      "learning_rate": 0.0006031901307350713,
      "loss": 4.8304,
      "step": 3932
    },
    {
      "epoch": 0.45098039215686275,
      "grad_norm": 0.0,
      "learning_rate": 0.0006030084410868905,
      "loss": 5.0371,
      "step": 3933
    },
    {
      "epoch": 0.4510950579062034,
      "grad_norm": 0.0,
      "learning_rate": 0.0006028267372375552,
      "loss": 5.0378,
      "step": 3934
    },
    {
      "epoch": 0.45120972365554407,
      "grad_norm": 0.0,
      "learning_rate": 0.0006026450192121282,
      "loss": 5.1893,
      "step": 3935
    },
    {
      "epoch": 0.4513243894048848,
      "grad_norm": 0.0,
      "learning_rate": 0.0006024632870356739,
      "loss": 4.7384,
      "step": 3936
    },
    {
      "epoch": 0.45143905515422544,
      "grad_norm": 0.0,
      "learning_rate": 0.0006022815407332589,
      "loss": 5.0207,
      "step": 3937
    },
    {
      "epoch": 0.4515537209035661,
      "grad_norm": 0.0,
      "learning_rate": 0.0006020997803299516,
      "loss": 5.0788,
      "step": 3938
    },
    {
      "epoch": 0.45166838665290676,
      "grad_norm": 0.0,
      "learning_rate": 0.0006019180058508222,
      "loss": 4.781,
      "step": 3939
    },
    {
      "epoch": 0.4517830524022475,
      "grad_norm": 0.0,
      "learning_rate": 0.0006017362173209434,
      "loss": 5.0495,
      "step": 3940
    },
    {
      "epoch": 0.45189771815158813,
      "grad_norm": 0.0,
      "learning_rate": 0.000601554414765389,
      "loss": 4.8711,
      "step": 3941
    },
    {
      "epoch": 0.4520123839009288,
      "grad_norm": 0.0,
      "learning_rate": 0.0006013725982092355,
      "loss": 5.0897,
      "step": 3942
    },
    {
      "epoch": 0.45212704965026945,
      "grad_norm": 0.0,
      "learning_rate": 0.0006011907676775612,
      "loss": 5.1362,
      "step": 3943
    },
    {
      "epoch": 0.4522417153996101,
      "grad_norm": 0.0,
      "learning_rate": 0.0006010089231954456,
      "loss": 5.1594,
      "step": 3944
    },
    {
      "epoch": 0.4523563811489508,
      "grad_norm": 0.0,
      "learning_rate": 0.0006008270647879711,
      "loss": 5.1438,
      "step": 3945
    },
    {
      "epoch": 0.4524710468982915,
      "grad_norm": 0.0,
      "learning_rate": 0.0006006451924802216,
      "loss": 4.9028,
      "step": 3946
    },
    {
      "epoch": 0.45258571264763214,
      "grad_norm": 0.0,
      "learning_rate": 0.0006004633062972826,
      "loss": 4.8451,
      "step": 3947
    },
    {
      "epoch": 0.4527003783969728,
      "grad_norm": 0.0,
      "learning_rate": 0.0006002814062642422,
      "loss": 5.0757,
      "step": 3948
    },
    {
      "epoch": 0.4528150441463135,
      "grad_norm": 0.0,
      "learning_rate": 0.0006000994924061899,
      "loss": 5.0667,
      "step": 3949
    },
    {
      "epoch": 0.4529297098956542,
      "grad_norm": 0.0,
      "learning_rate": 0.0005999175647482173,
      "loss": 5.0075,
      "step": 3950
    },
    {
      "epoch": 0.45304437564499483,
      "grad_norm": 0.0,
      "learning_rate": 0.0005997356233154176,
      "loss": 4.9585,
      "step": 3951
    },
    {
      "epoch": 0.4531590413943355,
      "grad_norm": 0.0,
      "learning_rate": 0.0005995536681328864,
      "loss": 5.3915,
      "step": 3952
    },
    {
      "epoch": 0.4532737071436762,
      "grad_norm": 0.0,
      "learning_rate": 0.0005993716992257209,
      "loss": 5.0194,
      "step": 3953
    },
    {
      "epoch": 0.45338837289301687,
      "grad_norm": 0.0,
      "learning_rate": 0.0005991897166190204,
      "loss": 5.1674,
      "step": 3954
    },
    {
      "epoch": 0.4535030386423575,
      "grad_norm": 0.0,
      "learning_rate": 0.0005990077203378856,
      "loss": 5.0585,
      "step": 3955
    },
    {
      "epoch": 0.4536177043916982,
      "grad_norm": 0.0,
      "learning_rate": 0.0005988257104074196,
      "loss": 5.0308,
      "step": 3956
    },
    {
      "epoch": 0.4537323701410389,
      "grad_norm": 0.0,
      "learning_rate": 0.0005986436868527272,
      "loss": 4.9043,
      "step": 3957
    },
    {
      "epoch": 0.45384703589037956,
      "grad_norm": 0.0,
      "learning_rate": 0.0005984616496989151,
      "loss": 4.7331,
      "step": 3958
    },
    {
      "epoch": 0.4539617016397202,
      "grad_norm": 0.0,
      "learning_rate": 0.0005982795989710919,
      "loss": 5.2774,
      "step": 3959
    },
    {
      "epoch": 0.4540763673890609,
      "grad_norm": 0.0,
      "learning_rate": 0.0005980975346943678,
      "loss": 4.7643,
      "step": 3960
    },
    {
      "epoch": 0.45419103313840153,
      "grad_norm": 0.0,
      "learning_rate": 0.0005979154568938553,
      "loss": 5.1208,
      "step": 3961
    },
    {
      "epoch": 0.45430569888774225,
      "grad_norm": 0.0,
      "learning_rate": 0.0005977333655946685,
      "loss": 5.0376,
      "step": 3962
    },
    {
      "epoch": 0.4544203646370829,
      "grad_norm": 0.0,
      "learning_rate": 0.0005975512608219235,
      "loss": 4.9201,
      "step": 3963
    },
    {
      "epoch": 0.45453503038642357,
      "grad_norm": 0.0,
      "learning_rate": 0.0005973691426007379,
      "loss": 5.0227,
      "step": 3964
    },
    {
      "epoch": 0.4546496961357642,
      "grad_norm": 0.0,
      "learning_rate": 0.0005971870109562318,
      "loss": 4.8131,
      "step": 3965
    },
    {
      "epoch": 0.45476436188510494,
      "grad_norm": 0.0,
      "learning_rate": 0.0005970048659135267,
      "loss": 4.8338,
      "step": 3966
    },
    {
      "epoch": 0.4548790276344456,
      "grad_norm": 0.0,
      "learning_rate": 0.0005968227074977458,
      "loss": 5.2072,
      "step": 3967
    },
    {
      "epoch": 0.45499369338378626,
      "grad_norm": 0.0,
      "learning_rate": 0.0005966405357340147,
      "loss": 5.0179,
      "step": 3968
    },
    {
      "epoch": 0.4551083591331269,
      "grad_norm": 0.0,
      "learning_rate": 0.0005964583506474602,
      "loss": 5.0428,
      "step": 3969
    },
    {
      "epoch": 0.45522302488246763,
      "grad_norm": 0.0,
      "learning_rate": 0.0005962761522632118,
      "loss": 4.9997,
      "step": 3970
    },
    {
      "epoch": 0.4553376906318083,
      "grad_norm": 0.0,
      "learning_rate": 0.0005960939406063996,
      "loss": 4.9715,
      "step": 3971
    },
    {
      "epoch": 0.45545235638114895,
      "grad_norm": 0.0,
      "learning_rate": 0.0005959117157021568,
      "loss": 5.1175,
      "step": 3972
    },
    {
      "epoch": 0.4555670221304896,
      "grad_norm": 0.0,
      "learning_rate": 0.0005957294775756174,
      "loss": 5.0191,
      "step": 3973
    },
    {
      "epoch": 0.4556816878798303,
      "grad_norm": 0.0,
      "learning_rate": 0.0005955472262519179,
      "loss": 5.1118,
      "step": 3974
    },
    {
      "epoch": 0.455796353629171,
      "grad_norm": 0.0,
      "learning_rate": 0.0005953649617561964,
      "loss": 5.2134,
      "step": 3975
    },
    {
      "epoch": 0.45591101937851164,
      "grad_norm": 0.0,
      "learning_rate": 0.000595182684113593,
      "loss": 4.9106,
      "step": 3976
    },
    {
      "epoch": 0.4560256851278523,
      "grad_norm": 0.0,
      "learning_rate": 0.0005950003933492489,
      "loss": 5.1283,
      "step": 3977
    },
    {
      "epoch": 0.45614035087719296,
      "grad_norm": 0.0,
      "learning_rate": 0.000594818089488308,
      "loss": 4.8395,
      "step": 3978
    },
    {
      "epoch": 0.45625501662653367,
      "grad_norm": 0.0,
      "learning_rate": 0.0005946357725559158,
      "loss": 4.9069,
      "step": 3979
    },
    {
      "epoch": 0.45636968237587433,
      "grad_norm": 0.0,
      "learning_rate": 0.0005944534425772192,
      "loss": 5.2743,
      "step": 3980
    },
    {
      "epoch": 0.456484348125215,
      "grad_norm": 0.0,
      "learning_rate": 0.0005942710995773674,
      "loss": 4.9716,
      "step": 3981
    },
    {
      "epoch": 0.45659901387455565,
      "grad_norm": 0.0,
      "learning_rate": 0.0005940887435815106,
      "loss": 4.9951,
      "step": 3982
    },
    {
      "epoch": 0.45671367962389636,
      "grad_norm": 0.0,
      "learning_rate": 0.0005939063746148017,
      "loss": 5.0952,
      "step": 3983
    },
    {
      "epoch": 0.456828345373237,
      "grad_norm": 0.0,
      "learning_rate": 0.000593723992702395,
      "loss": 4.9186,
      "step": 3984
    },
    {
      "epoch": 0.4569430111225777,
      "grad_norm": 0.0,
      "learning_rate": 0.0005935415978694466,
      "loss": 4.7048,
      "step": 3985
    },
    {
      "epoch": 0.45705767687191834,
      "grad_norm": 0.0,
      "learning_rate": 0.0005933591901411143,
      "loss": 5.0733,
      "step": 3986
    },
    {
      "epoch": 0.45717234262125905,
      "grad_norm": 0.0,
      "learning_rate": 0.0005931767695425581,
      "loss": 5.1336,
      "step": 3987
    },
    {
      "epoch": 0.4572870083705997,
      "grad_norm": 0.0,
      "learning_rate": 0.000592994336098939,
      "loss": 4.9555,
      "step": 3988
    },
    {
      "epoch": 0.45740167411994037,
      "grad_norm": 0.0,
      "learning_rate": 0.0005928118898354205,
      "loss": 5.1089,
      "step": 3989
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.0,
      "learning_rate": 0.0005926294307771673,
      "loss": 5.1204,
      "step": 3990
    },
    {
      "epoch": 0.45763100561862174,
      "grad_norm": 0.0,
      "learning_rate": 0.0005924469589493467,
      "loss": 4.9705,
      "step": 3991
    },
    {
      "epoch": 0.4577456713679624,
      "grad_norm": 0.0,
      "learning_rate": 0.0005922644743771267,
      "loss": 5.0937,
      "step": 3992
    },
    {
      "epoch": 0.45786033711730306,
      "grad_norm": 0.0,
      "learning_rate": 0.0005920819770856778,
      "loss": 4.932,
      "step": 3993
    },
    {
      "epoch": 0.4579750028666437,
      "grad_norm": 0.0,
      "learning_rate": 0.0005918994671001718,
      "loss": 5.0142,
      "step": 3994
    },
    {
      "epoch": 0.4580896686159844,
      "grad_norm": 0.0,
      "learning_rate": 0.0005917169444457826,
      "loss": 4.9015,
      "step": 3995
    },
    {
      "epoch": 0.4582043343653251,
      "grad_norm": 0.0,
      "learning_rate": 0.0005915344091476859,
      "loss": 4.9357,
      "step": 3996
    },
    {
      "epoch": 0.45831900011466575,
      "grad_norm": 0.0,
      "learning_rate": 0.0005913518612310586,
      "loss": 5.0177,
      "step": 3997
    },
    {
      "epoch": 0.4584336658640064,
      "grad_norm": 0.0,
      "learning_rate": 0.0005911693007210802,
      "loss": 4.9097,
      "step": 3998
    },
    {
      "epoch": 0.45854833161334707,
      "grad_norm": 0.0,
      "learning_rate": 0.0005909867276429311,
      "loss": 4.8066,
      "step": 3999
    },
    {
      "epoch": 0.4586629973626878,
      "grad_norm": 0.0,
      "learning_rate": 0.0005908041420217936,
      "loss": 5.0437,
      "step": 4000
    },
    {
      "epoch": 0.45877766311202844,
      "grad_norm": 0.0,
      "learning_rate": 0.0005906215438828524,
      "loss": 4.8787,
      "step": 4001
    },
    {
      "epoch": 0.4588923288613691,
      "grad_norm": 0.0,
      "learning_rate": 0.0005904389332512931,
      "loss": 4.9325,
      "step": 4002
    },
    {
      "epoch": 0.45900699461070976,
      "grad_norm": 0.0,
      "learning_rate": 0.0005902563101523034,
      "loss": 4.8688,
      "step": 4003
    },
    {
      "epoch": 0.4591216603600505,
      "grad_norm": 0.0,
      "learning_rate": 0.0005900736746110726,
      "loss": 4.9631,
      "step": 4004
    },
    {
      "epoch": 0.45923632610939114,
      "grad_norm": 0.0,
      "learning_rate": 0.000589891026652792,
      "loss": 4.9246,
      "step": 4005
    },
    {
      "epoch": 0.4593509918587318,
      "grad_norm": 0.0,
      "learning_rate": 0.0005897083663026542,
      "loss": 5.1588,
      "step": 4006
    },
    {
      "epoch": 0.45946565760807245,
      "grad_norm": 0.0,
      "learning_rate": 0.0005895256935858539,
      "loss": 4.9999,
      "step": 4007
    },
    {
      "epoch": 0.45958032335741317,
      "grad_norm": 0.0,
      "learning_rate": 0.0005893430085275873,
      "loss": 4.8792,
      "step": 4008
    },
    {
      "epoch": 0.4596949891067538,
      "grad_norm": 0.0,
      "learning_rate": 0.0005891603111530521,
      "loss": 4.9172,
      "step": 4009
    },
    {
      "epoch": 0.4598096548560945,
      "grad_norm": 0.0,
      "learning_rate": 0.0005889776014874481,
      "loss": 5.1483,
      "step": 4010
    },
    {
      "epoch": 0.45992432060543514,
      "grad_norm": 0.0,
      "learning_rate": 0.0005887948795559769,
      "loss": 4.946,
      "step": 4011
    },
    {
      "epoch": 0.4600389863547758,
      "grad_norm": 0.0,
      "learning_rate": 0.0005886121453838409,
      "loss": 5.0339,
      "step": 4012
    },
    {
      "epoch": 0.4601536521041165,
      "grad_norm": 0.0,
      "learning_rate": 0.000588429398996245,
      "loss": 5.0883,
      "step": 4013
    },
    {
      "epoch": 0.4602683178534572,
      "grad_norm": 0.0,
      "learning_rate": 0.000588246640418396,
      "loss": 4.8583,
      "step": 4014
    },
    {
      "epoch": 0.46038298360279784,
      "grad_norm": 0.0,
      "learning_rate": 0.0005880638696755014,
      "loss": 5.0048,
      "step": 4015
    },
    {
      "epoch": 0.4604976493521385,
      "grad_norm": 0.0,
      "learning_rate": 0.0005878810867927712,
      "loss": 5.2232,
      "step": 4016
    },
    {
      "epoch": 0.4606123151014792,
      "grad_norm": 0.0,
      "learning_rate": 0.0005876982917954167,
      "loss": 4.994,
      "step": 4017
    },
    {
      "epoch": 0.46072698085081987,
      "grad_norm": 0.0,
      "learning_rate": 0.0005875154847086511,
      "loss": 5.1716,
      "step": 4018
    },
    {
      "epoch": 0.4608416466001605,
      "grad_norm": 0.0,
      "learning_rate": 0.0005873326655576892,
      "loss": 5.32,
      "step": 4019
    },
    {
      "epoch": 0.4609563123495012,
      "grad_norm": 0.0,
      "learning_rate": 0.0005871498343677474,
      "loss": 4.8926,
      "step": 4020
    },
    {
      "epoch": 0.4610709780988419,
      "grad_norm": 0.0,
      "learning_rate": 0.0005869669911640438,
      "loss": 5.0433,
      "step": 4021
    },
    {
      "epoch": 0.46118564384818256,
      "grad_norm": 0.0,
      "learning_rate": 0.000586784135971798,
      "loss": 4.8542,
      "step": 4022
    },
    {
      "epoch": 0.4613003095975232,
      "grad_norm": 0.0,
      "learning_rate": 0.0005866012688162313,
      "loss": 5.0684,
      "step": 4023
    },
    {
      "epoch": 0.4614149753468639,
      "grad_norm": 0.0,
      "learning_rate": 0.000586418389722567,
      "loss": 4.9007,
      "step": 4024
    },
    {
      "epoch": 0.4615296410962046,
      "grad_norm": 0.0,
      "learning_rate": 0.0005862354987160298,
      "loss": 4.6841,
      "step": 4025
    },
    {
      "epoch": 0.46164430684554525,
      "grad_norm": 0.0,
      "learning_rate": 0.0005860525958218455,
      "loss": 4.9729,
      "step": 4026
    },
    {
      "epoch": 0.4617589725948859,
      "grad_norm": 0.0,
      "learning_rate": 0.0005858696810652428,
      "loss": 4.9322,
      "step": 4027
    },
    {
      "epoch": 0.46187363834422657,
      "grad_norm": 0.0,
      "learning_rate": 0.0005856867544714508,
      "loss": 5.1214,
      "step": 4028
    },
    {
      "epoch": 0.4619883040935672,
      "grad_norm": 0.0,
      "learning_rate": 0.000585503816065701,
      "loss": 4.7044,
      "step": 4029
    },
    {
      "epoch": 0.46210296984290794,
      "grad_norm": 0.0,
      "learning_rate": 0.000585320865873226,
      "loss": 4.8524,
      "step": 4030
    },
    {
      "epoch": 0.4622176355922486,
      "grad_norm": 0.0,
      "learning_rate": 0.0005851379039192608,
      "loss": 5.125,
      "step": 4031
    },
    {
      "epoch": 0.46233230134158926,
      "grad_norm": 0.0,
      "learning_rate": 0.000584954930229041,
      "loss": 4.946,
      "step": 4032
    },
    {
      "epoch": 0.4624469670909299,
      "grad_norm": 0.0,
      "learning_rate": 0.0005847719448278045,
      "loss": 4.9877,
      "step": 4033
    },
    {
      "epoch": 0.46256163284027063,
      "grad_norm": 0.0,
      "learning_rate": 0.0005845889477407905,
      "loss": 4.7992,
      "step": 4034
    },
    {
      "epoch": 0.4626762985896113,
      "grad_norm": 0.0,
      "learning_rate": 0.0005844059389932403,
      "loss": 5.0867,
      "step": 4035
    },
    {
      "epoch": 0.46279096433895195,
      "grad_norm": 0.0,
      "learning_rate": 0.0005842229186103964,
      "loss": 5.2481,
      "step": 4036
    },
    {
      "epoch": 0.4629056300882926,
      "grad_norm": 0.0,
      "learning_rate": 0.0005840398866175027,
      "loss": 5.0275,
      "step": 4037
    },
    {
      "epoch": 0.4630202958376333,
      "grad_norm": 0.0,
      "learning_rate": 0.0005838568430398052,
      "loss": 4.8627,
      "step": 4038
    },
    {
      "epoch": 0.463134961586974,
      "grad_norm": 0.0,
      "learning_rate": 0.000583673787902551,
      "loss": 4.8734,
      "step": 4039
    },
    {
      "epoch": 0.46324962733631464,
      "grad_norm": 0.0,
      "learning_rate": 0.0005834907212309894,
      "loss": 5.02,
      "step": 4040
    },
    {
      "epoch": 0.4633642930856553,
      "grad_norm": 0.0,
      "learning_rate": 0.0005833076430503709,
      "loss": 5.1,
      "step": 4041
    },
    {
      "epoch": 0.463478958834996,
      "grad_norm": 0.0,
      "learning_rate": 0.0005831245533859477,
      "loss": 5.0837,
      "step": 4042
    },
    {
      "epoch": 0.46359362458433667,
      "grad_norm": 0.0,
      "learning_rate": 0.0005829414522629732,
      "loss": 5.2745,
      "step": 4043
    },
    {
      "epoch": 0.46370829033367733,
      "grad_norm": 0.0,
      "learning_rate": 0.0005827583397067029,
      "loss": 5.3127,
      "step": 4044
    },
    {
      "epoch": 0.463822956083018,
      "grad_norm": 0.0,
      "learning_rate": 0.0005825752157423938,
      "loss": 5.2402,
      "step": 4045
    },
    {
      "epoch": 0.46393762183235865,
      "grad_norm": 0.0,
      "learning_rate": 0.0005823920803953041,
      "loss": 4.9535,
      "step": 4046
    },
    {
      "epoch": 0.46405228758169936,
      "grad_norm": 0.0,
      "learning_rate": 0.0005822089336906943,
      "loss": 4.6603,
      "step": 4047
    },
    {
      "epoch": 0.46416695333104,
      "grad_norm": 0.0,
      "learning_rate": 0.0005820257756538255,
      "loss": 4.8535,
      "step": 4048
    },
    {
      "epoch": 0.4642816190803807,
      "grad_norm": 0.0,
      "learning_rate": 0.0005818426063099608,
      "loss": 4.9765,
      "step": 4049
    },
    {
      "epoch": 0.46439628482972134,
      "grad_norm": 0.0,
      "learning_rate": 0.0005816594256843656,
      "loss": 5.1982,
      "step": 4050
    },
    {
      "epoch": 0.46451095057906205,
      "grad_norm": 0.0,
      "learning_rate": 0.0005814762338023054,
      "loss": 5.3107,
      "step": 4051
    },
    {
      "epoch": 0.4646256163284027,
      "grad_norm": 0.0,
      "learning_rate": 0.0005812930306890487,
      "loss": 5.0199,
      "step": 4052
    },
    {
      "epoch": 0.46474028207774337,
      "grad_norm": 0.0,
      "learning_rate": 0.0005811098163698645,
      "loss": 4.835,
      "step": 4053
    },
    {
      "epoch": 0.46485494782708403,
      "grad_norm": 0.0,
      "learning_rate": 0.0005809265908700236,
      "loss": 4.9314,
      "step": 4054
    },
    {
      "epoch": 0.46496961357642475,
      "grad_norm": 0.0,
      "learning_rate": 0.0005807433542147987,
      "loss": 5.1317,
      "step": 4055
    },
    {
      "epoch": 0.4650842793257654,
      "grad_norm": 0.0,
      "learning_rate": 0.0005805601064294637,
      "loss": 4.6937,
      "step": 4056
    },
    {
      "epoch": 0.46519894507510606,
      "grad_norm": 0.0,
      "learning_rate": 0.0005803768475392941,
      "loss": 4.8549,
      "step": 4057
    },
    {
      "epoch": 0.4653136108244467,
      "grad_norm": 0.0,
      "learning_rate": 0.0005801935775695674,
      "loss": 5.0937,
      "step": 4058
    },
    {
      "epoch": 0.46542827657378744,
      "grad_norm": 0.0,
      "learning_rate": 0.0005800102965455615,
      "loss": 4.9972,
      "step": 4059
    },
    {
      "epoch": 0.4655429423231281,
      "grad_norm": 0.0,
      "learning_rate": 0.000579827004492557,
      "loss": 5.1534,
      "step": 4060
    },
    {
      "epoch": 0.46565760807246875,
      "grad_norm": 0.0,
      "learning_rate": 0.0005796437014358353,
      "loss": 4.8985,
      "step": 4061
    },
    {
      "epoch": 0.4657722738218094,
      "grad_norm": 0.0,
      "learning_rate": 0.0005794603874006799,
      "loss": 4.97,
      "step": 4062
    },
    {
      "epoch": 0.46588693957115007,
      "grad_norm": 0.0,
      "learning_rate": 0.0005792770624123751,
      "loss": 4.9405,
      "step": 4063
    },
    {
      "epoch": 0.4660016053204908,
      "grad_norm": 0.0,
      "learning_rate": 0.0005790937264962074,
      "loss": 5.0484,
      "step": 4064
    },
    {
      "epoch": 0.46611627106983144,
      "grad_norm": 0.0,
      "learning_rate": 0.0005789103796774641,
      "loss": 5.0867,
      "step": 4065
    },
    {
      "epoch": 0.4662309368191721,
      "grad_norm": 0.0,
      "learning_rate": 0.0005787270219814348,
      "loss": 4.9649,
      "step": 4066
    },
    {
      "epoch": 0.46634560256851276,
      "grad_norm": 0.0,
      "learning_rate": 0.00057854365343341,
      "loss": 5.3411,
      "step": 4067
    },
    {
      "epoch": 0.4664602683178535,
      "grad_norm": 0.0,
      "learning_rate": 0.000578360274058682,
      "loss": 5.035,
      "step": 4068
    },
    {
      "epoch": 0.46657493406719414,
      "grad_norm": 0.0,
      "learning_rate": 0.0005781768838825444,
      "loss": 4.9809,
      "step": 4069
    },
    {
      "epoch": 0.4666895998165348,
      "grad_norm": 0.0,
      "learning_rate": 0.0005779934829302923,
      "loss": 4.9258,
      "step": 4070
    },
    {
      "epoch": 0.46680426556587545,
      "grad_norm": 0.0,
      "learning_rate": 0.0005778100712272225,
      "loss": 4.8147,
      "step": 4071
    },
    {
      "epoch": 0.46691893131521617,
      "grad_norm": 0.0,
      "learning_rate": 0.0005776266487986332,
      "loss": 5.0657,
      "step": 4072
    },
    {
      "epoch": 0.4670335970645568,
      "grad_norm": 0.0,
      "learning_rate": 0.000577443215669824,
      "loss": 4.9846,
      "step": 4073
    },
    {
      "epoch": 0.4671482628138975,
      "grad_norm": 0.0,
      "learning_rate": 0.0005772597718660957,
      "loss": 5.0077,
      "step": 4074
    },
    {
      "epoch": 0.46726292856323814,
      "grad_norm": 0.0,
      "learning_rate": 0.0005770763174127515,
      "loss": 4.8377,
      "step": 4075
    },
    {
      "epoch": 0.46737759431257886,
      "grad_norm": 0.0,
      "learning_rate": 0.0005768928523350947,
      "loss": 5.0894,
      "step": 4076
    },
    {
      "epoch": 0.4674922600619195,
      "grad_norm": 0.0,
      "learning_rate": 0.0005767093766584313,
      "loss": 4.8902,
      "step": 4077
    },
    {
      "epoch": 0.4676069258112602,
      "grad_norm": 0.0,
      "learning_rate": 0.0005765258904080682,
      "loss": 4.9751,
      "step": 4078
    },
    {
      "epoch": 0.46772159156060084,
      "grad_norm": 0.0,
      "learning_rate": 0.0005763423936093137,
      "loss": 5.3954,
      "step": 4079
    },
    {
      "epoch": 0.4678362573099415,
      "grad_norm": 0.0,
      "learning_rate": 0.0005761588862874779,
      "loss": 5.2056,
      "step": 4080
    },
    {
      "epoch": 0.4679509230592822,
      "grad_norm": 0.0,
      "learning_rate": 0.0005759753684678719,
      "loss": 5.1204,
      "step": 4081
    },
    {
      "epoch": 0.46806558880862287,
      "grad_norm": 0.0,
      "learning_rate": 0.0005757918401758086,
      "loss": 5.1035,
      "step": 4082
    },
    {
      "epoch": 0.4681802545579635,
      "grad_norm": 0.0,
      "learning_rate": 0.0005756083014366023,
      "loss": 4.7511,
      "step": 4083
    },
    {
      "epoch": 0.4682949203073042,
      "grad_norm": 0.0,
      "learning_rate": 0.0005754247522755685,
      "loss": 5.1214,
      "step": 4084
    },
    {
      "epoch": 0.4684095860566449,
      "grad_norm": 0.0,
      "learning_rate": 0.0005752411927180244,
      "loss": 4.9682,
      "step": 4085
    },
    {
      "epoch": 0.46852425180598556,
      "grad_norm": 0.0,
      "learning_rate": 0.0005750576227892886,
      "loss": 5.2111,
      "step": 4086
    },
    {
      "epoch": 0.4686389175553262,
      "grad_norm": 0.0,
      "learning_rate": 0.0005748740425146809,
      "loss": 5.0087,
      "step": 4087
    },
    {
      "epoch": 0.4687535833046669,
      "grad_norm": 0.0,
      "learning_rate": 0.0005746904519195228,
      "loss": 4.8466,
      "step": 4088
    },
    {
      "epoch": 0.4688682490540076,
      "grad_norm": 0.0,
      "learning_rate": 0.0005745068510291372,
      "loss": 4.7222,
      "step": 4089
    },
    {
      "epoch": 0.46898291480334825,
      "grad_norm": 0.0,
      "learning_rate": 0.0005743232398688483,
      "loss": 5.041,
      "step": 4090
    },
    {
      "epoch": 0.4690975805526889,
      "grad_norm": 0.0,
      "learning_rate": 0.0005741396184639817,
      "loss": 4.8209,
      "step": 4091
    },
    {
      "epoch": 0.46921224630202957,
      "grad_norm": 0.0,
      "learning_rate": 0.0005739559868398646,
      "loss": 5.0994,
      "step": 4092
    },
    {
      "epoch": 0.4693269120513703,
      "grad_norm": 0.0,
      "learning_rate": 0.0005737723450218254,
      "loss": 4.9736,
      "step": 4093
    },
    {
      "epoch": 0.46944157780071094,
      "grad_norm": 0.0,
      "learning_rate": 0.0005735886930351939,
      "loss": 5.114,
      "step": 4094
    },
    {
      "epoch": 0.4695562435500516,
      "grad_norm": 0.0,
      "learning_rate": 0.0005734050309053014,
      "loss": 4.9213,
      "step": 4095
    },
    {
      "epoch": 0.46967090929939226,
      "grad_norm": 0.0,
      "learning_rate": 0.0005732213586574807,
      "loss": 5.0077,
      "step": 4096
    },
    {
      "epoch": 0.4697855750487329,
      "grad_norm": 0.0,
      "learning_rate": 0.0005730376763170659,
      "loss": 5.2393,
      "step": 4097
    },
    {
      "epoch": 0.46990024079807363,
      "grad_norm": 0.0,
      "learning_rate": 0.0005728539839093924,
      "loss": 5.1979,
      "step": 4098
    },
    {
      "epoch": 0.4700149065474143,
      "grad_norm": 0.0,
      "learning_rate": 0.0005726702814597972,
      "loss": 5.065,
      "step": 4099
    },
    {
      "epoch": 0.47012957229675495,
      "grad_norm": 0.0,
      "learning_rate": 0.0005724865689936182,
      "loss": 4.9627,
      "step": 4100
    },
    {
      "epoch": 0.4702442380460956,
      "grad_norm": 0.0,
      "learning_rate": 0.0005723028465361953,
      "loss": 5.0967,
      "step": 4101
    },
    {
      "epoch": 0.4703589037954363,
      "grad_norm": 0.0,
      "learning_rate": 0.0005721191141128698,
      "loss": 4.999,
      "step": 4102
    },
    {
      "epoch": 0.470473569544777,
      "grad_norm": 0.0,
      "learning_rate": 0.0005719353717489836,
      "loss": 5.1967,
      "step": 4103
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 0.0,
      "learning_rate": 0.0005717516194698807,
      "loss": 4.9572,
      "step": 4104
    },
    {
      "epoch": 0.4707029010434583,
      "grad_norm": 0.0,
      "learning_rate": 0.0005715678573009059,
      "loss": 5.0777,
      "step": 4105
    },
    {
      "epoch": 0.470817566792799,
      "grad_norm": 0.0,
      "learning_rate": 0.0005713840852674061,
      "loss": 5.0848,
      "step": 4106
    },
    {
      "epoch": 0.4709322325421397,
      "grad_norm": 0.0,
      "learning_rate": 0.0005712003033947288,
      "loss": 5.1413,
      "step": 4107
    },
    {
      "epoch": 0.47104689829148033,
      "grad_norm": 0.0,
      "learning_rate": 0.0005710165117082238,
      "loss": 5.2709,
      "step": 4108
    },
    {
      "epoch": 0.471161564040821,
      "grad_norm": 0.0,
      "learning_rate": 0.000570832710233241,
      "loss": 4.953,
      "step": 4109
    },
    {
      "epoch": 0.4712762297901617,
      "grad_norm": 0.0,
      "learning_rate": 0.0005706488989951326,
      "loss": 5.0403,
      "step": 4110
    },
    {
      "epoch": 0.47139089553950236,
      "grad_norm": 0.0,
      "learning_rate": 0.0005704650780192517,
      "loss": 4.8429,
      "step": 4111
    },
    {
      "epoch": 0.471505561288843,
      "grad_norm": 0.0,
      "learning_rate": 0.0005702812473309531,
      "loss": 5.0189,
      "step": 4112
    },
    {
      "epoch": 0.4716202270381837,
      "grad_norm": 0.0,
      "learning_rate": 0.0005700974069555928,
      "loss": 5.0742,
      "step": 4113
    },
    {
      "epoch": 0.47173489278752434,
      "grad_norm": 0.0,
      "learning_rate": 0.0005699135569185279,
      "loss": 5.2744,
      "step": 4114
    },
    {
      "epoch": 0.47184955853686505,
      "grad_norm": 0.0,
      "learning_rate": 0.0005697296972451168,
      "loss": 4.76,
      "step": 4115
    },
    {
      "epoch": 0.4719642242862057,
      "grad_norm": 0.0,
      "learning_rate": 0.0005695458279607199,
      "loss": 5.0259,
      "step": 4116
    },
    {
      "epoch": 0.4720788900355464,
      "grad_norm": 0.0,
      "learning_rate": 0.0005693619490906982,
      "loss": 5.0266,
      "step": 4117
    },
    {
      "epoch": 0.47219355578488703,
      "grad_norm": 0.0,
      "learning_rate": 0.0005691780606604142,
      "loss": 4.7756,
      "step": 4118
    },
    {
      "epoch": 0.47230822153422775,
      "grad_norm": 0.0,
      "learning_rate": 0.0005689941626952321,
      "loss": 4.9247,
      "step": 4119
    },
    {
      "epoch": 0.4724228872835684,
      "grad_norm": 0.0,
      "learning_rate": 0.000568810255220517,
      "loss": 4.9308,
      "step": 4120
    },
    {
      "epoch": 0.47253755303290906,
      "grad_norm": 0.0,
      "learning_rate": 0.0005686263382616352,
      "loss": 4.8947,
      "step": 4121
    },
    {
      "epoch": 0.4726522187822497,
      "grad_norm": 0.0,
      "learning_rate": 0.0005684424118439548,
      "loss": 5.0068,
      "step": 4122
    },
    {
      "epoch": 0.47276688453159044,
      "grad_norm": 0.0,
      "learning_rate": 0.0005682584759928449,
      "loss": 5.1434,
      "step": 4123
    },
    {
      "epoch": 0.4728815502809311,
      "grad_norm": 0.0,
      "learning_rate": 0.0005680745307336759,
      "loss": 4.8569,
      "step": 4124
    },
    {
      "epoch": 0.47299621603027175,
      "grad_norm": 0.0,
      "learning_rate": 0.0005678905760918196,
      "loss": 5.0082,
      "step": 4125
    },
    {
      "epoch": 0.4731108817796124,
      "grad_norm": 0.0,
      "learning_rate": 0.000567706612092649,
      "loss": 5.1725,
      "step": 4126
    },
    {
      "epoch": 0.4732255475289531,
      "grad_norm": 0.0,
      "learning_rate": 0.0005675226387615382,
      "loss": 4.9398,
      "step": 4127
    },
    {
      "epoch": 0.4733402132782938,
      "grad_norm": 0.0,
      "learning_rate": 0.0005673386561238632,
      "loss": 4.6613,
      "step": 4128
    },
    {
      "epoch": 0.47345487902763445,
      "grad_norm": 0.0,
      "learning_rate": 0.0005671546642050006,
      "loss": 5.1699,
      "step": 4129
    },
    {
      "epoch": 0.4735695447769751,
      "grad_norm": 0.0,
      "learning_rate": 0.0005669706630303289,
      "loss": 5.0821,
      "step": 4130
    },
    {
      "epoch": 0.47368421052631576,
      "grad_norm": 0.0,
      "learning_rate": 0.0005667866526252272,
      "loss": 5.1364,
      "step": 4131
    },
    {
      "epoch": 0.4737988762756565,
      "grad_norm": 0.0,
      "learning_rate": 0.0005666026330150764,
      "loss": 5.2869,
      "step": 4132
    },
    {
      "epoch": 0.47391354202499714,
      "grad_norm": 0.0,
      "learning_rate": 0.0005664186042252585,
      "loss": 4.9223,
      "step": 4133
    },
    {
      "epoch": 0.4740282077743378,
      "grad_norm": 0.0,
      "learning_rate": 0.0005662345662811569,
      "loss": 5.15,
      "step": 4134
    },
    {
      "epoch": 0.47414287352367845,
      "grad_norm": 0.0,
      "learning_rate": 0.0005660505192081558,
      "loss": 4.9263,
      "step": 4135
    },
    {
      "epoch": 0.47425753927301917,
      "grad_norm": 0.0,
      "learning_rate": 0.0005658664630316413,
      "loss": 5.1225,
      "step": 4136
    },
    {
      "epoch": 0.4743722050223598,
      "grad_norm": 0.0,
      "learning_rate": 0.0005656823977770001,
      "loss": 4.9353,
      "step": 4137
    },
    {
      "epoch": 0.4744868707717005,
      "grad_norm": 0.0,
      "learning_rate": 0.0005654983234696208,
      "loss": 5.2775,
      "step": 4138
    },
    {
      "epoch": 0.47460153652104115,
      "grad_norm": 0.0,
      "learning_rate": 0.0005653142401348929,
      "loss": 4.9155,
      "step": 4139
    },
    {
      "epoch": 0.47471620227038186,
      "grad_norm": 0.0,
      "learning_rate": 0.0005651301477982069,
      "loss": 5.1316,
      "step": 4140
    },
    {
      "epoch": 0.4748308680197225,
      "grad_norm": 0.0,
      "learning_rate": 0.0005649460464849553,
      "loss": 4.8933,
      "step": 4141
    },
    {
      "epoch": 0.4749455337690632,
      "grad_norm": 0.0,
      "learning_rate": 0.000564761936220531,
      "loss": 5.0023,
      "step": 4142
    },
    {
      "epoch": 0.47506019951840384,
      "grad_norm": 0.0,
      "learning_rate": 0.0005645778170303286,
      "loss": 4.9545,
      "step": 4143
    },
    {
      "epoch": 0.47517486526774455,
      "grad_norm": 0.0,
      "learning_rate": 0.0005643936889397441,
      "loss": 5.1493,
      "step": 4144
    },
    {
      "epoch": 0.4752895310170852,
      "grad_norm": 0.0,
      "learning_rate": 0.0005642095519741739,
      "loss": 4.9422,
      "step": 4145
    },
    {
      "epoch": 0.47540419676642587,
      "grad_norm": 0.0,
      "learning_rate": 0.0005640254061590167,
      "loss": 4.9272,
      "step": 4146
    },
    {
      "epoch": 0.4755188625157665,
      "grad_norm": 0.0,
      "learning_rate": 0.0005638412515196716,
      "loss": 5.0823,
      "step": 4147
    },
    {
      "epoch": 0.4756335282651072,
      "grad_norm": 0.0,
      "learning_rate": 0.0005636570880815393,
      "loss": 5.0304,
      "step": 4148
    },
    {
      "epoch": 0.4757481940144479,
      "grad_norm": 0.0,
      "learning_rate": 0.0005634729158700216,
      "loss": 4.8994,
      "step": 4149
    },
    {
      "epoch": 0.47586285976378856,
      "grad_norm": 0.0,
      "learning_rate": 0.0005632887349105218,
      "loss": 4.88,
      "step": 4150
    },
    {
      "epoch": 0.4759775255131292,
      "grad_norm": 0.0,
      "learning_rate": 0.0005631045452284438,
      "loss": 4.7362,
      "step": 4151
    },
    {
      "epoch": 0.4760921912624699,
      "grad_norm": 0.0,
      "learning_rate": 0.0005629203468491933,
      "loss": 5.0731,
      "step": 4152
    },
    {
      "epoch": 0.4762068570118106,
      "grad_norm": 0.0,
      "learning_rate": 0.0005627361397981769,
      "loss": 4.871,
      "step": 4153
    },
    {
      "epoch": 0.47632152276115125,
      "grad_norm": 0.0,
      "learning_rate": 0.0005625519241008024,
      "loss": 5.0373,
      "step": 4154
    },
    {
      "epoch": 0.4764361885104919,
      "grad_norm": 0.0,
      "learning_rate": 0.0005623676997824787,
      "loss": 4.8315,
      "step": 4155
    },
    {
      "epoch": 0.47655085425983257,
      "grad_norm": 0.0,
      "learning_rate": 0.0005621834668686164,
      "loss": 5.1794,
      "step": 4156
    },
    {
      "epoch": 0.4766655200091733,
      "grad_norm": 0.0,
      "learning_rate": 0.0005619992253846265,
      "loss": 4.7831,
      "step": 4157
    },
    {
      "epoch": 0.47678018575851394,
      "grad_norm": 0.0,
      "learning_rate": 0.0005618149753559222,
      "loss": 4.9098,
      "step": 4158
    },
    {
      "epoch": 0.4768948515078546,
      "grad_norm": 0.0,
      "learning_rate": 0.0005616307168079167,
      "loss": 5.1248,
      "step": 4159
    },
    {
      "epoch": 0.47700951725719526,
      "grad_norm": 0.0,
      "learning_rate": 0.0005614464497660249,
      "loss": 4.8001,
      "step": 4160
    },
    {
      "epoch": 0.477124183006536,
      "grad_norm": 0.0,
      "learning_rate": 0.0005612621742556634,
      "loss": 4.8471,
      "step": 4161
    },
    {
      "epoch": 0.47723884875587663,
      "grad_norm": 0.0,
      "learning_rate": 0.0005610778903022493,
      "loss": 4.9543,
      "step": 4162
    },
    {
      "epoch": 0.4773535145052173,
      "grad_norm": 0.0,
      "learning_rate": 0.0005608935979312011,
      "loss": 4.9806,
      "step": 4163
    },
    {
      "epoch": 0.47746818025455795,
      "grad_norm": 0.0,
      "learning_rate": 0.0005607092971679383,
      "loss": 4.9251,
      "step": 4164
    },
    {
      "epoch": 0.4775828460038986,
      "grad_norm": 0.0,
      "learning_rate": 0.0005605249880378816,
      "loss": 5.0371,
      "step": 4165
    },
    {
      "epoch": 0.4776975117532393,
      "grad_norm": 0.0,
      "learning_rate": 0.0005603406705664533,
      "loss": 4.9027,
      "step": 4166
    },
    {
      "epoch": 0.47781217750258,
      "grad_norm": 0.0,
      "learning_rate": 0.0005601563447790759,
      "loss": 5.3309,
      "step": 4167
    },
    {
      "epoch": 0.47792684325192064,
      "grad_norm": 0.0,
      "learning_rate": 0.000559972010701174,
      "loss": 5.0816,
      "step": 4168
    },
    {
      "epoch": 0.4780415090012613,
      "grad_norm": 0.0,
      "learning_rate": 0.0005597876683581732,
      "loss": 5.0921,
      "step": 4169
    },
    {
      "epoch": 0.478156174750602,
      "grad_norm": 0.0,
      "learning_rate": 0.0005596033177754997,
      "loss": 5.1245,
      "step": 4170
    },
    {
      "epoch": 0.4782708404999427,
      "grad_norm": 0.0,
      "learning_rate": 0.0005594189589785811,
      "loss": 5.1735,
      "step": 4171
    },
    {
      "epoch": 0.47838550624928333,
      "grad_norm": 0.0,
      "learning_rate": 0.0005592345919928463,
      "loss": 4.9863,
      "step": 4172
    },
    {
      "epoch": 0.478500171998624,
      "grad_norm": 0.0,
      "learning_rate": 0.0005590502168437251,
      "loss": 4.8506,
      "step": 4173
    },
    {
      "epoch": 0.4786148377479647,
      "grad_norm": 0.0,
      "learning_rate": 0.000558865833556649,
      "loss": 4.835,
      "step": 4174
    },
    {
      "epoch": 0.47872950349730536,
      "grad_norm": 0.0,
      "learning_rate": 0.0005586814421570495,
      "loss": 5.0382,
      "step": 4175
    },
    {
      "epoch": 0.478844169246646,
      "grad_norm": 0.0,
      "learning_rate": 0.0005584970426703603,
      "loss": 5.3435,
      "step": 4176
    },
    {
      "epoch": 0.4789588349959867,
      "grad_norm": 0.0,
      "learning_rate": 0.0005583126351220155,
      "loss": 5.0893,
      "step": 4177
    },
    {
      "epoch": 0.4790735007453274,
      "grad_norm": 0.0,
      "learning_rate": 0.0005581282195374508,
      "loss": 4.8925,
      "step": 4178
    },
    {
      "epoch": 0.47918816649466806,
      "grad_norm": 0.0,
      "learning_rate": 0.0005579437959421029,
      "loss": 5.0378,
      "step": 4179
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 0.0,
      "learning_rate": 0.0005577593643614093,
      "loss": 5.0958,
      "step": 4180
    },
    {
      "epoch": 0.4794174979933494,
      "grad_norm": 0.0,
      "learning_rate": 0.0005575749248208089,
      "loss": 5.246,
      "step": 4181
    },
    {
      "epoch": 0.47953216374269003,
      "grad_norm": 0.0,
      "learning_rate": 0.0005573904773457418,
      "loss": 4.9018,
      "step": 4182
    },
    {
      "epoch": 0.47964682949203075,
      "grad_norm": 0.0,
      "learning_rate": 0.0005572060219616487,
      "loss": 5.0961,
      "step": 4183
    },
    {
      "epoch": 0.4797614952413714,
      "grad_norm": 0.0,
      "learning_rate": 0.0005570215586939719,
      "loss": 5.0318,
      "step": 4184
    },
    {
      "epoch": 0.47987616099071206,
      "grad_norm": 0.0,
      "learning_rate": 0.0005568370875681548,
      "loss": 4.9306,
      "step": 4185
    },
    {
      "epoch": 0.4799908267400527,
      "grad_norm": 0.0,
      "learning_rate": 0.0005566526086096411,
      "loss": 5.0478,
      "step": 4186
    },
    {
      "epoch": 0.48010549248939344,
      "grad_norm": 0.0,
      "learning_rate": 0.0005564681218438767,
      "loss": 4.9919,
      "step": 4187
    },
    {
      "epoch": 0.4802201582387341,
      "grad_norm": 0.0,
      "learning_rate": 0.0005562836272963076,
      "loss": 4.8337,
      "step": 4188
    },
    {
      "epoch": 0.48033482398807475,
      "grad_norm": 0.0,
      "learning_rate": 0.0005560991249923817,
      "loss": 4.6803,
      "step": 4189
    },
    {
      "epoch": 0.4804494897374154,
      "grad_norm": 0.0,
      "learning_rate": 0.0005559146149575473,
      "loss": 5.11,
      "step": 4190
    },
    {
      "epoch": 0.48056415548675613,
      "grad_norm": 0.0,
      "learning_rate": 0.0005557300972172544,
      "loss": 5.1714,
      "step": 4191
    },
    {
      "epoch": 0.4806788212360968,
      "grad_norm": 0.0,
      "learning_rate": 0.0005555455717969531,
      "loss": 5.1839,
      "step": 4192
    },
    {
      "epoch": 0.48079348698543745,
      "grad_norm": 0.0,
      "learning_rate": 0.0005553610387220956,
      "loss": 5.1502,
      "step": 4193
    },
    {
      "epoch": 0.4809081527347781,
      "grad_norm": 0.0,
      "learning_rate": 0.0005551764980181348,
      "loss": 5.2787,
      "step": 4194
    },
    {
      "epoch": 0.4810228184841188,
      "grad_norm": 0.0,
      "learning_rate": 0.0005549919497105243,
      "loss": 4.9669,
      "step": 4195
    },
    {
      "epoch": 0.4811374842334595,
      "grad_norm": 0.0,
      "learning_rate": 0.0005548073938247191,
      "loss": 4.9063,
      "step": 4196
    },
    {
      "epoch": 0.48125214998280014,
      "grad_norm": 0.0,
      "learning_rate": 0.0005546228303861752,
      "loss": 5.085,
      "step": 4197
    },
    {
      "epoch": 0.4813668157321408,
      "grad_norm": 0.0,
      "learning_rate": 0.0005544382594203497,
      "loss": 5.0577,
      "step": 4198
    },
    {
      "epoch": 0.48148148148148145,
      "grad_norm": 0.0,
      "learning_rate": 0.0005542536809527004,
      "loss": 4.7987,
      "step": 4199
    },
    {
      "epoch": 0.48159614723082217,
      "grad_norm": 0.0,
      "learning_rate": 0.0005540690950086865,
      "loss": 4.7126,
      "step": 4200
    },
    {
      "epoch": 0.48171081298016283,
      "grad_norm": 0.0,
      "learning_rate": 0.0005538845016137682,
      "loss": 5.0178,
      "step": 4201
    },
    {
      "epoch": 0.4818254787295035,
      "grad_norm": 0.0,
      "learning_rate": 0.0005536999007934067,
      "loss": 4.9283,
      "step": 4202
    },
    {
      "epoch": 0.48194014447884415,
      "grad_norm": 0.0,
      "learning_rate": 0.000553515292573064,
      "loss": 5.1378,
      "step": 4203
    },
    {
      "epoch": 0.48205481022818486,
      "grad_norm": 0.0,
      "learning_rate": 0.0005533306769782033,
      "loss": 5.0157,
      "step": 4204
    },
    {
      "epoch": 0.4821694759775255,
      "grad_norm": 0.0,
      "learning_rate": 0.0005531460540342889,
      "loss": 4.9297,
      "step": 4205
    },
    {
      "epoch": 0.4822841417268662,
      "grad_norm": 0.0,
      "learning_rate": 0.0005529614237667858,
      "loss": 5.352,
      "step": 4206
    },
    {
      "epoch": 0.48239880747620684,
      "grad_norm": 0.0,
      "learning_rate": 0.0005527767862011605,
      "loss": 4.9971,
      "step": 4207
    },
    {
      "epoch": 0.48251347322554755,
      "grad_norm": 0.0,
      "learning_rate": 0.00055259214136288,
      "loss": 4.9743,
      "step": 4208
    },
    {
      "epoch": 0.4826281389748882,
      "grad_norm": 0.0,
      "learning_rate": 0.0005524074892774127,
      "loss": 5.0594,
      "step": 4209
    },
    {
      "epoch": 0.48274280472422887,
      "grad_norm": 0.0,
      "learning_rate": 0.0005522228299702277,
      "loss": 4.9029,
      "step": 4210
    },
    {
      "epoch": 0.48285747047356953,
      "grad_norm": 0.0,
      "learning_rate": 0.0005520381634667955,
      "loss": 5.0739,
      "step": 4211
    },
    {
      "epoch": 0.48297213622291024,
      "grad_norm": 0.0,
      "learning_rate": 0.000551853489792587,
      "loss": 5.0328,
      "step": 4212
    },
    {
      "epoch": 0.4830868019722509,
      "grad_norm": 0.0,
      "learning_rate": 0.0005516688089730746,
      "loss": 5.1496,
      "step": 4213
    },
    {
      "epoch": 0.48320146772159156,
      "grad_norm": 0.0,
      "learning_rate": 0.0005514841210337313,
      "loss": 4.8016,
      "step": 4214
    },
    {
      "epoch": 0.4833161334709322,
      "grad_norm": 0.0,
      "learning_rate": 0.0005512994260000317,
      "loss": 5.0034,
      "step": 4215
    },
    {
      "epoch": 0.4834307992202729,
      "grad_norm": 0.0,
      "learning_rate": 0.0005511147238974505,
      "loss": 4.9376,
      "step": 4216
    },
    {
      "epoch": 0.4835454649696136,
      "grad_norm": 0.0,
      "learning_rate": 0.000550930014751464,
      "loss": 5.1347,
      "step": 4217
    },
    {
      "epoch": 0.48366013071895425,
      "grad_norm": 0.0,
      "learning_rate": 0.0005507452985875494,
      "loss": 5.0797,
      "step": 4218
    },
    {
      "epoch": 0.4837747964682949,
      "grad_norm": 0.0,
      "learning_rate": 0.0005505605754311848,
      "loss": 4.9272,
      "step": 4219
    },
    {
      "epoch": 0.48388946221763557,
      "grad_norm": 0.0,
      "learning_rate": 0.0005503758453078489,
      "loss": 5.0655,
      "step": 4220
    },
    {
      "epoch": 0.4840041279669763,
      "grad_norm": 0.0,
      "learning_rate": 0.000550191108243022,
      "loss": 4.8813,
      "step": 4221
    },
    {
      "epoch": 0.48411879371631694,
      "grad_norm": 0.0,
      "learning_rate": 0.0005500063642621851,
      "loss": 5.335,
      "step": 4222
    },
    {
      "epoch": 0.4842334594656576,
      "grad_norm": 0.0,
      "learning_rate": 0.0005498216133908198,
      "loss": 4.9828,
      "step": 4223
    },
    {
      "epoch": 0.48434812521499826,
      "grad_norm": 0.0,
      "learning_rate": 0.0005496368556544095,
      "loss": 5.1014,
      "step": 4224
    },
    {
      "epoch": 0.484462790964339,
      "grad_norm": 0.0,
      "learning_rate": 0.0005494520910784375,
      "loss": 4.5625,
      "step": 4225
    },
    {
      "epoch": 0.48457745671367963,
      "grad_norm": 0.0,
      "learning_rate": 0.0005492673196883887,
      "loss": 4.9412,
      "step": 4226
    },
    {
      "epoch": 0.4846921224630203,
      "grad_norm": 0.0,
      "learning_rate": 0.0005490825415097488,
      "loss": 5.0412,
      "step": 4227
    },
    {
      "epoch": 0.48480678821236095,
      "grad_norm": 0.0,
      "learning_rate": 0.0005488977565680045,
      "loss": 5.2108,
      "step": 4228
    },
    {
      "epoch": 0.48492145396170167,
      "grad_norm": 0.0,
      "learning_rate": 0.0005487129648886434,
      "loss": 5.0643,
      "step": 4229
    },
    {
      "epoch": 0.4850361197110423,
      "grad_norm": 0.0,
      "learning_rate": 0.0005485281664971538,
      "loss": 5.0481,
      "step": 4230
    },
    {
      "epoch": 0.485150785460383,
      "grad_norm": 0.0,
      "learning_rate": 0.000548343361419025,
      "loss": 5.233,
      "step": 4231
    },
    {
      "epoch": 0.48526545120972364,
      "grad_norm": 0.0,
      "learning_rate": 0.0005481585496797478,
      "loss": 5.1096,
      "step": 4232
    },
    {
      "epoch": 0.4853801169590643,
      "grad_norm": 0.0,
      "learning_rate": 0.0005479737313048131,
      "loss": 5.1591,
      "step": 4233
    },
    {
      "epoch": 0.485494782708405,
      "grad_norm": 0.0,
      "learning_rate": 0.0005477889063197131,
      "loss": 4.8975,
      "step": 4234
    },
    {
      "epoch": 0.4856094484577457,
      "grad_norm": 0.0,
      "learning_rate": 0.0005476040747499413,
      "loss": 5.0658,
      "step": 4235
    },
    {
      "epoch": 0.48572411420708633,
      "grad_norm": 0.0,
      "learning_rate": 0.0005474192366209911,
      "loss": 5.1682,
      "step": 4236
    },
    {
      "epoch": 0.485838779956427,
      "grad_norm": 0.0,
      "learning_rate": 0.0005472343919583575,
      "loss": 5.0288,
      "step": 4237
    },
    {
      "epoch": 0.4859534457057677,
      "grad_norm": 0.0,
      "learning_rate": 0.0005470495407875368,
      "loss": 4.8325,
      "step": 4238
    },
    {
      "epoch": 0.48606811145510836,
      "grad_norm": 0.0,
      "learning_rate": 0.000546864683134025,
      "loss": 5.1264,
      "step": 4239
    },
    {
      "epoch": 0.486182777204449,
      "grad_norm": 0.0,
      "learning_rate": 0.0005466798190233203,
      "loss": 4.8958,
      "step": 4240
    },
    {
      "epoch": 0.4862974429537897,
      "grad_norm": 0.0,
      "learning_rate": 0.0005464949484809208,
      "loss": 5.0855,
      "step": 4241
    },
    {
      "epoch": 0.4864121087031304,
      "grad_norm": 0.0,
      "learning_rate": 0.0005463100715323259,
      "loss": 4.9178,
      "step": 4242
    },
    {
      "epoch": 0.48652677445247106,
      "grad_norm": 0.0,
      "learning_rate": 0.000546125188203036,
      "loss": 5.1598,
      "step": 4243
    },
    {
      "epoch": 0.4866414402018117,
      "grad_norm": 0.0,
      "learning_rate": 0.0005459402985185521,
      "loss": 5.2642,
      "step": 4244
    },
    {
      "epoch": 0.4867561059511524,
      "grad_norm": 0.0,
      "learning_rate": 0.0005457554025043765,
      "loss": 4.8713,
      "step": 4245
    },
    {
      "epoch": 0.4868707717004931,
      "grad_norm": 0.0,
      "learning_rate": 0.0005455705001860117,
      "loss": 5.0205,
      "step": 4246
    },
    {
      "epoch": 0.48698543744983375,
      "grad_norm": 0.0,
      "learning_rate": 0.0005453855915889616,
      "loss": 5.0368,
      "step": 4247
    },
    {
      "epoch": 0.4871001031991744,
      "grad_norm": 0.0,
      "learning_rate": 0.0005452006767387308,
      "loss": 4.9674,
      "step": 4248
    },
    {
      "epoch": 0.48721476894851506,
      "grad_norm": 0.0,
      "learning_rate": 0.0005450157556608248,
      "loss": 4.8516,
      "step": 4249
    },
    {
      "epoch": 0.4873294346978557,
      "grad_norm": 0.0,
      "learning_rate": 0.0005448308283807498,
      "loss": 5.0078,
      "step": 4250
    },
    {
      "epoch": 0.48744410044719644,
      "grad_norm": 0.0,
      "learning_rate": 0.0005446458949240134,
      "loss": 5.2053,
      "step": 4251
    },
    {
      "epoch": 0.4875587661965371,
      "grad_norm": 0.0,
      "learning_rate": 0.0005444609553161232,
      "loss": 4.8933,
      "step": 4252
    },
    {
      "epoch": 0.48767343194587776,
      "grad_norm": 0.0,
      "learning_rate": 0.0005442760095825883,
      "loss": 5.0375,
      "step": 4253
    },
    {
      "epoch": 0.4877880976952184,
      "grad_norm": 0.0,
      "learning_rate": 0.0005440910577489183,
      "loss": 5.3279,
      "step": 4254
    },
    {
      "epoch": 0.48790276344455913,
      "grad_norm": 0.0,
      "learning_rate": 0.0005439060998406241,
      "loss": 4.8621,
      "step": 4255
    },
    {
      "epoch": 0.4880174291938998,
      "grad_norm": 0.0,
      "learning_rate": 0.0005437211358832166,
      "loss": 4.894,
      "step": 4256
    },
    {
      "epoch": 0.48813209494324045,
      "grad_norm": 0.0,
      "learning_rate": 0.0005435361659022087,
      "loss": 5.0692,
      "step": 4257
    },
    {
      "epoch": 0.4882467606925811,
      "grad_norm": 0.0,
      "learning_rate": 0.0005433511899231129,
      "loss": 5.0326,
      "step": 4258
    },
    {
      "epoch": 0.4883614264419218,
      "grad_norm": 0.0,
      "learning_rate": 0.0005431662079714433,
      "loss": 5.1077,
      "step": 4259
    },
    {
      "epoch": 0.4884760921912625,
      "grad_norm": 0.0,
      "learning_rate": 0.0005429812200727148,
      "loss": 5.0681,
      "step": 4260
    },
    {
      "epoch": 0.48859075794060314,
      "grad_norm": 0.0,
      "learning_rate": 0.0005427962262524429,
      "loss": 4.9767,
      "step": 4261
    },
    {
      "epoch": 0.4887054236899438,
      "grad_norm": 0.0,
      "learning_rate": 0.0005426112265361438,
      "loss": 5.0838,
      "step": 4262
    },
    {
      "epoch": 0.4888200894392845,
      "grad_norm": 0.0,
      "learning_rate": 0.0005424262209493348,
      "loss": 4.9956,
      "step": 4263
    },
    {
      "epoch": 0.48893475518862517,
      "grad_norm": 0.0,
      "learning_rate": 0.0005422412095175339,
      "loss": 4.9762,
      "step": 4264
    },
    {
      "epoch": 0.48904942093796583,
      "grad_norm": 0.0,
      "learning_rate": 0.00054205619226626,
      "loss": 5.0074,
      "step": 4265
    },
    {
      "epoch": 0.4891640866873065,
      "grad_norm": 0.0,
      "learning_rate": 0.0005418711692210323,
      "loss": 5.0451,
      "step": 4266
    },
    {
      "epoch": 0.48927875243664715,
      "grad_norm": 0.0,
      "learning_rate": 0.0005416861404073717,
      "loss": 5.1586,
      "step": 4267
    },
    {
      "epoch": 0.48939341818598786,
      "grad_norm": 0.0,
      "learning_rate": 0.0005415011058507993,
      "loss": 4.8771,
      "step": 4268
    },
    {
      "epoch": 0.4895080839353285,
      "grad_norm": 0.0,
      "learning_rate": 0.0005413160655768367,
      "loss": 5.0888,
      "step": 4269
    },
    {
      "epoch": 0.4896227496846692,
      "grad_norm": 0.0,
      "learning_rate": 0.0005411310196110071,
      "loss": 4.7238,
      "step": 4270
    },
    {
      "epoch": 0.48973741543400984,
      "grad_norm": 0.0,
      "learning_rate": 0.0005409459679788338,
      "loss": 4.9196,
      "step": 4271
    },
    {
      "epoch": 0.48985208118335055,
      "grad_norm": 0.0,
      "learning_rate": 0.0005407609107058413,
      "loss": 5.0183,
      "step": 4272
    },
    {
      "epoch": 0.4899667469326912,
      "grad_norm": 0.0,
      "learning_rate": 0.0005405758478175549,
      "loss": 4.997,
      "step": 4273
    },
    {
      "epoch": 0.49008141268203187,
      "grad_norm": 0.0,
      "learning_rate": 0.0005403907793395002,
      "loss": 5.052,
      "step": 4274
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.0,
      "learning_rate": 0.0005402057052972038,
      "loss": 5.2615,
      "step": 4275
    },
    {
      "epoch": 0.49031074418071324,
      "grad_norm": 0.0,
      "learning_rate": 0.0005400206257161935,
      "loss": 4.7943,
      "step": 4276
    },
    {
      "epoch": 0.4904254099300539,
      "grad_norm": 0.0,
      "learning_rate": 0.0005398355406219972,
      "loss": 4.9065,
      "step": 4277
    },
    {
      "epoch": 0.49054007567939456,
      "grad_norm": 0.0,
      "learning_rate": 0.000539650450040144,
      "loss": 4.7704,
      "step": 4278
    },
    {
      "epoch": 0.4906547414287352,
      "grad_norm": 0.0,
      "learning_rate": 0.0005394653539961635,
      "loss": 4.9804,
      "step": 4279
    },
    {
      "epoch": 0.49076940717807593,
      "grad_norm": 0.0,
      "learning_rate": 0.0005392802525155861,
      "loss": 4.964,
      "step": 4280
    },
    {
      "epoch": 0.4908840729274166,
      "grad_norm": 0.0,
      "learning_rate": 0.0005390951456239433,
      "loss": 5.0146,
      "step": 4281
    },
    {
      "epoch": 0.49099873867675725,
      "grad_norm": 0.0,
      "learning_rate": 0.000538910033346767,
      "loss": 4.9594,
      "step": 4282
    },
    {
      "epoch": 0.4911134044260979,
      "grad_norm": 0.0,
      "learning_rate": 0.0005387249157095897,
      "loss": 4.9616,
      "step": 4283
    },
    {
      "epoch": 0.49122807017543857,
      "grad_norm": 0.0,
      "learning_rate": 0.0005385397927379452,
      "loss": 5.0781,
      "step": 4284
    },
    {
      "epoch": 0.4913427359247793,
      "grad_norm": 0.0,
      "learning_rate": 0.0005383546644573673,
      "loss": 4.9258,
      "step": 4285
    },
    {
      "epoch": 0.49145740167411994,
      "grad_norm": 0.0,
      "learning_rate": 0.0005381695308933911,
      "loss": 5.0368,
      "step": 4286
    },
    {
      "epoch": 0.4915720674234606,
      "grad_norm": 0.0,
      "learning_rate": 0.0005379843920715522,
      "loss": 4.7048,
      "step": 4287
    },
    {
      "epoch": 0.49168673317280126,
      "grad_norm": 0.0,
      "learning_rate": 0.0005377992480173872,
      "loss": 4.9367,
      "step": 4288
    },
    {
      "epoch": 0.491801398922142,
      "grad_norm": 0.0,
      "learning_rate": 0.0005376140987564329,
      "loss": 5.3004,
      "step": 4289
    },
    {
      "epoch": 0.49191606467148263,
      "grad_norm": 0.0,
      "learning_rate": 0.0005374289443142271,
      "loss": 4.803,
      "step": 4290
    },
    {
      "epoch": 0.4920307304208233,
      "grad_norm": 0.0,
      "learning_rate": 0.0005372437847163086,
      "loss": 4.953,
      "step": 4291
    },
    {
      "epoch": 0.49214539617016395,
      "grad_norm": 0.0,
      "learning_rate": 0.0005370586199882163,
      "loss": 5.1284,
      "step": 4292
    },
    {
      "epoch": 0.49226006191950467,
      "grad_norm": 0.0,
      "learning_rate": 0.0005368734501554905,
      "loss": 5.0204,
      "step": 4293
    },
    {
      "epoch": 0.4923747276688453,
      "grad_norm": 0.0,
      "learning_rate": 0.0005366882752436716,
      "loss": 4.8715,
      "step": 4294
    },
    {
      "epoch": 0.492489393418186,
      "grad_norm": 0.0,
      "learning_rate": 0.000536503095278301,
      "loss": 4.791,
      "step": 4295
    },
    {
      "epoch": 0.49260405916752664,
      "grad_norm": 0.0,
      "learning_rate": 0.0005363179102849208,
      "loss": 4.9542,
      "step": 4296
    },
    {
      "epoch": 0.49271872491686736,
      "grad_norm": 0.0,
      "learning_rate": 0.0005361327202890738,
      "loss": 4.7824,
      "step": 4297
    },
    {
      "epoch": 0.492833390666208,
      "grad_norm": 0.0,
      "learning_rate": 0.0005359475253163031,
      "loss": 4.9957,
      "step": 4298
    },
    {
      "epoch": 0.4929480564155487,
      "grad_norm": 0.0,
      "learning_rate": 0.0005357623253921532,
      "loss": 4.7522,
      "step": 4299
    },
    {
      "epoch": 0.49306272216488933,
      "grad_norm": 0.0,
      "learning_rate": 0.0005355771205421687,
      "loss": 5.1183,
      "step": 4300
    },
    {
      "epoch": 0.49317738791423,
      "grad_norm": 0.0,
      "learning_rate": 0.0005353919107918953,
      "loss": 4.9472,
      "step": 4301
    },
    {
      "epoch": 0.4932920536635707,
      "grad_norm": 0.0,
      "learning_rate": 0.0005352066961668788,
      "loss": 4.8417,
      "step": 4302
    },
    {
      "epoch": 0.49340671941291137,
      "grad_norm": 0.0,
      "learning_rate": 0.0005350214766926662,
      "loss": 5.0671,
      "step": 4303
    },
    {
      "epoch": 0.493521385162252,
      "grad_norm": 0.0,
      "learning_rate": 0.000534836252394805,
      "loss": 4.904,
      "step": 4304
    },
    {
      "epoch": 0.4936360509115927,
      "grad_norm": 0.0,
      "learning_rate": 0.0005346510232988435,
      "loss": 4.5932,
      "step": 4305
    },
    {
      "epoch": 0.4937507166609334,
      "grad_norm": 0.0,
      "learning_rate": 0.0005344657894303304,
      "loss": 4.8032,
      "step": 4306
    },
    {
      "epoch": 0.49386538241027406,
      "grad_norm": 0.0,
      "learning_rate": 0.0005342805508148151,
      "loss": 5.025,
      "step": 4307
    },
    {
      "epoch": 0.4939800481596147,
      "grad_norm": 0.0,
      "learning_rate": 0.0005340953074778477,
      "loss": 5.0248,
      "step": 4308
    },
    {
      "epoch": 0.4940947139089554,
      "grad_norm": 0.0,
      "learning_rate": 0.0005339100594449793,
      "loss": 4.9522,
      "step": 4309
    },
    {
      "epoch": 0.4942093796582961,
      "grad_norm": 0.0,
      "learning_rate": 0.0005337248067417609,
      "loss": 4.9469,
      "step": 4310
    },
    {
      "epoch": 0.49432404540763675,
      "grad_norm": 0.0,
      "learning_rate": 0.000533539549393745,
      "loss": 5.159,
      "step": 4311
    },
    {
      "epoch": 0.4944387111569774,
      "grad_norm": 0.0,
      "learning_rate": 0.0005333542874264842,
      "loss": 4.8281,
      "step": 4312
    },
    {
      "epoch": 0.49455337690631807,
      "grad_norm": 0.0,
      "learning_rate": 0.0005331690208655315,
      "loss": 5.0934,
      "step": 4313
    },
    {
      "epoch": 0.4946680426556588,
      "grad_norm": 0.0,
      "learning_rate": 0.0005329837497364413,
      "loss": 5.2006,
      "step": 4314
    },
    {
      "epoch": 0.49478270840499944,
      "grad_norm": 0.0,
      "learning_rate": 0.0005327984740647683,
      "loss": 5.0299,
      "step": 4315
    },
    {
      "epoch": 0.4948973741543401,
      "grad_norm": 0.0,
      "learning_rate": 0.0005326131938760674,
      "loss": 5.0889,
      "step": 4316
    },
    {
      "epoch": 0.49501203990368076,
      "grad_norm": 0.0,
      "learning_rate": 0.0005324279091958947,
      "loss": 4.875,
      "step": 4317
    },
    {
      "epoch": 0.4951267056530214,
      "grad_norm": 0.0,
      "learning_rate": 0.0005322426200498062,
      "loss": 4.8511,
      "step": 4318
    },
    {
      "epoch": 0.49524137140236213,
      "grad_norm": 0.0,
      "learning_rate": 0.0005320573264633598,
      "loss": 4.8289,
      "step": 4319
    },
    {
      "epoch": 0.4953560371517028,
      "grad_norm": 0.0,
      "learning_rate": 0.0005318720284621128,
      "loss": 5.1753,
      "step": 4320
    },
    {
      "epoch": 0.49547070290104345,
      "grad_norm": 0.0,
      "learning_rate": 0.0005316867260716235,
      "loss": 5.0529,
      "step": 4321
    },
    {
      "epoch": 0.4955853686503841,
      "grad_norm": 0.0,
      "learning_rate": 0.0005315014193174507,
      "loss": 4.9651,
      "step": 4322
    },
    {
      "epoch": 0.4957000343997248,
      "grad_norm": 0.0,
      "learning_rate": 0.0005313161082251544,
      "loss": 5.4099,
      "step": 4323
    },
    {
      "epoch": 0.4958147001490655,
      "grad_norm": 0.0,
      "learning_rate": 0.0005311307928202944,
      "loss": 4.9533,
      "step": 4324
    },
    {
      "epoch": 0.49592936589840614,
      "grad_norm": 0.0,
      "learning_rate": 0.0005309454731284314,
      "loss": 5.1787,
      "step": 4325
    },
    {
      "epoch": 0.4960440316477468,
      "grad_norm": 0.0,
      "learning_rate": 0.0005307601491751268,
      "loss": 4.8321,
      "step": 4326
    },
    {
      "epoch": 0.4961586973970875,
      "grad_norm": 0.0,
      "learning_rate": 0.0005305748209859427,
      "loss": 4.7966,
      "step": 4327
    },
    {
      "epoch": 0.49627336314642817,
      "grad_norm": 0.0,
      "learning_rate": 0.0005303894885864413,
      "loss": 5.0722,
      "step": 4328
    },
    {
      "epoch": 0.49638802889576883,
      "grad_norm": 0.0,
      "learning_rate": 0.0005302041520021857,
      "loss": 4.9495,
      "step": 4329
    },
    {
      "epoch": 0.4965026946451095,
      "grad_norm": 0.0,
      "learning_rate": 0.0005300188112587397,
      "loss": 5.1043,
      "step": 4330
    },
    {
      "epoch": 0.4966173603944502,
      "grad_norm": 0.0,
      "learning_rate": 0.0005298334663816674,
      "loss": 4.7659,
      "step": 4331
    },
    {
      "epoch": 0.49673202614379086,
      "grad_norm": 0.0,
      "learning_rate": 0.0005296481173965335,
      "loss": 5.1233,
      "step": 4332
    },
    {
      "epoch": 0.4968466918931315,
      "grad_norm": 0.0,
      "learning_rate": 0.0005294627643289036,
      "loss": 5.2023,
      "step": 4333
    },
    {
      "epoch": 0.4969613576424722,
      "grad_norm": 0.0,
      "learning_rate": 0.0005292774072043437,
      "loss": 5.118,
      "step": 4334
    },
    {
      "epoch": 0.49707602339181284,
      "grad_norm": 0.0,
      "learning_rate": 0.00052909204604842,
      "loss": 5.1475,
      "step": 4335
    },
    {
      "epoch": 0.49719068914115355,
      "grad_norm": 0.0,
      "learning_rate": 0.0005289066808866996,
      "loss": 4.8232,
      "step": 4336
    },
    {
      "epoch": 0.4973053548904942,
      "grad_norm": 0.0,
      "learning_rate": 0.0005287213117447501,
      "loss": 5.2476,
      "step": 4337
    },
    {
      "epoch": 0.49742002063983487,
      "grad_norm": 0.0,
      "learning_rate": 0.0005285359386481398,
      "loss": 4.9862,
      "step": 4338
    },
    {
      "epoch": 0.49753468638917553,
      "grad_norm": 0.0,
      "learning_rate": 0.0005283505616224373,
      "loss": 4.9558,
      "step": 4339
    },
    {
      "epoch": 0.49764935213851624,
      "grad_norm": 0.0,
      "learning_rate": 0.0005281651806932115,
      "loss": 4.9184,
      "step": 4340
    },
    {
      "epoch": 0.4977640178878569,
      "grad_norm": 0.0,
      "learning_rate": 0.0005279797958860325,
      "loss": 4.8974,
      "step": 4341
    },
    {
      "epoch": 0.49787868363719756,
      "grad_norm": 0.0,
      "learning_rate": 0.0005277944072264707,
      "loss": 5.0806,
      "step": 4342
    },
    {
      "epoch": 0.4979933493865382,
      "grad_norm": 0.0,
      "learning_rate": 0.0005276090147400966,
      "loss": 5.0576,
      "step": 4343
    },
    {
      "epoch": 0.49810801513587893,
      "grad_norm": 0.0,
      "learning_rate": 0.0005274236184524819,
      "loss": 5.1689,
      "step": 4344
    },
    {
      "epoch": 0.4982226808852196,
      "grad_norm": 0.0,
      "learning_rate": 0.0005272382183891983,
      "loss": 4.853,
      "step": 4345
    },
    {
      "epoch": 0.49833734663456025,
      "grad_norm": 0.0,
      "learning_rate": 0.0005270528145758181,
      "loss": 5.0392,
      "step": 4346
    },
    {
      "epoch": 0.4984520123839009,
      "grad_norm": 0.0,
      "learning_rate": 0.0005268674070379145,
      "loss": 5.0305,
      "step": 4347
    },
    {
      "epoch": 0.4985666781332416,
      "grad_norm": 0.0,
      "learning_rate": 0.0005266819958010608,
      "loss": 4.8949,
      "step": 4348
    },
    {
      "epoch": 0.4986813438825823,
      "grad_norm": 0.0,
      "learning_rate": 0.0005264965808908308,
      "loss": 4.943,
      "step": 4349
    },
    {
      "epoch": 0.49879600963192294,
      "grad_norm": 0.0,
      "learning_rate": 0.0005263111623327992,
      "loss": 4.9818,
      "step": 4350
    },
    {
      "epoch": 0.4989106753812636,
      "grad_norm": 0.0,
      "learning_rate": 0.0005261257401525408,
      "loss": 5.1051,
      "step": 4351
    },
    {
      "epoch": 0.49902534113060426,
      "grad_norm": 0.0,
      "learning_rate": 0.000525940314375631,
      "loss": 5.1277,
      "step": 4352
    },
    {
      "epoch": 0.499140006879945,
      "grad_norm": 0.0,
      "learning_rate": 0.0005257548850276459,
      "loss": 5.1159,
      "step": 4353
    },
    {
      "epoch": 0.49925467262928563,
      "grad_norm": 0.0,
      "learning_rate": 0.000525569452134162,
      "loss": 4.8945,
      "step": 4354
    },
    {
      "epoch": 0.4993693383786263,
      "grad_norm": 0.0,
      "learning_rate": 0.000525384015720756,
      "loss": 4.9844,
      "step": 4355
    },
    {
      "epoch": 0.49948400412796695,
      "grad_norm": 0.0,
      "learning_rate": 0.0005251985758130054,
      "loss": 5.1273,
      "step": 4356
    },
    {
      "epoch": 0.49959866987730767,
      "grad_norm": 0.0,
      "learning_rate": 0.0005250131324364884,
      "loss": 4.9393,
      "step": 4357
    },
    {
      "epoch": 0.4997133356266483,
      "grad_norm": 0.0,
      "learning_rate": 0.0005248276856167829,
      "loss": 5.0253,
      "step": 4358
    },
    {
      "epoch": 0.499828001375989,
      "grad_norm": 0.0,
      "learning_rate": 0.0005246422353794681,
      "loss": 5.1386,
      "step": 4359
    },
    {
      "epoch": 0.49994266712532964,
      "grad_norm": 0.0,
      "learning_rate": 0.000524456781750123,
      "loss": 4.9661,
      "step": 4360
    },
    {
      "epoch": 0.5000573328746704,
      "grad_norm": 0.0,
      "learning_rate": 0.0005242713247543278,
      "loss": 5.0209,
      "step": 4361
    },
    {
      "epoch": 0.500171998624011,
      "grad_norm": 0.0,
      "learning_rate": 0.0005240858644176623,
      "loss": 4.8902,
      "step": 4362
    },
    {
      "epoch": 0.5002866643733517,
      "grad_norm": 0.0,
      "learning_rate": 0.0005239004007657077,
      "loss": 5.1889,
      "step": 4363
    },
    {
      "epoch": 0.5004013301226924,
      "grad_norm": 0.0,
      "learning_rate": 0.0005237149338240449,
      "loss": 5.0753,
      "step": 4364
    },
    {
      "epoch": 0.500515995872033,
      "grad_norm": 0.0,
      "learning_rate": 0.0005235294636182554,
      "loss": 4.8351,
      "step": 4365
    },
    {
      "epoch": 0.5006306616213737,
      "grad_norm": 0.0,
      "learning_rate": 0.0005233439901739218,
      "loss": 5.0312,
      "step": 4366
    },
    {
      "epoch": 0.5007453273707144,
      "grad_norm": 0.0,
      "learning_rate": 0.0005231585135166262,
      "loss": 4.9601,
      "step": 4367
    },
    {
      "epoch": 0.500859993120055,
      "grad_norm": 0.0,
      "learning_rate": 0.0005229730336719514,
      "loss": 5.0194,
      "step": 4368
    },
    {
      "epoch": 0.5009746588693957,
      "grad_norm": 0.0,
      "learning_rate": 0.0005227875506654812,
      "loss": 4.9238,
      "step": 4369
    },
    {
      "epoch": 0.5010893246187363,
      "grad_norm": 0.0,
      "learning_rate": 0.0005226020645227994,
      "loss": 4.854,
      "step": 4370
    },
    {
      "epoch": 0.5012039903680771,
      "grad_norm": 0.0,
      "learning_rate": 0.0005224165752694901,
      "loss": 4.9195,
      "step": 4371
    },
    {
      "epoch": 0.5013186561174178,
      "grad_norm": 0.0,
      "learning_rate": 0.0005222310829311379,
      "loss": 4.7782,
      "step": 4372
    },
    {
      "epoch": 0.5014333218667584,
      "grad_norm": 0.0,
      "learning_rate": 0.0005220455875333285,
      "loss": 5.1145,
      "step": 4373
    },
    {
      "epoch": 0.5015479876160991,
      "grad_norm": 0.0,
      "learning_rate": 0.0005218600891016467,
      "loss": 4.982,
      "step": 4374
    },
    {
      "epoch": 0.5016626533654397,
      "grad_norm": 0.0,
      "learning_rate": 0.0005216745876616788,
      "loss": 5.0152,
      "step": 4375
    },
    {
      "epoch": 0.5017773191147804,
      "grad_norm": 0.0,
      "learning_rate": 0.0005214890832390116,
      "loss": 5.1143,
      "step": 4376
    },
    {
      "epoch": 0.5018919848641211,
      "grad_norm": 0.0,
      "learning_rate": 0.0005213035758592315,
      "loss": 5.4454,
      "step": 4377
    },
    {
      "epoch": 0.5020066506134617,
      "grad_norm": 0.0,
      "learning_rate": 0.0005211180655479256,
      "loss": 4.9426,
      "step": 4378
    },
    {
      "epoch": 0.5021213163628024,
      "grad_norm": 0.0,
      "learning_rate": 0.0005209325523306817,
      "loss": 5.1229,
      "step": 4379
    },
    {
      "epoch": 0.5022359821121432,
      "grad_norm": 0.0,
      "learning_rate": 0.0005207470362330876,
      "loss": 5.0415,
      "step": 4380
    },
    {
      "epoch": 0.5023506478614838,
      "grad_norm": 0.0,
      "learning_rate": 0.000520561517280732,
      "loss": 5.0237,
      "step": 4381
    },
    {
      "epoch": 0.5024653136108245,
      "grad_norm": 0.0,
      "learning_rate": 0.0005203759954992036,
      "loss": 5.0115,
      "step": 4382
    },
    {
      "epoch": 0.5025799793601651,
      "grad_norm": 0.0,
      "learning_rate": 0.0005201904709140916,
      "loss": 5.1363,
      "step": 4383
    },
    {
      "epoch": 0.5026946451095058,
      "grad_norm": 0.0,
      "learning_rate": 0.0005200049435509855,
      "loss": 5.2682,
      "step": 4384
    },
    {
      "epoch": 0.5028093108588465,
      "grad_norm": 0.0,
      "learning_rate": 0.0005198194134354752,
      "loss": 5.0972,
      "step": 4385
    },
    {
      "epoch": 0.5029239766081871,
      "grad_norm": 0.0,
      "learning_rate": 0.0005196338805931512,
      "loss": 5.282,
      "step": 4386
    },
    {
      "epoch": 0.5030386423575278,
      "grad_norm": 0.0,
      "learning_rate": 0.0005194483450496043,
      "loss": 5.0124,
      "step": 4387
    },
    {
      "epoch": 0.5031533081068684,
      "grad_norm": 0.0,
      "learning_rate": 0.0005192628068304254,
      "loss": 4.752,
      "step": 4388
    },
    {
      "epoch": 0.5032679738562091,
      "grad_norm": 0.0,
      "learning_rate": 0.0005190772659612062,
      "loss": 5.2829,
      "step": 4389
    },
    {
      "epoch": 0.5033826396055499,
      "grad_norm": 0.0,
      "learning_rate": 0.0005188917224675381,
      "loss": 5.1816,
      "step": 4390
    },
    {
      "epoch": 0.5034973053548905,
      "grad_norm": 0.0,
      "learning_rate": 0.0005187061763750136,
      "loss": 4.9594,
      "step": 4391
    },
    {
      "epoch": 0.5036119711042312,
      "grad_norm": 0.0,
      "learning_rate": 0.0005185206277092253,
      "loss": 5.0496,
      "step": 4392
    },
    {
      "epoch": 0.5037266368535719,
      "grad_norm": 0.0,
      "learning_rate": 0.0005183350764957658,
      "loss": 4.9795,
      "step": 4393
    },
    {
      "epoch": 0.5038413026029125,
      "grad_norm": 0.0,
      "learning_rate": 0.0005181495227602286,
      "loss": 4.9073,
      "step": 4394
    },
    {
      "epoch": 0.5039559683522532,
      "grad_norm": 0.0,
      "learning_rate": 0.0005179639665282074,
      "loss": 4.8678,
      "step": 4395
    },
    {
      "epoch": 0.5040706341015938,
      "grad_norm": 0.0,
      "learning_rate": 0.0005177784078252959,
      "loss": 4.8543,
      "step": 4396
    },
    {
      "epoch": 0.5041852998509345,
      "grad_norm": 0.0,
      "learning_rate": 0.0005175928466770882,
      "loss": 4.9989,
      "step": 4397
    },
    {
      "epoch": 0.5042999656002752,
      "grad_norm": 0.0,
      "learning_rate": 0.0005174072831091798,
      "loss": 5.2482,
      "step": 4398
    },
    {
      "epoch": 0.5044146313496158,
      "grad_norm": 0.0,
      "learning_rate": 0.0005172217171471645,
      "loss": 4.7355,
      "step": 4399
    },
    {
      "epoch": 0.5045292970989566,
      "grad_norm": 0.0,
      "learning_rate": 0.0005170361488166385,
      "loss": 4.976,
      "step": 4400
    },
    {
      "epoch": 0.5046439628482973,
      "grad_norm": 0.0,
      "learning_rate": 0.000516850578143197,
      "loss": 4.868,
      "step": 4401
    },
    {
      "epoch": 0.5047586285976379,
      "grad_norm": 0.0,
      "learning_rate": 0.0005166650051524358,
      "loss": 5.3007,
      "step": 4402
    },
    {
      "epoch": 0.5048732943469786,
      "grad_norm": 0.0,
      "learning_rate": 0.0005164794298699513,
      "loss": 5.0109,
      "step": 4403
    },
    {
      "epoch": 0.5049879600963192,
      "grad_norm": 0.0,
      "learning_rate": 0.0005162938523213403,
      "loss": 5.0865,
      "step": 4404
    },
    {
      "epoch": 0.5051026258456599,
      "grad_norm": 0.0,
      "learning_rate": 0.0005161082725321995,
      "loss": 5.1435,
      "step": 4405
    },
    {
      "epoch": 0.5052172915950006,
      "grad_norm": 0.0,
      "learning_rate": 0.0005159226905281261,
      "loss": 4.6481,
      "step": 4406
    },
    {
      "epoch": 0.5053319573443412,
      "grad_norm": 0.0,
      "learning_rate": 0.0005157371063347176,
      "loss": 4.7197,
      "step": 4407
    },
    {
      "epoch": 0.5054466230936819,
      "grad_norm": 0.0,
      "learning_rate": 0.0005155515199775719,
      "loss": 5.0783,
      "step": 4408
    },
    {
      "epoch": 0.5055612888430225,
      "grad_norm": 0.0,
      "learning_rate": 0.0005153659314822869,
      "loss": 4.8754,
      "step": 4409
    },
    {
      "epoch": 0.5056759545923633,
      "grad_norm": 0.0,
      "learning_rate": 0.000515180340874461,
      "loss": 5.2295,
      "step": 4410
    },
    {
      "epoch": 0.505790620341704,
      "grad_norm": 0.0,
      "learning_rate": 0.0005149947481796931,
      "loss": 4.9728,
      "step": 4411
    },
    {
      "epoch": 0.5059052860910446,
      "grad_norm": 0.0,
      "learning_rate": 0.0005148091534235821,
      "loss": 4.9761,
      "step": 4412
    },
    {
      "epoch": 0.5060199518403853,
      "grad_norm": 0.0,
      "learning_rate": 0.0005146235566317271,
      "loss": 4.8029,
      "step": 4413
    },
    {
      "epoch": 0.506134617589726,
      "grad_norm": 0.0,
      "learning_rate": 0.0005144379578297278,
      "loss": 5.0945,
      "step": 4414
    },
    {
      "epoch": 0.5062492833390666,
      "grad_norm": 0.0,
      "learning_rate": 0.000514252357043184,
      "loss": 4.9315,
      "step": 4415
    },
    {
      "epoch": 0.5063639490884073,
      "grad_norm": 0.0,
      "learning_rate": 0.0005140667542976958,
      "loss": 4.8929,
      "step": 4416
    },
    {
      "epoch": 0.5064786148377479,
      "grad_norm": 0.0,
      "learning_rate": 0.0005138811496188634,
      "loss": 5.1343,
      "step": 4417
    },
    {
      "epoch": 0.5065932805870886,
      "grad_norm": 0.0,
      "learning_rate": 0.0005136955430322879,
      "loss": 4.9273,
      "step": 4418
    },
    {
      "epoch": 0.5067079463364293,
      "grad_norm": 0.0,
      "learning_rate": 0.0005135099345635695,
      "loss": 4.9783,
      "step": 4419
    },
    {
      "epoch": 0.50682261208577,
      "grad_norm": 0.0,
      "learning_rate": 0.0005133243242383098,
      "loss": 4.9597,
      "step": 4420
    },
    {
      "epoch": 0.5069372778351107,
      "grad_norm": 0.0,
      "learning_rate": 0.0005131387120821101,
      "loss": 5.104,
      "step": 4421
    },
    {
      "epoch": 0.5070519435844513,
      "grad_norm": 0.0,
      "learning_rate": 0.000512953098120572,
      "loss": 4.9782,
      "step": 4422
    },
    {
      "epoch": 0.507166609333792,
      "grad_norm": 0.0,
      "learning_rate": 0.0005127674823792975,
      "loss": 5.1139,
      "step": 4423
    },
    {
      "epoch": 0.5072812750831327,
      "grad_norm": 0.0,
      "learning_rate": 0.0005125818648838888,
      "loss": 5.0926,
      "step": 4424
    },
    {
      "epoch": 0.5073959408324733,
      "grad_norm": 0.0,
      "learning_rate": 0.0005123962456599481,
      "loss": 4.8934,
      "step": 4425
    },
    {
      "epoch": 0.507510606581814,
      "grad_norm": 0.0,
      "learning_rate": 0.0005122106247330781,
      "loss": 4.6643,
      "step": 4426
    },
    {
      "epoch": 0.5076252723311547,
      "grad_norm": 0.0,
      "learning_rate": 0.0005120250021288821,
      "loss": 5.2731,
      "step": 4427
    },
    {
      "epoch": 0.5077399380804953,
      "grad_norm": 0.0,
      "learning_rate": 0.0005118393778729626,
      "loss": 5.049,
      "step": 4428
    },
    {
      "epoch": 0.507854603829836,
      "grad_norm": 0.0,
      "learning_rate": 0.0005116537519909231,
      "loss": 4.9636,
      "step": 4429
    },
    {
      "epoch": 0.5079692695791767,
      "grad_norm": 0.0,
      "learning_rate": 0.0005114681245083672,
      "loss": 5.0472,
      "step": 4430
    },
    {
      "epoch": 0.5080839353285174,
      "grad_norm": 0.0,
      "learning_rate": 0.0005112824954508986,
      "loss": 5.3423,
      "step": 4431
    },
    {
      "epoch": 0.5081986010778581,
      "grad_norm": 0.0,
      "learning_rate": 0.0005110968648441214,
      "loss": 4.8409,
      "step": 4432
    },
    {
      "epoch": 0.5083132668271987,
      "grad_norm": 0.0,
      "learning_rate": 0.0005109112327136399,
      "loss": 5.052,
      "step": 4433
    },
    {
      "epoch": 0.5084279325765394,
      "grad_norm": 0.0,
      "learning_rate": 0.0005107255990850583,
      "loss": 5.0651,
      "step": 4434
    },
    {
      "epoch": 0.5085425983258801,
      "grad_norm": 0.0,
      "learning_rate": 0.0005105399639839812,
      "loss": 4.5234,
      "step": 4435
    },
    {
      "epoch": 0.5086572640752207,
      "grad_norm": 0.0,
      "learning_rate": 0.0005103543274360137,
      "loss": 5.0529,
      "step": 4436
    },
    {
      "epoch": 0.5087719298245614,
      "grad_norm": 0.0,
      "learning_rate": 0.0005101686894667606,
      "loss": 4.7088,
      "step": 4437
    },
    {
      "epoch": 0.508886595573902,
      "grad_norm": 0.0,
      "learning_rate": 0.0005099830501018271,
      "loss": 4.9693,
      "step": 4438
    },
    {
      "epoch": 0.5090012613232427,
      "grad_norm": 0.0,
      "learning_rate": 0.0005097974093668189,
      "loss": 5.1039,
      "step": 4439
    },
    {
      "epoch": 0.5091159270725835,
      "grad_norm": 0.0,
      "learning_rate": 0.0005096117672873411,
      "loss": 5.0006,
      "step": 4440
    },
    {
      "epoch": 0.5092305928219241,
      "grad_norm": 0.0,
      "learning_rate": 0.0005094261238889999,
      "loss": 5.3129,
      "step": 4441
    },
    {
      "epoch": 0.5093452585712648,
      "grad_norm": 0.0,
      "learning_rate": 0.000509240479197401,
      "loss": 5.2035,
      "step": 4442
    },
    {
      "epoch": 0.5094599243206054,
      "grad_norm": 0.0,
      "learning_rate": 0.0005090548332381507,
      "loss": 4.9404,
      "step": 4443
    },
    {
      "epoch": 0.5095745900699461,
      "grad_norm": 0.0,
      "learning_rate": 0.0005088691860368555,
      "loss": 5.0298,
      "step": 4444
    },
    {
      "epoch": 0.5096892558192868,
      "grad_norm": 0.0,
      "learning_rate": 0.0005086835376191215,
      "loss": 4.8449,
      "step": 4445
    },
    {
      "epoch": 0.5098039215686274,
      "grad_norm": 0.0,
      "learning_rate": 0.0005084978880105557,
      "loss": 4.9818,
      "step": 4446
    },
    {
      "epoch": 0.5099185873179681,
      "grad_norm": 0.0,
      "learning_rate": 0.0005083122372367647,
      "loss": 5.1364,
      "step": 4447
    },
    {
      "epoch": 0.5100332530673088,
      "grad_norm": 0.0,
      "learning_rate": 0.0005081265853233556,
      "loss": 5.1016,
      "step": 4448
    },
    {
      "epoch": 0.5101479188166494,
      "grad_norm": 0.0,
      "learning_rate": 0.0005079409322959356,
      "loss": 4.9903,
      "step": 4449
    },
    {
      "epoch": 0.5102625845659902,
      "grad_norm": 0.0,
      "learning_rate": 0.0005077552781801118,
      "loss": 5.0084,
      "step": 4450
    },
    {
      "epoch": 0.5103772503153308,
      "grad_norm": 0.0,
      "learning_rate": 0.0005075696230014917,
      "loss": 5.0449,
      "step": 4451
    },
    {
      "epoch": 0.5104919160646715,
      "grad_norm": 0.0,
      "learning_rate": 0.0005073839667856829,
      "loss": 4.8526,
      "step": 4452
    },
    {
      "epoch": 0.5106065818140122,
      "grad_norm": 0.0,
      "learning_rate": 0.0005071983095582934,
      "loss": 5.1835,
      "step": 4453
    },
    {
      "epoch": 0.5107212475633528,
      "grad_norm": 0.0,
      "learning_rate": 0.0005070126513449306,
      "loss": 4.872,
      "step": 4454
    },
    {
      "epoch": 0.5108359133126935,
      "grad_norm": 0.0,
      "learning_rate": 0.000506826992171203,
      "loss": 5.1911,
      "step": 4455
    },
    {
      "epoch": 0.5109505790620341,
      "grad_norm": 0.0,
      "learning_rate": 0.0005066413320627183,
      "loss": 4.9861,
      "step": 4456
    },
    {
      "epoch": 0.5110652448113748,
      "grad_norm": 0.0,
      "learning_rate": 0.000506455671045085,
      "loss": 4.8507,
      "step": 4457
    },
    {
      "epoch": 0.5111799105607155,
      "grad_norm": 0.0,
      "learning_rate": 0.0005062700091439116,
      "loss": 4.9353,
      "step": 4458
    },
    {
      "epoch": 0.5112945763100561,
      "grad_norm": 0.0,
      "learning_rate": 0.0005060843463848066,
      "loss": 4.8532,
      "step": 4459
    },
    {
      "epoch": 0.5114092420593969,
      "grad_norm": 0.0,
      "learning_rate": 0.0005058986827933784,
      "loss": 5.2264,
      "step": 4460
    },
    {
      "epoch": 0.5115239078087376,
      "grad_norm": 0.0,
      "learning_rate": 0.0005057130183952359,
      "loss": 4.9684,
      "step": 4461
    },
    {
      "epoch": 0.5116385735580782,
      "grad_norm": 0.0,
      "learning_rate": 0.000505527353215988,
      "loss": 5.0192,
      "step": 4462
    },
    {
      "epoch": 0.5117532393074189,
      "grad_norm": 0.0,
      "learning_rate": 0.0005053416872812436,
      "loss": 4.9838,
      "step": 4463
    },
    {
      "epoch": 0.5118679050567595,
      "grad_norm": 0.0,
      "learning_rate": 0.0005051560206166117,
      "loss": 5.0769,
      "step": 4464
    },
    {
      "epoch": 0.5119825708061002,
      "grad_norm": 0.0,
      "learning_rate": 0.0005049703532477018,
      "loss": 4.8035,
      "step": 4465
    },
    {
      "epoch": 0.5120972365554409,
      "grad_norm": 0.0,
      "learning_rate": 0.0005047846852001229,
      "loss": 5.0006,
      "step": 4466
    },
    {
      "epoch": 0.5122119023047815,
      "grad_norm": 0.0,
      "learning_rate": 0.0005045990164994844,
      "loss": 4.9965,
      "step": 4467
    },
    {
      "epoch": 0.5123265680541222,
      "grad_norm": 0.0,
      "learning_rate": 0.0005044133471713957,
      "loss": 4.8588,
      "step": 4468
    },
    {
      "epoch": 0.512441233803463,
      "grad_norm": 0.0,
      "learning_rate": 0.0005042276772414666,
      "loss": 4.847,
      "step": 4469
    },
    {
      "epoch": 0.5125558995528036,
      "grad_norm": 0.0,
      "learning_rate": 0.0005040420067353064,
      "loss": 4.8474,
      "step": 4470
    },
    {
      "epoch": 0.5126705653021443,
      "grad_norm": 0.0,
      "learning_rate": 0.0005038563356785251,
      "loss": 5.0901,
      "step": 4471
    },
    {
      "epoch": 0.5127852310514849,
      "grad_norm": 0.0,
      "learning_rate": 0.0005036706640967324,
      "loss": 4.8565,
      "step": 4472
    },
    {
      "epoch": 0.5128998968008256,
      "grad_norm": 0.0,
      "learning_rate": 0.0005034849920155378,
      "loss": 4.6769,
      "step": 4473
    },
    {
      "epoch": 0.5130145625501663,
      "grad_norm": 0.0,
      "learning_rate": 0.0005032993194605518,
      "loss": 4.9887,
      "step": 4474
    },
    {
      "epoch": 0.5131292282995069,
      "grad_norm": 0.0,
      "learning_rate": 0.0005031136464573838,
      "loss": 5.18,
      "step": 4475
    },
    {
      "epoch": 0.5132438940488476,
      "grad_norm": 0.0,
      "learning_rate": 0.0005029279730316445,
      "loss": 4.9653,
      "step": 4476
    },
    {
      "epoch": 0.5133585597981882,
      "grad_norm": 0.0,
      "learning_rate": 0.0005027422992089436,
      "loss": 5.0228,
      "step": 4477
    },
    {
      "epoch": 0.5134732255475289,
      "grad_norm": 0.0,
      "learning_rate": 0.0005025566250148913,
      "loss": 4.9622,
      "step": 4478
    },
    {
      "epoch": 0.5135878912968697,
      "grad_norm": 0.0,
      "learning_rate": 0.0005023709504750979,
      "loss": 4.8027,
      "step": 4479
    },
    {
      "epoch": 0.5137025570462103,
      "grad_norm": 0.0,
      "learning_rate": 0.0005021852756151735,
      "loss": 4.8923,
      "step": 4480
    },
    {
      "epoch": 0.513817222795551,
      "grad_norm": 0.0,
      "learning_rate": 0.0005019996004607287,
      "loss": 4.8844,
      "step": 4481
    },
    {
      "epoch": 0.5139318885448917,
      "grad_norm": 0.0,
      "learning_rate": 0.0005018139250373738,
      "loss": 5.1008,
      "step": 4482
    },
    {
      "epoch": 0.5140465542942323,
      "grad_norm": 0.0,
      "learning_rate": 0.0005016282493707187,
      "loss": 4.9627,
      "step": 4483
    },
    {
      "epoch": 0.514161220043573,
      "grad_norm": 0.0,
      "learning_rate": 0.0005014425734863743,
      "loss": 4.9979,
      "step": 4484
    },
    {
      "epoch": 0.5142758857929136,
      "grad_norm": 0.0,
      "learning_rate": 0.000501256897409951,
      "loss": 4.8928,
      "step": 4485
    },
    {
      "epoch": 0.5143905515422543,
      "grad_norm": 0.0,
      "learning_rate": 0.0005010712211670591,
      "loss": 5.1314,
      "step": 4486
    },
    {
      "epoch": 0.514505217291595,
      "grad_norm": 0.0,
      "learning_rate": 0.0005008855447833092,
      "loss": 5.0315,
      "step": 4487
    },
    {
      "epoch": 0.5146198830409356,
      "grad_norm": 0.0,
      "learning_rate": 0.0005006998682843122,
      "loss": 4.9233,
      "step": 4488
    },
    {
      "epoch": 0.5147345487902764,
      "grad_norm": 0.0,
      "learning_rate": 0.0005005141916956781,
      "loss": 5.1326,
      "step": 4489
    },
    {
      "epoch": 0.514849214539617,
      "grad_norm": 0.0,
      "learning_rate": 0.0005003285150430173,
      "loss": 4.9623,
      "step": 4490
    },
    {
      "epoch": 0.5149638802889577,
      "grad_norm": 0.0,
      "learning_rate": 0.000500142838351941,
      "loss": 4.9959,
      "step": 4491
    },
    {
      "epoch": 0.5150785460382984,
      "grad_norm": 0.0,
      "learning_rate": 0.0004999571616480592,
      "loss": 4.9859,
      "step": 4492
    },
    {
      "epoch": 0.515193211787639,
      "grad_norm": 0.0,
      "learning_rate": 0.0004997714849569828,
      "loss": 4.9453,
      "step": 4493
    },
    {
      "epoch": 0.5153078775369797,
      "grad_norm": 0.0,
      "learning_rate": 0.0004995858083043221,
      "loss": 5.045,
      "step": 4494
    },
    {
      "epoch": 0.5154225432863204,
      "grad_norm": 0.0,
      "learning_rate": 0.0004994001317156879,
      "loss": 5.0008,
      "step": 4495
    },
    {
      "epoch": 0.515537209035661,
      "grad_norm": 0.0,
      "learning_rate": 0.0004992144552166906,
      "loss": 5.0212,
      "step": 4496
    },
    {
      "epoch": 0.5156518747850017,
      "grad_norm": 0.0,
      "learning_rate": 0.0004990287788329408,
      "loss": 5.0263,
      "step": 4497
    },
    {
      "epoch": 0.5157665405343423,
      "grad_norm": 0.0,
      "learning_rate": 0.000498843102590049,
      "loss": 5.0583,
      "step": 4498
    },
    {
      "epoch": 0.5158812062836831,
      "grad_norm": 0.0,
      "learning_rate": 0.0004986574265136257,
      "loss": 4.8966,
      "step": 4499
    },
    {
      "epoch": 0.5159958720330238,
      "grad_norm": 0.0,
      "learning_rate": 0.0004984717506292815,
      "loss": 5.0338,
      "step": 4500
    },
    {
      "epoch": 0.5161105377823644,
      "grad_norm": 0.0,
      "learning_rate": 0.0004982860749626265,
      "loss": 4.9929,
      "step": 4501
    },
    {
      "epoch": 0.5162252035317051,
      "grad_norm": 0.0,
      "learning_rate": 0.0004981003995392714,
      "loss": 4.9385,
      "step": 4502
    },
    {
      "epoch": 0.5163398692810458,
      "grad_norm": 0.0,
      "learning_rate": 0.0004979147243848264,
      "loss": 5.0132,
      "step": 4503
    },
    {
      "epoch": 0.5164545350303864,
      "grad_norm": 0.0,
      "learning_rate": 0.0004977290495249023,
      "loss": 4.9945,
      "step": 4504
    },
    {
      "epoch": 0.5165692007797271,
      "grad_norm": 0.0,
      "learning_rate": 0.0004975433749851089,
      "loss": 5.1499,
      "step": 4505
    },
    {
      "epoch": 0.5166838665290677,
      "grad_norm": 0.0,
      "learning_rate": 0.0004973577007910565,
      "loss": 4.7715,
      "step": 4506
    },
    {
      "epoch": 0.5167985322784084,
      "grad_norm": 0.0,
      "learning_rate": 0.0004971720269683555,
      "loss": 5.1151,
      "step": 4507
    },
    {
      "epoch": 0.5169131980277492,
      "grad_norm": 0.0,
      "learning_rate": 0.000496986353542616,
      "loss": 5.2468,
      "step": 4508
    },
    {
      "epoch": 0.5170278637770898,
      "grad_norm": 0.0,
      "learning_rate": 0.0004968006805394483,
      "loss": 4.924,
      "step": 4509
    },
    {
      "epoch": 0.5171425295264305,
      "grad_norm": 0.0,
      "learning_rate": 0.0004966150079844624,
      "loss": 4.75,
      "step": 4510
    },
    {
      "epoch": 0.5172571952757711,
      "grad_norm": 0.0,
      "learning_rate": 0.0004964293359032679,
      "loss": 5.052,
      "step": 4511
    },
    {
      "epoch": 0.5173718610251118,
      "grad_norm": 0.0,
      "learning_rate": 0.000496243664321475,
      "loss": 4.9178,
      "step": 4512
    },
    {
      "epoch": 0.5174865267744525,
      "grad_norm": 0.0,
      "learning_rate": 0.0004960579932646936,
      "loss": 5.0414,
      "step": 4513
    },
    {
      "epoch": 0.5176011925237931,
      "grad_norm": 0.0,
      "learning_rate": 0.0004958723227585335,
      "loss": 5.0015,
      "step": 4514
    },
    {
      "epoch": 0.5177158582731338,
      "grad_norm": 0.0,
      "learning_rate": 0.0004956866528286044,
      "loss": 5.3072,
      "step": 4515
    },
    {
      "epoch": 0.5178305240224745,
      "grad_norm": 0.0,
      "learning_rate": 0.0004955009835005158,
      "loss": 5.1455,
      "step": 4516
    },
    {
      "epoch": 0.5179451897718151,
      "grad_norm": 0.0,
      "learning_rate": 0.0004953153147998772,
      "loss": 5.0389,
      "step": 4517
    },
    {
      "epoch": 0.5180598555211559,
      "grad_norm": 0.0,
      "learning_rate": 0.0004951296467522982,
      "loss": 4.9581,
      "step": 4518
    },
    {
      "epoch": 0.5181745212704965,
      "grad_norm": 0.0,
      "learning_rate": 0.0004949439793833882,
      "loss": 5.1083,
      "step": 4519
    },
    {
      "epoch": 0.5182891870198372,
      "grad_norm": 0.0,
      "learning_rate": 0.0004947583127187565,
      "loss": 5.029,
      "step": 4520
    },
    {
      "epoch": 0.5184038527691779,
      "grad_norm": 0.0,
      "learning_rate": 0.0004945726467840122,
      "loss": 5.0816,
      "step": 4521
    },
    {
      "epoch": 0.5185185185185185,
      "grad_norm": 0.0,
      "learning_rate": 0.0004943869816047642,
      "loss": 5.0136,
      "step": 4522
    },
    {
      "epoch": 0.5186331842678592,
      "grad_norm": 0.0,
      "learning_rate": 0.0004942013172066216,
      "loss": 5.075,
      "step": 4523
    },
    {
      "epoch": 0.5187478500171998,
      "grad_norm": 0.0,
      "learning_rate": 0.0004940156536151934,
      "loss": 4.8832,
      "step": 4524
    },
    {
      "epoch": 0.5188625157665405,
      "grad_norm": 0.0,
      "learning_rate": 0.0004938299908560883,
      "loss": 5.0133,
      "step": 4525
    },
    {
      "epoch": 0.5189771815158812,
      "grad_norm": 0.0,
      "learning_rate": 0.000493644328954915,
      "loss": 4.9996,
      "step": 4526
    },
    {
      "epoch": 0.5190918472652218,
      "grad_norm": 0.0,
      "learning_rate": 0.0004934586679372818,
      "loss": 4.9115,
      "step": 4527
    },
    {
      "epoch": 0.5192065130145626,
      "grad_norm": 0.0,
      "learning_rate": 0.0004932730078287971,
      "loss": 5.0574,
      "step": 4528
    },
    {
      "epoch": 0.5193211787639033,
      "grad_norm": 0.0,
      "learning_rate": 0.0004930873486550694,
      "loss": 4.8411,
      "step": 4529
    },
    {
      "epoch": 0.5194358445132439,
      "grad_norm": 0.0,
      "learning_rate": 0.0004929016904417068,
      "loss": 5.0317,
      "step": 4530
    },
    {
      "epoch": 0.5195505102625846,
      "grad_norm": 0.0,
      "learning_rate": 0.0004927160332143171,
      "loss": 5.065,
      "step": 4531
    },
    {
      "epoch": 0.5196651760119252,
      "grad_norm": 0.0,
      "learning_rate": 0.0004925303769985084,
      "loss": 4.7344,
      "step": 4532
    },
    {
      "epoch": 0.5197798417612659,
      "grad_norm": 0.0,
      "learning_rate": 0.0004923447218198884,
      "loss": 5.2023,
      "step": 4533
    },
    {
      "epoch": 0.5198945075106066,
      "grad_norm": 0.0,
      "learning_rate": 0.0004921590677040645,
      "loss": 4.9105,
      "step": 4534
    },
    {
      "epoch": 0.5200091732599472,
      "grad_norm": 0.0,
      "learning_rate": 0.0004919734146766444,
      "loss": 4.9084,
      "step": 4535
    },
    {
      "epoch": 0.5201238390092879,
      "grad_norm": 0.0,
      "learning_rate": 0.0004917877627632353,
      "loss": 5.3649,
      "step": 4536
    },
    {
      "epoch": 0.5202385047586287,
      "grad_norm": 0.0,
      "learning_rate": 0.0004916021119894444,
      "loss": 4.7186,
      "step": 4537
    },
    {
      "epoch": 0.5203531705079693,
      "grad_norm": 0.0,
      "learning_rate": 0.0004914164623808785,
      "loss": 5.2793,
      "step": 4538
    },
    {
      "epoch": 0.52046783625731,
      "grad_norm": 0.0,
      "learning_rate": 0.0004912308139631446,
      "loss": 5.1432,
      "step": 4539
    },
    {
      "epoch": 0.5205825020066506,
      "grad_norm": 0.0,
      "learning_rate": 0.0004910451667618493,
      "loss": 5.131,
      "step": 4540
    },
    {
      "epoch": 0.5206971677559913,
      "grad_norm": 0.0,
      "learning_rate": 0.0004908595208025991,
      "loss": 5.3419,
      "step": 4541
    },
    {
      "epoch": 0.520811833505332,
      "grad_norm": 0.0,
      "learning_rate": 0.0004906738761110002,
      "loss": 4.8924,
      "step": 4542
    },
    {
      "epoch": 0.5209264992546726,
      "grad_norm": 0.0,
      "learning_rate": 0.0004904882327126591,
      "loss": 4.894,
      "step": 4543
    },
    {
      "epoch": 0.5210411650040133,
      "grad_norm": 0.0,
      "learning_rate": 0.0004903025906331814,
      "loss": 4.9564,
      "step": 4544
    },
    {
      "epoch": 0.5211558307533539,
      "grad_norm": 0.0,
      "learning_rate": 0.000490116949898173,
      "loss": 5.0125,
      "step": 4545
    },
    {
      "epoch": 0.5212704965026946,
      "grad_norm": 0.0,
      "learning_rate": 0.0004899313105332395,
      "loss": 4.8173,
      "step": 4546
    },
    {
      "epoch": 0.5213851622520354,
      "grad_norm": 0.0,
      "learning_rate": 0.0004897456725639864,
      "loss": 5.1175,
      "step": 4547
    },
    {
      "epoch": 0.521499828001376,
      "grad_norm": 0.0,
      "learning_rate": 0.0004895600360160188,
      "loss": 5.2323,
      "step": 4548
    },
    {
      "epoch": 0.5216144937507167,
      "grad_norm": 0.0,
      "learning_rate": 0.0004893744009149418,
      "loss": 4.7674,
      "step": 4549
    },
    {
      "epoch": 0.5217291595000574,
      "grad_norm": 0.0,
      "learning_rate": 0.0004891887672863601,
      "loss": 5.0705,
      "step": 4550
    },
    {
      "epoch": 0.521843825249398,
      "grad_norm": 0.0,
      "learning_rate": 0.0004890031351558787,
      "loss": 5.1147,
      "step": 4551
    },
    {
      "epoch": 0.5219584909987387,
      "grad_norm": 0.0,
      "learning_rate": 0.0004888175045491015,
      "loss": 5.0504,
      "step": 4552
    },
    {
      "epoch": 0.5220731567480793,
      "grad_norm": 0.0,
      "learning_rate": 0.000488631875491633,
      "loss": 5.0738,
      "step": 4553
    },
    {
      "epoch": 0.52218782249742,
      "grad_norm": 0.0,
      "learning_rate": 0.0004884462480090772,
      "loss": 5.1434,
      "step": 4554
    },
    {
      "epoch": 0.5223024882467607,
      "grad_norm": 0.0,
      "learning_rate": 0.00048826062212703757,
      "loss": 4.8258,
      "step": 4555
    },
    {
      "epoch": 0.5224171539961013,
      "grad_norm": 0.0,
      "learning_rate": 0.0004880749978711181,
      "loss": 5.4087,
      "step": 4556
    },
    {
      "epoch": 0.522531819745442,
      "grad_norm": 0.0,
      "learning_rate": 0.00048788937526692173,
      "loss": 4.8083,
      "step": 4557
    },
    {
      "epoch": 0.5226464854947827,
      "grad_norm": 0.0,
      "learning_rate": 0.0004877037543400519,
      "loss": 5.0236,
      "step": 4558
    },
    {
      "epoch": 0.5227611512441234,
      "grad_norm": 0.0,
      "learning_rate": 0.00048751813511611127,
      "loss": 4.922,
      "step": 4559
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.0,
      "learning_rate": 0.00048733251762070253,
      "loss": 5.0367,
      "step": 4560
    },
    {
      "epoch": 0.5229904827428047,
      "grad_norm": 0.0,
      "learning_rate": 0.0004871469018794281,
      "loss": 5.0574,
      "step": 4561
    },
    {
      "epoch": 0.5231051484921454,
      "grad_norm": 0.0,
      "learning_rate": 0.00048696128791789005,
      "loss": 4.8785,
      "step": 4562
    },
    {
      "epoch": 0.5232198142414861,
      "grad_norm": 0.0,
      "learning_rate": 0.00048677567576169037,
      "loss": 5.0356,
      "step": 4563
    },
    {
      "epoch": 0.5233344799908267,
      "grad_norm": 0.0,
      "learning_rate": 0.00048659006543643065,
      "loss": 5.1654,
      "step": 4564
    },
    {
      "epoch": 0.5234491457401674,
      "grad_norm": 0.0,
      "learning_rate": 0.0004864044569677124,
      "loss": 5.0344,
      "step": 4565
    },
    {
      "epoch": 0.523563811489508,
      "grad_norm": 0.0,
      "learning_rate": 0.00048621885038113656,
      "loss": 4.9599,
      "step": 4566
    },
    {
      "epoch": 0.5236784772388487,
      "grad_norm": 0.0,
      "learning_rate": 0.00048603324570230423,
      "loss": 4.707,
      "step": 4567
    },
    {
      "epoch": 0.5237931429881895,
      "grad_norm": 0.0,
      "learning_rate": 0.000485847642956816,
      "loss": 4.8211,
      "step": 4568
    },
    {
      "epoch": 0.5239078087375301,
      "grad_norm": 0.0,
      "learning_rate": 0.0004856620421702722,
      "loss": 5.0061,
      "step": 4569
    },
    {
      "epoch": 0.5240224744868708,
      "grad_norm": 0.0,
      "learning_rate": 0.000485476443368273,
      "loss": 5.0402,
      "step": 4570
    },
    {
      "epoch": 0.5241371402362115,
      "grad_norm": 0.0,
      "learning_rate": 0.00048529084657641816,
      "loss": 4.9469,
      "step": 4571
    },
    {
      "epoch": 0.5242518059855521,
      "grad_norm": 0.0,
      "learning_rate": 0.00048510525182030706,
      "loss": 5.0545,
      "step": 4572
    },
    {
      "epoch": 0.5243664717348928,
      "grad_norm": 0.0,
      "learning_rate": 0.0004849196591255391,
      "loss": 4.9967,
      "step": 4573
    },
    {
      "epoch": 0.5244811374842334,
      "grad_norm": 0.0,
      "learning_rate": 0.0004847340685177132,
      "loss": 4.9954,
      "step": 4574
    },
    {
      "epoch": 0.5245958032335741,
      "grad_norm": 0.0,
      "learning_rate": 0.00048454848002242823,
      "loss": 4.8386,
      "step": 4575
    },
    {
      "epoch": 0.5247104689829148,
      "grad_norm": 0.0,
      "learning_rate": 0.0004843628936652825,
      "loss": 5.1884,
      "step": 4576
    },
    {
      "epoch": 0.5248251347322554,
      "grad_norm": 0.0,
      "learning_rate": 0.00048417730947187393,
      "loss": 4.8644,
      "step": 4577
    },
    {
      "epoch": 0.5249398004815962,
      "grad_norm": 0.0,
      "learning_rate": 0.00048399172746780054,
      "loss": 5.1613,
      "step": 4578
    },
    {
      "epoch": 0.5250544662309368,
      "grad_norm": 0.0,
      "learning_rate": 0.0004838061476786597,
      "loss": 4.887,
      "step": 4579
    },
    {
      "epoch": 0.5251691319802775,
      "grad_norm": 0.0,
      "learning_rate": 0.0004836205701300486,
      "loss": 5.093,
      "step": 4580
    },
    {
      "epoch": 0.5252837977296182,
      "grad_norm": 0.0,
      "learning_rate": 0.0004834349948475645,
      "loss": 5.1052,
      "step": 4581
    },
    {
      "epoch": 0.5253984634789588,
      "grad_norm": 0.0,
      "learning_rate": 0.00048324942185680334,
      "loss": 4.9063,
      "step": 4582
    },
    {
      "epoch": 0.5255131292282995,
      "grad_norm": 0.0,
      "learning_rate": 0.0004830638511833617,
      "loss": 4.9464,
      "step": 4583
    },
    {
      "epoch": 0.5256277949776402,
      "grad_norm": 0.0,
      "learning_rate": 0.0004828782828528355,
      "loss": 4.8251,
      "step": 4584
    },
    {
      "epoch": 0.5257424607269808,
      "grad_norm": 0.0,
      "learning_rate": 0.00048269271689082037,
      "loss": 5.1028,
      "step": 4585
    },
    {
      "epoch": 0.5258571264763215,
      "grad_norm": 0.0,
      "learning_rate": 0.0004825071533229116,
      "loss": 4.7427,
      "step": 4586
    },
    {
      "epoch": 0.5259717922256621,
      "grad_norm": 0.0,
      "learning_rate": 0.00048232159217470426,
      "loss": 5.0734,
      "step": 4587
    },
    {
      "epoch": 0.5260864579750029,
      "grad_norm": 0.0,
      "learning_rate": 0.00048213603347179275,
      "loss": 4.8228,
      "step": 4588
    },
    {
      "epoch": 0.5262011237243436,
      "grad_norm": 0.0,
      "learning_rate": 0.0004819504772397714,
      "loss": 5.1465,
      "step": 4589
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 0.0,
      "learning_rate": 0.00048176492350423416,
      "loss": 5.1135,
      "step": 4590
    },
    {
      "epoch": 0.5264304552230249,
      "grad_norm": 0.0,
      "learning_rate": 0.00048157937229077486,
      "loss": 4.8036,
      "step": 4591
    },
    {
      "epoch": 0.5265451209723655,
      "grad_norm": 0.0,
      "learning_rate": 0.0004813938236249865,
      "loss": 4.8416,
      "step": 4592
    },
    {
      "epoch": 0.5266597867217062,
      "grad_norm": 0.0,
      "learning_rate": 0.000481208277532462,
      "loss": 4.9623,
      "step": 4593
    },
    {
      "epoch": 0.5267744524710469,
      "grad_norm": 0.0,
      "learning_rate": 0.000481022734038794,
      "loss": 5.1268,
      "step": 4594
    },
    {
      "epoch": 0.5268891182203875,
      "grad_norm": 0.0,
      "learning_rate": 0.00048083719316957465,
      "loss": 4.8604,
      "step": 4595
    },
    {
      "epoch": 0.5270037839697282,
      "grad_norm": 0.0,
      "learning_rate": 0.00048065165495039564,
      "loss": 4.9658,
      "step": 4596
    },
    {
      "epoch": 0.527118449719069,
      "grad_norm": 0.0,
      "learning_rate": 0.0004804661194068487,
      "loss": 4.9293,
      "step": 4597
    },
    {
      "epoch": 0.5272331154684096,
      "grad_norm": 0.0,
      "learning_rate": 0.0004802805865645249,
      "loss": 5.0267,
      "step": 4598
    },
    {
      "epoch": 0.5273477812177503,
      "grad_norm": 0.0,
      "learning_rate": 0.0004800950564490146,
      "loss": 4.8512,
      "step": 4599
    },
    {
      "epoch": 0.5274624469670909,
      "grad_norm": 0.0,
      "learning_rate": 0.0004799095290859085,
      "loss": 5.0645,
      "step": 4600
    },
    {
      "epoch": 0.5275771127164316,
      "grad_norm": 0.0,
      "learning_rate": 0.0004797240045007965,
      "loss": 5.3912,
      "step": 4601
    },
    {
      "epoch": 0.5276917784657723,
      "grad_norm": 0.0,
      "learning_rate": 0.0004795384827192681,
      "loss": 5.2141,
      "step": 4602
    },
    {
      "epoch": 0.5278064442151129,
      "grad_norm": 0.0,
      "learning_rate": 0.0004793529637669125,
      "loss": 4.8912,
      "step": 4603
    },
    {
      "epoch": 0.5279211099644536,
      "grad_norm": 0.0,
      "learning_rate": 0.0004791674476693185,
      "loss": 5.1287,
      "step": 4604
    },
    {
      "epoch": 0.5280357757137943,
      "grad_norm": 0.0,
      "learning_rate": 0.00047898193445207454,
      "loss": 5.2596,
      "step": 4605
    },
    {
      "epoch": 0.528150441463135,
      "grad_norm": 0.0,
      "learning_rate": 0.0004787964241407687,
      "loss": 4.7664,
      "step": 4606
    },
    {
      "epoch": 0.5282651072124757,
      "grad_norm": 0.0,
      "learning_rate": 0.0004786109167609884,
      "loss": 4.8733,
      "step": 4607
    },
    {
      "epoch": 0.5283797729618163,
      "grad_norm": 0.0,
      "learning_rate": 0.00047842541233832097,
      "loss": 5.096,
      "step": 4608
    },
    {
      "epoch": 0.528494438711157,
      "grad_norm": 0.0,
      "learning_rate": 0.00047823991089835337,
      "loss": 4.711,
      "step": 4609
    },
    {
      "epoch": 0.5286091044604977,
      "grad_norm": 0.0,
      "learning_rate": 0.00047805441246667177,
      "loss": 5.1618,
      "step": 4610
    },
    {
      "epoch": 0.5287237702098383,
      "grad_norm": 0.0,
      "learning_rate": 0.0004778689170688621,
      "loss": 5.0944,
      "step": 4611
    },
    {
      "epoch": 0.528838435959179,
      "grad_norm": 0.0,
      "learning_rate": 0.0004776834247305101,
      "loss": 4.8062,
      "step": 4612
    },
    {
      "epoch": 0.5289531017085196,
      "grad_norm": 0.0,
      "learning_rate": 0.00047749793547720076,
      "loss": 5.0909,
      "step": 4613
    },
    {
      "epoch": 0.5290677674578603,
      "grad_norm": 0.0,
      "learning_rate": 0.0004773124493345188,
      "loss": 4.8679,
      "step": 4614
    },
    {
      "epoch": 0.529182433207201,
      "grad_norm": 0.0,
      "learning_rate": 0.0004771269663280487,
      "loss": 5.2626,
      "step": 4615
    },
    {
      "epoch": 0.5292970989565416,
      "grad_norm": 0.0,
      "learning_rate": 0.00047694148648337397,
      "loss": 4.5293,
      "step": 4616
    },
    {
      "epoch": 0.5294117647058824,
      "grad_norm": 0.0,
      "learning_rate": 0.00047675600982607827,
      "loss": 5.1469,
      "step": 4617
    },
    {
      "epoch": 0.5295264304552231,
      "grad_norm": 0.0,
      "learning_rate": 0.0004765705363817444,
      "loss": 4.7694,
      "step": 4618
    },
    {
      "epoch": 0.5296410962045637,
      "grad_norm": 0.0,
      "learning_rate": 0.0004763850661759551,
      "loss": 5.1668,
      "step": 4619
    },
    {
      "epoch": 0.5297557619539044,
      "grad_norm": 0.0,
      "learning_rate": 0.0004761995992342923,
      "loss": 5.0768,
      "step": 4620
    },
    {
      "epoch": 0.529870427703245,
      "grad_norm": 0.0,
      "learning_rate": 0.0004760141355823376,
      "loss": 4.9013,
      "step": 4621
    },
    {
      "epoch": 0.5299850934525857,
      "grad_norm": 0.0,
      "learning_rate": 0.0004758286752456724,
      "loss": 5.2408,
      "step": 4622
    },
    {
      "epoch": 0.5300997592019264,
      "grad_norm": 0.0,
      "learning_rate": 0.00047564321824987703,
      "loss": 4.88,
      "step": 4623
    },
    {
      "epoch": 0.530214424951267,
      "grad_norm": 0.0,
      "learning_rate": 0.0004754577646205321,
      "loss": 5.0313,
      "step": 4624
    },
    {
      "epoch": 0.5303290907006077,
      "grad_norm": 0.0,
      "learning_rate": 0.00047527231438321716,
      "loss": 5.1268,
      "step": 4625
    },
    {
      "epoch": 0.5304437564499485,
      "grad_norm": 0.0,
      "learning_rate": 0.00047508686756351175,
      "loss": 5.1396,
      "step": 4626
    },
    {
      "epoch": 0.5305584221992891,
      "grad_norm": 0.0,
      "learning_rate": 0.00047490142418699457,
      "loss": 5.0411,
      "step": 4627
    },
    {
      "epoch": 0.5306730879486298,
      "grad_norm": 0.0,
      "learning_rate": 0.00047471598427924406,
      "loss": 5.1482,
      "step": 4628
    },
    {
      "epoch": 0.5307877536979704,
      "grad_norm": 0.0,
      "learning_rate": 0.00047453054786583806,
      "loss": 5.1053,
      "step": 4629
    },
    {
      "epoch": 0.5309024194473111,
      "grad_norm": 0.0,
      "learning_rate": 0.000474345114972354,
      "loss": 4.8964,
      "step": 4630
    },
    {
      "epoch": 0.5310170851966518,
      "grad_norm": 0.0,
      "learning_rate": 0.00047415968562436906,
      "loss": 5.1683,
      "step": 4631
    },
    {
      "epoch": 0.5311317509459924,
      "grad_norm": 0.0,
      "learning_rate": 0.0004739742598474594,
      "loss": 4.7711,
      "step": 4632
    },
    {
      "epoch": 0.5312464166953331,
      "grad_norm": 0.0,
      "learning_rate": 0.000473788837667201,
      "loss": 5.0065,
      "step": 4633
    },
    {
      "epoch": 0.5313610824446737,
      "grad_norm": 0.0,
      "learning_rate": 0.00047360341910916926,
      "loss": 5.1553,
      "step": 4634
    },
    {
      "epoch": 0.5314757481940144,
      "grad_norm": 0.0,
      "learning_rate": 0.00047341800419893935,
      "loss": 4.9705,
      "step": 4635
    },
    {
      "epoch": 0.5315904139433552,
      "grad_norm": 0.0,
      "learning_rate": 0.00047323259296208555,
      "loss": 4.9726,
      "step": 4636
    },
    {
      "epoch": 0.5317050796926958,
      "grad_norm": 0.0,
      "learning_rate": 0.00047304718542418196,
      "loss": 5.0622,
      "step": 4637
    },
    {
      "epoch": 0.5318197454420365,
      "grad_norm": 0.0,
      "learning_rate": 0.0004728617816108018,
      "loss": 4.9636,
      "step": 4638
    },
    {
      "epoch": 0.5319344111913772,
      "grad_norm": 0.0,
      "learning_rate": 0.0004726763815475182,
      "loss": 5.0516,
      "step": 4639
    },
    {
      "epoch": 0.5320490769407178,
      "grad_norm": 0.0,
      "learning_rate": 0.0004724909852599034,
      "loss": 4.9113,
      "step": 4640
    },
    {
      "epoch": 0.5321637426900585,
      "grad_norm": 0.0,
      "learning_rate": 0.00047230559277352944,
      "loss": 5.1274,
      "step": 4641
    },
    {
      "epoch": 0.5322784084393991,
      "grad_norm": 0.0,
      "learning_rate": 0.0004721202041139677,
      "loss": 4.9136,
      "step": 4642
    },
    {
      "epoch": 0.5323930741887398,
      "grad_norm": 0.0,
      "learning_rate": 0.0004719348193067888,
      "loss": 5.0346,
      "step": 4643
    },
    {
      "epoch": 0.5325077399380805,
      "grad_norm": 0.0,
      "learning_rate": 0.0004717494383775631,
      "loss": 5.1623,
      "step": 4644
    },
    {
      "epoch": 0.5326224056874211,
      "grad_norm": 0.0,
      "learning_rate": 0.0004715640613518604,
      "loss": 4.8692,
      "step": 4645
    },
    {
      "epoch": 0.5327370714367619,
      "grad_norm": 0.0,
      "learning_rate": 0.00047137868825524994,
      "loss": 4.996,
      "step": 4646
    },
    {
      "epoch": 0.5328517371861025,
      "grad_norm": 0.0,
      "learning_rate": 0.0004711933191133004,
      "loss": 4.8184,
      "step": 4647
    },
    {
      "epoch": 0.5329664029354432,
      "grad_norm": 0.0,
      "learning_rate": 0.0004710079539515801,
      "loss": 4.9814,
      "step": 4648
    },
    {
      "epoch": 0.5330810686847839,
      "grad_norm": 0.0,
      "learning_rate": 0.0004708225927956564,
      "loss": 4.9439,
      "step": 4649
    },
    {
      "epoch": 0.5331957344341245,
      "grad_norm": 0.0,
      "learning_rate": 0.0004706372356710963,
      "loss": 5.0094,
      "step": 4650
    },
    {
      "epoch": 0.5333104001834652,
      "grad_norm": 0.0,
      "learning_rate": 0.00047045188260346637,
      "loss": 5.055,
      "step": 4651
    },
    {
      "epoch": 0.5334250659328059,
      "grad_norm": 0.0,
      "learning_rate": 0.00047026653361833273,
      "loss": 5.003,
      "step": 4652
    },
    {
      "epoch": 0.5335397316821465,
      "grad_norm": 0.0,
      "learning_rate": 0.0004700811887412605,
      "loss": 5.2503,
      "step": 4653
    },
    {
      "epoch": 0.5336543974314872,
      "grad_norm": 0.0,
      "learning_rate": 0.00046989584799781445,
      "loss": 5.2158,
      "step": 4654
    },
    {
      "epoch": 0.5337690631808278,
      "grad_norm": 0.0,
      "learning_rate": 0.0004697105114135589,
      "loss": 5.0177,
      "step": 4655
    },
    {
      "epoch": 0.5338837289301686,
      "grad_norm": 0.0,
      "learning_rate": 0.0004695251790140574,
      "loss": 4.7083,
      "step": 4656
    },
    {
      "epoch": 0.5339983946795093,
      "grad_norm": 0.0,
      "learning_rate": 0.0004693398508248731,
      "loss": 5.2573,
      "step": 4657
    },
    {
      "epoch": 0.5341130604288499,
      "grad_norm": 0.0,
      "learning_rate": 0.00046915452687156856,
      "loss": 5.0557,
      "step": 4658
    },
    {
      "epoch": 0.5342277261781906,
      "grad_norm": 0.0,
      "learning_rate": 0.00046896920717970564,
      "loss": 4.9231,
      "step": 4659
    },
    {
      "epoch": 0.5343423919275313,
      "grad_norm": 0.0,
      "learning_rate": 0.0004687838917748456,
      "loss": 5.1335,
      "step": 4660
    },
    {
      "epoch": 0.5344570576768719,
      "grad_norm": 0.0,
      "learning_rate": 0.00046859858068254917,
      "loss": 4.9612,
      "step": 4661
    },
    {
      "epoch": 0.5345717234262126,
      "grad_norm": 0.0,
      "learning_rate": 0.00046841327392837666,
      "loss": 5.2318,
      "step": 4662
    },
    {
      "epoch": 0.5346863891755532,
      "grad_norm": 0.0,
      "learning_rate": 0.00046822797153788735,
      "loss": 4.6961,
      "step": 4663
    },
    {
      "epoch": 0.5348010549248939,
      "grad_norm": 0.0,
      "learning_rate": 0.0004680426735366403,
      "loss": 4.8418,
      "step": 4664
    },
    {
      "epoch": 0.5349157206742347,
      "grad_norm": 0.0,
      "learning_rate": 0.00046785737995019383,
      "loss": 4.9641,
      "step": 4665
    },
    {
      "epoch": 0.5350303864235753,
      "grad_norm": 0.0,
      "learning_rate": 0.0004676720908041056,
      "loss": 5.0367,
      "step": 4666
    },
    {
      "epoch": 0.535145052172916,
      "grad_norm": 0.0,
      "learning_rate": 0.00046748680612393277,
      "loss": 5.159,
      "step": 4667
    },
    {
      "epoch": 0.5352597179222566,
      "grad_norm": 0.0,
      "learning_rate": 0.0004673015259352318,
      "loss": 4.9679,
      "step": 4668
    },
    {
      "epoch": 0.5353743836715973,
      "grad_norm": 0.0,
      "learning_rate": 0.00046711625026355863,
      "loss": 5.1629,
      "step": 4669
    },
    {
      "epoch": 0.535489049420938,
      "grad_norm": 0.0,
      "learning_rate": 0.00046693097913446855,
      "loss": 4.8465,
      "step": 4670
    },
    {
      "epoch": 0.5356037151702786,
      "grad_norm": 0.0,
      "learning_rate": 0.000466745712573516,
      "loss": 4.883,
      "step": 4671
    },
    {
      "epoch": 0.5357183809196193,
      "grad_norm": 0.0,
      "learning_rate": 0.000466560450606255,
      "loss": 4.888,
      "step": 4672
    },
    {
      "epoch": 0.53583304666896,
      "grad_norm": 0.0,
      "learning_rate": 0.0004663751932582391,
      "loss": 4.897,
      "step": 4673
    },
    {
      "epoch": 0.5359477124183006,
      "grad_norm": 0.0,
      "learning_rate": 0.00046618994055502085,
      "loss": 5.115,
      "step": 4674
    },
    {
      "epoch": 0.5360623781676414,
      "grad_norm": 0.0,
      "learning_rate": 0.00046600469252215237,
      "loss": 4.6826,
      "step": 4675
    },
    {
      "epoch": 0.536177043916982,
      "grad_norm": 0.0,
      "learning_rate": 0.00046581944918518505,
      "loss": 4.9669,
      "step": 4676
    },
    {
      "epoch": 0.5362917096663227,
      "grad_norm": 0.0,
      "learning_rate": 0.00046563421056966975,
      "loss": 5.2899,
      "step": 4677
    },
    {
      "epoch": 0.5364063754156634,
      "grad_norm": 0.0,
      "learning_rate": 0.00046544897670115656,
      "loss": 5.0462,
      "step": 4678
    },
    {
      "epoch": 0.536521041165004,
      "grad_norm": 0.0,
      "learning_rate": 0.0004652637476051949,
      "loss": 5.0606,
      "step": 4679
    },
    {
      "epoch": 0.5366357069143447,
      "grad_norm": 0.0,
      "learning_rate": 0.0004650785233073337,
      "loss": 5.0826,
      "step": 4680
    },
    {
      "epoch": 0.5367503726636853,
      "grad_norm": 0.0,
      "learning_rate": 0.0004648933038331213,
      "loss": 5.1187,
      "step": 4681
    },
    {
      "epoch": 0.536865038413026,
      "grad_norm": 0.0,
      "learning_rate": 0.00046470808920810486,
      "loss": 5.3294,
      "step": 4682
    },
    {
      "epoch": 0.5369797041623667,
      "grad_norm": 0.0,
      "learning_rate": 0.00046452287945783136,
      "loss": 5.1902,
      "step": 4683
    },
    {
      "epoch": 0.5370943699117073,
      "grad_norm": 0.0,
      "learning_rate": 0.0004643376746078468,
      "loss": 5.0426,
      "step": 4684
    },
    {
      "epoch": 0.537209035661048,
      "grad_norm": 0.0,
      "learning_rate": 0.0004641524746836969,
      "loss": 5.0274,
      "step": 4685
    },
    {
      "epoch": 0.5373237014103888,
      "grad_norm": 0.0,
      "learning_rate": 0.0004639672797109264,
      "loss": 5.0734,
      "step": 4686
    },
    {
      "epoch": 0.5374383671597294,
      "grad_norm": 0.0,
      "learning_rate": 0.0004637820897150792,
      "loss": 4.8195,
      "step": 4687
    },
    {
      "epoch": 0.5375530329090701,
      "grad_norm": 0.0,
      "learning_rate": 0.000463596904721699,
      "loss": 5.1261,
      "step": 4688
    },
    {
      "epoch": 0.5376676986584107,
      "grad_norm": 0.0,
      "learning_rate": 0.0004634117247563284,
      "loss": 5.037,
      "step": 4689
    },
    {
      "epoch": 0.5377823644077514,
      "grad_norm": 0.0,
      "learning_rate": 0.0004632265498445095,
      "loss": 4.9708,
      "step": 4690
    },
    {
      "epoch": 0.5378970301570921,
      "grad_norm": 0.0,
      "learning_rate": 0.00046304138001178357,
      "loss": 4.9073,
      "step": 4691
    },
    {
      "epoch": 0.5380116959064327,
      "grad_norm": 0.0,
      "learning_rate": 0.00046285621528369147,
      "loss": 5.0915,
      "step": 4692
    },
    {
      "epoch": 0.5381263616557734,
      "grad_norm": 0.0,
      "learning_rate": 0.000462671055685773,
      "loss": 4.6421,
      "step": 4693
    },
    {
      "epoch": 0.5382410274051141,
      "grad_norm": 0.0,
      "learning_rate": 0.00046248590124356724,
      "loss": 4.9915,
      "step": 4694
    },
    {
      "epoch": 0.5383556931544548,
      "grad_norm": 0.0,
      "learning_rate": 0.0004623007519826129,
      "loss": 5.2514,
      "step": 4695
    },
    {
      "epoch": 0.5384703589037955,
      "grad_norm": 0.0,
      "learning_rate": 0.00046211560792844774,
      "loss": 5.216,
      "step": 4696
    },
    {
      "epoch": 0.5385850246531361,
      "grad_norm": 0.0,
      "learning_rate": 0.000461930469106609,
      "loss": 4.9264,
      "step": 4697
    },
    {
      "epoch": 0.5386996904024768,
      "grad_norm": 0.0,
      "learning_rate": 0.0004617453355426328,
      "loss": 5.0875,
      "step": 4698
    },
    {
      "epoch": 0.5388143561518175,
      "grad_norm": 0.0,
      "learning_rate": 0.0004615602072620549,
      "loss": 5.1445,
      "step": 4699
    },
    {
      "epoch": 0.5389290219011581,
      "grad_norm": 0.0,
      "learning_rate": 0.0004613750842904103,
      "loss": 5.1175,
      "step": 4700
    },
    {
      "epoch": 0.5390436876504988,
      "grad_norm": 0.0,
      "learning_rate": 0.00046118996665323297,
      "loss": 4.9863,
      "step": 4701
    },
    {
      "epoch": 0.5391583533998394,
      "grad_norm": 0.0,
      "learning_rate": 0.00046100485437605666,
      "loss": 4.9292,
      "step": 4702
    },
    {
      "epoch": 0.5392730191491801,
      "grad_norm": 0.0,
      "learning_rate": 0.000460819747484414,
      "loss": 5.1126,
      "step": 4703
    },
    {
      "epoch": 0.5393876848985208,
      "grad_norm": 0.0,
      "learning_rate": 0.00046063464600383676,
      "loss": 5.171,
      "step": 4704
    },
    {
      "epoch": 0.5395023506478615,
      "grad_norm": 0.0,
      "learning_rate": 0.00046044954995985623,
      "loss": 5.0868,
      "step": 4705
    },
    {
      "epoch": 0.5396170163972022,
      "grad_norm": 0.0,
      "learning_rate": 0.0004602644593780029,
      "loss": 4.8979,
      "step": 4706
    },
    {
      "epoch": 0.5397316821465429,
      "grad_norm": 0.0,
      "learning_rate": 0.00046007937428380654,
      "loss": 5.2165,
      "step": 4707
    },
    {
      "epoch": 0.5398463478958835,
      "grad_norm": 0.0,
      "learning_rate": 0.00045989429470279626,
      "loss": 5.1219,
      "step": 4708
    },
    {
      "epoch": 0.5399610136452242,
      "grad_norm": 0.0,
      "learning_rate": 0.0004597092206604999,
      "loss": 4.7807,
      "step": 4709
    },
    {
      "epoch": 0.5400756793945648,
      "grad_norm": 0.0,
      "learning_rate": 0.00045952415218244514,
      "loss": 5.0527,
      "step": 4710
    },
    {
      "epoch": 0.5401903451439055,
      "grad_norm": 0.0,
      "learning_rate": 0.00045933908929415856,
      "loss": 5.0154,
      "step": 4711
    },
    {
      "epoch": 0.5403050108932462,
      "grad_norm": 0.0,
      "learning_rate": 0.00045915403202116613,
      "loss": 4.892,
      "step": 4712
    },
    {
      "epoch": 0.5404196766425868,
      "grad_norm": 0.0,
      "learning_rate": 0.000458968980388993,
      "loss": 5.0271,
      "step": 4713
    },
    {
      "epoch": 0.5405343423919275,
      "grad_norm": 0.0,
      "learning_rate": 0.00045878393442316345,
      "loss": 5.0391,
      "step": 4714
    },
    {
      "epoch": 0.5406490081412682,
      "grad_norm": 0.0,
      "learning_rate": 0.00045859889414920097,
      "loss": 4.8397,
      "step": 4715
    },
    {
      "epoch": 0.5407636738906089,
      "grad_norm": 0.0,
      "learning_rate": 0.0004584138595926284,
      "loss": 5.1431,
      "step": 4716
    },
    {
      "epoch": 0.5408783396399496,
      "grad_norm": 0.0,
      "learning_rate": 0.00045822883077896773,
      "loss": 5.2446,
      "step": 4717
    },
    {
      "epoch": 0.5409930053892902,
      "grad_norm": 0.0,
      "learning_rate": 0.0004580438077337402,
      "loss": 4.833,
      "step": 4718
    },
    {
      "epoch": 0.5411076711386309,
      "grad_norm": 0.0,
      "learning_rate": 0.0004578587904824662,
      "loss": 4.7883,
      "step": 4719
    },
    {
      "epoch": 0.5412223368879716,
      "grad_norm": 0.0,
      "learning_rate": 0.00045767377905066525,
      "loss": 5.0121,
      "step": 4720
    },
    {
      "epoch": 0.5413370026373122,
      "grad_norm": 0.0,
      "learning_rate": 0.00045748877346385626,
      "loss": 4.9223,
      "step": 4721
    },
    {
      "epoch": 0.5414516683866529,
      "grad_norm": 0.0,
      "learning_rate": 0.0004573037737475571,
      "loss": 4.9745,
      "step": 4722
    },
    {
      "epoch": 0.5415663341359935,
      "grad_norm": 0.0,
      "learning_rate": 0.00045711877992728525,
      "loss": 4.8266,
      "step": 4723
    },
    {
      "epoch": 0.5416809998853342,
      "grad_norm": 0.0,
      "learning_rate": 0.00045693379202855675,
      "loss": 5.194,
      "step": 4724
    },
    {
      "epoch": 0.541795665634675,
      "grad_norm": 0.0,
      "learning_rate": 0.0004567488100768873,
      "loss": 4.9568,
      "step": 4725
    },
    {
      "epoch": 0.5419103313840156,
      "grad_norm": 0.0,
      "learning_rate": 0.0004565638340977915,
      "loss": 5.1205,
      "step": 4726
    },
    {
      "epoch": 0.5420249971333563,
      "grad_norm": 0.0,
      "learning_rate": 0.00045637886411678335,
      "loss": 5.0839,
      "step": 4727
    },
    {
      "epoch": 0.542139662882697,
      "grad_norm": 0.0,
      "learning_rate": 0.00045619390015937605,
      "loss": 4.9595,
      "step": 4728
    },
    {
      "epoch": 0.5422543286320376,
      "grad_norm": 0.0,
      "learning_rate": 0.00045600894225108167,
      "loss": 5.222,
      "step": 4729
    },
    {
      "epoch": 0.5423689943813783,
      "grad_norm": 0.0,
      "learning_rate": 0.0004558239904174118,
      "loss": 5.0476,
      "step": 4730
    },
    {
      "epoch": 0.5424836601307189,
      "grad_norm": 0.0,
      "learning_rate": 0.00045563904468387697,
      "loss": 4.854,
      "step": 4731
    },
    {
      "epoch": 0.5425983258800596,
      "grad_norm": 0.0,
      "learning_rate": 0.00045545410507598664,
      "loss": 5.387,
      "step": 4732
    },
    {
      "epoch": 0.5427129916294003,
      "grad_norm": 0.0,
      "learning_rate": 0.0004552691716192501,
      "loss": 5.1541,
      "step": 4733
    },
    {
      "epoch": 0.542827657378741,
      "grad_norm": 0.0,
      "learning_rate": 0.0004550842443391753,
      "loss": 4.9763,
      "step": 4734
    },
    {
      "epoch": 0.5429423231280817,
      "grad_norm": 0.0,
      "learning_rate": 0.0004548993232612693,
      "loss": 4.7526,
      "step": 4735
    },
    {
      "epoch": 0.5430569888774223,
      "grad_norm": 0.0,
      "learning_rate": 0.0004547144084110386,
      "loss": 5.2437,
      "step": 4736
    },
    {
      "epoch": 0.543171654626763,
      "grad_norm": 0.0,
      "learning_rate": 0.00045452949981398844,
      "loss": 4.838,
      "step": 4737
    },
    {
      "epoch": 0.5432863203761037,
      "grad_norm": 0.0,
      "learning_rate": 0.00045434459749562364,
      "loss": 4.9736,
      "step": 4738
    },
    {
      "epoch": 0.5434009861254443,
      "grad_norm": 0.0,
      "learning_rate": 0.00045415970148144773,
      "loss": 5.0147,
      "step": 4739
    },
    {
      "epoch": 0.543515651874785,
      "grad_norm": 0.0,
      "learning_rate": 0.0004539748117969639,
      "loss": 5.1844,
      "step": 4740
    },
    {
      "epoch": 0.5436303176241257,
      "grad_norm": 0.0,
      "learning_rate": 0.0004537899284676741,
      "loss": 5.0818,
      "step": 4741
    },
    {
      "epoch": 0.5437449833734663,
      "grad_norm": 0.0,
      "learning_rate": 0.00045360505151907925,
      "loss": 4.8864,
      "step": 4742
    },
    {
      "epoch": 0.543859649122807,
      "grad_norm": 0.0,
      "learning_rate": 0.0004534201809766798,
      "loss": 5.0726,
      "step": 4743
    },
    {
      "epoch": 0.5439743148721476,
      "grad_norm": 0.0,
      "learning_rate": 0.00045323531686597505,
      "loss": 5.1148,
      "step": 4744
    },
    {
      "epoch": 0.5440889806214884,
      "grad_norm": 0.0,
      "learning_rate": 0.00045305045921246334,
      "loss": 5.0015,
      "step": 4745
    },
    {
      "epoch": 0.5442036463708291,
      "grad_norm": 0.0,
      "learning_rate": 0.0004528656080416425,
      "loss": 5.0899,
      "step": 4746
    },
    {
      "epoch": 0.5443183121201697,
      "grad_norm": 0.0,
      "learning_rate": 0.0004526807633790091,
      "loss": 4.6648,
      "step": 4747
    },
    {
      "epoch": 0.5444329778695104,
      "grad_norm": 0.0,
      "learning_rate": 0.0004524959252500589,
      "loss": 5.0638,
      "step": 4748
    },
    {
      "epoch": 0.544547643618851,
      "grad_norm": 0.0,
      "learning_rate": 0.00045231109368028684,
      "loss": 5.0577,
      "step": 4749
    },
    {
      "epoch": 0.5446623093681917,
      "grad_norm": 0.0,
      "learning_rate": 0.00045212626869518694,
      "loss": 5.1978,
      "step": 4750
    },
    {
      "epoch": 0.5447769751175324,
      "grad_norm": 0.0,
      "learning_rate": 0.0004519414503202522,
      "loss": 5.2343,
      "step": 4751
    },
    {
      "epoch": 0.544891640866873,
      "grad_norm": 0.0,
      "learning_rate": 0.00045175663858097503,
      "loss": 4.9257,
      "step": 4752
    },
    {
      "epoch": 0.5450063066162137,
      "grad_norm": 0.0,
      "learning_rate": 0.0004515718335028464,
      "loss": 5.0066,
      "step": 4753
    },
    {
      "epoch": 0.5451209723655545,
      "grad_norm": 0.0,
      "learning_rate": 0.0004513870351113569,
      "loss": 4.9973,
      "step": 4754
    },
    {
      "epoch": 0.5452356381148951,
      "grad_norm": 0.0,
      "learning_rate": 0.00045120224343199564,
      "loss": 4.5502,
      "step": 4755
    },
    {
      "epoch": 0.5453503038642358,
      "grad_norm": 0.0,
      "learning_rate": 0.00045101745849025125,
      "loss": 4.6846,
      "step": 4756
    },
    {
      "epoch": 0.5454649696135764,
      "grad_norm": 0.0,
      "learning_rate": 0.0004508326803116113,
      "loss": 4.7949,
      "step": 4757
    },
    {
      "epoch": 0.5455796353629171,
      "grad_norm": 0.0,
      "learning_rate": 0.0004506479089215626,
      "loss": 4.8974,
      "step": 4758
    },
    {
      "epoch": 0.5456943011122578,
      "grad_norm": 0.0,
      "learning_rate": 0.0004504631443455906,
      "loss": 5.0313,
      "step": 4759
    },
    {
      "epoch": 0.5458089668615984,
      "grad_norm": 0.0,
      "learning_rate": 0.00045027838660918014,
      "loss": 5.0874,
      "step": 4760
    },
    {
      "epoch": 0.5459236326109391,
      "grad_norm": 0.0,
      "learning_rate": 0.0004500936357378149,
      "loss": 4.9959,
      "step": 4761
    },
    {
      "epoch": 0.5460382983602798,
      "grad_norm": 0.0,
      "learning_rate": 0.0004499088917569779,
      "loss": 5.1546,
      "step": 4762
    },
    {
      "epoch": 0.5461529641096204,
      "grad_norm": 0.0,
      "learning_rate": 0.00044972415469215116,
      "loss": 5.2204,
      "step": 4763
    },
    {
      "epoch": 0.5462676298589612,
      "grad_norm": 0.0,
      "learning_rate": 0.0004495394245688155,
      "loss": 5.0747,
      "step": 4764
    },
    {
      "epoch": 0.5463822956083018,
      "grad_norm": 0.0,
      "learning_rate": 0.0004493547014124507,
      "loss": 4.924,
      "step": 4765
    },
    {
      "epoch": 0.5464969613576425,
      "grad_norm": 0.0,
      "learning_rate": 0.00044916998524853604,
      "loss": 5.0458,
      "step": 4766
    },
    {
      "epoch": 0.5466116271069832,
      "grad_norm": 0.0,
      "learning_rate": 0.00044898527610254957,
      "loss": 4.9182,
      "step": 4767
    },
    {
      "epoch": 0.5467262928563238,
      "grad_norm": 0.0,
      "learning_rate": 0.0004488005739999684,
      "loss": 5.0191,
      "step": 4768
    },
    {
      "epoch": 0.5468409586056645,
      "grad_norm": 0.0,
      "learning_rate": 0.0004486158789662687,
      "loss": 4.9447,
      "step": 4769
    },
    {
      "epoch": 0.5469556243550051,
      "grad_norm": 0.0,
      "learning_rate": 0.00044843119102692546,
      "loss": 5.2019,
      "step": 4770
    },
    {
      "epoch": 0.5470702901043458,
      "grad_norm": 0.0,
      "learning_rate": 0.000448246510207413,
      "loss": 4.8392,
      "step": 4771
    },
    {
      "epoch": 0.5471849558536865,
      "grad_norm": 0.0,
      "learning_rate": 0.00044806183653320456,
      "loss": 5.0724,
      "step": 4772
    },
    {
      "epoch": 0.5472996216030271,
      "grad_norm": 0.0,
      "learning_rate": 0.00044787717002977217,
      "loss": 5.2227,
      "step": 4773
    },
    {
      "epoch": 0.5474142873523679,
      "grad_norm": 0.0,
      "learning_rate": 0.00044769251072258745,
      "loss": 5.1903,
      "step": 4774
    },
    {
      "epoch": 0.5475289531017086,
      "grad_norm": 0.0,
      "learning_rate": 0.0004475078586371201,
      "loss": 4.89,
      "step": 4775
    },
    {
      "epoch": 0.5476436188510492,
      "grad_norm": 0.0,
      "learning_rate": 0.00044732321379883965,
      "loss": 5.0917,
      "step": 4776
    },
    {
      "epoch": 0.5477582846003899,
      "grad_norm": 0.0,
      "learning_rate": 0.0004471385762332143,
      "loss": 5.237,
      "step": 4777
    },
    {
      "epoch": 0.5478729503497305,
      "grad_norm": 0.0,
      "learning_rate": 0.0004469539459657112,
      "loss": 5.0104,
      "step": 4778
    },
    {
      "epoch": 0.5479876160990712,
      "grad_norm": 0.0,
      "learning_rate": 0.00044676932302179667,
      "loss": 5.3422,
      "step": 4779
    },
    {
      "epoch": 0.5481022818484119,
      "grad_norm": 0.0,
      "learning_rate": 0.0004465847074269361,
      "loss": 5.0441,
      "step": 4780
    },
    {
      "epoch": 0.5482169475977525,
      "grad_norm": 0.0,
      "learning_rate": 0.0004464000992065933,
      "loss": 4.8206,
      "step": 4781
    },
    {
      "epoch": 0.5483316133470932,
      "grad_norm": 0.0,
      "learning_rate": 0.0004462154983862317,
      "loss": 4.8499,
      "step": 4782
    },
    {
      "epoch": 0.5484462790964338,
      "grad_norm": 0.0,
      "learning_rate": 0.00044603090499131337,
      "loss": 5.2191,
      "step": 4783
    },
    {
      "epoch": 0.5485609448457746,
      "grad_norm": 0.0,
      "learning_rate": 0.00044584631904729966,
      "loss": 4.9286,
      "step": 4784
    },
    {
      "epoch": 0.5486756105951153,
      "grad_norm": 0.0,
      "learning_rate": 0.00044566174057965053,
      "loss": 4.985,
      "step": 4785
    },
    {
      "epoch": 0.5487902763444559,
      "grad_norm": 0.0,
      "learning_rate": 0.0004454771696138249,
      "loss": 5.0775,
      "step": 4786
    },
    {
      "epoch": 0.5489049420937966,
      "grad_norm": 0.0,
      "learning_rate": 0.000445292606175281,
      "loss": 5.071,
      "step": 4787
    },
    {
      "epoch": 0.5490196078431373,
      "grad_norm": 0.0,
      "learning_rate": 0.0004451080502894758,
      "loss": 4.928,
      "step": 4788
    },
    {
      "epoch": 0.5491342735924779,
      "grad_norm": 0.0,
      "learning_rate": 0.00044492350198186526,
      "loss": 4.6942,
      "step": 4789
    },
    {
      "epoch": 0.5492489393418186,
      "grad_norm": 0.0,
      "learning_rate": 0.0004447389612779043,
      "loss": 4.8902,
      "step": 4790
    },
    {
      "epoch": 0.5493636050911592,
      "grad_norm": 0.0,
      "learning_rate": 0.0004445544282030469,
      "loss": 5.1835,
      "step": 4791
    },
    {
      "epoch": 0.5494782708404999,
      "grad_norm": 0.0,
      "learning_rate": 0.0004443699027827458,
      "loss": 4.9749,
      "step": 4792
    },
    {
      "epoch": 0.5495929365898407,
      "grad_norm": 0.0,
      "learning_rate": 0.00044418538504245266,
      "loss": 5.0022,
      "step": 4793
    },
    {
      "epoch": 0.5497076023391813,
      "grad_norm": 0.0,
      "learning_rate": 0.00044400087500761834,
      "loss": 4.6402,
      "step": 4794
    },
    {
      "epoch": 0.549822268088522,
      "grad_norm": 0.0,
      "learning_rate": 0.0004438163727036924,
      "loss": 5.0943,
      "step": 4795
    },
    {
      "epoch": 0.5499369338378627,
      "grad_norm": 0.0,
      "learning_rate": 0.00044363187815612355,
      "loss": 4.9459,
      "step": 4796
    },
    {
      "epoch": 0.5500515995872033,
      "grad_norm": 0.0,
      "learning_rate": 0.000443447391390359,
      "loss": 5.1821,
      "step": 4797
    },
    {
      "epoch": 0.550166265336544,
      "grad_norm": 0.0,
      "learning_rate": 0.0004432629124318454,
      "loss": 4.9508,
      "step": 4798
    },
    {
      "epoch": 0.5502809310858846,
      "grad_norm": 0.0,
      "learning_rate": 0.00044307844130602803,
      "loss": 4.9785,
      "step": 4799
    },
    {
      "epoch": 0.5503955968352253,
      "grad_norm": 0.0,
      "learning_rate": 0.0004428939780383513,
      "loss": 5.11,
      "step": 4800
    },
    {
      "epoch": 0.550510262584566,
      "grad_norm": 0.0,
      "learning_rate": 0.00044270952265425826,
      "loss": 4.9945,
      "step": 4801
    },
    {
      "epoch": 0.5506249283339066,
      "grad_norm": 0.0,
      "learning_rate": 0.00044252507517919114,
      "loss": 5.1536,
      "step": 4802
    },
    {
      "epoch": 0.5507395940832474,
      "grad_norm": 0.0,
      "learning_rate": 0.00044234063563859075,
      "loss": 5.1649,
      "step": 4803
    },
    {
      "epoch": 0.550854259832588,
      "grad_norm": 0.0,
      "learning_rate": 0.0004421562040578972,
      "loss": 5.1931,
      "step": 4804
    },
    {
      "epoch": 0.5509689255819287,
      "grad_norm": 0.0,
      "learning_rate": 0.0004419717804625493,
      "loss": 5.1934,
      "step": 4805
    },
    {
      "epoch": 0.5510835913312694,
      "grad_norm": 0.0,
      "learning_rate": 0.0004417873648779846,
      "loss": 5.016,
      "step": 4806
    },
    {
      "epoch": 0.55119825708061,
      "grad_norm": 0.0,
      "learning_rate": 0.00044160295732964,
      "loss": 5.0759,
      "step": 4807
    },
    {
      "epoch": 0.5513129228299507,
      "grad_norm": 0.0,
      "learning_rate": 0.00044141855784295066,
      "loss": 4.8117,
      "step": 4808
    },
    {
      "epoch": 0.5514275885792914,
      "grad_norm": 0.0,
      "learning_rate": 0.00044123416644335116,
      "loss": 4.9746,
      "step": 4809
    },
    {
      "epoch": 0.551542254328632,
      "grad_norm": 0.0,
      "learning_rate": 0.0004410497831562748,
      "loss": 4.8039,
      "step": 4810
    },
    {
      "epoch": 0.5516569200779727,
      "grad_norm": 0.0,
      "learning_rate": 0.0004408654080071537,
      "loss": 4.971,
      "step": 4811
    },
    {
      "epoch": 0.5517715858273133,
      "grad_norm": 0.0,
      "learning_rate": 0.00044068104102141885,
      "loss": 5.0948,
      "step": 4812
    },
    {
      "epoch": 0.551886251576654,
      "grad_norm": 0.0,
      "learning_rate": 0.0004404966822245004,
      "loss": 5.0576,
      "step": 4813
    },
    {
      "epoch": 0.5520009173259948,
      "grad_norm": 0.0,
      "learning_rate": 0.00044031233164182684,
      "loss": 5.0239,
      "step": 4814
    },
    {
      "epoch": 0.5521155830753354,
      "grad_norm": 0.0,
      "learning_rate": 0.000440127989298826,
      "loss": 4.9981,
      "step": 4815
    },
    {
      "epoch": 0.5522302488246761,
      "grad_norm": 0.0,
      "learning_rate": 0.00043994365522092416,
      "loss": 4.8951,
      "step": 4816
    },
    {
      "epoch": 0.5523449145740167,
      "grad_norm": 0.0,
      "learning_rate": 0.00043975932943354697,
      "loss": 5.0076,
      "step": 4817
    },
    {
      "epoch": 0.5524595803233574,
      "grad_norm": 0.0,
      "learning_rate": 0.0004395750119621185,
      "loss": 5.0656,
      "step": 4818
    },
    {
      "epoch": 0.5525742460726981,
      "grad_norm": 0.0,
      "learning_rate": 0.00043939070283206187,
      "loss": 5.0566,
      "step": 4819
    },
    {
      "epoch": 0.5526889118220387,
      "grad_norm": 0.0,
      "learning_rate": 0.000439206402068799,
      "loss": 4.8998,
      "step": 4820
    },
    {
      "epoch": 0.5528035775713794,
      "grad_norm": 0.0,
      "learning_rate": 0.0004390221096977507,
      "loss": 5.0677,
      "step": 4821
    },
    {
      "epoch": 0.5529182433207201,
      "grad_norm": 0.0,
      "learning_rate": 0.0004388378257443365,
      "loss": 4.9375,
      "step": 4822
    },
    {
      "epoch": 0.5530329090700608,
      "grad_norm": 0.0,
      "learning_rate": 0.00043865355023397503,
      "loss": 5.0228,
      "step": 4823
    },
    {
      "epoch": 0.5531475748194015,
      "grad_norm": 0.0,
      "learning_rate": 0.0004384692831920835,
      "loss": 4.9617,
      "step": 4824
    },
    {
      "epoch": 0.5532622405687421,
      "grad_norm": 0.0,
      "learning_rate": 0.000438285024644078,
      "loss": 4.9291,
      "step": 4825
    },
    {
      "epoch": 0.5533769063180828,
      "grad_norm": 0.0,
      "learning_rate": 0.00043810077461537344,
      "loss": 5.151,
      "step": 4826
    },
    {
      "epoch": 0.5534915720674235,
      "grad_norm": 0.0,
      "learning_rate": 0.00043791653313138366,
      "loss": 5.1494,
      "step": 4827
    },
    {
      "epoch": 0.5536062378167641,
      "grad_norm": 0.0,
      "learning_rate": 0.00043773230021752123,
      "loss": 4.7557,
      "step": 4828
    },
    {
      "epoch": 0.5537209035661048,
      "grad_norm": 0.0,
      "learning_rate": 0.0004375480758991978,
      "loss": 4.8913,
      "step": 4829
    },
    {
      "epoch": 0.5538355693154455,
      "grad_norm": 0.0,
      "learning_rate": 0.0004373638602018232,
      "loss": 4.813,
      "step": 4830
    },
    {
      "epoch": 0.5539502350647861,
      "grad_norm": 0.0,
      "learning_rate": 0.00043717965315080677,
      "loss": 5.0485,
      "step": 4831
    },
    {
      "epoch": 0.5540649008141268,
      "grad_norm": 0.0,
      "learning_rate": 0.0004369954547715562,
      "loss": 4.9087,
      "step": 4832
    },
    {
      "epoch": 0.5541795665634675,
      "grad_norm": 0.0,
      "learning_rate": 0.0004368112650894782,
      "loss": 4.7973,
      "step": 4833
    },
    {
      "epoch": 0.5542942323128082,
      "grad_norm": 0.0,
      "learning_rate": 0.0004366270841299783,
      "loss": 4.9753,
      "step": 4834
    },
    {
      "epoch": 0.5544088980621489,
      "grad_norm": 0.0,
      "learning_rate": 0.00043644291191846093,
      "loss": 4.9731,
      "step": 4835
    },
    {
      "epoch": 0.5545235638114895,
      "grad_norm": 0.0,
      "learning_rate": 0.0004362587484803286,
      "loss": 5.0961,
      "step": 4836
    },
    {
      "epoch": 0.5546382295608302,
      "grad_norm": 0.0,
      "learning_rate": 0.00043607459384098355,
      "loss": 5.1748,
      "step": 4837
    },
    {
      "epoch": 0.5547528953101708,
      "grad_norm": 0.0,
      "learning_rate": 0.00043589044802582616,
      "loss": 5.0913,
      "step": 4838
    },
    {
      "epoch": 0.5548675610595115,
      "grad_norm": 0.0,
      "learning_rate": 0.0004357063110602561,
      "loss": 4.8715,
      "step": 4839
    },
    {
      "epoch": 0.5549822268088522,
      "grad_norm": 0.0,
      "learning_rate": 0.00043552218296967146,
      "loss": 5.1943,
      "step": 4840
    },
    {
      "epoch": 0.5550968925581928,
      "grad_norm": 0.0,
      "learning_rate": 0.0004353380637794691,
      "loss": 4.9796,
      "step": 4841
    },
    {
      "epoch": 0.5552115583075335,
      "grad_norm": 0.0,
      "learning_rate": 0.0004351539535150448,
      "loss": 4.9315,
      "step": 4842
    },
    {
      "epoch": 0.5553262240568743,
      "grad_norm": 0.0,
      "learning_rate": 0.000434969852201793,
      "loss": 5.3285,
      "step": 4843
    },
    {
      "epoch": 0.5554408898062149,
      "grad_norm": 0.0,
      "learning_rate": 0.0004347857598651072,
      "loss": 5.1765,
      "step": 4844
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.0,
      "learning_rate": 0.0004346016765303793,
      "loss": 5.1322,
      "step": 4845
    },
    {
      "epoch": 0.5556702213048962,
      "grad_norm": 0.0,
      "learning_rate": 0.000434417602223,
      "loss": 4.9318,
      "step": 4846
    },
    {
      "epoch": 0.5557848870542369,
      "grad_norm": 0.0,
      "learning_rate": 0.00043423353696835895,
      "loss": 5.0119,
      "step": 4847
    },
    {
      "epoch": 0.5558995528035776,
      "grad_norm": 0.0,
      "learning_rate": 0.00043404948079184426,
      "loss": 5.178,
      "step": 4848
    },
    {
      "epoch": 0.5560142185529182,
      "grad_norm": 0.0,
      "learning_rate": 0.00043386543371884325,
      "loss": 5.2709,
      "step": 4849
    },
    {
      "epoch": 0.5561288843022589,
      "grad_norm": 0.0,
      "learning_rate": 0.0004336813957747415,
      "loss": 5.2681,
      "step": 4850
    },
    {
      "epoch": 0.5562435500515995,
      "grad_norm": 0.0,
      "learning_rate": 0.00043349736698492365,
      "loss": 4.8453,
      "step": 4851
    },
    {
      "epoch": 0.5563582158009402,
      "grad_norm": 0.0,
      "learning_rate": 0.00043331334737477283,
      "loss": 5.0963,
      "step": 4852
    },
    {
      "epoch": 0.556472881550281,
      "grad_norm": 0.0,
      "learning_rate": 0.00043312933696967117,
      "loss": 4.9293,
      "step": 4853
    },
    {
      "epoch": 0.5565875472996216,
      "grad_norm": 0.0,
      "learning_rate": 0.00043294533579499935,
      "loss": 5.1934,
      "step": 4854
    },
    {
      "epoch": 0.5567022130489623,
      "grad_norm": 0.0,
      "learning_rate": 0.0004327613438761368,
      "loss": 4.9804,
      "step": 4855
    },
    {
      "epoch": 0.556816878798303,
      "grad_norm": 0.0,
      "learning_rate": 0.00043257736123846185,
      "loss": 4.9875,
      "step": 4856
    },
    {
      "epoch": 0.5569315445476436,
      "grad_norm": 0.0,
      "learning_rate": 0.0004323933879073512,
      "loss": 4.9464,
      "step": 4857
    },
    {
      "epoch": 0.5570462102969843,
      "grad_norm": 0.0,
      "learning_rate": 0.00043220942390818055,
      "loss": 5.1112,
      "step": 4858
    },
    {
      "epoch": 0.5571608760463249,
      "grad_norm": 0.0,
      "learning_rate": 0.00043202546926632415,
      "loss": 5.0793,
      "step": 4859
    },
    {
      "epoch": 0.5572755417956656,
      "grad_norm": 0.0,
      "learning_rate": 0.0004318415240071551,
      "loss": 5.0051,
      "step": 4860
    },
    {
      "epoch": 0.5573902075450063,
      "grad_norm": 0.0,
      "learning_rate": 0.0004316575881560452,
      "loss": 4.7052,
      "step": 4861
    },
    {
      "epoch": 0.557504873294347,
      "grad_norm": 0.0,
      "learning_rate": 0.0004314736617383648,
      "loss": 5.1913,
      "step": 4862
    },
    {
      "epoch": 0.5576195390436877,
      "grad_norm": 0.0,
      "learning_rate": 0.00043128974477948305,
      "loss": 4.7337,
      "step": 4863
    },
    {
      "epoch": 0.5577342047930284,
      "grad_norm": 0.0,
      "learning_rate": 0.0004311058373047679,
      "loss": 5.0081,
      "step": 4864
    },
    {
      "epoch": 0.557848870542369,
      "grad_norm": 0.0,
      "learning_rate": 0.0004309219393395857,
      "loss": 5.1105,
      "step": 4865
    },
    {
      "epoch": 0.5579635362917097,
      "grad_norm": 0.0,
      "learning_rate": 0.00043073805090930185,
      "loss": 5.3413,
      "step": 4866
    },
    {
      "epoch": 0.5580782020410503,
      "grad_norm": 0.0,
      "learning_rate": 0.0004305541720392802,
      "loss": 5.0403,
      "step": 4867
    },
    {
      "epoch": 0.558192867790391,
      "grad_norm": 0.0,
      "learning_rate": 0.00043037030275488324,
      "loss": 4.9888,
      "step": 4868
    },
    {
      "epoch": 0.5583075335397317,
      "grad_norm": 0.0,
      "learning_rate": 0.00043018644308147233,
      "loss": 5.1391,
      "step": 4869
    },
    {
      "epoch": 0.5584221992890723,
      "grad_norm": 0.0,
      "learning_rate": 0.00043000259304440733,
      "loss": 5.0353,
      "step": 4870
    },
    {
      "epoch": 0.558536865038413,
      "grad_norm": 0.0,
      "learning_rate": 0.00042981875266904693,
      "loss": 4.9417,
      "step": 4871
    },
    {
      "epoch": 0.5586515307877536,
      "grad_norm": 0.0,
      "learning_rate": 0.0004296349219807483,
      "loss": 4.9375,
      "step": 4872
    },
    {
      "epoch": 0.5587661965370944,
      "grad_norm": 0.0,
      "learning_rate": 0.0004294511010048676,
      "loss": 5.0006,
      "step": 4873
    },
    {
      "epoch": 0.5588808622864351,
      "grad_norm": 0.0,
      "learning_rate": 0.00042926728976675914,
      "loss": 5.2126,
      "step": 4874
    },
    {
      "epoch": 0.5589955280357757,
      "grad_norm": 0.0,
      "learning_rate": 0.00042908348829177634,
      "loss": 4.814,
      "step": 4875
    },
    {
      "epoch": 0.5591101937851164,
      "grad_norm": 0.0,
      "learning_rate": 0.00042889969660527113,
      "loss": 5.1308,
      "step": 4876
    },
    {
      "epoch": 0.5592248595344571,
      "grad_norm": 0.0,
      "learning_rate": 0.000428715914732594,
      "loss": 4.8216,
      "step": 4877
    },
    {
      "epoch": 0.5593395252837977,
      "grad_norm": 0.0,
      "learning_rate": 0.0004285321426990942,
      "loss": 4.9615,
      "step": 4878
    },
    {
      "epoch": 0.5594541910331384,
      "grad_norm": 0.0,
      "learning_rate": 0.0004283483805301196,
      "loss": 4.8664,
      "step": 4879
    },
    {
      "epoch": 0.559568856782479,
      "grad_norm": 0.0,
      "learning_rate": 0.00042816462825101656,
      "loss": 4.9333,
      "step": 4880
    },
    {
      "epoch": 0.5596835225318197,
      "grad_norm": 0.0,
      "learning_rate": 0.0004279808858871303,
      "loss": 4.9264,
      "step": 4881
    },
    {
      "epoch": 0.5597981882811605,
      "grad_norm": 0.0,
      "learning_rate": 0.00042779715346380454,
      "loss": 5.2677,
      "step": 4882
    },
    {
      "epoch": 0.5599128540305011,
      "grad_norm": 0.0,
      "learning_rate": 0.0004276134310063817,
      "loss": 4.9485,
      "step": 4883
    },
    {
      "epoch": 0.5600275197798418,
      "grad_norm": 0.0,
      "learning_rate": 0.000427429718540203,
      "loss": 5.0684,
      "step": 4884
    },
    {
      "epoch": 0.5601421855291824,
      "grad_norm": 0.0,
      "learning_rate": 0.00042724601609060763,
      "loss": 5.1064,
      "step": 4885
    },
    {
      "epoch": 0.5602568512785231,
      "grad_norm": 0.0,
      "learning_rate": 0.00042706232368293416,
      "loss": 4.9529,
      "step": 4886
    },
    {
      "epoch": 0.5603715170278638,
      "grad_norm": 0.0,
      "learning_rate": 0.00042687864134251935,
      "loss": 4.8904,
      "step": 4887
    },
    {
      "epoch": 0.5604861827772044,
      "grad_norm": 0.0,
      "learning_rate": 0.00042669496909469867,
      "loss": 4.816,
      "step": 4888
    },
    {
      "epoch": 0.5606008485265451,
      "grad_norm": 0.0,
      "learning_rate": 0.00042651130696480624,
      "loss": 4.7695,
      "step": 4889
    },
    {
      "epoch": 0.5607155142758858,
      "grad_norm": 0.0,
      "learning_rate": 0.0004263276549781748,
      "loss": 4.8842,
      "step": 4890
    },
    {
      "epoch": 0.5608301800252264,
      "grad_norm": 0.0,
      "learning_rate": 0.00042614401316013546,
      "loss": 4.9398,
      "step": 4891
    },
    {
      "epoch": 0.5609448457745672,
      "grad_norm": 0.0,
      "learning_rate": 0.00042596038153601824,
      "loss": 5.0343,
      "step": 4892
    },
    {
      "epoch": 0.5610595115239078,
      "grad_norm": 0.0,
      "learning_rate": 0.0004257767601311517,
      "loss": 5.0151,
      "step": 4893
    },
    {
      "epoch": 0.5611741772732485,
      "grad_norm": 0.0,
      "learning_rate": 0.0004255931489708627,
      "loss": 5.377,
      "step": 4894
    },
    {
      "epoch": 0.5612888430225892,
      "grad_norm": 0.0,
      "learning_rate": 0.0004254095480804773,
      "loss": 4.9633,
      "step": 4895
    },
    {
      "epoch": 0.5614035087719298,
      "grad_norm": 0.0,
      "learning_rate": 0.00042522595748531927,
      "loss": 4.9721,
      "step": 4896
    },
    {
      "epoch": 0.5615181745212705,
      "grad_norm": 0.0,
      "learning_rate": 0.00042504237721071166,
      "loss": 4.9318,
      "step": 4897
    },
    {
      "epoch": 0.5616328402706112,
      "grad_norm": 0.0,
      "learning_rate": 0.0004248588072819757,
      "loss": 5.0087,
      "step": 4898
    },
    {
      "epoch": 0.5617475060199518,
      "grad_norm": 0.0,
      "learning_rate": 0.0004246752477244317,
      "loss": 4.9031,
      "step": 4899
    },
    {
      "epoch": 0.5618621717692925,
      "grad_norm": 0.0,
      "learning_rate": 0.0004244916985633978,
      "loss": 5.1133,
      "step": 4900
    },
    {
      "epoch": 0.5619768375186331,
      "grad_norm": 0.0,
      "learning_rate": 0.0004243081598241915,
      "loss": 5.3289,
      "step": 4901
    },
    {
      "epoch": 0.5620915032679739,
      "grad_norm": 0.0,
      "learning_rate": 0.0004241246315321282,
      "loss": 5.3185,
      "step": 4902
    },
    {
      "epoch": 0.5622061690173146,
      "grad_norm": 0.0,
      "learning_rate": 0.0004239411137125222,
      "loss": 4.8394,
      "step": 4903
    },
    {
      "epoch": 0.5623208347666552,
      "grad_norm": 0.0,
      "learning_rate": 0.0004237576063906863,
      "loss": 5.0629,
      "step": 4904
    },
    {
      "epoch": 0.5624355005159959,
      "grad_norm": 0.0,
      "learning_rate": 0.00042357410959193174,
      "loss": 4.83,
      "step": 4905
    },
    {
      "epoch": 0.5625501662653365,
      "grad_norm": 0.0,
      "learning_rate": 0.00042339062334156873,
      "loss": 5.0218,
      "step": 4906
    },
    {
      "epoch": 0.5626648320146772,
      "grad_norm": 0.0,
      "learning_rate": 0.00042320714766490547,
      "loss": 4.9012,
      "step": 4907
    },
    {
      "epoch": 0.5627794977640179,
      "grad_norm": 0.0,
      "learning_rate": 0.0004230236825872488,
      "loss": 4.8047,
      "step": 4908
    },
    {
      "epoch": 0.5628941635133585,
      "grad_norm": 0.0,
      "learning_rate": 0.00042284022813390425,
      "loss": 5.0904,
      "step": 4909
    },
    {
      "epoch": 0.5630088292626992,
      "grad_norm": 0.0,
      "learning_rate": 0.00042265678433017615,
      "loss": 4.8097,
      "step": 4910
    },
    {
      "epoch": 0.56312349501204,
      "grad_norm": 0.0,
      "learning_rate": 0.00042247335120136674,
      "loss": 5.0058,
      "step": 4911
    },
    {
      "epoch": 0.5632381607613806,
      "grad_norm": 0.0,
      "learning_rate": 0.0004222899287727775,
      "loss": 5.0718,
      "step": 4912
    },
    {
      "epoch": 0.5633528265107213,
      "grad_norm": 0.0,
      "learning_rate": 0.0004221065170697077,
      "loss": 4.9327,
      "step": 4913
    },
    {
      "epoch": 0.5634674922600619,
      "grad_norm": 0.0,
      "learning_rate": 0.00042192311611745565,
      "loss": 5.1879,
      "step": 4914
    },
    {
      "epoch": 0.5635821580094026,
      "grad_norm": 0.0,
      "learning_rate": 0.00042173972594131804,
      "loss": 5.1711,
      "step": 4915
    },
    {
      "epoch": 0.5636968237587433,
      "grad_norm": 0.0,
      "learning_rate": 0.00042155634656658995,
      "loss": 5.0035,
      "step": 4916
    },
    {
      "epoch": 0.5638114895080839,
      "grad_norm": 0.0,
      "learning_rate": 0.0004213729780185653,
      "loss": 4.8761,
      "step": 4917
    },
    {
      "epoch": 0.5639261552574246,
      "grad_norm": 0.0,
      "learning_rate": 0.000421189620322536,
      "loss": 4.8201,
      "step": 4918
    },
    {
      "epoch": 0.5640408210067652,
      "grad_norm": 0.0,
      "learning_rate": 0.00042100627350379283,
      "loss": 4.7221,
      "step": 4919
    },
    {
      "epoch": 0.5641554867561059,
      "grad_norm": 0.0,
      "learning_rate": 0.00042082293758762495,
      "loss": 5.02,
      "step": 4920
    },
    {
      "epoch": 0.5642701525054467,
      "grad_norm": 0.0,
      "learning_rate": 0.00042063961259932017,
      "loss": 5.0379,
      "step": 4921
    },
    {
      "epoch": 0.5643848182547873,
      "grad_norm": 0.0,
      "learning_rate": 0.0004204562985641647,
      "loss": 5.097,
      "step": 4922
    },
    {
      "epoch": 0.564499484004128,
      "grad_norm": 0.0,
      "learning_rate": 0.00042027299550744315,
      "loss": 4.7372,
      "step": 4923
    },
    {
      "epoch": 0.5646141497534687,
      "grad_norm": 0.0,
      "learning_rate": 0.0004200897034544386,
      "loss": 5.1498,
      "step": 4924
    },
    {
      "epoch": 0.5647288155028093,
      "grad_norm": 0.0,
      "learning_rate": 0.0004199064224304328,
      "loss": 5.128,
      "step": 4925
    },
    {
      "epoch": 0.56484348125215,
      "grad_norm": 0.0,
      "learning_rate": 0.0004197231524607058,
      "loss": 5.345,
      "step": 4926
    },
    {
      "epoch": 0.5649581470014906,
      "grad_norm": 0.0,
      "learning_rate": 0.0004195398935705364,
      "loss": 4.7241,
      "step": 4927
    },
    {
      "epoch": 0.5650728127508313,
      "grad_norm": 0.0,
      "learning_rate": 0.0004193566457852015,
      "loss": 4.9907,
      "step": 4928
    },
    {
      "epoch": 0.565187478500172,
      "grad_norm": 0.0,
      "learning_rate": 0.00041917340912997665,
      "loss": 4.8081,
      "step": 4929
    },
    {
      "epoch": 0.5653021442495126,
      "grad_norm": 0.0,
      "learning_rate": 0.0004189901836301357,
      "loss": 4.8369,
      "step": 4930
    },
    {
      "epoch": 0.5654168099988534,
      "grad_norm": 0.0,
      "learning_rate": 0.0004188069693109514,
      "loss": 4.8082,
      "step": 4931
    },
    {
      "epoch": 0.5655314757481941,
      "grad_norm": 0.0,
      "learning_rate": 0.0004186237661976945,
      "loss": 5.3771,
      "step": 4932
    },
    {
      "epoch": 0.5656461414975347,
      "grad_norm": 0.0,
      "learning_rate": 0.00041844057431563445,
      "loss": 4.8707,
      "step": 4933
    },
    {
      "epoch": 0.5657608072468754,
      "grad_norm": 0.0,
      "learning_rate": 0.0004182573936900391,
      "loss": 5.095,
      "step": 4934
    },
    {
      "epoch": 0.565875472996216,
      "grad_norm": 0.0,
      "learning_rate": 0.00041807422434617466,
      "loss": 4.8657,
      "step": 4935
    },
    {
      "epoch": 0.5659901387455567,
      "grad_norm": 0.0,
      "learning_rate": 0.00041789106630930585,
      "loss": 4.9644,
      "step": 4936
    },
    {
      "epoch": 0.5661048044948974,
      "grad_norm": 0.0,
      "learning_rate": 0.0004177079196046959,
      "loss": 5.2693,
      "step": 4937
    },
    {
      "epoch": 0.566219470244238,
      "grad_norm": 0.0,
      "learning_rate": 0.0004175247842576063,
      "loss": 4.8303,
      "step": 4938
    },
    {
      "epoch": 0.5663341359935787,
      "grad_norm": 0.0,
      "learning_rate": 0.00041734166029329725,
      "loss": 5.0268,
      "step": 4939
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 0.0,
      "learning_rate": 0.00041715854773702695,
      "loss": 4.9552,
      "step": 4940
    },
    {
      "epoch": 0.56656346749226,
      "grad_norm": 0.0,
      "learning_rate": 0.00041697544661405253,
      "loss": 4.8632,
      "step": 4941
    },
    {
      "epoch": 0.5666781332416008,
      "grad_norm": 0.0,
      "learning_rate": 0.0004167923569496291,
      "loss": 5.1418,
      "step": 4942
    },
    {
      "epoch": 0.5667927989909414,
      "grad_norm": 0.0,
      "learning_rate": 0.00041660927876901056,
      "loss": 5.0105,
      "step": 4943
    },
    {
      "epoch": 0.5669074647402821,
      "grad_norm": 0.0,
      "learning_rate": 0.00041642621209744894,
      "loss": 4.9946,
      "step": 4944
    },
    {
      "epoch": 0.5670221304896228,
      "grad_norm": 0.0,
      "learning_rate": 0.000416243156960195,
      "loss": 5.1872,
      "step": 4945
    },
    {
      "epoch": 0.5671367962389634,
      "grad_norm": 0.0,
      "learning_rate": 0.0004160601133824974,
      "loss": 5.0069,
      "step": 4946
    },
    {
      "epoch": 0.5672514619883041,
      "grad_norm": 0.0,
      "learning_rate": 0.0004158770813896038,
      "loss": 4.8094,
      "step": 4947
    },
    {
      "epoch": 0.5673661277376447,
      "grad_norm": 0.0,
      "learning_rate": 0.00041569406100675974,
      "loss": 4.8272,
      "step": 4948
    },
    {
      "epoch": 0.5674807934869854,
      "grad_norm": 0.0,
      "learning_rate": 0.0004155110522592094,
      "loss": 4.9563,
      "step": 4949
    },
    {
      "epoch": 0.5675954592363261,
      "grad_norm": 0.0,
      "learning_rate": 0.0004153280551721957,
      "loss": 4.979,
      "step": 4950
    },
    {
      "epoch": 0.5677101249856668,
      "grad_norm": 0.0,
      "learning_rate": 0.00041514506977095915,
      "loss": 5.0085,
      "step": 4951
    },
    {
      "epoch": 0.5678247907350075,
      "grad_norm": 0.0,
      "learning_rate": 0.00041496209608073934,
      "loss": 5.3669,
      "step": 4952
    },
    {
      "epoch": 0.5679394564843481,
      "grad_norm": 0.0,
      "learning_rate": 0.0004147791341267739,
      "loss": 4.9038,
      "step": 4953
    },
    {
      "epoch": 0.5680541222336888,
      "grad_norm": 0.0,
      "learning_rate": 0.00041459618393429904,
      "loss": 5.1049,
      "step": 4954
    },
    {
      "epoch": 0.5681687879830295,
      "grad_norm": 0.0,
      "learning_rate": 0.0004144132455285492,
      "loss": 4.941,
      "step": 4955
    },
    {
      "epoch": 0.5682834537323701,
      "grad_norm": 0.0,
      "learning_rate": 0.0004142303189347573,
      "loss": 4.9448,
      "step": 4956
    },
    {
      "epoch": 0.5683981194817108,
      "grad_norm": 0.0,
      "learning_rate": 0.00041404740417815456,
      "loss": 5.014,
      "step": 4957
    },
    {
      "epoch": 0.5685127852310515,
      "grad_norm": 0.0,
      "learning_rate": 0.0004138645012839705,
      "loss": 5.0926,
      "step": 4958
    },
    {
      "epoch": 0.5686274509803921,
      "grad_norm": 0.0,
      "learning_rate": 0.0004136816102774331,
      "loss": 4.6634,
      "step": 4959
    },
    {
      "epoch": 0.5687421167297328,
      "grad_norm": 0.0,
      "learning_rate": 0.00041349873118376874,
      "loss": 4.8961,
      "step": 4960
    },
    {
      "epoch": 0.5688567824790735,
      "grad_norm": 0.0,
      "learning_rate": 0.0004133158640282022,
      "loss": 4.7954,
      "step": 4961
    },
    {
      "epoch": 0.5689714482284142,
      "grad_norm": 0.0,
      "learning_rate": 0.00041313300883595626,
      "loss": 4.9036,
      "step": 4962
    },
    {
      "epoch": 0.5690861139777549,
      "grad_norm": 0.0,
      "learning_rate": 0.0004129501656322526,
      "loss": 4.9796,
      "step": 4963
    },
    {
      "epoch": 0.5692007797270955,
      "grad_norm": 0.0,
      "learning_rate": 0.0004127673344423107,
      "loss": 5.1051,
      "step": 4964
    },
    {
      "epoch": 0.5693154454764362,
      "grad_norm": 0.0,
      "learning_rate": 0.0004125845152913487,
      "loss": 4.991,
      "step": 4965
    },
    {
      "epoch": 0.5694301112257769,
      "grad_norm": 0.0,
      "learning_rate": 0.00041240170820458315,
      "loss": 5.1032,
      "step": 4966
    },
    {
      "epoch": 0.5695447769751175,
      "grad_norm": 0.0,
      "learning_rate": 0.00041221891320722886,
      "loss": 5.1382,
      "step": 4967
    },
    {
      "epoch": 0.5696594427244582,
      "grad_norm": 0.0,
      "learning_rate": 0.00041203613032449876,
      "loss": 4.8187,
      "step": 4968
    },
    {
      "epoch": 0.5697741084737988,
      "grad_norm": 0.0,
      "learning_rate": 0.00041185335958160424,
      "loss": 5.0984,
      "step": 4969
    },
    {
      "epoch": 0.5698887742231395,
      "grad_norm": 0.0,
      "learning_rate": 0.00041167060100375495,
      "loss": 5.138,
      "step": 4970
    },
    {
      "epoch": 0.5700034399724803,
      "grad_norm": 0.0,
      "learning_rate": 0.0004114878546161592,
      "loss": 5.0169,
      "step": 4971
    },
    {
      "epoch": 0.5701181057218209,
      "grad_norm": 0.0,
      "learning_rate": 0.0004113051204440233,
      "loss": 5.0472,
      "step": 4972
    },
    {
      "epoch": 0.5702327714711616,
      "grad_norm": 0.0,
      "learning_rate": 0.0004111223985125518,
      "loss": 5.3003,
      "step": 4973
    },
    {
      "epoch": 0.5703474372205022,
      "grad_norm": 0.0,
      "learning_rate": 0.00041093968884694783,
      "loss": 4.8423,
      "step": 4974
    },
    {
      "epoch": 0.5704621029698429,
      "grad_norm": 0.0,
      "learning_rate": 0.00041075699147241276,
      "loss": 4.8798,
      "step": 4975
    },
    {
      "epoch": 0.5705767687191836,
      "grad_norm": 0.0,
      "learning_rate": 0.000410574306414146,
      "loss": 4.9111,
      "step": 4976
    },
    {
      "epoch": 0.5706914344685242,
      "grad_norm": 0.0,
      "learning_rate": 0.00041039163369734565,
      "loss": 4.9159,
      "step": 4977
    },
    {
      "epoch": 0.5708061002178649,
      "grad_norm": 0.0,
      "learning_rate": 0.0004102089733472082,
      "loss": 5.039,
      "step": 4978
    },
    {
      "epoch": 0.5709207659672056,
      "grad_norm": 0.0,
      "learning_rate": 0.0004100263253889275,
      "loss": 5.0787,
      "step": 4979
    },
    {
      "epoch": 0.5710354317165462,
      "grad_norm": 0.0,
      "learning_rate": 0.0004098436898476968,
      "loss": 5.0562,
      "step": 4980
    },
    {
      "epoch": 0.571150097465887,
      "grad_norm": 0.0,
      "learning_rate": 0.00040966106674870706,
      "loss": 5.1366,
      "step": 4981
    },
    {
      "epoch": 0.5712647632152276,
      "grad_norm": 0.0,
      "learning_rate": 0.0004094784561171477,
      "loss": 4.911,
      "step": 4982
    },
    {
      "epoch": 0.5713794289645683,
      "grad_norm": 0.0,
      "learning_rate": 0.00040929585797820644,
      "loss": 5.2339,
      "step": 4983
    },
    {
      "epoch": 0.571494094713909,
      "grad_norm": 0.0,
      "learning_rate": 0.0004091132723570691,
      "loss": 5.0197,
      "step": 4984
    },
    {
      "epoch": 0.5716087604632496,
      "grad_norm": 0.0,
      "learning_rate": 0.0004089306992789199,
      "loss": 5.0815,
      "step": 4985
    },
    {
      "epoch": 0.5717234262125903,
      "grad_norm": 0.0,
      "learning_rate": 0.00040874813876894123,
      "loss": 4.9586,
      "step": 4986
    },
    {
      "epoch": 0.5718380919619309,
      "grad_norm": 0.0,
      "learning_rate": 0.00040856559085231407,
      "loss": 5.0959,
      "step": 4987
    },
    {
      "epoch": 0.5719527577112716,
      "grad_norm": 0.0,
      "learning_rate": 0.0004083830555542173,
      "loss": 4.8088,
      "step": 4988
    },
    {
      "epoch": 0.5720674234606123,
      "grad_norm": 0.0,
      "learning_rate": 0.0004082005328998283,
      "loss": 5.1263,
      "step": 4989
    },
    {
      "epoch": 0.572182089209953,
      "grad_norm": 0.0,
      "learning_rate": 0.00040801802291432236,
      "loss": 5.1598,
      "step": 4990
    },
    {
      "epoch": 0.5722967549592937,
      "grad_norm": 0.0,
      "learning_rate": 0.00040783552562287335,
      "loss": 4.9996,
      "step": 4991
    },
    {
      "epoch": 0.5724114207086344,
      "grad_norm": 0.0,
      "learning_rate": 0.0004076530410506534,
      "loss": 5.2033,
      "step": 4992
    },
    {
      "epoch": 0.572526086457975,
      "grad_norm": 0.0,
      "learning_rate": 0.00040747056922283255,
      "loss": 4.9157,
      "step": 4993
    },
    {
      "epoch": 0.5726407522073157,
      "grad_norm": 0.0,
      "learning_rate": 0.00040728811016457956,
      "loss": 5.0292,
      "step": 4994
    },
    {
      "epoch": 0.5727554179566563,
      "grad_norm": 0.0,
      "learning_rate": 0.0004071056639010611,
      "loss": 4.8931,
      "step": 4995
    },
    {
      "epoch": 0.572870083705997,
      "grad_norm": 0.0,
      "learning_rate": 0.000406923230457442,
      "loss": 5.0833,
      "step": 4996
    },
    {
      "epoch": 0.5729847494553377,
      "grad_norm": 0.0,
      "learning_rate": 0.0004067408098588856,
      "loss": 5.2384,
      "step": 4997
    },
    {
      "epoch": 0.5730994152046783,
      "grad_norm": 0.0,
      "learning_rate": 0.0004065584021305535,
      "loss": 4.983,
      "step": 4998
    },
    {
      "epoch": 0.573214080954019,
      "grad_norm": 0.0,
      "learning_rate": 0.00040637600729760513,
      "loss": 5.1864,
      "step": 4999
    },
    {
      "epoch": 0.5733287467033598,
      "grad_norm": 0.0,
      "learning_rate": 0.0004061936253851985,
      "loss": 4.9216,
      "step": 5000
    },
    {
      "epoch": 0.5734434124527004,
      "grad_norm": 0.0,
      "learning_rate": 0.00040601125641848964,
      "loss": 5.1844,
      "step": 5001
    },
    {
      "epoch": 0.5735580782020411,
      "grad_norm": 0.0,
      "learning_rate": 0.00040582890042263294,
      "loss": 5.2831,
      "step": 5002
    },
    {
      "epoch": 0.5736727439513817,
      "grad_norm": 0.0,
      "learning_rate": 0.0004056465574227808,
      "loss": 5.0223,
      "step": 5003
    },
    {
      "epoch": 0.5737874097007224,
      "grad_norm": 0.0,
      "learning_rate": 0.00040546422744408415,
      "loss": 5.038,
      "step": 5004
    },
    {
      "epoch": 0.5739020754500631,
      "grad_norm": 0.0,
      "learning_rate": 0.0004052819105116919,
      "loss": 5.0323,
      "step": 5005
    },
    {
      "epoch": 0.5740167411994037,
      "grad_norm": 0.0,
      "learning_rate": 0.0004050996066507511,
      "loss": 5.046,
      "step": 5006
    },
    {
      "epoch": 0.5741314069487444,
      "grad_norm": 0.0,
      "learning_rate": 0.0004049173158864072,
      "loss": 4.8269,
      "step": 5007
    },
    {
      "epoch": 0.574246072698085,
      "grad_norm": 0.0,
      "learning_rate": 0.0004047350382438036,
      "loss": 4.9567,
      "step": 5008
    },
    {
      "epoch": 0.5743607384474257,
      "grad_norm": 0.0,
      "learning_rate": 0.0004045527737480822,
      "loss": 5.0112,
      "step": 5009
    },
    {
      "epoch": 0.5744754041967665,
      "grad_norm": 0.0,
      "learning_rate": 0.0004043705224243827,
      "loss": 5.1311,
      "step": 5010
    },
    {
      "epoch": 0.5745900699461071,
      "grad_norm": 0.0,
      "learning_rate": 0.00040418828429784345,
      "loss": 4.8496,
      "step": 5011
    },
    {
      "epoch": 0.5747047356954478,
      "grad_norm": 0.0,
      "learning_rate": 0.0004040060593936005,
      "loss": 4.9889,
      "step": 5012
    },
    {
      "epoch": 0.5748194014447885,
      "grad_norm": 0.0,
      "learning_rate": 0.00040382384773678836,
      "loss": 5.1688,
      "step": 5013
    },
    {
      "epoch": 0.5749340671941291,
      "grad_norm": 0.0,
      "learning_rate": 0.0004036416493525397,
      "loss": 5.0363,
      "step": 5014
    },
    {
      "epoch": 0.5750487329434698,
      "grad_norm": 0.0,
      "learning_rate": 0.00040345946426598536,
      "loss": 4.8816,
      "step": 5015
    },
    {
      "epoch": 0.5751633986928104,
      "grad_norm": 0.0,
      "learning_rate": 0.00040327729250225425,
      "loss": 4.9729,
      "step": 5016
    },
    {
      "epoch": 0.5752780644421511,
      "grad_norm": 0.0,
      "learning_rate": 0.00040309513408647344,
      "loss": 5.0965,
      "step": 5017
    },
    {
      "epoch": 0.5753927301914918,
      "grad_norm": 0.0,
      "learning_rate": 0.00040291298904376833,
      "loss": 5.1016,
      "step": 5018
    },
    {
      "epoch": 0.5755073959408324,
      "grad_norm": 0.0,
      "learning_rate": 0.0004027308573992622,
      "loss": 4.7682,
      "step": 5019
    },
    {
      "epoch": 0.5756220616901732,
      "grad_norm": 0.0,
      "learning_rate": 0.00040254873917807673,
      "loss": 5.089,
      "step": 5020
    },
    {
      "epoch": 0.5757367274395138,
      "grad_norm": 0.0,
      "learning_rate": 0.00040236663440533163,
      "loss": 4.9519,
      "step": 5021
    },
    {
      "epoch": 0.5758513931888545,
      "grad_norm": 0.0,
      "learning_rate": 0.00040218454310614484,
      "loss": 4.8241,
      "step": 5022
    },
    {
      "epoch": 0.5759660589381952,
      "grad_norm": 0.0,
      "learning_rate": 0.00040200246530563234,
      "loss": 4.7609,
      "step": 5023
    },
    {
      "epoch": 0.5760807246875358,
      "grad_norm": 0.0,
      "learning_rate": 0.0004018204010289082,
      "loss": 4.6344,
      "step": 5024
    },
    {
      "epoch": 0.5761953904368765,
      "grad_norm": 0.0,
      "learning_rate": 0.0004016383503010849,
      "loss": 4.9224,
      "step": 5025
    },
    {
      "epoch": 0.5763100561862172,
      "grad_norm": 0.0,
      "learning_rate": 0.0004014563131472727,
      "loss": 5.2148,
      "step": 5026
    },
    {
      "epoch": 0.5764247219355578,
      "grad_norm": 0.0,
      "learning_rate": 0.00040127428959258046,
      "loss": 5.3165,
      "step": 5027
    },
    {
      "epoch": 0.5765393876848985,
      "grad_norm": 0.0,
      "learning_rate": 0.00040109227966211446,
      "loss": 5.1246,
      "step": 5028
    },
    {
      "epoch": 0.5766540534342391,
      "grad_norm": 0.0,
      "learning_rate": 0.00040091028338097974,
      "loss": 4.9328,
      "step": 5029
    },
    {
      "epoch": 0.5767687191835799,
      "grad_norm": 0.0,
      "learning_rate": 0.00040072830077427906,
      "loss": 4.8114,
      "step": 5030
    },
    {
      "epoch": 0.5768833849329206,
      "grad_norm": 0.0,
      "learning_rate": 0.0004005463318671136,
      "loss": 4.9613,
      "step": 5031
    },
    {
      "epoch": 0.5769980506822612,
      "grad_norm": 0.0,
      "learning_rate": 0.00040036437668458235,
      "loss": 4.9891,
      "step": 5032
    },
    {
      "epoch": 0.5771127164316019,
      "grad_norm": 0.0,
      "learning_rate": 0.00040018243525178287,
      "loss": 4.9196,
      "step": 5033
    },
    {
      "epoch": 0.5772273821809426,
      "grad_norm": 0.0,
      "learning_rate": 0.0004000005075938101,
      "loss": 4.9201,
      "step": 5034
    },
    {
      "epoch": 0.5773420479302832,
      "grad_norm": 0.0,
      "learning_rate": 0.0003998185937357578,
      "loss": 4.923,
      "step": 5035
    },
    {
      "epoch": 0.5774567136796239,
      "grad_norm": 0.0,
      "learning_rate": 0.0003996366937027174,
      "loss": 4.9773,
      "step": 5036
    },
    {
      "epoch": 0.5775713794289645,
      "grad_norm": 0.0,
      "learning_rate": 0.00039945480751977846,
      "loss": 5.0482,
      "step": 5037
    },
    {
      "epoch": 0.5776860451783052,
      "grad_norm": 0.0,
      "learning_rate": 0.0003992729352120289,
      "loss": 5.056,
      "step": 5038
    },
    {
      "epoch": 0.577800710927646,
      "grad_norm": 0.0,
      "learning_rate": 0.00039909107680455454,
      "loss": 4.9565,
      "step": 5039
    },
    {
      "epoch": 0.5779153766769866,
      "grad_norm": 0.0,
      "learning_rate": 0.00039890923232243904,
      "loss": 4.8546,
      "step": 5040
    },
    {
      "epoch": 0.5780300424263273,
      "grad_norm": 0.0,
      "learning_rate": 0.0003987274017907645,
      "loss": 4.9417,
      "step": 5041
    },
    {
      "epoch": 0.5781447081756679,
      "grad_norm": 0.0,
      "learning_rate": 0.000398545585234611,
      "loss": 5.161,
      "step": 5042
    },
    {
      "epoch": 0.5782593739250086,
      "grad_norm": 0.0,
      "learning_rate": 0.0003983637826790567,
      "loss": 5.1647,
      "step": 5043
    },
    {
      "epoch": 0.5783740396743493,
      "grad_norm": 0.0,
      "learning_rate": 0.0003981819941491778,
      "loss": 4.886,
      "step": 5044
    },
    {
      "epoch": 0.5784887054236899,
      "grad_norm": 0.0,
      "learning_rate": 0.0003980002196700485,
      "loss": 4.9877,
      "step": 5045
    },
    {
      "epoch": 0.5786033711730306,
      "grad_norm": 0.0,
      "learning_rate": 0.0003978184592667411,
      "loss": 4.7585,
      "step": 5046
    },
    {
      "epoch": 0.5787180369223713,
      "grad_norm": 0.0,
      "learning_rate": 0.000397636712964326,
      "loss": 4.975,
      "step": 5047
    },
    {
      "epoch": 0.5788327026717119,
      "grad_norm": 0.0,
      "learning_rate": 0.00039745498078787176,
      "loss": 5.0265,
      "step": 5048
    },
    {
      "epoch": 0.5789473684210527,
      "grad_norm": 0.0,
      "learning_rate": 0.00039727326276244496,
      "loss": 4.7509,
      "step": 5049
    },
    {
      "epoch": 0.5790620341703933,
      "grad_norm": 0.0,
      "learning_rate": 0.0003970915589131098,
      "loss": 5.0987,
      "step": 5050
    },
    {
      "epoch": 0.579176699919734,
      "grad_norm": 0.0,
      "learning_rate": 0.00039690986926492895,
      "loss": 5.1513,
      "step": 5051
    },
    {
      "epoch": 0.5792913656690747,
      "grad_norm": 0.0,
      "learning_rate": 0.0003967281938429631,
      "loss": 5.0298,
      "step": 5052
    },
    {
      "epoch": 0.5794060314184153,
      "grad_norm": 0.0,
      "learning_rate": 0.00039654653267227094,
      "loss": 4.9473,
      "step": 5053
    },
    {
      "epoch": 0.579520697167756,
      "grad_norm": 0.0,
      "learning_rate": 0.0003963648857779091,
      "loss": 4.9844,
      "step": 5054
    },
    {
      "epoch": 0.5796353629170966,
      "grad_norm": 0.0,
      "learning_rate": 0.00039618325318493253,
      "loss": 4.8014,
      "step": 5055
    },
    {
      "epoch": 0.5797500286664373,
      "grad_norm": 0.0,
      "learning_rate": 0.0003960016349183937,
      "loss": 5.1114,
      "step": 5056
    },
    {
      "epoch": 0.579864694415778,
      "grad_norm": 0.0,
      "learning_rate": 0.00039582003100334335,
      "loss": 4.9242,
      "step": 5057
    },
    {
      "epoch": 0.5799793601651186,
      "grad_norm": 0.0,
      "learning_rate": 0.00039563844146483053,
      "loss": 4.9105,
      "step": 5058
    },
    {
      "epoch": 0.5800940259144594,
      "grad_norm": 0.0,
      "learning_rate": 0.0003954568663279021,
      "loss": 4.9988,
      "step": 5059
    },
    {
      "epoch": 0.5802086916638001,
      "grad_norm": 0.0,
      "learning_rate": 0.0003952753056176027,
      "loss": 4.925,
      "step": 5060
    },
    {
      "epoch": 0.5803233574131407,
      "grad_norm": 0.0,
      "learning_rate": 0.000395093759358975,
      "loss": 5.1896,
      "step": 5061
    },
    {
      "epoch": 0.5804380231624814,
      "grad_norm": 0.0,
      "learning_rate": 0.00039491222757706015,
      "loss": 4.9871,
      "step": 5062
    },
    {
      "epoch": 0.580552688911822,
      "grad_norm": 0.0,
      "learning_rate": 0.0003947307102968969,
      "loss": 4.9359,
      "step": 5063
    },
    {
      "epoch": 0.5806673546611627,
      "grad_norm": 0.0,
      "learning_rate": 0.00039454920754352203,
      "loss": 4.8332,
      "step": 5064
    },
    {
      "epoch": 0.5807820204105034,
      "grad_norm": 0.0,
      "learning_rate": 0.00039436771934197044,
      "loss": 4.907,
      "step": 5065
    },
    {
      "epoch": 0.580896686159844,
      "grad_norm": 0.0,
      "learning_rate": 0.0003941862457172752,
      "loss": 5.0122,
      "step": 5066
    },
    {
      "epoch": 0.5810113519091847,
      "grad_norm": 0.0,
      "learning_rate": 0.0003940047866944667,
      "loss": 5.4359,
      "step": 5067
    },
    {
      "epoch": 0.5811260176585255,
      "grad_norm": 0.0,
      "learning_rate": 0.00039382334229857405,
      "loss": 5.0709,
      "step": 5068
    },
    {
      "epoch": 0.581240683407866,
      "grad_norm": 0.0,
      "learning_rate": 0.00039364191255462396,
      "loss": 5.0558,
      "step": 5069
    },
    {
      "epoch": 0.5813553491572068,
      "grad_norm": 0.0,
      "learning_rate": 0.00039346049748764124,
      "loss": 5.1881,
      "step": 5070
    },
    {
      "epoch": 0.5814700149065474,
      "grad_norm": 0.0,
      "learning_rate": 0.00039327909712264864,
      "loss": 4.9056,
      "step": 5071
    },
    {
      "epoch": 0.5815846806558881,
      "grad_norm": 0.0,
      "learning_rate": 0.0003930977114846668,
      "loss": 5.0193,
      "step": 5072
    },
    {
      "epoch": 0.5816993464052288,
      "grad_norm": 0.0,
      "learning_rate": 0.00039291634059871437,
      "loss": 4.9331,
      "step": 5073
    },
    {
      "epoch": 0.5818140121545694,
      "grad_norm": 0.0,
      "learning_rate": 0.00039273498448980814,
      "loss": 5.2948,
      "step": 5074
    },
    {
      "epoch": 0.5819286779039101,
      "grad_norm": 0.0,
      "learning_rate": 0.0003925536431829627,
      "loss": 4.974,
      "step": 5075
    },
    {
      "epoch": 0.5820433436532507,
      "grad_norm": 0.0,
      "learning_rate": 0.0003923723167031906,
      "loss": 4.9187,
      "step": 5076
    },
    {
      "epoch": 0.5821580094025914,
      "grad_norm": 0.0,
      "learning_rate": 0.0003921910050755026,
      "loss": 5.145,
      "step": 5077
    },
    {
      "epoch": 0.5822726751519322,
      "grad_norm": 0.0,
      "learning_rate": 0.0003920097083249067,
      "loss": 4.6478,
      "step": 5078
    },
    {
      "epoch": 0.5823873409012728,
      "grad_norm": 0.0,
      "learning_rate": 0.0003918284264764097,
      "loss": 4.9929,
      "step": 5079
    },
    {
      "epoch": 0.5825020066506135,
      "grad_norm": 0.0,
      "learning_rate": 0.00039164715955501597,
      "loss": 5.0387,
      "step": 5080
    },
    {
      "epoch": 0.5826166723999542,
      "grad_norm": 0.0,
      "learning_rate": 0.00039146590758572757,
      "loss": 4.9024,
      "step": 5081
    },
    {
      "epoch": 0.5827313381492948,
      "grad_norm": 0.0,
      "learning_rate": 0.0003912846705935451,
      "loss": 4.9579,
      "step": 5082
    },
    {
      "epoch": 0.5828460038986355,
      "grad_norm": 0.0,
      "learning_rate": 0.00039110344860346645,
      "loss": 5.2127,
      "step": 5083
    },
    {
      "epoch": 0.5829606696479761,
      "grad_norm": 0.0,
      "learning_rate": 0.0003909222416404878,
      "loss": 4.8459,
      "step": 5084
    },
    {
      "epoch": 0.5830753353973168,
      "grad_norm": 0.0,
      "learning_rate": 0.00039074104972960336,
      "loss": 5.1383,
      "step": 5085
    },
    {
      "epoch": 0.5831900011466575,
      "grad_norm": 0.0,
      "learning_rate": 0.00039055987289580486,
      "loss": 4.8869,
      "step": 5086
    },
    {
      "epoch": 0.5833046668959981,
      "grad_norm": 0.0,
      "learning_rate": 0.0003903787111640824,
      "loss": 4.9845,
      "step": 5087
    },
    {
      "epoch": 0.5834193326453389,
      "grad_norm": 0.0,
      "learning_rate": 0.00039019756455942385,
      "loss": 4.9883,
      "step": 5088
    },
    {
      "epoch": 0.5835339983946795,
      "grad_norm": 0.0,
      "learning_rate": 0.0003900164331068146,
      "loss": 4.9906,
      "step": 5089
    },
    {
      "epoch": 0.5836486641440202,
      "grad_norm": 0.0,
      "learning_rate": 0.00038983531683123865,
      "loss": 5.095,
      "step": 5090
    },
    {
      "epoch": 0.5837633298933609,
      "grad_norm": 0.0,
      "learning_rate": 0.00038965421575767715,
      "loss": 5.102,
      "step": 5091
    },
    {
      "epoch": 0.5838779956427015,
      "grad_norm": 0.0,
      "learning_rate": 0.00038947312991110985,
      "loss": 5.0568,
      "step": 5092
    },
    {
      "epoch": 0.5839926613920422,
      "grad_norm": 0.0,
      "learning_rate": 0.000389292059316514,
      "loss": 5.1509,
      "step": 5093
    },
    {
      "epoch": 0.5841073271413829,
      "grad_norm": 0.0,
      "learning_rate": 0.00038911100399886486,
      "loss": 4.7762,
      "step": 5094
    },
    {
      "epoch": 0.5842219928907235,
      "grad_norm": 0.0,
      "learning_rate": 0.00038892996398313544,
      "loss": 4.8914,
      "step": 5095
    },
    {
      "epoch": 0.5843366586400642,
      "grad_norm": 0.0,
      "learning_rate": 0.00038874893929429687,
      "loss": 5.2754,
      "step": 5096
    },
    {
      "epoch": 0.5844513243894048,
      "grad_norm": 0.0,
      "learning_rate": 0.00038856792995731806,
      "loss": 5.0764,
      "step": 5097
    },
    {
      "epoch": 0.5845659901387456,
      "grad_norm": 0.0,
      "learning_rate": 0.00038838693599716574,
      "loss": 5.0759,
      "step": 5098
    },
    {
      "epoch": 0.5846806558880863,
      "grad_norm": 0.0,
      "learning_rate": 0.00038820595743880464,
      "loss": 4.7704,
      "step": 5099
    },
    {
      "epoch": 0.5847953216374269,
      "grad_norm": 0.0,
      "learning_rate": 0.0003880249943071974,
      "loss": 5.2211,
      "step": 5100
    },
    {
      "epoch": 0.5849099873867676,
      "grad_norm": 0.0,
      "learning_rate": 0.0003878440466273041,
      "loss": 5.2888,
      "step": 5101
    },
    {
      "epoch": 0.5850246531361083,
      "grad_norm": 0.0,
      "learning_rate": 0.00038766311442408333,
      "loss": 4.784,
      "step": 5102
    },
    {
      "epoch": 0.5851393188854489,
      "grad_norm": 0.0,
      "learning_rate": 0.000387482197722491,
      "loss": 5.0438,
      "step": 5103
    },
    {
      "epoch": 0.5852539846347896,
      "grad_norm": 0.0,
      "learning_rate": 0.0003873012965474815,
      "loss": 5.1837,
      "step": 5104
    },
    {
      "epoch": 0.5853686503841302,
      "grad_norm": 0.0,
      "learning_rate": 0.0003871204109240062,
      "loss": 5.1771,
      "step": 5105
    },
    {
      "epoch": 0.5854833161334709,
      "grad_norm": 0.0,
      "learning_rate": 0.0003869395408770152,
      "loss": 4.8239,
      "step": 5106
    },
    {
      "epoch": 0.5855979818828116,
      "grad_norm": 0.0,
      "learning_rate": 0.00038675868643145596,
      "loss": 4.9512,
      "step": 5107
    },
    {
      "epoch": 0.5857126476321523,
      "grad_norm": 0.0,
      "learning_rate": 0.0003865778476122738,
      "loss": 5.0286,
      "step": 5108
    },
    {
      "epoch": 0.585827313381493,
      "grad_norm": 0.0,
      "learning_rate": 0.00038639702444441217,
      "loss": 4.9183,
      "step": 5109
    },
    {
      "epoch": 0.5859419791308336,
      "grad_norm": 0.0,
      "learning_rate": 0.0003862162169528123,
      "loss": 5.002,
      "step": 5110
    },
    {
      "epoch": 0.5860566448801743,
      "grad_norm": 0.0,
      "learning_rate": 0.00038603542516241267,
      "loss": 5.0817,
      "step": 5111
    },
    {
      "epoch": 0.586171310629515,
      "grad_norm": 0.0,
      "learning_rate": 0.00038585464909815043,
      "loss": 5.0691,
      "step": 5112
    },
    {
      "epoch": 0.5862859763788556,
      "grad_norm": 0.0,
      "learning_rate": 0.00038567388878495997,
      "loss": 5.2725,
      "step": 5113
    },
    {
      "epoch": 0.5864006421281963,
      "grad_norm": 0.0,
      "learning_rate": 0.0003854931442477739,
      "loss": 4.9864,
      "step": 5114
    },
    {
      "epoch": 0.586515307877537,
      "grad_norm": 0.0,
      "learning_rate": 0.0003853124155115225,
      "loss": 5.2006,
      "step": 5115
    },
    {
      "epoch": 0.5866299736268776,
      "grad_norm": 0.0,
      "learning_rate": 0.0003851317026011337,
      "loss": 4.9387,
      "step": 5116
    },
    {
      "epoch": 0.5867446393762183,
      "grad_norm": 0.0,
      "learning_rate": 0.0003849510055415335,
      "loss": 4.9256,
      "step": 5117
    },
    {
      "epoch": 0.586859305125559,
      "grad_norm": 0.0,
      "learning_rate": 0.0003847703243576456,
      "loss": 4.9189,
      "step": 5118
    },
    {
      "epoch": 0.5869739708748997,
      "grad_norm": 0.0,
      "learning_rate": 0.0003845896590743915,
      "loss": 4.6739,
      "step": 5119
    },
    {
      "epoch": 0.5870886366242404,
      "grad_norm": 0.0,
      "learning_rate": 0.00038440900971669067,
      "loss": 4.6941,
      "step": 5120
    },
    {
      "epoch": 0.587203302373581,
      "grad_norm": 0.0,
      "learning_rate": 0.0003842283763094601,
      "loss": 4.8933,
      "step": 5121
    },
    {
      "epoch": 0.5873179681229217,
      "grad_norm": 0.0,
      "learning_rate": 0.00038404775887761466,
      "loss": 5.0125,
      "step": 5122
    },
    {
      "epoch": 0.5874326338722623,
      "grad_norm": 0.0,
      "learning_rate": 0.0003838671574460673,
      "loss": 5.0785,
      "step": 5123
    },
    {
      "epoch": 0.587547299621603,
      "grad_norm": 0.0,
      "learning_rate": 0.0003836865720397283,
      "loss": 4.9876,
      "step": 5124
    },
    {
      "epoch": 0.5876619653709437,
      "grad_norm": 0.0,
      "learning_rate": 0.0003835060026835061,
      "loss": 4.9697,
      "step": 5125
    },
    {
      "epoch": 0.5877766311202843,
      "grad_norm": 0.0,
      "learning_rate": 0.0003833254494023069,
      "loss": 4.9247,
      "step": 5126
    },
    {
      "epoch": 0.587891296869625,
      "grad_norm": 0.0,
      "learning_rate": 0.0003831449122210344,
      "loss": 4.9968,
      "step": 5127
    },
    {
      "epoch": 0.5880059626189658,
      "grad_norm": 0.0,
      "learning_rate": 0.00038296439116459037,
      "loss": 4.9566,
      "step": 5128
    },
    {
      "epoch": 0.5881206283683064,
      "grad_norm": 0.0,
      "learning_rate": 0.0003827838862578742,
      "loss": 4.8713,
      "step": 5129
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.0,
      "learning_rate": 0.0003826033975257832,
      "loss": 5.6107,
      "step": 5130
    },
    {
      "epoch": 0.5883499598669877,
      "grad_norm": 0.0,
      "learning_rate": 0.0003824229249932122,
      "loss": 5.0139,
      "step": 5131
    },
    {
      "epoch": 0.5884646256163284,
      "grad_norm": 0.0,
      "learning_rate": 0.0003822424686850541,
      "loss": 4.891,
      "step": 5132
    },
    {
      "epoch": 0.5885792913656691,
      "grad_norm": 0.0,
      "learning_rate": 0.0003820620286261993,
      "loss": 5.1741,
      "step": 5133
    },
    {
      "epoch": 0.5886939571150097,
      "grad_norm": 0.0,
      "learning_rate": 0.00038188160484153605,
      "loss": 5.0512,
      "step": 5134
    },
    {
      "epoch": 0.5888086228643504,
      "grad_norm": 0.0,
      "learning_rate": 0.00038170119735595045,
      "loss": 5.0466,
      "step": 5135
    },
    {
      "epoch": 0.5889232886136911,
      "grad_norm": 0.0,
      "learning_rate": 0.0003815208061943262,
      "loss": 4.6157,
      "step": 5136
    },
    {
      "epoch": 0.5890379543630317,
      "grad_norm": 0.0,
      "learning_rate": 0.00038134043138154483,
      "loss": 5.094,
      "step": 5137
    },
    {
      "epoch": 0.5891526201123725,
      "grad_norm": 0.0,
      "learning_rate": 0.00038116007294248584,
      "loss": 5.0373,
      "step": 5138
    },
    {
      "epoch": 0.5892672858617131,
      "grad_norm": 0.0,
      "learning_rate": 0.00038097973090202585,
      "loss": 5.1297,
      "step": 5139
    },
    {
      "epoch": 0.5893819516110538,
      "grad_norm": 0.0,
      "learning_rate": 0.0003807994052850399,
      "loss": 5.1165,
      "step": 5140
    },
    {
      "epoch": 0.5894966173603945,
      "grad_norm": 0.0,
      "learning_rate": 0.00038061909611640033,
      "loss": 4.8494,
      "step": 5141
    },
    {
      "epoch": 0.5896112831097351,
      "grad_norm": 0.0,
      "learning_rate": 0.00038043880342097735,
      "loss": 4.8985,
      "step": 5142
    },
    {
      "epoch": 0.5897259488590758,
      "grad_norm": 0.0,
      "learning_rate": 0.00038025852722363906,
      "loss": 5.0038,
      "step": 5143
    },
    {
      "epoch": 0.5898406146084164,
      "grad_norm": 0.0,
      "learning_rate": 0.0003800782675492508,
      "loss": 4.8473,
      "step": 5144
    },
    {
      "epoch": 0.5899552803577571,
      "grad_norm": 0.0,
      "learning_rate": 0.0003798980244226764,
      "loss": 4.9804,
      "step": 5145
    },
    {
      "epoch": 0.5900699461070978,
      "grad_norm": 0.0,
      "learning_rate": 0.00037971779786877654,
      "loss": 5.0301,
      "step": 5146
    },
    {
      "epoch": 0.5901846118564384,
      "grad_norm": 0.0,
      "learning_rate": 0.00037953758791241026,
      "loss": 4.9854,
      "step": 5147
    },
    {
      "epoch": 0.5902992776057792,
      "grad_norm": 0.0,
      "learning_rate": 0.00037935739457843403,
      "loss": 5.1308,
      "step": 5148
    },
    {
      "epoch": 0.5904139433551199,
      "grad_norm": 0.0,
      "learning_rate": 0.0003791772178917023,
      "loss": 4.9763,
      "step": 5149
    },
    {
      "epoch": 0.5905286091044605,
      "grad_norm": 0.0,
      "learning_rate": 0.00037899705787706664,
      "loss": 4.8946,
      "step": 5150
    },
    {
      "epoch": 0.5906432748538012,
      "grad_norm": 0.0,
      "learning_rate": 0.00037881691455937693,
      "loss": 5.0179,
      "step": 5151
    },
    {
      "epoch": 0.5907579406031418,
      "grad_norm": 0.0,
      "learning_rate": 0.0003786367879634804,
      "loss": 5.2436,
      "step": 5152
    },
    {
      "epoch": 0.5908726063524825,
      "grad_norm": 0.0,
      "learning_rate": 0.0003784566781142221,
      "loss": 4.9518,
      "step": 5153
    },
    {
      "epoch": 0.5909872721018232,
      "grad_norm": 0.0,
      "learning_rate": 0.00037827658503644494,
      "loss": 4.9712,
      "step": 5154
    },
    {
      "epoch": 0.5911019378511638,
      "grad_norm": 0.0,
      "learning_rate": 0.000378096508754989,
      "loss": 5.0616,
      "step": 5155
    },
    {
      "epoch": 0.5912166036005045,
      "grad_norm": 0.0,
      "learning_rate": 0.00037791644929469255,
      "loss": 5.132,
      "step": 5156
    },
    {
      "epoch": 0.5913312693498453,
      "grad_norm": 0.0,
      "learning_rate": 0.00037773640668039134,
      "loss": 5.2434,
      "step": 5157
    },
    {
      "epoch": 0.5914459350991859,
      "grad_norm": 0.0,
      "learning_rate": 0.00037755638093691886,
      "loss": 5.3297,
      "step": 5158
    },
    {
      "epoch": 0.5915606008485266,
      "grad_norm": 0.0,
      "learning_rate": 0.00037737637208910607,
      "loss": 5.0548,
      "step": 5159
    },
    {
      "epoch": 0.5916752665978672,
      "grad_norm": 0.0,
      "learning_rate": 0.0003771963801617821,
      "loss": 4.8741,
      "step": 5160
    },
    {
      "epoch": 0.5917899323472079,
      "grad_norm": 0.0,
      "learning_rate": 0.0003770164051797731,
      "loss": 5.0332,
      "step": 5161
    },
    {
      "epoch": 0.5919045980965486,
      "grad_norm": 0.0,
      "learning_rate": 0.00037683644716790326,
      "loss": 5.4897,
      "step": 5162
    },
    {
      "epoch": 0.5920192638458892,
      "grad_norm": 0.0,
      "learning_rate": 0.00037665650615099433,
      "loss": 4.8579,
      "step": 5163
    },
    {
      "epoch": 0.5921339295952299,
      "grad_norm": 0.0,
      "learning_rate": 0.00037647658215386574,
      "loss": 5.106,
      "step": 5164
    },
    {
      "epoch": 0.5922485953445705,
      "grad_norm": 0.0,
      "learning_rate": 0.00037629667520133476,
      "loss": 4.8378,
      "step": 5165
    },
    {
      "epoch": 0.5923632610939112,
      "grad_norm": 0.0,
      "learning_rate": 0.0003761167853182159,
      "loss": 4.9335,
      "step": 5166
    },
    {
      "epoch": 0.592477926843252,
      "grad_norm": 0.0,
      "learning_rate": 0.0003759369125293216,
      "loss": 5.1314,
      "step": 5167
    },
    {
      "epoch": 0.5925925925925926,
      "grad_norm": 0.0,
      "learning_rate": 0.00037575705685946186,
      "loss": 5.1629,
      "step": 5168
    },
    {
      "epoch": 0.5927072583419333,
      "grad_norm": 0.0,
      "learning_rate": 0.00037557721833344446,
      "loss": 4.8516,
      "step": 5169
    },
    {
      "epoch": 0.592821924091274,
      "grad_norm": 0.0,
      "learning_rate": 0.00037539739697607454,
      "loss": 5.0188,
      "step": 5170
    },
    {
      "epoch": 0.5929365898406146,
      "grad_norm": 0.0,
      "learning_rate": 0.0003752175928121554,
      "loss": 5.0214,
      "step": 5171
    },
    {
      "epoch": 0.5930512555899553,
      "grad_norm": 0.0,
      "learning_rate": 0.0003750378058664871,
      "loss": 4.6487,
      "step": 5172
    },
    {
      "epoch": 0.5931659213392959,
      "grad_norm": 0.0,
      "learning_rate": 0.00037485803616386806,
      "loss": 4.9991,
      "step": 5173
    },
    {
      "epoch": 0.5932805870886366,
      "grad_norm": 0.0,
      "learning_rate": 0.0003746782837290939,
      "loss": 5.1096,
      "step": 5174
    },
    {
      "epoch": 0.5933952528379773,
      "grad_norm": 0.0,
      "learning_rate": 0.0003744985485869584,
      "loss": 4.8214,
      "step": 5175
    },
    {
      "epoch": 0.5935099185873179,
      "grad_norm": 0.0,
      "learning_rate": 0.00037431883076225234,
      "loss": 5.0305,
      "step": 5176
    },
    {
      "epoch": 0.5936245843366587,
      "grad_norm": 0.0,
      "learning_rate": 0.0003741391302797644,
      "loss": 4.879,
      "step": 5177
    },
    {
      "epoch": 0.5937392500859993,
      "grad_norm": 0.0,
      "learning_rate": 0.0003739594471642808,
      "loss": 5.0652,
      "step": 5178
    },
    {
      "epoch": 0.59385391583534,
      "grad_norm": 0.0,
      "learning_rate": 0.0003737797814405855,
      "loss": 4.9925,
      "step": 5179
    },
    {
      "epoch": 0.5939685815846807,
      "grad_norm": 0.0,
      "learning_rate": 0.00037360013313345996,
      "loss": 4.8216,
      "step": 5180
    },
    {
      "epoch": 0.5940832473340213,
      "grad_norm": 0.0,
      "learning_rate": 0.0003734205022676832,
      "loss": 4.9551,
      "step": 5181
    },
    {
      "epoch": 0.594197913083362,
      "grad_norm": 0.0,
      "learning_rate": 0.00037324088886803196,
      "loss": 4.7681,
      "step": 5182
    },
    {
      "epoch": 0.5943125788327027,
      "grad_norm": 0.0,
      "learning_rate": 0.00037306129295928026,
      "loss": 5.0214,
      "step": 5183
    },
    {
      "epoch": 0.5944272445820433,
      "grad_norm": 0.0,
      "learning_rate": 0.0003728817145662001,
      "loss": 4.9965,
      "step": 5184
    },
    {
      "epoch": 0.594541910331384,
      "grad_norm": 0.0,
      "learning_rate": 0.00037270215371356085,
      "loss": 4.99,
      "step": 5185
    },
    {
      "epoch": 0.5946565760807246,
      "grad_norm": 0.0,
      "learning_rate": 0.0003725226104261295,
      "loss": 4.9323,
      "step": 5186
    },
    {
      "epoch": 0.5947712418300654,
      "grad_norm": 0.0,
      "learning_rate": 0.00037234308472867077,
      "loss": 5.0242,
      "step": 5187
    },
    {
      "epoch": 0.5948859075794061,
      "grad_norm": 0.0,
      "learning_rate": 0.0003721635766459466,
      "loss": 4.9362,
      "step": 5188
    },
    {
      "epoch": 0.5950005733287467,
      "grad_norm": 0.0,
      "learning_rate": 0.0003719840862027168,
      "loss": 4.6077,
      "step": 5189
    },
    {
      "epoch": 0.5951152390780874,
      "grad_norm": 0.0,
      "learning_rate": 0.0003718046134237386,
      "loss": 4.939,
      "step": 5190
    },
    {
      "epoch": 0.5952299048274281,
      "grad_norm": 0.0,
      "learning_rate": 0.00037162515833376704,
      "loss": 4.8504,
      "step": 5191
    },
    {
      "epoch": 0.5953445705767687,
      "grad_norm": 0.0,
      "learning_rate": 0.00037144572095755427,
      "loss": 4.8954,
      "step": 5192
    },
    {
      "epoch": 0.5954592363261094,
      "grad_norm": 0.0,
      "learning_rate": 0.0003712663013198505,
      "loss": 5.0604,
      "step": 5193
    },
    {
      "epoch": 0.59557390207545,
      "grad_norm": 0.0,
      "learning_rate": 0.000371086899445403,
      "loss": 5.0602,
      "step": 5194
    },
    {
      "epoch": 0.5956885678247907,
      "grad_norm": 0.0,
      "learning_rate": 0.0003709075153589569,
      "loss": 5.0945,
      "step": 5195
    },
    {
      "epoch": 0.5958032335741315,
      "grad_norm": 0.0,
      "learning_rate": 0.000370728149085255,
      "loss": 4.9768,
      "step": 5196
    },
    {
      "epoch": 0.5959178993234721,
      "grad_norm": 0.0,
      "learning_rate": 0.0003705488006490373,
      "loss": 4.9188,
      "step": 5197
    },
    {
      "epoch": 0.5960325650728128,
      "grad_norm": 0.0,
      "learning_rate": 0.00037036947007504156,
      "loss": 4.823,
      "step": 5198
    },
    {
      "epoch": 0.5961472308221534,
      "grad_norm": 0.0,
      "learning_rate": 0.0003701901573880029,
      "loss": 5.0863,
      "step": 5199
    },
    {
      "epoch": 0.5962618965714941,
      "grad_norm": 0.0,
      "learning_rate": 0.00037001086261265426,
      "loss": 5.1614,
      "step": 5200
    },
    {
      "epoch": 0.5963765623208348,
      "grad_norm": 0.0,
      "learning_rate": 0.00036983158577372585,
      "loss": 5.0399,
      "step": 5201
    },
    {
      "epoch": 0.5964912280701754,
      "grad_norm": 0.0,
      "learning_rate": 0.0003696523268959455,
      "loss": 5.0585,
      "step": 5202
    },
    {
      "epoch": 0.5966058938195161,
      "grad_norm": 0.0,
      "learning_rate": 0.0003694730860040385,
      "loss": 5.0955,
      "step": 5203
    },
    {
      "epoch": 0.5967205595688568,
      "grad_norm": 0.0,
      "learning_rate": 0.00036929386312272783,
      "loss": 4.9822,
      "step": 5204
    },
    {
      "epoch": 0.5968352253181974,
      "grad_norm": 0.0,
      "learning_rate": 0.00036911465827673377,
      "loss": 4.9854,
      "step": 5205
    },
    {
      "epoch": 0.5969498910675382,
      "grad_norm": 0.0,
      "learning_rate": 0.00036893547149077424,
      "loss": 5.0436,
      "step": 5206
    },
    {
      "epoch": 0.5970645568168788,
      "grad_norm": 0.0,
      "learning_rate": 0.0003687563027895645,
      "loss": 5.2359,
      "step": 5207
    },
    {
      "epoch": 0.5971792225662195,
      "grad_norm": 0.0,
      "learning_rate": 0.0003685771521978178,
      "loss": 4.9974,
      "step": 5208
    },
    {
      "epoch": 0.5972938883155602,
      "grad_norm": 0.0,
      "learning_rate": 0.00036839801974024436,
      "loss": 4.9253,
      "step": 5209
    },
    {
      "epoch": 0.5974085540649008,
      "grad_norm": 0.0,
      "learning_rate": 0.000368218905441552,
      "loss": 4.7706,
      "step": 5210
    },
    {
      "epoch": 0.5975232198142415,
      "grad_norm": 0.0,
      "learning_rate": 0.0003680398093264462,
      "loss": 4.8993,
      "step": 5211
    },
    {
      "epoch": 0.5976378855635821,
      "grad_norm": 0.0,
      "learning_rate": 0.00036786073141963,
      "loss": 4.8103,
      "step": 5212
    },
    {
      "epoch": 0.5977525513129228,
      "grad_norm": 0.0,
      "learning_rate": 0.0003676816717458034,
      "loss": 4.9081,
      "step": 5213
    },
    {
      "epoch": 0.5978672170622635,
      "grad_norm": 0.0,
      "learning_rate": 0.0003675026303296647,
      "loss": 5.1065,
      "step": 5214
    },
    {
      "epoch": 0.5979818828116041,
      "grad_norm": 0.0,
      "learning_rate": 0.0003673236071959091,
      "loss": 4.8011,
      "step": 5215
    },
    {
      "epoch": 0.5980965485609449,
      "grad_norm": 0.0,
      "learning_rate": 0.0003671446023692293,
      "loss": 5.0904,
      "step": 5216
    },
    {
      "epoch": 0.5982112143102856,
      "grad_norm": 0.0,
      "learning_rate": 0.00036696561587431565,
      "loss": 4.9265,
      "step": 5217
    },
    {
      "epoch": 0.5983258800596262,
      "grad_norm": 0.0,
      "learning_rate": 0.00036678664773585597,
      "loss": 4.9813,
      "step": 5218
    },
    {
      "epoch": 0.5984405458089669,
      "grad_norm": 0.0,
      "learning_rate": 0.00036660769797853556,
      "loss": 4.9895,
      "step": 5219
    },
    {
      "epoch": 0.5985552115583075,
      "grad_norm": 0.0,
      "learning_rate": 0.0003664287666270371,
      "loss": 5.0956,
      "step": 5220
    },
    {
      "epoch": 0.5986698773076482,
      "grad_norm": 0.0,
      "learning_rate": 0.0003662498537060406,
      "loss": 4.7958,
      "step": 5221
    },
    {
      "epoch": 0.5987845430569889,
      "grad_norm": 0.0,
      "learning_rate": 0.0003660709592402241,
      "loss": 5.0775,
      "step": 5222
    },
    {
      "epoch": 0.5988992088063295,
      "grad_norm": 0.0,
      "learning_rate": 0.00036589208325426214,
      "loss": 5.1297,
      "step": 5223
    },
    {
      "epoch": 0.5990138745556702,
      "grad_norm": 0.0,
      "learning_rate": 0.00036571322577282756,
      "loss": 5.2361,
      "step": 5224
    },
    {
      "epoch": 0.599128540305011,
      "grad_norm": 0.0,
      "learning_rate": 0.00036553438682059025,
      "loss": 4.6992,
      "step": 5225
    },
    {
      "epoch": 0.5992432060543516,
      "grad_norm": 0.0,
      "learning_rate": 0.0003653555664222178,
      "loss": 5.0172,
      "step": 5226
    },
    {
      "epoch": 0.5993578718036923,
      "grad_norm": 0.0,
      "learning_rate": 0.00036517676460237495,
      "loss": 4.9546,
      "step": 5227
    },
    {
      "epoch": 0.5994725375530329,
      "grad_norm": 0.0,
      "learning_rate": 0.00036499798138572387,
      "loss": 5.1195,
      "step": 5228
    },
    {
      "epoch": 0.5995872033023736,
      "grad_norm": 0.0,
      "learning_rate": 0.0003648192167969245,
      "loss": 5.0137,
      "step": 5229
    },
    {
      "epoch": 0.5997018690517143,
      "grad_norm": 0.0,
      "learning_rate": 0.000364640470860634,
      "loss": 5.0019,
      "step": 5230
    },
    {
      "epoch": 0.5998165348010549,
      "grad_norm": 0.0,
      "learning_rate": 0.00036446174360150687,
      "loss": 5.1274,
      "step": 5231
    },
    {
      "epoch": 0.5999312005503956,
      "grad_norm": 0.0,
      "learning_rate": 0.00036428303504419527,
      "loss": 5.3322,
      "step": 5232
    },
    {
      "epoch": 0.6000458662997362,
      "grad_norm": 0.0,
      "learning_rate": 0.0003641043452133483,
      "loss": 5.0606,
      "step": 5233
    },
    {
      "epoch": 0.6001605320490769,
      "grad_norm": 0.0,
      "learning_rate": 0.0003639256741336132,
      "loss": 5.2852,
      "step": 5234
    },
    {
      "epoch": 0.6002751977984176,
      "grad_norm": 0.0,
      "learning_rate": 0.000363747021829634,
      "loss": 4.9809,
      "step": 5235
    },
    {
      "epoch": 0.6003898635477583,
      "grad_norm": 0.0,
      "learning_rate": 0.0003635683883260525,
      "loss": 5.086,
      "step": 5236
    },
    {
      "epoch": 0.600504529297099,
      "grad_norm": 0.0,
      "learning_rate": 0.00036338977364750786,
      "loss": 4.9424,
      "step": 5237
    },
    {
      "epoch": 0.6006191950464397,
      "grad_norm": 0.0,
      "learning_rate": 0.00036321117781863634,
      "loss": 4.9456,
      "step": 5238
    },
    {
      "epoch": 0.6007338607957803,
      "grad_norm": 0.0,
      "learning_rate": 0.000363032600864072,
      "loss": 4.9939,
      "step": 5239
    },
    {
      "epoch": 0.600848526545121,
      "grad_norm": 0.0,
      "learning_rate": 0.00036285404280844604,
      "loss": 4.9316,
      "step": 5240
    },
    {
      "epoch": 0.6009631922944616,
      "grad_norm": 0.0,
      "learning_rate": 0.00036267550367638713,
      "loss": 5.1921,
      "step": 5241
    },
    {
      "epoch": 0.6010778580438023,
      "grad_norm": 0.0,
      "learning_rate": 0.00036249698349252166,
      "loss": 4.9707,
      "step": 5242
    },
    {
      "epoch": 0.601192523793143,
      "grad_norm": 0.0,
      "learning_rate": 0.00036231848228147266,
      "loss": 5.1188,
      "step": 5243
    },
    {
      "epoch": 0.6013071895424836,
      "grad_norm": 0.0,
      "learning_rate": 0.0003621400000678611,
      "loss": 4.9719,
      "step": 5244
    },
    {
      "epoch": 0.6014218552918243,
      "grad_norm": 0.0,
      "learning_rate": 0.00036196153687630513,
      "loss": 5.0224,
      "step": 5245
    },
    {
      "epoch": 0.601536521041165,
      "grad_norm": 0.0,
      "learning_rate": 0.00036178309273142054,
      "loss": 4.9938,
      "step": 5246
    },
    {
      "epoch": 0.6016511867905057,
      "grad_norm": 0.0,
      "learning_rate": 0.0003616046676578201,
      "loss": 5.1562,
      "step": 5247
    },
    {
      "epoch": 0.6017658525398464,
      "grad_norm": 0.0,
      "learning_rate": 0.0003614262616801145,
      "loss": 5.1074,
      "step": 5248
    },
    {
      "epoch": 0.601880518289187,
      "grad_norm": 0.0,
      "learning_rate": 0.000361247874822911,
      "loss": 5.0819,
      "step": 5249
    },
    {
      "epoch": 0.6019951840385277,
      "grad_norm": 0.0,
      "learning_rate": 0.00036106950711081487,
      "loss": 4.9399,
      "step": 5250
    },
    {
      "epoch": 0.6021098497878684,
      "grad_norm": 0.0,
      "learning_rate": 0.0003608911585684285,
      "loss": 5.0228,
      "step": 5251
    },
    {
      "epoch": 0.602224515537209,
      "grad_norm": 0.0,
      "learning_rate": 0.00036071282922035185,
      "loss": 4.8733,
      "step": 5252
    },
    {
      "epoch": 0.6023391812865497,
      "grad_norm": 0.0,
      "learning_rate": 0.00036053451909118196,
      "loss": 4.9841,
      "step": 5253
    },
    {
      "epoch": 0.6024538470358903,
      "grad_norm": 0.0,
      "learning_rate": 0.000360356228205513,
      "loss": 5.1649,
      "step": 5254
    },
    {
      "epoch": 0.602568512785231,
      "grad_norm": 0.0,
      "learning_rate": 0.0003601779565879371,
      "loss": 5.2747,
      "step": 5255
    },
    {
      "epoch": 0.6026831785345718,
      "grad_norm": 0.0,
      "learning_rate": 0.00035999970426304345,
      "loss": 5.1249,
      "step": 5256
    },
    {
      "epoch": 0.6027978442839124,
      "grad_norm": 0.0,
      "learning_rate": 0.0003598214712554185,
      "loss": 5.1651,
      "step": 5257
    },
    {
      "epoch": 0.6029125100332531,
      "grad_norm": 0.0,
      "learning_rate": 0.000359643257589646,
      "loss": 5.188,
      "step": 5258
    },
    {
      "epoch": 0.6030271757825938,
      "grad_norm": 0.0,
      "learning_rate": 0.0003594650632903073,
      "loss": 5.2069,
      "step": 5259
    },
    {
      "epoch": 0.6031418415319344,
      "grad_norm": 0.0,
      "learning_rate": 0.0003592868883819809,
      "loss": 4.8293,
      "step": 5260
    },
    {
      "epoch": 0.6032565072812751,
      "grad_norm": 0.0,
      "learning_rate": 0.0003591087328892424,
      "loss": 4.7974,
      "step": 5261
    },
    {
      "epoch": 0.6033711730306157,
      "grad_norm": 0.0,
      "learning_rate": 0.0003589305968366652,
      "loss": 5.1402,
      "step": 5262
    },
    {
      "epoch": 0.6034858387799564,
      "grad_norm": 0.0,
      "learning_rate": 0.0003587524802488197,
      "loss": 5.0584,
      "step": 5263
    },
    {
      "epoch": 0.6036005045292971,
      "grad_norm": 0.0,
      "learning_rate": 0.00035857438315027373,
      "loss": 5.2099,
      "step": 5264
    },
    {
      "epoch": 0.6037151702786377,
      "grad_norm": 0.0,
      "learning_rate": 0.0003583963055655922,
      "loss": 4.9142,
      "step": 5265
    },
    {
      "epoch": 0.6038298360279785,
      "grad_norm": 0.0,
      "learning_rate": 0.00035821824751933775,
      "loss": 4.9659,
      "step": 5266
    },
    {
      "epoch": 0.6039445017773191,
      "grad_norm": 0.0,
      "learning_rate": 0.0003580402090360699,
      "loss": 5.2389,
      "step": 5267
    },
    {
      "epoch": 0.6040591675266598,
      "grad_norm": 0.0,
      "learning_rate": 0.00035786219014034577,
      "loss": 5.2058,
      "step": 5268
    },
    {
      "epoch": 0.6041738332760005,
      "grad_norm": 0.0,
      "learning_rate": 0.0003576841908567197,
      "loss": 4.9229,
      "step": 5269
    },
    {
      "epoch": 0.6042884990253411,
      "grad_norm": 0.0,
      "learning_rate": 0.0003575062112097434,
      "loss": 5.2485,
      "step": 5270
    },
    {
      "epoch": 0.6044031647746818,
      "grad_norm": 0.0,
      "learning_rate": 0.00035732825122396537,
      "loss": 4.7375,
      "step": 5271
    },
    {
      "epoch": 0.6045178305240225,
      "grad_norm": 0.0,
      "learning_rate": 0.00035715031092393225,
      "loss": 4.7854,
      "step": 5272
    },
    {
      "epoch": 0.6046324962733631,
      "grad_norm": 0.0,
      "learning_rate": 0.00035697239033418733,
      "loss": 5.3529,
      "step": 5273
    },
    {
      "epoch": 0.6047471620227038,
      "grad_norm": 0.0,
      "learning_rate": 0.00035679448947927126,
      "loss": 4.9429,
      "step": 5274
    },
    {
      "epoch": 0.6048618277720444,
      "grad_norm": 0.0,
      "learning_rate": 0.00035661660838372223,
      "loss": 5.1403,
      "step": 5275
    },
    {
      "epoch": 0.6049764935213852,
      "grad_norm": 0.0,
      "learning_rate": 0.00035643874707207547,
      "loss": 5.1107,
      "step": 5276
    },
    {
      "epoch": 0.6050911592707259,
      "grad_norm": 0.0,
      "learning_rate": 0.0003562609055688635,
      "loss": 5.0063,
      "step": 5277
    },
    {
      "epoch": 0.6052058250200665,
      "grad_norm": 0.0,
      "learning_rate": 0.0003560830838986163,
      "loss": 5.0992,
      "step": 5278
    },
    {
      "epoch": 0.6053204907694072,
      "grad_norm": 0.0,
      "learning_rate": 0.0003559052820858608,
      "loss": 5.1212,
      "step": 5279
    },
    {
      "epoch": 0.6054351565187478,
      "grad_norm": 0.0,
      "learning_rate": 0.00035572750015512155,
      "loss": 4.9386,
      "step": 5280
    },
    {
      "epoch": 0.6055498222680885,
      "grad_norm": 0.0,
      "learning_rate": 0.0003555497381309203,
      "loss": 5.2518,
      "step": 5281
    },
    {
      "epoch": 0.6056644880174292,
      "grad_norm": 0.0,
      "learning_rate": 0.0003553719960377756,
      "loss": 5.045,
      "step": 5282
    },
    {
      "epoch": 0.6057791537667698,
      "grad_norm": 0.0,
      "learning_rate": 0.00035519427390020376,
      "loss": 4.9006,
      "step": 5283
    },
    {
      "epoch": 0.6058938195161105,
      "grad_norm": 0.0,
      "learning_rate": 0.0003550165717427181,
      "loss": 5.0774,
      "step": 5284
    },
    {
      "epoch": 0.6060084852654513,
      "grad_norm": 0.0,
      "learning_rate": 0.00035483888958982927,
      "loss": 5.0651,
      "step": 5285
    },
    {
      "epoch": 0.6061231510147919,
      "grad_norm": 0.0,
      "learning_rate": 0.0003546612274660452,
      "loss": 5.0258,
      "step": 5286
    },
    {
      "epoch": 0.6062378167641326,
      "grad_norm": 0.0,
      "learning_rate": 0.00035448358539587094,
      "loss": 4.9425,
      "step": 5287
    },
    {
      "epoch": 0.6063524825134732,
      "grad_norm": 0.0,
      "learning_rate": 0.00035430596340380884,
      "loss": 5.0576,
      "step": 5288
    },
    {
      "epoch": 0.6064671482628139,
      "grad_norm": 0.0,
      "learning_rate": 0.0003541283615143583,
      "loss": 4.7018,
      "step": 5289
    },
    {
      "epoch": 0.6065818140121546,
      "grad_norm": 0.0,
      "learning_rate": 0.00035395077975201633,
      "loss": 4.878,
      "step": 5290
    },
    {
      "epoch": 0.6066964797614952,
      "grad_norm": 0.0,
      "learning_rate": 0.00035377321814127695,
      "loss": 4.8437,
      "step": 5291
    },
    {
      "epoch": 0.6068111455108359,
      "grad_norm": 0.0,
      "learning_rate": 0.0003535956767066314,
      "loss": 4.869,
      "step": 5292
    },
    {
      "epoch": 0.6069258112601766,
      "grad_norm": 0.0,
      "learning_rate": 0.00035341815547256807,
      "loss": 5.0398,
      "step": 5293
    },
    {
      "epoch": 0.6070404770095172,
      "grad_norm": 0.0,
      "learning_rate": 0.0003532406544635726,
      "loss": 4.845,
      "step": 5294
    },
    {
      "epoch": 0.607155142758858,
      "grad_norm": 0.0,
      "learning_rate": 0.00035306317370412783,
      "loss": 5.1385,
      "step": 5295
    },
    {
      "epoch": 0.6072698085081986,
      "grad_norm": 0.0,
      "learning_rate": 0.00035288571321871395,
      "loss": 5.011,
      "step": 5296
    },
    {
      "epoch": 0.6073844742575393,
      "grad_norm": 0.0,
      "learning_rate": 0.0003527082730318083,
      "loss": 5.1169,
      "step": 5297
    },
    {
      "epoch": 0.60749914000688,
      "grad_norm": 0.0,
      "learning_rate": 0.00035253085316788523,
      "loss": 4.9924,
      "step": 5298
    },
    {
      "epoch": 0.6076138057562206,
      "grad_norm": 0.0,
      "learning_rate": 0.0003523534536514164,
      "loss": 5.0118,
      "step": 5299
    },
    {
      "epoch": 0.6077284715055613,
      "grad_norm": 0.0,
      "learning_rate": 0.00035217607450687094,
      "loss": 4.8968,
      "step": 5300
    },
    {
      "epoch": 0.6078431372549019,
      "grad_norm": 0.0,
      "learning_rate": 0.0003519987157587147,
      "loss": 5.0414,
      "step": 5301
    },
    {
      "epoch": 0.6079578030042426,
      "grad_norm": 0.0,
      "learning_rate": 0.00035182137743141093,
      "loss": 4.99,
      "step": 5302
    },
    {
      "epoch": 0.6080724687535833,
      "grad_norm": 0.0,
      "learning_rate": 0.0003516440595494205,
      "loss": 4.9082,
      "step": 5303
    },
    {
      "epoch": 0.6081871345029239,
      "grad_norm": 0.0,
      "learning_rate": 0.0003514667621372003,
      "loss": 5.2621,
      "step": 5304
    },
    {
      "epoch": 0.6083018002522647,
      "grad_norm": 0.0,
      "learning_rate": 0.00035128948521920565,
      "loss": 4.8664,
      "step": 5305
    },
    {
      "epoch": 0.6084164660016054,
      "grad_norm": 0.0,
      "learning_rate": 0.0003511122288198884,
      "loss": 5.2188,
      "step": 5306
    },
    {
      "epoch": 0.608531131750946,
      "grad_norm": 0.0,
      "learning_rate": 0.00035093499296369755,
      "loss": 4.8546,
      "step": 5307
    },
    {
      "epoch": 0.6086457975002867,
      "grad_norm": 0.0,
      "learning_rate": 0.0003507577776750797,
      "loss": 5.0229,
      "step": 5308
    },
    {
      "epoch": 0.6087604632496273,
      "grad_norm": 0.0,
      "learning_rate": 0.00035058058297847807,
      "loss": 5.004,
      "step": 5309
    },
    {
      "epoch": 0.608875128998968,
      "grad_norm": 0.0,
      "learning_rate": 0.0003504034088983333,
      "loss": 4.7923,
      "step": 5310
    },
    {
      "epoch": 0.6089897947483087,
      "grad_norm": 0.0,
      "learning_rate": 0.00035022625545908333,
      "loss": 4.9863,
      "step": 5311
    },
    {
      "epoch": 0.6091044604976493,
      "grad_norm": 0.0,
      "learning_rate": 0.000350049122685163,
      "loss": 4.954,
      "step": 5312
    },
    {
      "epoch": 0.60921912624699,
      "grad_norm": 0.0,
      "learning_rate": 0.0003498720106010045,
      "loss": 4.9535,
      "step": 5313
    },
    {
      "epoch": 0.6093337919963306,
      "grad_norm": 0.0,
      "learning_rate": 0.00034969491923103694,
      "loss": 4.952,
      "step": 5314
    },
    {
      "epoch": 0.6094484577456714,
      "grad_norm": 0.0,
      "learning_rate": 0.0003495178485996867,
      "loss": 4.9116,
      "step": 5315
    },
    {
      "epoch": 0.6095631234950121,
      "grad_norm": 0.0,
      "learning_rate": 0.00034934079873137733,
      "loss": 5.0576,
      "step": 5316
    },
    {
      "epoch": 0.6096777892443527,
      "grad_norm": 0.0,
      "learning_rate": 0.00034916376965052955,
      "loss": 5.1004,
      "step": 5317
    },
    {
      "epoch": 0.6097924549936934,
      "grad_norm": 0.0,
      "learning_rate": 0.00034898676138156107,
      "loss": 4.8853,
      "step": 5318
    },
    {
      "epoch": 0.6099071207430341,
      "grad_norm": 0.0,
      "learning_rate": 0.00034880977394888686,
      "loss": 5.0606,
      "step": 5319
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 0.0,
      "learning_rate": 0.0003486328073769188,
      "loss": 4.9957,
      "step": 5320
    },
    {
      "epoch": 0.6101364522417154,
      "grad_norm": 0.0,
      "learning_rate": 0.0003484558616900663,
      "loss": 4.8125,
      "step": 5321
    },
    {
      "epoch": 0.610251117991056,
      "grad_norm": 0.0,
      "learning_rate": 0.00034827893691273553,
      "loss": 5.0098,
      "step": 5322
    },
    {
      "epoch": 0.6103657837403967,
      "grad_norm": 0.0,
      "learning_rate": 0.0003481020330693298,
      "loss": 4.8316,
      "step": 5323
    },
    {
      "epoch": 0.6104804494897375,
      "grad_norm": 0.0,
      "learning_rate": 0.0003479251501842499,
      "loss": 4.9292,
      "step": 5324
    },
    {
      "epoch": 0.6105951152390781,
      "grad_norm": 0.0,
      "learning_rate": 0.00034774828828189325,
      "loss": 5.0034,
      "step": 5325
    },
    {
      "epoch": 0.6107097809884188,
      "grad_norm": 0.0,
      "learning_rate": 0.0003475714473866545,
      "loss": 5.0123,
      "step": 5326
    },
    {
      "epoch": 0.6108244467377595,
      "grad_norm": 0.0,
      "learning_rate": 0.00034739462752292555,
      "loss": 4.87,
      "step": 5327
    },
    {
      "epoch": 0.6109391124871001,
      "grad_norm": 0.0,
      "learning_rate": 0.0003472178287150954,
      "loss": 4.9752,
      "step": 5328
    },
    {
      "epoch": 0.6110537782364408,
      "grad_norm": 0.0,
      "learning_rate": 0.00034704105098754993,
      "loss": 4.9939,
      "step": 5329
    },
    {
      "epoch": 0.6111684439857814,
      "grad_norm": 0.0,
      "learning_rate": 0.0003468642943646726,
      "loss": 5.222,
      "step": 5330
    },
    {
      "epoch": 0.6112831097351221,
      "grad_norm": 0.0,
      "learning_rate": 0.0003466875588708432,
      "loss": 4.9668,
      "step": 5331
    },
    {
      "epoch": 0.6113977754844628,
      "grad_norm": 0.0,
      "learning_rate": 0.0003465108445304392,
      "loss": 4.7821,
      "step": 5332
    },
    {
      "epoch": 0.6115124412338034,
      "grad_norm": 0.0,
      "learning_rate": 0.00034633415136783505,
      "loss": 4.919,
      "step": 5333
    },
    {
      "epoch": 0.6116271069831442,
      "grad_norm": 0.0,
      "learning_rate": 0.0003461574794074021,
      "loss": 5.1585,
      "step": 5334
    },
    {
      "epoch": 0.6117417727324848,
      "grad_norm": 0.0,
      "learning_rate": 0.0003459808286735089,
      "loss": 5.0281,
      "step": 5335
    },
    {
      "epoch": 0.6118564384818255,
      "grad_norm": 0.0,
      "learning_rate": 0.00034580419919052113,
      "loss": 4.8717,
      "step": 5336
    },
    {
      "epoch": 0.6119711042311662,
      "grad_norm": 0.0,
      "learning_rate": 0.00034562759098280126,
      "loss": 4.9603,
      "step": 5337
    },
    {
      "epoch": 0.6120857699805068,
      "grad_norm": 0.0,
      "learning_rate": 0.00034545100407470925,
      "loss": 5.1651,
      "step": 5338
    },
    {
      "epoch": 0.6122004357298475,
      "grad_norm": 0.0,
      "learning_rate": 0.00034527443849060175,
      "loss": 4.8825,
      "step": 5339
    },
    {
      "epoch": 0.6123151014791882,
      "grad_norm": 0.0,
      "learning_rate": 0.0003450978942548326,
      "loss": 5.0157,
      "step": 5340
    },
    {
      "epoch": 0.6124297672285288,
      "grad_norm": 0.0,
      "learning_rate": 0.00034492137139175295,
      "loss": 5.031,
      "step": 5341
    },
    {
      "epoch": 0.6125444329778695,
      "grad_norm": 0.0,
      "learning_rate": 0.00034474486992571053,
      "loss": 4.9862,
      "step": 5342
    },
    {
      "epoch": 0.6126590987272101,
      "grad_norm": 0.0,
      "learning_rate": 0.0003445683898810503,
      "loss": 4.9447,
      "step": 5343
    },
    {
      "epoch": 0.6127737644765509,
      "grad_norm": 0.0,
      "learning_rate": 0.0003443919312821147,
      "loss": 5.0793,
      "step": 5344
    },
    {
      "epoch": 0.6128884302258916,
      "grad_norm": 0.0,
      "learning_rate": 0.0003442154941532424,
      "loss": 4.8529,
      "step": 5345
    },
    {
      "epoch": 0.6130030959752322,
      "grad_norm": 0.0,
      "learning_rate": 0.00034403907851876964,
      "loss": 4.9192,
      "step": 5346
    },
    {
      "epoch": 0.6131177617245729,
      "grad_norm": 0.0,
      "learning_rate": 0.0003438626844030298,
      "loss": 5.0376,
      "step": 5347
    },
    {
      "epoch": 0.6132324274739135,
      "grad_norm": 0.0,
      "learning_rate": 0.0003436863118303529,
      "loss": 4.9313,
      "step": 5348
    },
    {
      "epoch": 0.6133470932232542,
      "grad_norm": 0.0,
      "learning_rate": 0.0003435099608250661,
      "loss": 5.1438,
      "step": 5349
    },
    {
      "epoch": 0.6134617589725949,
      "grad_norm": 0.0,
      "learning_rate": 0.00034333363141149386,
      "loss": 5.2261,
      "step": 5350
    },
    {
      "epoch": 0.6135764247219355,
      "grad_norm": 0.0,
      "learning_rate": 0.0003431573236139574,
      "loss": 5.1926,
      "step": 5351
    },
    {
      "epoch": 0.6136910904712762,
      "grad_norm": 0.0,
      "learning_rate": 0.00034298103745677506,
      "loss": 5.0,
      "step": 5352
    },
    {
      "epoch": 0.613805756220617,
      "grad_norm": 0.0,
      "learning_rate": 0.0003428047729642619,
      "loss": 5.0858,
      "step": 5353
    },
    {
      "epoch": 0.6139204219699576,
      "grad_norm": 0.0,
      "learning_rate": 0.0003426285301607307,
      "loss": 4.968,
      "step": 5354
    },
    {
      "epoch": 0.6140350877192983,
      "grad_norm": 0.0,
      "learning_rate": 0.0003424523090704905,
      "loss": 4.9342,
      "step": 5355
    },
    {
      "epoch": 0.6141497534686389,
      "grad_norm": 0.0,
      "learning_rate": 0.00034227610971784747,
      "loss": 4.8192,
      "step": 5356
    },
    {
      "epoch": 0.6142644192179796,
      "grad_norm": 0.0,
      "learning_rate": 0.00034209993212710527,
      "loss": 4.9546,
      "step": 5357
    },
    {
      "epoch": 0.6143790849673203,
      "grad_norm": 0.0,
      "learning_rate": 0.00034192377632256423,
      "loss": 4.9749,
      "step": 5358
    },
    {
      "epoch": 0.6144937507166609,
      "grad_norm": 0.0,
      "learning_rate": 0.00034174764232852153,
      "loss": 5.1483,
      "step": 5359
    },
    {
      "epoch": 0.6146084164660016,
      "grad_norm": 0.0,
      "learning_rate": 0.0003415715301692715,
      "loss": 4.9252,
      "step": 5360
    },
    {
      "epoch": 0.6147230822153423,
      "grad_norm": 0.0,
      "learning_rate": 0.0003413954398691054,
      "loss": 5.1264,
      "step": 5361
    },
    {
      "epoch": 0.6148377479646829,
      "grad_norm": 0.0,
      "learning_rate": 0.0003412193714523118,
      "loss": 5.312,
      "step": 5362
    },
    {
      "epoch": 0.6149524137140236,
      "grad_norm": 0.0,
      "learning_rate": 0.00034104332494317585,
      "loss": 4.9419,
      "step": 5363
    },
    {
      "epoch": 0.6150670794633643,
      "grad_norm": 0.0,
      "learning_rate": 0.00034086730036597977,
      "loss": 5.0035,
      "step": 5364
    },
    {
      "epoch": 0.615181745212705,
      "grad_norm": 0.0,
      "learning_rate": 0.00034069129774500276,
      "loss": 5.0641,
      "step": 5365
    },
    {
      "epoch": 0.6152964109620457,
      "grad_norm": 0.0,
      "learning_rate": 0.0003405153171045211,
      "loss": 5.0,
      "step": 5366
    },
    {
      "epoch": 0.6154110767113863,
      "grad_norm": 0.0,
      "learning_rate": 0.00034033935846880786,
      "loss": 5.051,
      "step": 5367
    },
    {
      "epoch": 0.615525742460727,
      "grad_norm": 0.0,
      "learning_rate": 0.00034016342186213327,
      "loss": 5.1403,
      "step": 5368
    },
    {
      "epoch": 0.6156404082100676,
      "grad_norm": 0.0,
      "learning_rate": 0.00033998750730876453,
      "loss": 5.0533,
      "step": 5369
    },
    {
      "epoch": 0.6157550739594083,
      "grad_norm": 0.0,
      "learning_rate": 0.0003398116148329655,
      "loss": 5.0872,
      "step": 5370
    },
    {
      "epoch": 0.615869739708749,
      "grad_norm": 0.0,
      "learning_rate": 0.0003396357444589973,
      "loss": 4.8368,
      "step": 5371
    },
    {
      "epoch": 0.6159844054580896,
      "grad_norm": 0.0,
      "learning_rate": 0.0003394598962111178,
      "loss": 5.0401,
      "step": 5372
    },
    {
      "epoch": 0.6160990712074303,
      "grad_norm": 0.0,
      "learning_rate": 0.00033928407011358207,
      "loss": 5.018,
      "step": 5373
    },
    {
      "epoch": 0.6162137369567711,
      "grad_norm": 0.0,
      "learning_rate": 0.0003391082661906419,
      "loss": 5.2919,
      "step": 5374
    },
    {
      "epoch": 0.6163284027061117,
      "grad_norm": 0.0,
      "learning_rate": 0.0003389324844665462,
      "loss": 5.0866,
      "step": 5375
    },
    {
      "epoch": 0.6164430684554524,
      "grad_norm": 0.0,
      "learning_rate": 0.00033875672496554046,
      "loss": 4.9368,
      "step": 5376
    },
    {
      "epoch": 0.616557734204793,
      "grad_norm": 0.0,
      "learning_rate": 0.00033858098771186743,
      "loss": 4.8563,
      "step": 5377
    },
    {
      "epoch": 0.6166723999541337,
      "grad_norm": 0.0,
      "learning_rate": 0.0003384052727297668,
      "loss": 5.0129,
      "step": 5378
    },
    {
      "epoch": 0.6167870657034744,
      "grad_norm": 0.0,
      "learning_rate": 0.00033822958004347506,
      "loss": 4.9057,
      "step": 5379
    },
    {
      "epoch": 0.616901731452815,
      "grad_norm": 0.0,
      "learning_rate": 0.00033805390967722574,
      "loss": 5.025,
      "step": 5380
    },
    {
      "epoch": 0.6170163972021557,
      "grad_norm": 0.0,
      "learning_rate": 0.0003378782616552491,
      "loss": 5.0225,
      "step": 5381
    },
    {
      "epoch": 0.6171310629514963,
      "grad_norm": 0.0,
      "learning_rate": 0.00033770263600177246,
      "loss": 4.8612,
      "step": 5382
    },
    {
      "epoch": 0.617245728700837,
      "grad_norm": 0.0,
      "learning_rate": 0.0003375270327410201,
      "loss": 4.9279,
      "step": 5383
    },
    {
      "epoch": 0.6173603944501778,
      "grad_norm": 0.0,
      "learning_rate": 0.00033735145189721307,
      "loss": 4.9941,
      "step": 5384
    },
    {
      "epoch": 0.6174750601995184,
      "grad_norm": 0.0,
      "learning_rate": 0.0003371758934945696,
      "loss": 5.0621,
      "step": 5385
    },
    {
      "epoch": 0.6175897259488591,
      "grad_norm": 0.0,
      "learning_rate": 0.00033700035755730435,
      "loss": 5.0268,
      "step": 5386
    },
    {
      "epoch": 0.6177043916981998,
      "grad_norm": 0.0,
      "learning_rate": 0.0003368248441096292,
      "loss": 5.1099,
      "step": 5387
    },
    {
      "epoch": 0.6178190574475404,
      "grad_norm": 0.0,
      "learning_rate": 0.000336649353175753,
      "loss": 4.8563,
      "step": 5388
    },
    {
      "epoch": 0.6179337231968811,
      "grad_norm": 0.0,
      "learning_rate": 0.00033647388477988125,
      "loss": 5.2984,
      "step": 5389
    },
    {
      "epoch": 0.6180483889462217,
      "grad_norm": 0.0,
      "learning_rate": 0.00033629843894621657,
      "loss": 5.0491,
      "step": 5390
    },
    {
      "epoch": 0.6181630546955624,
      "grad_norm": 0.0,
      "learning_rate": 0.00033612301569895854,
      "loss": 5.1253,
      "step": 5391
    },
    {
      "epoch": 0.6182777204449031,
      "grad_norm": 0.0,
      "learning_rate": 0.0003359476150623031,
      "loss": 5.1398,
      "step": 5392
    },
    {
      "epoch": 0.6183923861942437,
      "grad_norm": 0.0,
      "learning_rate": 0.00033577223706044356,
      "loss": 5.0114,
      "step": 5393
    },
    {
      "epoch": 0.6185070519435845,
      "grad_norm": 0.0,
      "learning_rate": 0.00033559688171757007,
      "loss": 5.0467,
      "step": 5394
    },
    {
      "epoch": 0.6186217176929252,
      "grad_norm": 0.0,
      "learning_rate": 0.00033542154905786945,
      "loss": 5.0908,
      "step": 5395
    },
    {
      "epoch": 0.6187363834422658,
      "grad_norm": 0.0,
      "learning_rate": 0.0003352462391055257,
      "loss": 5.2728,
      "step": 5396
    },
    {
      "epoch": 0.6188510491916065,
      "grad_norm": 0.0,
      "learning_rate": 0.00033507095188471913,
      "loss": 5.232,
      "step": 5397
    },
    {
      "epoch": 0.6189657149409471,
      "grad_norm": 0.0,
      "learning_rate": 0.0003348956874196275,
      "loss": 5.0849,
      "step": 5398
    },
    {
      "epoch": 0.6190803806902878,
      "grad_norm": 0.0,
      "learning_rate": 0.0003347204457344251,
      "loss": 4.8378,
      "step": 5399
    },
    {
      "epoch": 0.6191950464396285,
      "grad_norm": 0.0,
      "learning_rate": 0.00033454522685328334,
      "loss": 4.8996,
      "step": 5400
    },
    {
      "epoch": 0.6193097121889691,
      "grad_norm": 0.0,
      "learning_rate": 0.00033437003080037013,
      "loss": 5.2175,
      "step": 5401
    },
    {
      "epoch": 0.6194243779383098,
      "grad_norm": 0.0,
      "learning_rate": 0.0003341948575998507,
      "loss": 4.8308,
      "step": 5402
    },
    {
      "epoch": 0.6195390436876504,
      "grad_norm": 0.0,
      "learning_rate": 0.0003340197072758865,
      "loss": 4.8681,
      "step": 5403
    },
    {
      "epoch": 0.6196537094369912,
      "grad_norm": 0.0,
      "learning_rate": 0.00033384457985263636,
      "loss": 4.9265,
      "step": 5404
    },
    {
      "epoch": 0.6197683751863319,
      "grad_norm": 0.0,
      "learning_rate": 0.00033366947535425594,
      "loss": 5.1118,
      "step": 5405
    },
    {
      "epoch": 0.6198830409356725,
      "grad_norm": 0.0,
      "learning_rate": 0.00033349439380489726,
      "loss": 4.9033,
      "step": 5406
    },
    {
      "epoch": 0.6199977066850132,
      "grad_norm": 0.0,
      "learning_rate": 0.0003333193352287097,
      "loss": 4.9093,
      "step": 5407
    },
    {
      "epoch": 0.6201123724343539,
      "grad_norm": 0.0,
      "learning_rate": 0.0003331442996498391,
      "loss": 5.0607,
      "step": 5408
    },
    {
      "epoch": 0.6202270381836945,
      "grad_norm": 0.0,
      "learning_rate": 0.00033296928709242835,
      "loss": 5.1402,
      "step": 5409
    },
    {
      "epoch": 0.6203417039330352,
      "grad_norm": 0.0,
      "learning_rate": 0.0003327942975806171,
      "loss": 4.9918,
      "step": 5410
    },
    {
      "epoch": 0.6204563696823758,
      "grad_norm": 0.0,
      "learning_rate": 0.0003326193311385417,
      "loss": 4.9682,
      "step": 5411
    },
    {
      "epoch": 0.6205710354317165,
      "grad_norm": 0.0,
      "learning_rate": 0.0003324443877903357,
      "loss": 4.961,
      "step": 5412
    },
    {
      "epoch": 0.6206857011810573,
      "grad_norm": 0.0,
      "learning_rate": 0.00033226946756012907,
      "loss": 5.0294,
      "step": 5413
    },
    {
      "epoch": 0.6208003669303979,
      "grad_norm": 0.0,
      "learning_rate": 0.0003320945704720487,
      "loss": 5.07,
      "step": 5414
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 0.0,
      "learning_rate": 0.00033191969655021824,
      "loss": 4.793,
      "step": 5415
    },
    {
      "epoch": 0.6210296984290792,
      "grad_norm": 0.0,
      "learning_rate": 0.0003317448458187583,
      "loss": 5.0121,
      "step": 5416
    },
    {
      "epoch": 0.6211443641784199,
      "grad_norm": 0.0,
      "learning_rate": 0.0003315700183017862,
      "loss": 5.0014,
      "step": 5417
    },
    {
      "epoch": 0.6212590299277606,
      "grad_norm": 0.0,
      "learning_rate": 0.0003313952140234162,
      "loss": 5.0991,
      "step": 5418
    },
    {
      "epoch": 0.6213736956771012,
      "grad_norm": 0.0,
      "learning_rate": 0.0003312204330077589,
      "loss": 4.8796,
      "step": 5419
    },
    {
      "epoch": 0.6214883614264419,
      "grad_norm": 0.0,
      "learning_rate": 0.0003310456752789221,
      "loss": 5.1956,
      "step": 5420
    },
    {
      "epoch": 0.6216030271757826,
      "grad_norm": 0.0,
      "learning_rate": 0.0003308709408610105,
      "loss": 5.0988,
      "step": 5421
    },
    {
      "epoch": 0.6217176929251232,
      "grad_norm": 0.0,
      "learning_rate": 0.0003306962297781252,
      "loss": 5.2201,
      "step": 5422
    },
    {
      "epoch": 0.621832358674464,
      "grad_norm": 0.0,
      "learning_rate": 0.00033052154205436435,
      "loss": 5.1641,
      "step": 5423
    },
    {
      "epoch": 0.6219470244238046,
      "grad_norm": 0.0,
      "learning_rate": 0.0003303468777138229,
      "loss": 4.8277,
      "step": 5424
    },
    {
      "epoch": 0.6220616901731453,
      "grad_norm": 0.0,
      "learning_rate": 0.0003301722367805923,
      "loss": 5.0433,
      "step": 5425
    },
    {
      "epoch": 0.622176355922486,
      "grad_norm": 0.0,
      "learning_rate": 0.00032999761927876087,
      "loss": 5.045,
      "step": 5426
    },
    {
      "epoch": 0.6222910216718266,
      "grad_norm": 0.0,
      "learning_rate": 0.00032982302523241384,
      "loss": 4.9737,
      "step": 5427
    },
    {
      "epoch": 0.6224056874211673,
      "grad_norm": 0.0,
      "learning_rate": 0.0003296484546656332,
      "loss": 4.8552,
      "step": 5428
    },
    {
      "epoch": 0.622520353170508,
      "grad_norm": 0.0,
      "learning_rate": 0.0003294739076024977,
      "loss": 5.1294,
      "step": 5429
    },
    {
      "epoch": 0.6226350189198486,
      "grad_norm": 0.0,
      "learning_rate": 0.0003292993840670825,
      "loss": 4.8609,
      "step": 5430
    },
    {
      "epoch": 0.6227496846691893,
      "grad_norm": 0.0,
      "learning_rate": 0.00032912488408346006,
      "loss": 4.9553,
      "step": 5431
    },
    {
      "epoch": 0.6228643504185299,
      "grad_norm": 0.0,
      "learning_rate": 0.00032895040767569924,
      "loss": 5.047,
      "step": 5432
    },
    {
      "epoch": 0.6229790161678707,
      "grad_norm": 0.0,
      "learning_rate": 0.00032877595486786567,
      "loss": 4.9493,
      "step": 5433
    },
    {
      "epoch": 0.6230936819172114,
      "grad_norm": 0.0,
      "learning_rate": 0.0003286015256840218,
      "loss": 5.1228,
      "step": 5434
    },
    {
      "epoch": 0.623208347666552,
      "grad_norm": 0.0,
      "learning_rate": 0.000328427120148227,
      "loss": 4.9661,
      "step": 5435
    },
    {
      "epoch": 0.6233230134158927,
      "grad_norm": 0.0,
      "learning_rate": 0.00032825273828453704,
      "loss": 5.0575,
      "step": 5436
    },
    {
      "epoch": 0.6234376791652333,
      "grad_norm": 0.0,
      "learning_rate": 0.0003280783801170046,
      "loss": 5.2429,
      "step": 5437
    },
    {
      "epoch": 0.623552344914574,
      "grad_norm": 0.0,
      "learning_rate": 0.00032790404566967893,
      "loss": 5.0599,
      "step": 5438
    },
    {
      "epoch": 0.6236670106639147,
      "grad_norm": 0.0,
      "learning_rate": 0.0003277297349666062,
      "loss": 5.1736,
      "step": 5439
    },
    {
      "epoch": 0.6237816764132553,
      "grad_norm": 0.0,
      "learning_rate": 0.0003275554480318295,
      "loss": 4.8048,
      "step": 5440
    },
    {
      "epoch": 0.623896342162596,
      "grad_norm": 0.0,
      "learning_rate": 0.00032738118488938805,
      "loss": 4.9771,
      "step": 5441
    },
    {
      "epoch": 0.6240110079119368,
      "grad_norm": 0.0,
      "learning_rate": 0.00032720694556331826,
      "loss": 4.8233,
      "step": 5442
    },
    {
      "epoch": 0.6241256736612774,
      "grad_norm": 0.0,
      "learning_rate": 0.0003270327300776532,
      "loss": 4.5837,
      "step": 5443
    },
    {
      "epoch": 0.6242403394106181,
      "grad_norm": 0.0,
      "learning_rate": 0.0003268585384564225,
      "loss": 5.1034,
      "step": 5444
    },
    {
      "epoch": 0.6243550051599587,
      "grad_norm": 0.0,
      "learning_rate": 0.00032668437072365267,
      "loss": 5.0185,
      "step": 5445
    },
    {
      "epoch": 0.6244696709092994,
      "grad_norm": 0.0,
      "learning_rate": 0.0003265102269033668,
      "loss": 5.0031,
      "step": 5446
    },
    {
      "epoch": 0.6245843366586401,
      "grad_norm": 0.0,
      "learning_rate": 0.00032633610701958453,
      "loss": 5.1352,
      "step": 5447
    },
    {
      "epoch": 0.6246990024079807,
      "grad_norm": 0.0,
      "learning_rate": 0.0003261620110963225,
      "loss": 5.1012,
      "step": 5448
    },
    {
      "epoch": 0.6248136681573214,
      "grad_norm": 0.0,
      "learning_rate": 0.00032598793915759395,
      "loss": 4.9886,
      "step": 5449
    },
    {
      "epoch": 0.624928333906662,
      "grad_norm": 0.0,
      "learning_rate": 0.0003258138912274087,
      "loss": 5.1753,
      "step": 5450
    },
    {
      "epoch": 0.6250429996560027,
      "grad_norm": 0.0,
      "learning_rate": 0.0003256398673297736,
      "loss": 5.0831,
      "step": 5451
    },
    {
      "epoch": 0.6251576654053435,
      "grad_norm": 0.0,
      "learning_rate": 0.00032546586748869165,
      "loss": 5.0683,
      "step": 5452
    },
    {
      "epoch": 0.6252723311546841,
      "grad_norm": 0.0,
      "learning_rate": 0.0003252918917281629,
      "loss": 5.0872,
      "step": 5453
    },
    {
      "epoch": 0.6253869969040248,
      "grad_norm": 0.0,
      "learning_rate": 0.00032511794007218387,
      "loss": 5.2583,
      "step": 5454
    },
    {
      "epoch": 0.6255016626533655,
      "grad_norm": 0.0,
      "learning_rate": 0.00032494401254474814,
      "loss": 4.8138,
      "step": 5455
    },
    {
      "epoch": 0.6256163284027061,
      "grad_norm": 0.0,
      "learning_rate": 0.0003247701091698456,
      "loss": 4.9812,
      "step": 5456
    },
    {
      "epoch": 0.6257309941520468,
      "grad_norm": 0.0,
      "learning_rate": 0.0003245962299714629,
      "loss": 5.2858,
      "step": 5457
    },
    {
      "epoch": 0.6258456599013874,
      "grad_norm": 0.0,
      "learning_rate": 0.0003244223749735831,
      "loss": 5.063,
      "step": 5458
    },
    {
      "epoch": 0.6259603256507281,
      "grad_norm": 0.0,
      "learning_rate": 0.00032424854420018656,
      "loss": 4.9727,
      "step": 5459
    },
    {
      "epoch": 0.6260749914000688,
      "grad_norm": 0.0,
      "learning_rate": 0.00032407473767524965,
      "loss": 4.7808,
      "step": 5460
    },
    {
      "epoch": 0.6261896571494094,
      "grad_norm": 0.0,
      "learning_rate": 0.0003239009554227458,
      "loss": 5.0208,
      "step": 5461
    },
    {
      "epoch": 0.6263043228987502,
      "grad_norm": 0.0,
      "learning_rate": 0.0003237271974666451,
      "loss": 4.8376,
      "step": 5462
    },
    {
      "epoch": 0.6264189886480909,
      "grad_norm": 0.0,
      "learning_rate": 0.00032355346383091386,
      "loss": 5.1976,
      "step": 5463
    },
    {
      "epoch": 0.6265336543974315,
      "grad_norm": 0.0,
      "learning_rate": 0.0003233797545395155,
      "loss": 4.8552,
      "step": 5464
    },
    {
      "epoch": 0.6266483201467722,
      "grad_norm": 0.0,
      "learning_rate": 0.00032320606961640984,
      "loss": 4.9079,
      "step": 5465
    },
    {
      "epoch": 0.6267629858961128,
      "grad_norm": 0.0,
      "learning_rate": 0.0003230324090855535,
      "loss": 5.0843,
      "step": 5466
    },
    {
      "epoch": 0.6268776516454535,
      "grad_norm": 0.0,
      "learning_rate": 0.0003228587729708995,
      "loss": 5.2498,
      "step": 5467
    },
    {
      "epoch": 0.6269923173947942,
      "grad_norm": 0.0,
      "learning_rate": 0.00032268516129639775,
      "loss": 5.0321,
      "step": 5468
    },
    {
      "epoch": 0.6271069831441348,
      "grad_norm": 0.0,
      "learning_rate": 0.0003225115740859945,
      "loss": 4.8027,
      "step": 5469
    },
    {
      "epoch": 0.6272216488934755,
      "grad_norm": 0.0,
      "learning_rate": 0.00032233801136363294,
      "loss": 4.7892,
      "step": 5470
    },
    {
      "epoch": 0.6273363146428161,
      "grad_norm": 0.0,
      "learning_rate": 0.00032216447315325274,
      "loss": 4.8469,
      "step": 5471
    },
    {
      "epoch": 0.6274509803921569,
      "grad_norm": 0.0,
      "learning_rate": 0.00032199095947879023,
      "loss": 4.896,
      "step": 5472
    },
    {
      "epoch": 0.6275656461414976,
      "grad_norm": 0.0,
      "learning_rate": 0.0003218174703641782,
      "loss": 5.1236,
      "step": 5473
    },
    {
      "epoch": 0.6276803118908382,
      "grad_norm": 0.0,
      "learning_rate": 0.0003216440058333462,
      "loss": 5.1186,
      "step": 5474
    },
    {
      "epoch": 0.6277949776401789,
      "grad_norm": 0.0,
      "learning_rate": 0.00032147056591022035,
      "loss": 4.9187,
      "step": 5475
    },
    {
      "epoch": 0.6279096433895196,
      "grad_norm": 0.0,
      "learning_rate": 0.0003212971506187235,
      "loss": 4.9017,
      "step": 5476
    },
    {
      "epoch": 0.6280243091388602,
      "grad_norm": 0.0,
      "learning_rate": 0.0003211237599827747,
      "loss": 5.2434,
      "step": 5477
    },
    {
      "epoch": 0.6281389748882009,
      "grad_norm": 0.0,
      "learning_rate": 0.00032095039402629035,
      "loss": 4.7444,
      "step": 5478
    },
    {
      "epoch": 0.6282536406375415,
      "grad_norm": 0.0,
      "learning_rate": 0.0003207770527731823,
      "loss": 4.8869,
      "step": 5479
    },
    {
      "epoch": 0.6283683063868822,
      "grad_norm": 0.0,
      "learning_rate": 0.00032060373624736037,
      "loss": 5.0506,
      "step": 5480
    },
    {
      "epoch": 0.628482972136223,
      "grad_norm": 0.0,
      "learning_rate": 0.00032043044447272975,
      "loss": 5.1498,
      "step": 5481
    },
    {
      "epoch": 0.6285976378855636,
      "grad_norm": 0.0,
      "learning_rate": 0.00032025717747319316,
      "loss": 4.996,
      "step": 5482
    },
    {
      "epoch": 0.6287123036349043,
      "grad_norm": 0.0,
      "learning_rate": 0.0003200839352726493,
      "loss": 5.1595,
      "step": 5483
    },
    {
      "epoch": 0.6288269693842449,
      "grad_norm": 0.0,
      "learning_rate": 0.0003199107178949933,
      "loss": 4.9609,
      "step": 5484
    },
    {
      "epoch": 0.6289416351335856,
      "grad_norm": 0.0,
      "learning_rate": 0.0003197375253641178,
      "loss": 4.9395,
      "step": 5485
    },
    {
      "epoch": 0.6290563008829263,
      "grad_norm": 0.0,
      "learning_rate": 0.00031956435770391097,
      "loss": 5.1646,
      "step": 5486
    },
    {
      "epoch": 0.6291709666322669,
      "grad_norm": 0.0,
      "learning_rate": 0.00031939121493825825,
      "loss": 5.348,
      "step": 5487
    },
    {
      "epoch": 0.6292856323816076,
      "grad_norm": 0.0,
      "learning_rate": 0.0003192180970910412,
      "loss": 4.7567,
      "step": 5488
    },
    {
      "epoch": 0.6294002981309483,
      "grad_norm": 0.0,
      "learning_rate": 0.0003190450041861381,
      "loss": 5.2289,
      "step": 5489
    },
    {
      "epoch": 0.6295149638802889,
      "grad_norm": 0.0,
      "learning_rate": 0.000318871936247424,
      "loss": 5.0619,
      "step": 5490
    },
    {
      "epoch": 0.6296296296296297,
      "grad_norm": 0.0,
      "learning_rate": 0.00031869889329877004,
      "loss": 4.9789,
      "step": 5491
    },
    {
      "epoch": 0.6297442953789703,
      "grad_norm": 0.0,
      "learning_rate": 0.0003185258753640446,
      "loss": 4.9535,
      "step": 5492
    },
    {
      "epoch": 0.629858961128311,
      "grad_norm": 0.0,
      "learning_rate": 0.000318352882467112,
      "loss": 4.9854,
      "step": 5493
    },
    {
      "epoch": 0.6299736268776517,
      "grad_norm": 0.0,
      "learning_rate": 0.0003181799146318331,
      "loss": 4.8177,
      "step": 5494
    },
    {
      "epoch": 0.6300882926269923,
      "grad_norm": 0.0,
      "learning_rate": 0.0003180069718820659,
      "loss": 5.4108,
      "step": 5495
    },
    {
      "epoch": 0.630202958376333,
      "grad_norm": 0.0,
      "learning_rate": 0.00031783405424166435,
      "loss": 4.8194,
      "step": 5496
    },
    {
      "epoch": 0.6303176241256737,
      "grad_norm": 0.0,
      "learning_rate": 0.00031766116173447917,
      "loss": 4.8354,
      "step": 5497
    },
    {
      "epoch": 0.6304322898750143,
      "grad_norm": 0.0,
      "learning_rate": 0.0003174882943843576,
      "loss": 5.0657,
      "step": 5498
    },
    {
      "epoch": 0.630546955624355,
      "grad_norm": 0.0,
      "learning_rate": 0.00031731545221514313,
      "loss": 4.8332,
      "step": 5499
    },
    {
      "epoch": 0.6306616213736956,
      "grad_norm": 0.0,
      "learning_rate": 0.0003171426352506766,
      "loss": 4.9568,
      "step": 5500
    },
    {
      "epoch": 0.6307762871230363,
      "grad_norm": 0.0,
      "learning_rate": 0.0003169698435147943,
      "loss": 4.671,
      "step": 5501
    },
    {
      "epoch": 0.6308909528723771,
      "grad_norm": 0.0,
      "learning_rate": 0.0003167970770313299,
      "loss": 4.9725,
      "step": 5502
    },
    {
      "epoch": 0.6310056186217177,
      "grad_norm": 0.0,
      "learning_rate": 0.00031662433582411287,
      "loss": 5.2737,
      "step": 5503
    },
    {
      "epoch": 0.6311202843710584,
      "grad_norm": 0.0,
      "learning_rate": 0.00031645161991697006,
      "loss": 5.3314,
      "step": 5504
    },
    {
      "epoch": 0.631234950120399,
      "grad_norm": 0.0,
      "learning_rate": 0.0003162789293337241,
      "loss": 4.9646,
      "step": 5505
    },
    {
      "epoch": 0.6313496158697397,
      "grad_norm": 0.0,
      "learning_rate": 0.000316106264098194,
      "loss": 4.7504,
      "step": 5506
    },
    {
      "epoch": 0.6314642816190804,
      "grad_norm": 0.0,
      "learning_rate": 0.00031593362423419646,
      "loss": 5.0486,
      "step": 5507
    },
    {
      "epoch": 0.631578947368421,
      "grad_norm": 0.0,
      "learning_rate": 0.00031576100976554304,
      "loss": 5.0387,
      "step": 5508
    },
    {
      "epoch": 0.6316936131177617,
      "grad_norm": 0.0,
      "learning_rate": 0.0003155884207160431,
      "loss": 4.8965,
      "step": 5509
    },
    {
      "epoch": 0.6318082788671024,
      "grad_norm": 0.0,
      "learning_rate": 0.00031541585710950196,
      "loss": 5.0557,
      "step": 5510
    },
    {
      "epoch": 0.631922944616443,
      "grad_norm": 0.0,
      "learning_rate": 0.00031524331896972107,
      "loss": 5.1863,
      "step": 5511
    },
    {
      "epoch": 0.6320376103657838,
      "grad_norm": 0.0,
      "learning_rate": 0.00031507080632049933,
      "loss": 5.0666,
      "step": 5512
    },
    {
      "epoch": 0.6321522761151244,
      "grad_norm": 0.0,
      "learning_rate": 0.0003148983191856312,
      "loss": 5.1067,
      "step": 5513
    },
    {
      "epoch": 0.6322669418644651,
      "grad_norm": 0.0,
      "learning_rate": 0.0003147258575889083,
      "loss": 4.8637,
      "step": 5514
    },
    {
      "epoch": 0.6323816076138058,
      "grad_norm": 0.0,
      "learning_rate": 0.0003145534215541182,
      "loss": 4.7401,
      "step": 5515
    },
    {
      "epoch": 0.6324962733631464,
      "grad_norm": 0.0,
      "learning_rate": 0.00031438101110504497,
      "loss": 5.2978,
      "step": 5516
    },
    {
      "epoch": 0.6326109391124871,
      "grad_norm": 0.0,
      "learning_rate": 0.00031420862626547,
      "loss": 5.0332,
      "step": 5517
    },
    {
      "epoch": 0.6327256048618277,
      "grad_norm": 0.0,
      "learning_rate": 0.0003140362670591697,
      "loss": 5.0408,
      "step": 5518
    },
    {
      "epoch": 0.6328402706111684,
      "grad_norm": 0.0,
      "learning_rate": 0.00031386393350991835,
      "loss": 4.8097,
      "step": 5519
    },
    {
      "epoch": 0.6329549363605091,
      "grad_norm": 0.0,
      "learning_rate": 0.00031369162564148583,
      "loss": 4.9993,
      "step": 5520
    },
    {
      "epoch": 0.6330696021098497,
      "grad_norm": 0.0,
      "learning_rate": 0.0003135193434776385,
      "loss": 4.8722,
      "step": 5521
    },
    {
      "epoch": 0.6331842678591905,
      "grad_norm": 0.0,
      "learning_rate": 0.00031334708704213994,
      "loss": 4.874,
      "step": 5522
    },
    {
      "epoch": 0.6332989336085312,
      "grad_norm": 0.0,
      "learning_rate": 0.00031317485635874904,
      "loss": 5.0554,
      "step": 5523
    },
    {
      "epoch": 0.6334135993578718,
      "grad_norm": 0.0,
      "learning_rate": 0.00031300265145122234,
      "loss": 5.0282,
      "step": 5524
    },
    {
      "epoch": 0.6335282651072125,
      "grad_norm": 0.0,
      "learning_rate": 0.0003128304723433116,
      "loss": 5.2948,
      "step": 5525
    },
    {
      "epoch": 0.6336429308565531,
      "grad_norm": 0.0,
      "learning_rate": 0.0003126583190587662,
      "loss": 4.7136,
      "step": 5526
    },
    {
      "epoch": 0.6337575966058938,
      "grad_norm": 0.0,
      "learning_rate": 0.0003124861916213313,
      "loss": 4.8932,
      "step": 5527
    },
    {
      "epoch": 0.6338722623552345,
      "grad_norm": 0.0,
      "learning_rate": 0.0003123140900547483,
      "loss": 4.994,
      "step": 5528
    },
    {
      "epoch": 0.6339869281045751,
      "grad_norm": 0.0,
      "learning_rate": 0.0003121420143827555,
      "loss": 5.2808,
      "step": 5529
    },
    {
      "epoch": 0.6341015938539158,
      "grad_norm": 0.0,
      "learning_rate": 0.0003119699646290873,
      "loss": 4.9706,
      "step": 5530
    },
    {
      "epoch": 0.6342162596032566,
      "grad_norm": 0.0,
      "learning_rate": 0.00031179794081747514,
      "loss": 4.6922,
      "step": 5531
    },
    {
      "epoch": 0.6343309253525972,
      "grad_norm": 0.0,
      "learning_rate": 0.0003116259429716461,
      "loss": 4.8864,
      "step": 5532
    },
    {
      "epoch": 0.6344455911019379,
      "grad_norm": 0.0,
      "learning_rate": 0.00031145397111532384,
      "loss": 4.9856,
      "step": 5533
    },
    {
      "epoch": 0.6345602568512785,
      "grad_norm": 0.0,
      "learning_rate": 0.000311282025272229,
      "loss": 4.967,
      "step": 5534
    },
    {
      "epoch": 0.6346749226006192,
      "grad_norm": 0.0,
      "learning_rate": 0.00031111010546607784,
      "loss": 4.9301,
      "step": 5535
    },
    {
      "epoch": 0.6347895883499599,
      "grad_norm": 0.0,
      "learning_rate": 0.00031093821172058385,
      "loss": 4.9898,
      "step": 5536
    },
    {
      "epoch": 0.6349042540993005,
      "grad_norm": 0.0,
      "learning_rate": 0.00031076634405945614,
      "loss": 5.0572,
      "step": 5537
    },
    {
      "epoch": 0.6350189198486412,
      "grad_norm": 0.0,
      "learning_rate": 0.00031059450250640067,
      "loss": 5.0395,
      "step": 5538
    },
    {
      "epoch": 0.6351335855979818,
      "grad_norm": 0.0,
      "learning_rate": 0.00031042268708511973,
      "loss": 4.9895,
      "step": 5539
    },
    {
      "epoch": 0.6352482513473225,
      "grad_norm": 0.0,
      "learning_rate": 0.00031025089781931193,
      "loss": 4.8665,
      "step": 5540
    },
    {
      "epoch": 0.6353629170966633,
      "grad_norm": 0.0,
      "learning_rate": 0.0003100791347326725,
      "loss": 5.0455,
      "step": 5541
    },
    {
      "epoch": 0.6354775828460039,
      "grad_norm": 0.0,
      "learning_rate": 0.00030990739784889277,
      "loss": 5.1901,
      "step": 5542
    },
    {
      "epoch": 0.6355922485953446,
      "grad_norm": 0.0,
      "learning_rate": 0.00030973568719166035,
      "loss": 5.188,
      "step": 5543
    },
    {
      "epoch": 0.6357069143446853,
      "grad_norm": 0.0,
      "learning_rate": 0.00030956400278465984,
      "loss": 4.964,
      "step": 5544
    },
    {
      "epoch": 0.6358215800940259,
      "grad_norm": 0.0,
      "learning_rate": 0.0003093923446515715,
      "loss": 5.3021,
      "step": 5545
    },
    {
      "epoch": 0.6359362458433666,
      "grad_norm": 0.0,
      "learning_rate": 0.0003092207128160726,
      "loss": 5.238,
      "step": 5546
    },
    {
      "epoch": 0.6360509115927072,
      "grad_norm": 0.0,
      "learning_rate": 0.00030904910730183624,
      "loss": 5.0857,
      "step": 5547
    },
    {
      "epoch": 0.6361655773420479,
      "grad_norm": 0.0,
      "learning_rate": 0.00030887752813253227,
      "loss": 5.1906,
      "step": 5548
    },
    {
      "epoch": 0.6362802430913886,
      "grad_norm": 0.0,
      "learning_rate": 0.0003087059753318268,
      "loss": 4.8327,
      "step": 5549
    },
    {
      "epoch": 0.6363949088407292,
      "grad_norm": 0.0,
      "learning_rate": 0.00030853444892338204,
      "loss": 4.9564,
      "step": 5550
    },
    {
      "epoch": 0.63650957459007,
      "grad_norm": 0.0,
      "learning_rate": 0.000308362948930857,
      "loss": 5.0888,
      "step": 5551
    },
    {
      "epoch": 0.6366242403394106,
      "grad_norm": 0.0,
      "learning_rate": 0.0003081914753779066,
      "loss": 4.7395,
      "step": 5552
    },
    {
      "epoch": 0.6367389060887513,
      "grad_norm": 0.0,
      "learning_rate": 0.00030802002828818277,
      "loss": 4.9116,
      "step": 5553
    },
    {
      "epoch": 0.636853571838092,
      "grad_norm": 0.0,
      "learning_rate": 0.00030784860768533315,
      "loss": 5.2625,
      "step": 5554
    },
    {
      "epoch": 0.6369682375874326,
      "grad_norm": 0.0,
      "learning_rate": 0.0003076772135930016,
      "loss": 5.2712,
      "step": 5555
    },
    {
      "epoch": 0.6370829033367733,
      "grad_norm": 0.0,
      "learning_rate": 0.00030750584603482923,
      "loss": 5.0827,
      "step": 5556
    },
    {
      "epoch": 0.637197569086114,
      "grad_norm": 0.0,
      "learning_rate": 0.00030733450503445255,
      "loss": 4.8851,
      "step": 5557
    },
    {
      "epoch": 0.6373122348354546,
      "grad_norm": 0.0,
      "learning_rate": 0.000307163190615505,
      "loss": 5.0956,
      "step": 5558
    },
    {
      "epoch": 0.6374269005847953,
      "grad_norm": 0.0,
      "learning_rate": 0.0003069919028016161,
      "loss": 4.8083,
      "step": 5559
    },
    {
      "epoch": 0.637541566334136,
      "grad_norm": 0.0,
      "learning_rate": 0.0003068206416164114,
      "loss": 4.6846,
      "step": 5560
    },
    {
      "epoch": 0.6376562320834767,
      "grad_norm": 0.0,
      "learning_rate": 0.0003066494070835137,
      "loss": 5.1064,
      "step": 5561
    },
    {
      "epoch": 0.6377708978328174,
      "grad_norm": 0.0,
      "learning_rate": 0.000306478199226541,
      "loss": 4.911,
      "step": 5562
    },
    {
      "epoch": 0.637885563582158,
      "grad_norm": 0.0,
      "learning_rate": 0.00030630701806910857,
      "loss": 5.2699,
      "step": 5563
    },
    {
      "epoch": 0.6380002293314987,
      "grad_norm": 0.0,
      "learning_rate": 0.0003061358636348274,
      "loss": 5.1272,
      "step": 5564
    },
    {
      "epoch": 0.6381148950808394,
      "grad_norm": 0.0,
      "learning_rate": 0.0003059647359473049,
      "loss": 5.0375,
      "step": 5565
    },
    {
      "epoch": 0.63822956083018,
      "grad_norm": 0.0,
      "learning_rate": 0.0003057936350301451,
      "loss": 5.1416,
      "step": 5566
    },
    {
      "epoch": 0.6383442265795207,
      "grad_norm": 0.0,
      "learning_rate": 0.00030562256090694786,
      "loss": 4.7929,
      "step": 5567
    },
    {
      "epoch": 0.6384588923288613,
      "grad_norm": 0.0,
      "learning_rate": 0.00030545151360130996,
      "loss": 5.0397,
      "step": 5568
    },
    {
      "epoch": 0.638573558078202,
      "grad_norm": 0.0,
      "learning_rate": 0.00030528049313682354,
      "loss": 4.9438,
      "step": 5569
    },
    {
      "epoch": 0.6386882238275428,
      "grad_norm": 0.0,
      "learning_rate": 0.0003051094995370782,
      "loss": 5.0385,
      "step": 5570
    },
    {
      "epoch": 0.6388028895768834,
      "grad_norm": 0.0,
      "learning_rate": 0.00030493853282565896,
      "loss": 4.9604,
      "step": 5571
    },
    {
      "epoch": 0.6389175553262241,
      "grad_norm": 0.0,
      "learning_rate": 0.00030476759302614724,
      "loss": 4.7357,
      "step": 5572
    },
    {
      "epoch": 0.6390322210755647,
      "grad_norm": 0.0,
      "learning_rate": 0.0003045966801621214,
      "loss": 5.0846,
      "step": 5573
    },
    {
      "epoch": 0.6391468868249054,
      "grad_norm": 0.0,
      "learning_rate": 0.0003044257942571552,
      "loss": 4.7443,
      "step": 5574
    },
    {
      "epoch": 0.6392615525742461,
      "grad_norm": 0.0,
      "learning_rate": 0.00030425493533481937,
      "loss": 5.3172,
      "step": 5575
    },
    {
      "epoch": 0.6393762183235867,
      "grad_norm": 0.0,
      "learning_rate": 0.0003040841034186805,
      "loss": 4.9612,
      "step": 5576
    },
    {
      "epoch": 0.6394908840729274,
      "grad_norm": 0.0,
      "learning_rate": 0.0003039132985323014,
      "loss": 5.1448,
      "step": 5577
    },
    {
      "epoch": 0.6396055498222681,
      "grad_norm": 0.0,
      "learning_rate": 0.000303742520699242,
      "loss": 5.2,
      "step": 5578
    },
    {
      "epoch": 0.6397202155716087,
      "grad_norm": 0.0,
      "learning_rate": 0.00030357176994305694,
      "loss": 4.9933,
      "step": 5579
    },
    {
      "epoch": 0.6398348813209495,
      "grad_norm": 0.0,
      "learning_rate": 0.0003034010462872988,
      "loss": 5.0951,
      "step": 5580
    },
    {
      "epoch": 0.6399495470702901,
      "grad_norm": 0.0,
      "learning_rate": 0.00030323034975551533,
      "loss": 5.2092,
      "step": 5581
    },
    {
      "epoch": 0.6400642128196308,
      "grad_norm": 0.0,
      "learning_rate": 0.00030305968037125066,
      "loss": 4.8879,
      "step": 5582
    },
    {
      "epoch": 0.6401788785689715,
      "grad_norm": 0.0,
      "learning_rate": 0.0003028890381580459,
      "loss": 4.9651,
      "step": 5583
    },
    {
      "epoch": 0.6402935443183121,
      "grad_norm": 0.0,
      "learning_rate": 0.0003027184231394373,
      "loss": 4.9235,
      "step": 5584
    },
    {
      "epoch": 0.6404082100676528,
      "grad_norm": 0.0,
      "learning_rate": 0.0003025478353389584,
      "loss": 5.1651,
      "step": 5585
    },
    {
      "epoch": 0.6405228758169934,
      "grad_norm": 0.0,
      "learning_rate": 0.0003023772747801384,
      "loss": 5.039,
      "step": 5586
    },
    {
      "epoch": 0.6406375415663341,
      "grad_norm": 0.0,
      "learning_rate": 0.0003022067414865028,
      "loss": 4.794,
      "step": 5587
    },
    {
      "epoch": 0.6407522073156748,
      "grad_norm": 0.0,
      "learning_rate": 0.0003020362354815737,
      "loss": 4.9529,
      "step": 5588
    },
    {
      "epoch": 0.6408668730650154,
      "grad_norm": 0.0,
      "learning_rate": 0.0003018657567888685,
      "loss": 5.0719,
      "step": 5589
    },
    {
      "epoch": 0.6409815388143562,
      "grad_norm": 0.0,
      "learning_rate": 0.00030169530543190225,
      "loss": 5.4235,
      "step": 5590
    },
    {
      "epoch": 0.6410962045636969,
      "grad_norm": 0.0,
      "learning_rate": 0.0003015248814341849,
      "loss": 4.7852,
      "step": 5591
    },
    {
      "epoch": 0.6412108703130375,
      "grad_norm": 0.0,
      "learning_rate": 0.0003013544848192237,
      "loss": 5.2459,
      "step": 5592
    },
    {
      "epoch": 0.6413255360623782,
      "grad_norm": 0.0,
      "learning_rate": 0.0003011841156105213,
      "loss": 5.0678,
      "step": 5593
    },
    {
      "epoch": 0.6414402018117188,
      "grad_norm": 0.0,
      "learning_rate": 0.00030101377383157666,
      "loss": 4.9625,
      "step": 5594
    },
    {
      "epoch": 0.6415548675610595,
      "grad_norm": 0.0,
      "learning_rate": 0.0003008434595058857,
      "loss": 5.1173,
      "step": 5595
    },
    {
      "epoch": 0.6416695333104002,
      "grad_norm": 0.0,
      "learning_rate": 0.0003006731726569395,
      "loss": 5.0125,
      "step": 5596
    },
    {
      "epoch": 0.6417841990597408,
      "grad_norm": 0.0,
      "learning_rate": 0.0003005029133082265,
      "loss": 4.9706,
      "step": 5597
    },
    {
      "epoch": 0.6418988648090815,
      "grad_norm": 0.0,
      "learning_rate": 0.00030033268148323025,
      "loss": 4.8752,
      "step": 5598
    },
    {
      "epoch": 0.6420135305584223,
      "grad_norm": 0.0,
      "learning_rate": 0.0003001624772054312,
      "loss": 4.987,
      "step": 5599
    },
    {
      "epoch": 0.6421281963077629,
      "grad_norm": 0.0,
      "learning_rate": 0.00029999230049830567,
      "loss": 5.0928,
      "step": 5600
    },
    {
      "epoch": 0.6422428620571036,
      "grad_norm": 0.0,
      "learning_rate": 0.0002998221513853262,
      "loss": 5.4977,
      "step": 5601
    },
    {
      "epoch": 0.6423575278064442,
      "grad_norm": 0.0,
      "learning_rate": 0.00029965202988996195,
      "loss": 5.0178,
      "step": 5602
    },
    {
      "epoch": 0.6424721935557849,
      "grad_norm": 0.0,
      "learning_rate": 0.00029948193603567767,
      "loss": 5.1168,
      "step": 5603
    },
    {
      "epoch": 0.6425868593051256,
      "grad_norm": 0.0,
      "learning_rate": 0.00029931186984593456,
      "loss": 4.836,
      "step": 5604
    },
    {
      "epoch": 0.6427015250544662,
      "grad_norm": 0.0,
      "learning_rate": 0.0002991418313441902,
      "loss": 5.0643,
      "step": 5605
    },
    {
      "epoch": 0.6428161908038069,
      "grad_norm": 0.0,
      "learning_rate": 0.0002989718205538979,
      "loss": 4.886,
      "step": 5606
    },
    {
      "epoch": 0.6429308565531475,
      "grad_norm": 0.0,
      "learning_rate": 0.00029880183749850773,
      "loss": 4.8397,
      "step": 5607
    },
    {
      "epoch": 0.6430455223024882,
      "grad_norm": 0.0,
      "learning_rate": 0.0002986318822014654,
      "loss": 5.1298,
      "step": 5608
    },
    {
      "epoch": 0.643160188051829,
      "grad_norm": 0.0,
      "learning_rate": 0.00029846195468621303,
      "loss": 5.1268,
      "step": 5609
    },
    {
      "epoch": 0.6432748538011696,
      "grad_norm": 0.0,
      "learning_rate": 0.00029829205497618893,
      "loss": 4.8472,
      "step": 5610
    },
    {
      "epoch": 0.6433895195505103,
      "grad_norm": 0.0,
      "learning_rate": 0.00029812218309482733,
      "loss": 4.9883,
      "step": 5611
    },
    {
      "epoch": 0.643504185299851,
      "grad_norm": 0.0,
      "learning_rate": 0.0002979523390655592,
      "loss": 4.6712,
      "step": 5612
    },
    {
      "epoch": 0.6436188510491916,
      "grad_norm": 0.0,
      "learning_rate": 0.0002977825229118108,
      "loss": 4.9303,
      "step": 5613
    },
    {
      "epoch": 0.6437335167985323,
      "grad_norm": 0.0,
      "learning_rate": 0.00029761273465700553,
      "loss": 4.8234,
      "step": 5614
    },
    {
      "epoch": 0.6438481825478729,
      "grad_norm": 0.0,
      "learning_rate": 0.0002974429743245622,
      "loss": 5.1344,
      "step": 5615
    },
    {
      "epoch": 0.6439628482972136,
      "grad_norm": 0.0,
      "learning_rate": 0.0002972732419378958,
      "loss": 5.2142,
      "step": 5616
    },
    {
      "epoch": 0.6440775140465543,
      "grad_norm": 0.0,
      "learning_rate": 0.0002971035375204181,
      "loss": 4.9521,
      "step": 5617
    },
    {
      "epoch": 0.6441921797958949,
      "grad_norm": 0.0,
      "learning_rate": 0.0002969338610955363,
      "loss": 4.8591,
      "step": 5618
    },
    {
      "epoch": 0.6443068455452357,
      "grad_norm": 0.0,
      "learning_rate": 0.00029676421268665424,
      "loss": 4.9908,
      "step": 5619
    },
    {
      "epoch": 0.6444215112945763,
      "grad_norm": 0.0,
      "learning_rate": 0.00029659459231717145,
      "loss": 5.1597,
      "step": 5620
    },
    {
      "epoch": 0.644536177043917,
      "grad_norm": 0.0,
      "learning_rate": 0.0002964250000104839,
      "loss": 5.0383,
      "step": 5621
    },
    {
      "epoch": 0.6446508427932577,
      "grad_norm": 0.0,
      "learning_rate": 0.0002962554357899838,
      "loss": 5.0662,
      "step": 5622
    },
    {
      "epoch": 0.6447655085425983,
      "grad_norm": 0.0,
      "learning_rate": 0.00029608589967905887,
      "loss": 5.0746,
      "step": 5623
    },
    {
      "epoch": 0.644880174291939,
      "grad_norm": 0.0,
      "learning_rate": 0.00029591639170109394,
      "loss": 5.3247,
      "step": 5624
    },
    {
      "epoch": 0.6449948400412797,
      "grad_norm": 0.0,
      "learning_rate": 0.0002957469118794691,
      "loss": 4.8393,
      "step": 5625
    },
    {
      "epoch": 0.6451095057906203,
      "grad_norm": 0.0,
      "learning_rate": 0.0002955774602375608,
      "loss": 4.8103,
      "step": 5626
    },
    {
      "epoch": 0.645224171539961,
      "grad_norm": 0.0,
      "learning_rate": 0.0002954080367987419,
      "loss": 5.03,
      "step": 5627
    },
    {
      "epoch": 0.6453388372893016,
      "grad_norm": 0.0,
      "learning_rate": 0.00029523864158638067,
      "loss": 5.0256,
      "step": 5628
    },
    {
      "epoch": 0.6454535030386424,
      "grad_norm": 0.0,
      "learning_rate": 0.0002950692746238428,
      "loss": 4.7913,
      "step": 5629
    },
    {
      "epoch": 0.6455681687879831,
      "grad_norm": 0.0,
      "learning_rate": 0.0002948999359344884,
      "loss": 4.9044,
      "step": 5630
    },
    {
      "epoch": 0.6456828345373237,
      "grad_norm": 0.0,
      "learning_rate": 0.00029473062554167466,
      "loss": 5.1196,
      "step": 5631
    },
    {
      "epoch": 0.6457975002866644,
      "grad_norm": 0.0,
      "learning_rate": 0.00029456134346875516,
      "loss": 5.2158,
      "step": 5632
    },
    {
      "epoch": 0.6459121660360051,
      "grad_norm": 0.0,
      "learning_rate": 0.00029439208973907867,
      "loss": 5.0904,
      "step": 5633
    },
    {
      "epoch": 0.6460268317853457,
      "grad_norm": 0.0,
      "learning_rate": 0.00029422286437599083,
      "loss": 5.0008,
      "step": 5634
    },
    {
      "epoch": 0.6461414975346864,
      "grad_norm": 0.0,
      "learning_rate": 0.0002940536674028327,
      "loss": 5.034,
      "step": 5635
    },
    {
      "epoch": 0.646256163284027,
      "grad_norm": 0.0,
      "learning_rate": 0.00029388449884294233,
      "loss": 4.7092,
      "step": 5636
    },
    {
      "epoch": 0.6463708290333677,
      "grad_norm": 0.0,
      "learning_rate": 0.0002937153587196529,
      "loss": 4.9691,
      "step": 5637
    },
    {
      "epoch": 0.6464854947827084,
      "grad_norm": 0.0,
      "learning_rate": 0.00029354624705629404,
      "loss": 5.0451,
      "step": 5638
    },
    {
      "epoch": 0.646600160532049,
      "grad_norm": 0.0,
      "learning_rate": 0.00029337716387619174,
      "loss": 4.8255,
      "step": 5639
    },
    {
      "epoch": 0.6467148262813898,
      "grad_norm": 0.0,
      "learning_rate": 0.00029320810920266735,
      "loss": 5.0402,
      "step": 5640
    },
    {
      "epoch": 0.6468294920307304,
      "grad_norm": 0.0,
      "learning_rate": 0.00029303908305903923,
      "loss": 5.1211,
      "step": 5641
    },
    {
      "epoch": 0.6469441577800711,
      "grad_norm": 0.0,
      "learning_rate": 0.0002928700854686212,
      "loss": 5.1409,
      "step": 5642
    },
    {
      "epoch": 0.6470588235294118,
      "grad_norm": 0.0,
      "learning_rate": 0.0002927011164547229,
      "loss": 4.9455,
      "step": 5643
    },
    {
      "epoch": 0.6471734892787524,
      "grad_norm": 0.0,
      "learning_rate": 0.0002925321760406509,
      "loss": 4.9646,
      "step": 5644
    },
    {
      "epoch": 0.6472881550280931,
      "grad_norm": 0.0,
      "learning_rate": 0.0002923632642497068,
      "loss": 4.9075,
      "step": 5645
    },
    {
      "epoch": 0.6474028207774338,
      "grad_norm": 0.0,
      "learning_rate": 0.0002921943811051893,
      "loss": 5.1037,
      "step": 5646
    },
    {
      "epoch": 0.6475174865267744,
      "grad_norm": 0.0,
      "learning_rate": 0.0002920255266303923,
      "loss": 5.015,
      "step": 5647
    },
    {
      "epoch": 0.6476321522761151,
      "grad_norm": 0.0,
      "learning_rate": 0.000291856700848606,
      "loss": 5.2108,
      "step": 5648
    },
    {
      "epoch": 0.6477468180254558,
      "grad_norm": 0.0,
      "learning_rate": 0.00029168790378311676,
      "loss": 5.0879,
      "step": 5649
    },
    {
      "epoch": 0.6478614837747965,
      "grad_norm": 0.0,
      "learning_rate": 0.00029151913545720704,
      "loss": 5.1339,
      "step": 5650
    },
    {
      "epoch": 0.6479761495241372,
      "grad_norm": 0.0,
      "learning_rate": 0.0002913503958941551,
      "loss": 4.8912,
      "step": 5651
    },
    {
      "epoch": 0.6480908152734778,
      "grad_norm": 0.0,
      "learning_rate": 0.0002911816851172355,
      "loss": 4.6696,
      "step": 5652
    },
    {
      "epoch": 0.6482054810228185,
      "grad_norm": 0.0,
      "learning_rate": 0.00029101300314971813,
      "loss": 4.7936,
      "step": 5653
    },
    {
      "epoch": 0.6483201467721592,
      "grad_norm": 0.0,
      "learning_rate": 0.00029084435001487034,
      "loss": 5.2879,
      "step": 5654
    },
    {
      "epoch": 0.6484348125214998,
      "grad_norm": 0.0,
      "learning_rate": 0.000290675725735954,
      "loss": 5.1197,
      "step": 5655
    },
    {
      "epoch": 0.6485494782708405,
      "grad_norm": 0.0,
      "learning_rate": 0.0002905071303362276,
      "loss": 5.0749,
      "step": 5656
    },
    {
      "epoch": 0.6486641440201811,
      "grad_norm": 0.0,
      "learning_rate": 0.000290338563838946,
      "loss": 5.0514,
      "step": 5657
    },
    {
      "epoch": 0.6487788097695218,
      "grad_norm": 0.0,
      "learning_rate": 0.0002901700262673594,
      "loss": 5.1357,
      "step": 5658
    },
    {
      "epoch": 0.6488934755188626,
      "grad_norm": 0.0,
      "learning_rate": 0.00029000151764471476,
      "loss": 5.0717,
      "step": 5659
    },
    {
      "epoch": 0.6490081412682032,
      "grad_norm": 0.0,
      "learning_rate": 0.000289833037994254,
      "loss": 4.9748,
      "step": 5660
    },
    {
      "epoch": 0.6491228070175439,
      "grad_norm": 0.0,
      "learning_rate": 0.0002896645873392164,
      "loss": 5.1265,
      "step": 5661
    },
    {
      "epoch": 0.6492374727668845,
      "grad_norm": 0.0,
      "learning_rate": 0.00028949616570283577,
      "loss": 4.9383,
      "step": 5662
    },
    {
      "epoch": 0.6493521385162252,
      "grad_norm": 0.0,
      "learning_rate": 0.0002893277731083435,
      "loss": 5.0342,
      "step": 5663
    },
    {
      "epoch": 0.6494668042655659,
      "grad_norm": 0.0,
      "learning_rate": 0.0002891594095789654,
      "loss": 4.9801,
      "step": 5664
    },
    {
      "epoch": 0.6495814700149065,
      "grad_norm": 0.0,
      "learning_rate": 0.0002889910751379244,
      "loss": 4.9346,
      "step": 5665
    },
    {
      "epoch": 0.6496961357642472,
      "grad_norm": 0.0,
      "learning_rate": 0.0002888227698084392,
      "loss": 4.8743,
      "step": 5666
    },
    {
      "epoch": 0.6498108015135879,
      "grad_norm": 0.0,
      "learning_rate": 0.00028865449361372347,
      "loss": 5.0378,
      "step": 5667
    },
    {
      "epoch": 0.6499254672629285,
      "grad_norm": 0.0,
      "learning_rate": 0.0002884862465769889,
      "loss": 4.6939,
      "step": 5668
    },
    {
      "epoch": 0.6500401330122693,
      "grad_norm": 0.0,
      "learning_rate": 0.000288318028721441,
      "loss": 5.1485,
      "step": 5669
    },
    {
      "epoch": 0.6501547987616099,
      "grad_norm": 0.0,
      "learning_rate": 0.00028814984007028257,
      "loss": 4.8854,
      "step": 5670
    },
    {
      "epoch": 0.6502694645109506,
      "grad_norm": 0.0,
      "learning_rate": 0.000287981680646712,
      "loss": 5.0486,
      "step": 5671
    },
    {
      "epoch": 0.6503841302602913,
      "grad_norm": 0.0,
      "learning_rate": 0.0002878135504739237,
      "loss": 5.0095,
      "step": 5672
    },
    {
      "epoch": 0.6504987960096319,
      "grad_norm": 0.0,
      "learning_rate": 0.00028764544957510805,
      "loss": 4.9722,
      "step": 5673
    },
    {
      "epoch": 0.6506134617589726,
      "grad_norm": 0.0,
      "learning_rate": 0.00028747737797345154,
      "loss": 5.0123,
      "step": 5674
    },
    {
      "epoch": 0.6507281275083132,
      "grad_norm": 0.0,
      "learning_rate": 0.00028730933569213595,
      "loss": 4.946,
      "step": 5675
    },
    {
      "epoch": 0.6508427932576539,
      "grad_norm": 0.0,
      "learning_rate": 0.0002871413227543399,
      "loss": 5.1403,
      "step": 5676
    },
    {
      "epoch": 0.6509574590069946,
      "grad_norm": 0.0,
      "learning_rate": 0.0002869733391832374,
      "loss": 5.3065,
      "step": 5677
    },
    {
      "epoch": 0.6510721247563352,
      "grad_norm": 0.0,
      "learning_rate": 0.0002868053850019987,
      "loss": 4.9716,
      "step": 5678
    },
    {
      "epoch": 0.651186790505676,
      "grad_norm": 0.0,
      "learning_rate": 0.00028663746023378984,
      "loss": 4.9368,
      "step": 5679
    },
    {
      "epoch": 0.6513014562550167,
      "grad_norm": 0.0,
      "learning_rate": 0.00028646956490177274,
      "loss": 4.9667,
      "step": 5680
    },
    {
      "epoch": 0.6514161220043573,
      "grad_norm": 0.0,
      "learning_rate": 0.0002863016990291057,
      "loss": 5.0429,
      "step": 5681
    },
    {
      "epoch": 0.651530787753698,
      "grad_norm": 0.0,
      "learning_rate": 0.000286133862638942,
      "loss": 4.9483,
      "step": 5682
    },
    {
      "epoch": 0.6516454535030386,
      "grad_norm": 0.0,
      "learning_rate": 0.00028596605575443223,
      "loss": 5.1399,
      "step": 5683
    },
    {
      "epoch": 0.6517601192523793,
      "grad_norm": 0.0,
      "learning_rate": 0.0002857982783987213,
      "loss": 5.1618,
      "step": 5684
    },
    {
      "epoch": 0.65187478500172,
      "grad_norm": 0.0,
      "learning_rate": 0.0002856305305949518,
      "loss": 4.9016,
      "step": 5685
    },
    {
      "epoch": 0.6519894507510606,
      "grad_norm": 0.0,
      "learning_rate": 0.00028546281236626085,
      "loss": 5.174,
      "step": 5686
    },
    {
      "epoch": 0.6521041165004013,
      "grad_norm": 0.0,
      "learning_rate": 0.0002852951237357817,
      "loss": 5.2976,
      "step": 5687
    },
    {
      "epoch": 0.6522187822497421,
      "grad_norm": 0.0,
      "learning_rate": 0.00028512746472664446,
      "loss": 5.0551,
      "step": 5688
    },
    {
      "epoch": 0.6523334479990827,
      "grad_norm": 0.0,
      "learning_rate": 0.00028495983536197376,
      "loss": 5.0636,
      "step": 5689
    },
    {
      "epoch": 0.6524481137484234,
      "grad_norm": 0.0,
      "learning_rate": 0.0002847922356648918,
      "loss": 4.8967,
      "step": 5690
    },
    {
      "epoch": 0.652562779497764,
      "grad_norm": 0.0,
      "learning_rate": 0.000284624665658515,
      "loss": 4.8981,
      "step": 5691
    },
    {
      "epoch": 0.6526774452471047,
      "grad_norm": 0.0,
      "learning_rate": 0.0002844571253659566,
      "loss": 4.6383,
      "step": 5692
    },
    {
      "epoch": 0.6527921109964454,
      "grad_norm": 0.0,
      "learning_rate": 0.0002842896148103257,
      "loss": 4.9258,
      "step": 5693
    },
    {
      "epoch": 0.652906776745786,
      "grad_norm": 0.0,
      "learning_rate": 0.00028412213401472725,
      "loss": 4.9396,
      "step": 5694
    },
    {
      "epoch": 0.6530214424951267,
      "grad_norm": 0.0,
      "learning_rate": 0.0002839546830022621,
      "loss": 4.8096,
      "step": 5695
    },
    {
      "epoch": 0.6531361082444673,
      "grad_norm": 0.0,
      "learning_rate": 0.00028378726179602656,
      "loss": 4.8755,
      "step": 5696
    },
    {
      "epoch": 0.653250773993808,
      "grad_norm": 0.0,
      "learning_rate": 0.0002836198704191134,
      "loss": 4.8416,
      "step": 5697
    },
    {
      "epoch": 0.6533654397431488,
      "grad_norm": 0.0,
      "learning_rate": 0.00028345250889461114,
      "loss": 4.9057,
      "step": 5698
    },
    {
      "epoch": 0.6534801054924894,
      "grad_norm": 0.0,
      "learning_rate": 0.0002832851772456041,
      "loss": 4.9299,
      "step": 5699
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.0,
      "learning_rate": 0.00028311787549517245,
      "loss": 5.0589,
      "step": 5700
    },
    {
      "epoch": 0.6537094369911708,
      "grad_norm": 0.0,
      "learning_rate": 0.0002829506036663921,
      "loss": 5.2964,
      "step": 5701
    },
    {
      "epoch": 0.6538241027405114,
      "grad_norm": 0.0,
      "learning_rate": 0.00028278336178233526,
      "loss": 5.1222,
      "step": 5702
    },
    {
      "epoch": 0.6539387684898521,
      "grad_norm": 0.0,
      "learning_rate": 0.00028261614986607,
      "loss": 4.7725,
      "step": 5703
    },
    {
      "epoch": 0.6540534342391927,
      "grad_norm": 0.0,
      "learning_rate": 0.0002824489679406592,
      "loss": 5.203,
      "step": 5704
    },
    {
      "epoch": 0.6541680999885334,
      "grad_norm": 0.0,
      "learning_rate": 0.0002822818160291633,
      "loss": 4.9687,
      "step": 5705
    },
    {
      "epoch": 0.6542827657378741,
      "grad_norm": 0.0,
      "learning_rate": 0.0002821146941546371,
      "loss": 4.9693,
      "step": 5706
    },
    {
      "epoch": 0.6543974314872147,
      "grad_norm": 0.0,
      "learning_rate": 0.00028194760234013226,
      "loss": 5.2082,
      "step": 5707
    },
    {
      "epoch": 0.6545120972365555,
      "grad_norm": 0.0,
      "learning_rate": 0.0002817805406086959,
      "loss": 4.9875,
      "step": 5708
    },
    {
      "epoch": 0.6546267629858961,
      "grad_norm": 0.0,
      "learning_rate": 0.0002816135089833705,
      "loss": 5.1411,
      "step": 5709
    },
    {
      "epoch": 0.6547414287352368,
      "grad_norm": 0.0,
      "learning_rate": 0.0002814465074871956,
      "loss": 4.8481,
      "step": 5710
    },
    {
      "epoch": 0.6548560944845775,
      "grad_norm": 0.0,
      "learning_rate": 0.0002812795361432052,
      "loss": 5.1678,
      "step": 5711
    },
    {
      "epoch": 0.6549707602339181,
      "grad_norm": 0.0,
      "learning_rate": 0.0002811125949744304,
      "loss": 5.2851,
      "step": 5712
    },
    {
      "epoch": 0.6550854259832588,
      "grad_norm": 0.0,
      "learning_rate": 0.0002809456840038972,
      "loss": 5.1689,
      "step": 5713
    },
    {
      "epoch": 0.6552000917325995,
      "grad_norm": 0.0,
      "learning_rate": 0.0002807788032546279,
      "loss": 4.7968,
      "step": 5714
    },
    {
      "epoch": 0.6553147574819401,
      "grad_norm": 0.0,
      "learning_rate": 0.0002806119527496407,
      "loss": 4.8935,
      "step": 5715
    },
    {
      "epoch": 0.6554294232312808,
      "grad_norm": 0.0,
      "learning_rate": 0.00028044513251194883,
      "loss": 5.0609,
      "step": 5716
    },
    {
      "epoch": 0.6555440889806214,
      "grad_norm": 0.0,
      "learning_rate": 0.0002802783425645627,
      "loss": 5.1306,
      "step": 5717
    },
    {
      "epoch": 0.6556587547299622,
      "grad_norm": 0.0,
      "learning_rate": 0.0002801115829304874,
      "loss": 4.6257,
      "step": 5718
    },
    {
      "epoch": 0.6557734204793029,
      "grad_norm": 0.0,
      "learning_rate": 0.00027994485363272426,
      "loss": 4.9456,
      "step": 5719
    },
    {
      "epoch": 0.6558880862286435,
      "grad_norm": 0.0,
      "learning_rate": 0.00027977815469427047,
      "loss": 5.35,
      "step": 5720
    },
    {
      "epoch": 0.6560027519779842,
      "grad_norm": 0.0,
      "learning_rate": 0.00027961148613811905,
      "loss": 4.8932,
      "step": 5721
    },
    {
      "epoch": 0.6561174177273249,
      "grad_norm": 0.0,
      "learning_rate": 0.00027944484798725865,
      "loss": 4.9076,
      "step": 5722
    },
    {
      "epoch": 0.6562320834766655,
      "grad_norm": 0.0,
      "learning_rate": 0.0002792782402646738,
      "loss": 4.9713,
      "step": 5723
    },
    {
      "epoch": 0.6563467492260062,
      "grad_norm": 0.0,
      "learning_rate": 0.00027911166299334503,
      "loss": 5.0938,
      "step": 5724
    },
    {
      "epoch": 0.6564614149753468,
      "grad_norm": 0.0,
      "learning_rate": 0.00027894511619624854,
      "loss": 5.126,
      "step": 5725
    },
    {
      "epoch": 0.6565760807246875,
      "grad_norm": 0.0,
      "learning_rate": 0.00027877859989635577,
      "loss": 4.9023,
      "step": 5726
    },
    {
      "epoch": 0.6566907464740283,
      "grad_norm": 0.0,
      "learning_rate": 0.00027861211411663505,
      "loss": 5.1305,
      "step": 5727
    },
    {
      "epoch": 0.6568054122233689,
      "grad_norm": 0.0,
      "learning_rate": 0.0002784456588800496,
      "loss": 4.7308,
      "step": 5728
    },
    {
      "epoch": 0.6569200779727096,
      "grad_norm": 0.0,
      "learning_rate": 0.00027827923420955874,
      "loss": 5.108,
      "step": 5729
    },
    {
      "epoch": 0.6570347437220502,
      "grad_norm": 0.0,
      "learning_rate": 0.000278112840128118,
      "loss": 5.048,
      "step": 5730
    },
    {
      "epoch": 0.6571494094713909,
      "grad_norm": 0.0,
      "learning_rate": 0.0002779464766586776,
      "loss": 4.9354,
      "step": 5731
    },
    {
      "epoch": 0.6572640752207316,
      "grad_norm": 0.0,
      "learning_rate": 0.0002777801438241849,
      "loss": 5.1296,
      "step": 5732
    },
    {
      "epoch": 0.6573787409700722,
      "grad_norm": 0.0,
      "learning_rate": 0.00027761384164758156,
      "loss": 4.8403,
      "step": 5733
    },
    {
      "epoch": 0.6574934067194129,
      "grad_norm": 0.0,
      "learning_rate": 0.0002774475701518068,
      "loss": 4.9274,
      "step": 5734
    },
    {
      "epoch": 0.6576080724687536,
      "grad_norm": 0.0,
      "learning_rate": 0.00027728132935979377,
      "loss": 5.2311,
      "step": 5735
    },
    {
      "epoch": 0.6577227382180942,
      "grad_norm": 0.0,
      "learning_rate": 0.0002771151192944725,
      "loss": 5.0934,
      "step": 5736
    },
    {
      "epoch": 0.657837403967435,
      "grad_norm": 0.0,
      "learning_rate": 0.0002769489399787686,
      "loss": 5.1625,
      "step": 5737
    },
    {
      "epoch": 0.6579520697167756,
      "grad_norm": 0.0,
      "learning_rate": 0.000276782791435603,
      "loss": 5.1208,
      "step": 5738
    },
    {
      "epoch": 0.6580667354661163,
      "grad_norm": 0.0,
      "learning_rate": 0.0002766166736878932,
      "loss": 4.8745,
      "step": 5739
    },
    {
      "epoch": 0.658181401215457,
      "grad_norm": 0.0,
      "learning_rate": 0.00027645058675855166,
      "loss": 5.158,
      "step": 5740
    },
    {
      "epoch": 0.6582960669647976,
      "grad_norm": 0.0,
      "learning_rate": 0.0002762845306704869,
      "loss": 5.3625,
      "step": 5741
    },
    {
      "epoch": 0.6584107327141383,
      "grad_norm": 0.0,
      "learning_rate": 0.0002761185054466034,
      "loss": 5.1254,
      "step": 5742
    },
    {
      "epoch": 0.6585253984634789,
      "grad_norm": 0.0,
      "learning_rate": 0.0002759525111098009,
      "loss": 5.1185,
      "step": 5743
    },
    {
      "epoch": 0.6586400642128196,
      "grad_norm": 0.0,
      "learning_rate": 0.00027578654768297534,
      "loss": 5.3423,
      "step": 5744
    },
    {
      "epoch": 0.6587547299621603,
      "grad_norm": 0.0,
      "learning_rate": 0.00027562061518901824,
      "loss": 4.9344,
      "step": 5745
    },
    {
      "epoch": 0.6588693957115009,
      "grad_norm": 0.0,
      "learning_rate": 0.000275454713650817,
      "loss": 5.0174,
      "step": 5746
    },
    {
      "epoch": 0.6589840614608417,
      "grad_norm": 0.0,
      "learning_rate": 0.00027528884309125403,
      "loss": 5.2133,
      "step": 5747
    },
    {
      "epoch": 0.6590987272101824,
      "grad_norm": 0.0,
      "learning_rate": 0.00027512300353320834,
      "loss": 5.1308,
      "step": 5748
    },
    {
      "epoch": 0.659213392959523,
      "grad_norm": 0.0,
      "learning_rate": 0.0002749571949995544,
      "loss": 5.1265,
      "step": 5749
    },
    {
      "epoch": 0.6593280587088637,
      "grad_norm": 0.0,
      "learning_rate": 0.00027479141751316215,
      "loss": 4.9379,
      "step": 5750
    },
    {
      "epoch": 0.6594427244582043,
      "grad_norm": 0.0,
      "learning_rate": 0.0002746256710968976,
      "loss": 4.9898,
      "step": 5751
    },
    {
      "epoch": 0.659557390207545,
      "grad_norm": 0.0,
      "learning_rate": 0.00027445995577362237,
      "loss": 4.8858,
      "step": 5752
    },
    {
      "epoch": 0.6596720559568857,
      "grad_norm": 0.0,
      "learning_rate": 0.00027429427156619327,
      "loss": 4.9897,
      "step": 5753
    },
    {
      "epoch": 0.6597867217062263,
      "grad_norm": 0.0,
      "learning_rate": 0.00027412861849746397,
      "loss": 4.9045,
      "step": 5754
    },
    {
      "epoch": 0.659901387455567,
      "grad_norm": 0.0,
      "learning_rate": 0.0002739629965902824,
      "loss": 5.0421,
      "step": 5755
    },
    {
      "epoch": 0.6600160532049077,
      "grad_norm": 0.0,
      "learning_rate": 0.00027379740586749374,
      "loss": 4.8965,
      "step": 5756
    },
    {
      "epoch": 0.6601307189542484,
      "grad_norm": 0.0,
      "learning_rate": 0.0002736318463519377,
      "loss": 5.1497,
      "step": 5757
    },
    {
      "epoch": 0.6602453847035891,
      "grad_norm": 0.0,
      "learning_rate": 0.00027346631806644963,
      "loss": 5.0344,
      "step": 5758
    },
    {
      "epoch": 0.6603600504529297,
      "grad_norm": 0.0,
      "learning_rate": 0.0002733008210338618,
      "loss": 4.9687,
      "step": 5759
    },
    {
      "epoch": 0.6604747162022704,
      "grad_norm": 0.0,
      "learning_rate": 0.00027313535527700056,
      "loss": 4.7615,
      "step": 5760
    },
    {
      "epoch": 0.6605893819516111,
      "grad_norm": 0.0,
      "learning_rate": 0.0002729699208186896,
      "loss": 4.977,
      "step": 5761
    },
    {
      "epoch": 0.6607040477009517,
      "grad_norm": 0.0,
      "learning_rate": 0.0002728045176817468,
      "loss": 5.1964,
      "step": 5762
    },
    {
      "epoch": 0.6608187134502924,
      "grad_norm": 0.0,
      "learning_rate": 0.0002726391458889866,
      "loss": 5.273,
      "step": 5763
    },
    {
      "epoch": 0.660933379199633,
      "grad_norm": 0.0,
      "learning_rate": 0.0002724738054632189,
      "loss": 4.9143,
      "step": 5764
    },
    {
      "epoch": 0.6610480449489737,
      "grad_norm": 0.0,
      "learning_rate": 0.0002723084964272492,
      "loss": 5.0267,
      "step": 5765
    },
    {
      "epoch": 0.6611627106983144,
      "grad_norm": 0.0,
      "learning_rate": 0.000272143218803879,
      "loss": 5.1851,
      "step": 5766
    },
    {
      "epoch": 0.661277376447655,
      "grad_norm": 0.0,
      "learning_rate": 0.00027197797261590455,
      "loss": 5.1371,
      "step": 5767
    },
    {
      "epoch": 0.6613920421969958,
      "grad_norm": 0.0,
      "learning_rate": 0.0002718127578861192,
      "loss": 5.0688,
      "step": 5768
    },
    {
      "epoch": 0.6615067079463365,
      "grad_norm": 0.0,
      "learning_rate": 0.0002716475746373107,
      "loss": 5.1395,
      "step": 5769
    },
    {
      "epoch": 0.6616213736956771,
      "grad_norm": 0.0,
      "learning_rate": 0.00027148242289226296,
      "loss": 5.1033,
      "step": 5770
    },
    {
      "epoch": 0.6617360394450178,
      "grad_norm": 0.0,
      "learning_rate": 0.0002713173026737556,
      "loss": 5.1093,
      "step": 5771
    },
    {
      "epoch": 0.6618507051943584,
      "grad_norm": 0.0,
      "learning_rate": 0.0002711522140045637,
      "loss": 5.2696,
      "step": 5772
    },
    {
      "epoch": 0.6619653709436991,
      "grad_norm": 0.0,
      "learning_rate": 0.00027098715690745837,
      "loss": 4.8964,
      "step": 5773
    },
    {
      "epoch": 0.6620800366930398,
      "grad_norm": 0.0,
      "learning_rate": 0.00027082213140520593,
      "loss": 5.1743,
      "step": 5774
    },
    {
      "epoch": 0.6621947024423804,
      "grad_norm": 0.0,
      "learning_rate": 0.0002706571375205683,
      "loss": 5.167,
      "step": 5775
    },
    {
      "epoch": 0.6623093681917211,
      "grad_norm": 0.0,
      "learning_rate": 0.0002704921752763036,
      "loss": 4.9755,
      "step": 5776
    },
    {
      "epoch": 0.6624240339410618,
      "grad_norm": 0.0,
      "learning_rate": 0.00027032724469516496,
      "loss": 4.8641,
      "step": 5777
    },
    {
      "epoch": 0.6625386996904025,
      "grad_norm": 0.0,
      "learning_rate": 0.00027016234579990147,
      "loss": 5.1828,
      "step": 5778
    },
    {
      "epoch": 0.6626533654397432,
      "grad_norm": 0.0,
      "learning_rate": 0.0002699974786132581,
      "loss": 5.0981,
      "step": 5779
    },
    {
      "epoch": 0.6627680311890838,
      "grad_norm": 0.0,
      "learning_rate": 0.0002698326431579743,
      "loss": 5.0012,
      "step": 5780
    },
    {
      "epoch": 0.6628826969384245,
      "grad_norm": 0.0,
      "learning_rate": 0.00026966783945678703,
      "loss": 4.9537,
      "step": 5781
    },
    {
      "epoch": 0.6629973626877652,
      "grad_norm": 0.0,
      "learning_rate": 0.000269503067532427,
      "loss": 4.8693,
      "step": 5782
    },
    {
      "epoch": 0.6631120284371058,
      "grad_norm": 0.0,
      "learning_rate": 0.00026933832740762194,
      "loss": 4.8389,
      "step": 5783
    },
    {
      "epoch": 0.6632266941864465,
      "grad_norm": 0.0,
      "learning_rate": 0.0002691736191050942,
      "loss": 5.0661,
      "step": 5784
    },
    {
      "epoch": 0.6633413599357871,
      "grad_norm": 0.0,
      "learning_rate": 0.0002690089426475623,
      "loss": 5.2853,
      "step": 5785
    },
    {
      "epoch": 0.6634560256851278,
      "grad_norm": 0.0,
      "learning_rate": 0.00026884429805774024,
      "loss": 5.0234,
      "step": 5786
    },
    {
      "epoch": 0.6635706914344686,
      "grad_norm": 0.0,
      "learning_rate": 0.0002686796853583376,
      "loss": 5.2177,
      "step": 5787
    },
    {
      "epoch": 0.6636853571838092,
      "grad_norm": 0.0,
      "learning_rate": 0.0002685151045720597,
      "loss": 5.3264,
      "step": 5788
    },
    {
      "epoch": 0.6638000229331499,
      "grad_norm": 0.0,
      "learning_rate": 0.0002683505557216068,
      "loss": 4.9134,
      "step": 5789
    },
    {
      "epoch": 0.6639146886824906,
      "grad_norm": 0.0,
      "learning_rate": 0.000268186038829676,
      "loss": 4.9058,
      "step": 5790
    },
    {
      "epoch": 0.6640293544318312,
      "grad_norm": 0.0,
      "learning_rate": 0.00026802155391895873,
      "loss": 5.1613,
      "step": 5791
    },
    {
      "epoch": 0.6641440201811719,
      "grad_norm": 0.0,
      "learning_rate": 0.00026785710101214275,
      "loss": 4.9228,
      "step": 5792
    },
    {
      "epoch": 0.6642586859305125,
      "grad_norm": 0.0,
      "learning_rate": 0.00026769268013191117,
      "loss": 4.9918,
      "step": 5793
    },
    {
      "epoch": 0.6643733516798532,
      "grad_norm": 0.0,
      "learning_rate": 0.00026752829130094274,
      "loss": 4.9703,
      "step": 5794
    },
    {
      "epoch": 0.664488017429194,
      "grad_norm": 0.0,
      "learning_rate": 0.00026736393454191175,
      "loss": 4.9893,
      "step": 5795
    },
    {
      "epoch": 0.6646026831785345,
      "grad_norm": 0.0,
      "learning_rate": 0.00026719960987748833,
      "loss": 4.9701,
      "step": 5796
    },
    {
      "epoch": 0.6647173489278753,
      "grad_norm": 0.0,
      "learning_rate": 0.00026703531733033746,
      "loss": 4.9775,
      "step": 5797
    },
    {
      "epoch": 0.6648320146772159,
      "grad_norm": 0.0,
      "learning_rate": 0.0002668710569231204,
      "loss": 4.921,
      "step": 5798
    },
    {
      "epoch": 0.6649466804265566,
      "grad_norm": 0.0,
      "learning_rate": 0.00026670682867849374,
      "loss": 5.1037,
      "step": 5799
    },
    {
      "epoch": 0.6650613461758973,
      "grad_norm": 0.0,
      "learning_rate": 0.00026654263261910964,
      "loss": 5.2001,
      "step": 5800
    },
    {
      "epoch": 0.6651760119252379,
      "grad_norm": 0.0,
      "learning_rate": 0.00026637846876761604,
      "loss": 5.216,
      "step": 5801
    },
    {
      "epoch": 0.6652906776745786,
      "grad_norm": 0.0,
      "learning_rate": 0.00026621433714665556,
      "loss": 5.2698,
      "step": 5802
    },
    {
      "epoch": 0.6654053434239193,
      "grad_norm": 0.0,
      "learning_rate": 0.0002660502377788679,
      "loss": 4.9,
      "step": 5803
    },
    {
      "epoch": 0.6655200091732599,
      "grad_norm": 0.0,
      "learning_rate": 0.0002658861706868865,
      "loss": 5.0194,
      "step": 5804
    },
    {
      "epoch": 0.6656346749226006,
      "grad_norm": 0.0,
      "learning_rate": 0.0002657221358933423,
      "loss": 4.9034,
      "step": 5805
    },
    {
      "epoch": 0.6657493406719412,
      "grad_norm": 0.0,
      "learning_rate": 0.00026555813342085997,
      "loss": 5.0432,
      "step": 5806
    },
    {
      "epoch": 0.665864006421282,
      "grad_norm": 0.0,
      "learning_rate": 0.0002653941632920608,
      "loss": 5.2827,
      "step": 5807
    },
    {
      "epoch": 0.6659786721706227,
      "grad_norm": 0.0,
      "learning_rate": 0.00026523022552956164,
      "loss": 5.005,
      "step": 5808
    },
    {
      "epoch": 0.6660933379199633,
      "grad_norm": 0.0,
      "learning_rate": 0.0002650663201559739,
      "loss": 5.1387,
      "step": 5809
    },
    {
      "epoch": 0.666208003669304,
      "grad_norm": 0.0,
      "learning_rate": 0.000264902447193906,
      "loss": 5.2119,
      "step": 5810
    },
    {
      "epoch": 0.6663226694186446,
      "grad_norm": 0.0,
      "learning_rate": 0.00026473860666596024,
      "loss": 5.0128,
      "step": 5811
    },
    {
      "epoch": 0.6664373351679853,
      "grad_norm": 0.0,
      "learning_rate": 0.0002645747985947361,
      "loss": 4.9663,
      "step": 5812
    },
    {
      "epoch": 0.666552000917326,
      "grad_norm": 0.0,
      "learning_rate": 0.00026441102300282733,
      "loss": 5.0127,
      "step": 5813
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.0,
      "learning_rate": 0.00026424727991282367,
      "loss": 5.0692,
      "step": 5814
    },
    {
      "epoch": 0.6667813324160073,
      "grad_norm": 0.0,
      "learning_rate": 0.0002640835693473105,
      "loss": 4.6438,
      "step": 5815
    },
    {
      "epoch": 0.6668959981653481,
      "grad_norm": 0.0,
      "learning_rate": 0.00026391989132886845,
      "loss": 4.9841,
      "step": 5816
    },
    {
      "epoch": 0.6670106639146887,
      "grad_norm": 0.0,
      "learning_rate": 0.00026375624588007403,
      "loss": 4.9757,
      "step": 5817
    },
    {
      "epoch": 0.6671253296640294,
      "grad_norm": 0.0,
      "learning_rate": 0.0002635926330234987,
      "loss": 5.0772,
      "step": 5818
    },
    {
      "epoch": 0.66723999541337,
      "grad_norm": 0.0,
      "learning_rate": 0.0002634290527817098,
      "loss": 5.3299,
      "step": 5819
    },
    {
      "epoch": 0.6673546611627107,
      "grad_norm": 0.0,
      "learning_rate": 0.0002632655051772703,
      "loss": 4.9542,
      "step": 5820
    },
    {
      "epoch": 0.6674693269120514,
      "grad_norm": 0.0,
      "learning_rate": 0.0002631019902327381,
      "loss": 4.9741,
      "step": 5821
    },
    {
      "epoch": 0.667583992661392,
      "grad_norm": 0.0,
      "learning_rate": 0.0002629385079706673,
      "loss": 4.9017,
      "step": 5822
    },
    {
      "epoch": 0.6676986584107327,
      "grad_norm": 0.0,
      "learning_rate": 0.0002627750584136073,
      "loss": 4.8154,
      "step": 5823
    },
    {
      "epoch": 0.6678133241600734,
      "grad_norm": 0.0,
      "learning_rate": 0.0002626116415841023,
      "loss": 5.1725,
      "step": 5824
    },
    {
      "epoch": 0.667927989909414,
      "grad_norm": 0.0,
      "learning_rate": 0.00026244825750469317,
      "loss": 4.8508,
      "step": 5825
    },
    {
      "epoch": 0.6680426556587548,
      "grad_norm": 0.0,
      "learning_rate": 0.00026228490619791494,
      "loss": 4.8422,
      "step": 5826
    },
    {
      "epoch": 0.6681573214080954,
      "grad_norm": 0.0,
      "learning_rate": 0.00026212158768629956,
      "loss": 5.015,
      "step": 5827
    },
    {
      "epoch": 0.6682719871574361,
      "grad_norm": 0.0,
      "learning_rate": 0.00026195830199237334,
      "loss": 4.9272,
      "step": 5828
    },
    {
      "epoch": 0.6683866529067768,
      "grad_norm": 0.0,
      "learning_rate": 0.000261795049138658,
      "loss": 4.732,
      "step": 5829
    },
    {
      "epoch": 0.6685013186561174,
      "grad_norm": 0.0,
      "learning_rate": 0.000261631829147672,
      "loss": 4.896,
      "step": 5830
    },
    {
      "epoch": 0.6686159844054581,
      "grad_norm": 0.0,
      "learning_rate": 0.0002614686420419276,
      "loss": 5.0127,
      "step": 5831
    },
    {
      "epoch": 0.6687306501547987,
      "grad_norm": 0.0,
      "learning_rate": 0.0002613054878439342,
      "loss": 5.2468,
      "step": 5832
    },
    {
      "epoch": 0.6688453159041394,
      "grad_norm": 0.0,
      "learning_rate": 0.00026114236657619487,
      "loss": 5.105,
      "step": 5833
    },
    {
      "epoch": 0.6689599816534801,
      "grad_norm": 0.0,
      "learning_rate": 0.00026097927826121,
      "loss": 5.2278,
      "step": 5834
    },
    {
      "epoch": 0.6690746474028207,
      "grad_norm": 0.0,
      "learning_rate": 0.00026081622292147396,
      "loss": 5.0488,
      "step": 5835
    },
    {
      "epoch": 0.6691893131521615,
      "grad_norm": 0.0,
      "learning_rate": 0.00026065320057947725,
      "loss": 4.9474,
      "step": 5836
    },
    {
      "epoch": 0.6693039789015022,
      "grad_norm": 0.0,
      "learning_rate": 0.00026049021125770566,
      "loss": 5.2347,
      "step": 5837
    },
    {
      "epoch": 0.6694186446508428,
      "grad_norm": 0.0,
      "learning_rate": 0.0002603272549786405,
      "loss": 4.9259,
      "step": 5838
    },
    {
      "epoch": 0.6695333104001835,
      "grad_norm": 0.0,
      "learning_rate": 0.0002601643317647587,
      "loss": 5.0635,
      "step": 5839
    },
    {
      "epoch": 0.6696479761495241,
      "grad_norm": 0.0,
      "learning_rate": 0.000260001441638532,
      "loss": 5.183,
      "step": 5840
    },
    {
      "epoch": 0.6697626418988648,
      "grad_norm": 0.0,
      "learning_rate": 0.00025983858462242813,
      "loss": 4.9553,
      "step": 5841
    },
    {
      "epoch": 0.6698773076482055,
      "grad_norm": 0.0,
      "learning_rate": 0.0002596757607389102,
      "loss": 5.3438,
      "step": 5842
    },
    {
      "epoch": 0.6699919733975461,
      "grad_norm": 0.0,
      "learning_rate": 0.0002595129700104367,
      "loss": 4.8739,
      "step": 5843
    },
    {
      "epoch": 0.6701066391468868,
      "grad_norm": 0.0,
      "learning_rate": 0.00025935021245946136,
      "loss": 5.2423,
      "step": 5844
    },
    {
      "epoch": 0.6702213048962274,
      "grad_norm": 0.0,
      "learning_rate": 0.0002591874881084338,
      "loss": 5.2425,
      "step": 5845
    },
    {
      "epoch": 0.6703359706455682,
      "grad_norm": 0.0,
      "learning_rate": 0.000259024796979798,
      "loss": 4.6828,
      "step": 5846
    },
    {
      "epoch": 0.6704506363949089,
      "grad_norm": 0.0,
      "learning_rate": 0.0002588621390959951,
      "loss": 5.0498,
      "step": 5847
    },
    {
      "epoch": 0.6705653021442495,
      "grad_norm": 0.0,
      "learning_rate": 0.00025869951447945994,
      "loss": 5.1638,
      "step": 5848
    },
    {
      "epoch": 0.6706799678935902,
      "grad_norm": 0.0,
      "learning_rate": 0.0002585369231526236,
      "loss": 4.9375,
      "step": 5849
    },
    {
      "epoch": 0.6707946336429309,
      "grad_norm": 0.0,
      "learning_rate": 0.0002583743651379129,
      "loss": 4.7665,
      "step": 5850
    },
    {
      "epoch": 0.6709092993922715,
      "grad_norm": 0.0,
      "learning_rate": 0.0002582118404577488,
      "loss": 4.8278,
      "step": 5851
    },
    {
      "epoch": 0.6710239651416122,
      "grad_norm": 0.0,
      "learning_rate": 0.00025804934913454934,
      "loss": 5.0092,
      "step": 5852
    },
    {
      "epoch": 0.6711386308909528,
      "grad_norm": 0.0,
      "learning_rate": 0.00025788689119072634,
      "loss": 4.8312,
      "step": 5853
    },
    {
      "epoch": 0.6712532966402935,
      "grad_norm": 0.0,
      "learning_rate": 0.0002577244666486885,
      "loss": 5.0599,
      "step": 5854
    },
    {
      "epoch": 0.6713679623896343,
      "grad_norm": 0.0,
      "learning_rate": 0.00025756207553083855,
      "loss": 5.1481,
      "step": 5855
    },
    {
      "epoch": 0.6714826281389749,
      "grad_norm": 0.0,
      "learning_rate": 0.0002573997178595758,
      "loss": 4.9016,
      "step": 5856
    },
    {
      "epoch": 0.6715972938883156,
      "grad_norm": 0.0,
      "learning_rate": 0.0002572373936572941,
      "loss": 4.8369,
      "step": 5857
    },
    {
      "epoch": 0.6717119596376563,
      "grad_norm": 0.0,
      "learning_rate": 0.0002570751029463829,
      "loss": 5.1472,
      "step": 5858
    },
    {
      "epoch": 0.6718266253869969,
      "grad_norm": 0.0,
      "learning_rate": 0.00025691284574922747,
      "loss": 4.9661,
      "step": 5859
    },
    {
      "epoch": 0.6719412911363376,
      "grad_norm": 0.0,
      "learning_rate": 0.0002567506220882074,
      "loss": 5.1858,
      "step": 5860
    },
    {
      "epoch": 0.6720559568856782,
      "grad_norm": 0.0,
      "learning_rate": 0.0002565884319856993,
      "loss": 4.9694,
      "step": 5861
    },
    {
      "epoch": 0.6721706226350189,
      "grad_norm": 0.0,
      "learning_rate": 0.00025642627546407345,
      "loss": 5.1155,
      "step": 5862
    },
    {
      "epoch": 0.6722852883843596,
      "grad_norm": 0.0,
      "learning_rate": 0.0002562641525456964,
      "loss": 5.0888,
      "step": 5863
    },
    {
      "epoch": 0.6723999541337002,
      "grad_norm": 0.0,
      "learning_rate": 0.0002561020632529302,
      "loss": 4.7951,
      "step": 5864
    },
    {
      "epoch": 0.672514619883041,
      "grad_norm": 0.0,
      "learning_rate": 0.00025594000760813175,
      "loss": 4.9185,
      "step": 5865
    },
    {
      "epoch": 0.6726292856323816,
      "grad_norm": 0.0,
      "learning_rate": 0.0002557779856336536,
      "loss": 5.0851,
      "step": 5866
    },
    {
      "epoch": 0.6727439513817223,
      "grad_norm": 0.0,
      "learning_rate": 0.0002556159973518437,
      "loss": 5.2453,
      "step": 5867
    },
    {
      "epoch": 0.672858617131063,
      "grad_norm": 0.0,
      "learning_rate": 0.00025545404278504505,
      "loss": 5.1276,
      "step": 5868
    },
    {
      "epoch": 0.6729732828804036,
      "grad_norm": 0.0,
      "learning_rate": 0.0002552921219555962,
      "loss": 5.0502,
      "step": 5869
    },
    {
      "epoch": 0.6730879486297443,
      "grad_norm": 0.0,
      "learning_rate": 0.00025513023488583117,
      "loss": 4.81,
      "step": 5870
    },
    {
      "epoch": 0.673202614379085,
      "grad_norm": 0.0,
      "learning_rate": 0.00025496838159807904,
      "loss": 5.2023,
      "step": 5871
    },
    {
      "epoch": 0.6733172801284256,
      "grad_norm": 0.0,
      "learning_rate": 0.00025480656211466476,
      "loss": 5.159,
      "step": 5872
    },
    {
      "epoch": 0.6734319458777663,
      "grad_norm": 0.0,
      "learning_rate": 0.00025464477645790757,
      "loss": 5.1164,
      "step": 5873
    },
    {
      "epoch": 0.6735466116271069,
      "grad_norm": 0.0,
      "learning_rate": 0.00025448302465012353,
      "loss": 4.918,
      "step": 5874
    },
    {
      "epoch": 0.6736612773764477,
      "grad_norm": 0.0,
      "learning_rate": 0.00025432130671362233,
      "loss": 4.965,
      "step": 5875
    },
    {
      "epoch": 0.6737759431257884,
      "grad_norm": 0.0,
      "learning_rate": 0.0002541596226707108,
      "loss": 5.0783,
      "step": 5876
    },
    {
      "epoch": 0.673890608875129,
      "grad_norm": 0.0,
      "learning_rate": 0.0002539979725436894,
      "loss": 4.9835,
      "step": 5877
    },
    {
      "epoch": 0.6740052746244697,
      "grad_norm": 0.0,
      "learning_rate": 0.0002538363563548553,
      "loss": 4.9142,
      "step": 5878
    },
    {
      "epoch": 0.6741199403738103,
      "grad_norm": 0.0,
      "learning_rate": 0.00025367477412650016,
      "loss": 5.0291,
      "step": 5879
    },
    {
      "epoch": 0.674234606123151,
      "grad_norm": 0.0,
      "learning_rate": 0.0002535132258809107,
      "loss": 4.9653,
      "step": 5880
    },
    {
      "epoch": 0.6743492718724917,
      "grad_norm": 0.0,
      "learning_rate": 0.00025335171164037013,
      "loss": 5.0674,
      "step": 5881
    },
    {
      "epoch": 0.6744639376218323,
      "grad_norm": 0.0,
      "learning_rate": 0.0002531902314271556,
      "loss": 5.1679,
      "step": 5882
    },
    {
      "epoch": 0.674578603371173,
      "grad_norm": 0.0,
      "learning_rate": 0.0002530287852635409,
      "loss": 5.1764,
      "step": 5883
    },
    {
      "epoch": 0.6746932691205138,
      "grad_norm": 0.0,
      "learning_rate": 0.000252867373171794,
      "loss": 5.0114,
      "step": 5884
    },
    {
      "epoch": 0.6748079348698544,
      "grad_norm": 0.0,
      "learning_rate": 0.0002527059951741787,
      "loss": 5.0947,
      "step": 5885
    },
    {
      "epoch": 0.6749226006191951,
      "grad_norm": 0.0,
      "learning_rate": 0.00025254465129295414,
      "loss": 5.0983,
      "step": 5886
    },
    {
      "epoch": 0.6750372663685357,
      "grad_norm": 0.0,
      "learning_rate": 0.0002523833415503744,
      "loss": 5.0233,
      "step": 5887
    },
    {
      "epoch": 0.6751519321178764,
      "grad_norm": 0.0,
      "learning_rate": 0.0002522220659686896,
      "loss": 5.0699,
      "step": 5888
    },
    {
      "epoch": 0.6752665978672171,
      "grad_norm": 0.0,
      "learning_rate": 0.00025206082457014396,
      "loss": 5.1881,
      "step": 5889
    },
    {
      "epoch": 0.6753812636165577,
      "grad_norm": 0.0,
      "learning_rate": 0.000251899617376978,
      "loss": 5.0351,
      "step": 5890
    },
    {
      "epoch": 0.6754959293658984,
      "grad_norm": 0.0,
      "learning_rate": 0.0002517384444114272,
      "loss": 5.0105,
      "step": 5891
    },
    {
      "epoch": 0.6756105951152391,
      "grad_norm": 0.0,
      "learning_rate": 0.0002515773056957221,
      "loss": 5.2071,
      "step": 5892
    },
    {
      "epoch": 0.6757252608645797,
      "grad_norm": 0.0,
      "learning_rate": 0.00025141620125208896,
      "loss": 4.8399,
      "step": 5893
    },
    {
      "epoch": 0.6758399266139204,
      "grad_norm": 0.0,
      "learning_rate": 0.00025125513110274913,
      "loss": 5.1365,
      "step": 5894
    },
    {
      "epoch": 0.675954592363261,
      "grad_norm": 0.0,
      "learning_rate": 0.0002510940952699187,
      "loss": 5.1733,
      "step": 5895
    },
    {
      "epoch": 0.6760692581126018,
      "grad_norm": 0.0,
      "learning_rate": 0.0002509330937758101,
      "loss": 4.6496,
      "step": 5896
    },
    {
      "epoch": 0.6761839238619425,
      "grad_norm": 0.0,
      "learning_rate": 0.0002507721266426297,
      "loss": 5.1035,
      "step": 5897
    },
    {
      "epoch": 0.6762985896112831,
      "grad_norm": 0.0,
      "learning_rate": 0.00025061119389258073,
      "loss": 5.1852,
      "step": 5898
    },
    {
      "epoch": 0.6764132553606238,
      "grad_norm": 0.0,
      "learning_rate": 0.0002504502955478601,
      "loss": 5.138,
      "step": 5899
    },
    {
      "epoch": 0.6765279211099644,
      "grad_norm": 0.0,
      "learning_rate": 0.00025028943163066085,
      "loss": 5.0023,
      "step": 5900
    },
    {
      "epoch": 0.6766425868593051,
      "grad_norm": 0.0,
      "learning_rate": 0.0002501286021631714,
      "loss": 4.9561,
      "step": 5901
    },
    {
      "epoch": 0.6767572526086458,
      "grad_norm": 0.0,
      "learning_rate": 0.00024996780716757445,
      "loss": 4.8837,
      "step": 5902
    },
    {
      "epoch": 0.6768719183579864,
      "grad_norm": 0.0,
      "learning_rate": 0.0002498070466660494,
      "loss": 5.0731,
      "step": 5903
    },
    {
      "epoch": 0.6769865841073271,
      "grad_norm": 0.0,
      "learning_rate": 0.0002496463206807692,
      "loss": 5.031,
      "step": 5904
    },
    {
      "epoch": 0.6771012498566679,
      "grad_norm": 0.0,
      "learning_rate": 0.00024948562923390394,
      "loss": 5.0739,
      "step": 5905
    },
    {
      "epoch": 0.6772159156060085,
      "grad_norm": 0.0,
      "learning_rate": 0.0002493249723476172,
      "loss": 5.0569,
      "step": 5906
    },
    {
      "epoch": 0.6773305813553492,
      "grad_norm": 0.0,
      "learning_rate": 0.00024916435004406883,
      "loss": 5.0519,
      "step": 5907
    },
    {
      "epoch": 0.6774452471046898,
      "grad_norm": 0.0,
      "learning_rate": 0.00024900376234541344,
      "loss": 5.0307,
      "step": 5908
    },
    {
      "epoch": 0.6775599128540305,
      "grad_norm": 0.0,
      "learning_rate": 0.0002488432092738012,
      "loss": 4.888,
      "step": 5909
    },
    {
      "epoch": 0.6776745786033712,
      "grad_norm": 0.0,
      "learning_rate": 0.00024868269085137753,
      "loss": 4.9133,
      "step": 5910
    },
    {
      "epoch": 0.6777892443527118,
      "grad_norm": 0.0,
      "learning_rate": 0.00024852220710028244,
      "loss": 5.4154,
      "step": 5911
    },
    {
      "epoch": 0.6779039101020525,
      "grad_norm": 0.0,
      "learning_rate": 0.00024836175804265187,
      "loss": 5.2674,
      "step": 5912
    },
    {
      "epoch": 0.6780185758513931,
      "grad_norm": 0.0,
      "learning_rate": 0.0002482013437006166,
      "loss": 4.9813,
      "step": 5913
    },
    {
      "epoch": 0.6781332416007338,
      "grad_norm": 0.0,
      "learning_rate": 0.00024804096409630284,
      "loss": 4.906,
      "step": 5914
    },
    {
      "epoch": 0.6782479073500746,
      "grad_norm": 0.0,
      "learning_rate": 0.00024788061925183185,
      "loss": 4.7975,
      "step": 5915
    },
    {
      "epoch": 0.6783625730994152,
      "grad_norm": 0.0,
      "learning_rate": 0.00024772030918932014,
      "loss": 4.9934,
      "step": 5916
    },
    {
      "epoch": 0.6784772388487559,
      "grad_norm": 0.0,
      "learning_rate": 0.00024756003393087945,
      "loss": 5.1241,
      "step": 5917
    },
    {
      "epoch": 0.6785919045980966,
      "grad_norm": 0.0,
      "learning_rate": 0.00024739979349861684,
      "loss": 4.9603,
      "step": 5918
    },
    {
      "epoch": 0.6787065703474372,
      "grad_norm": 0.0,
      "learning_rate": 0.0002472395879146341,
      "loss": 4.9679,
      "step": 5919
    },
    {
      "epoch": 0.6788212360967779,
      "grad_norm": 0.0,
      "learning_rate": 0.00024707941720102864,
      "loss": 5.1056,
      "step": 5920
    },
    {
      "epoch": 0.6789359018461185,
      "grad_norm": 0.0,
      "learning_rate": 0.00024691928137989314,
      "loss": 4.9724,
      "step": 5921
    },
    {
      "epoch": 0.6790505675954592,
      "grad_norm": 0.0,
      "learning_rate": 0.00024675918047331504,
      "loss": 5.0052,
      "step": 5922
    },
    {
      "epoch": 0.6791652333448,
      "grad_norm": 0.0,
      "learning_rate": 0.0002465991145033776,
      "loss": 5.1262,
      "step": 5923
    },
    {
      "epoch": 0.6792798990941405,
      "grad_norm": 0.0,
      "learning_rate": 0.0002464390834921582,
      "loss": 4.8394,
      "step": 5924
    },
    {
      "epoch": 0.6793945648434813,
      "grad_norm": 0.0,
      "learning_rate": 0.00024627908746173086,
      "loss": 5.0548,
      "step": 5925
    },
    {
      "epoch": 0.679509230592822,
      "grad_norm": 0.0,
      "learning_rate": 0.00024611912643416315,
      "loss": 4.8466,
      "step": 5926
    },
    {
      "epoch": 0.6796238963421626,
      "grad_norm": 0.0,
      "learning_rate": 0.0002459592004315196,
      "loss": 5.02,
      "step": 5927
    },
    {
      "epoch": 0.6797385620915033,
      "grad_norm": 0.0,
      "learning_rate": 0.00024579930947585813,
      "loss": 5.1752,
      "step": 5928
    },
    {
      "epoch": 0.6798532278408439,
      "grad_norm": 0.0,
      "learning_rate": 0.00024563945358923293,
      "loss": 5.1312,
      "step": 5929
    },
    {
      "epoch": 0.6799678935901846,
      "grad_norm": 0.0,
      "learning_rate": 0.00024547963279369337,
      "loss": 5.2428,
      "step": 5930
    },
    {
      "epoch": 0.6800825593395253,
      "grad_norm": 0.0,
      "learning_rate": 0.00024531984711128306,
      "loss": 4.9503,
      "step": 5931
    },
    {
      "epoch": 0.6801972250888659,
      "grad_norm": 0.0,
      "learning_rate": 0.0002451600965640421,
      "loss": 5.1751,
      "step": 5932
    },
    {
      "epoch": 0.6803118908382066,
      "grad_norm": 0.0,
      "learning_rate": 0.0002450003811740044,
      "loss": 5.0196,
      "step": 5933
    },
    {
      "epoch": 0.6804265565875472,
      "grad_norm": 0.0,
      "learning_rate": 0.0002448407009632,
      "loss": 5.0849,
      "step": 5934
    },
    {
      "epoch": 0.680541222336888,
      "grad_norm": 0.0,
      "learning_rate": 0.00024468105595365367,
      "loss": 4.98,
      "step": 5935
    },
    {
      "epoch": 0.6806558880862287,
      "grad_norm": 0.0,
      "learning_rate": 0.0002445214461673854,
      "loss": 5.0543,
      "step": 5936
    },
    {
      "epoch": 0.6807705538355693,
      "grad_norm": 0.0,
      "learning_rate": 0.0002443618716264103,
      "loss": 5.0446,
      "step": 5937
    },
    {
      "epoch": 0.68088521958491,
      "grad_norm": 0.0,
      "learning_rate": 0.00024420233235273865,
      "loss": 5.2285,
      "step": 5938
    },
    {
      "epoch": 0.6809998853342507,
      "grad_norm": 0.0,
      "learning_rate": 0.00024404282836837604,
      "loss": 4.9904,
      "step": 5939
    },
    {
      "epoch": 0.6811145510835913,
      "grad_norm": 0.0,
      "learning_rate": 0.00024388335969532265,
      "loss": 4.8852,
      "step": 5940
    },
    {
      "epoch": 0.681229216832932,
      "grad_norm": 0.0,
      "learning_rate": 0.0002437239263555743,
      "loss": 4.89,
      "step": 5941
    },
    {
      "epoch": 0.6813438825822726,
      "grad_norm": 0.0,
      "learning_rate": 0.00024356452837112177,
      "loss": 5.2484,
      "step": 5942
    },
    {
      "epoch": 0.6814585483316133,
      "grad_norm": 0.0,
      "learning_rate": 0.00024340516576395096,
      "loss": 4.9197,
      "step": 5943
    },
    {
      "epoch": 0.6815732140809541,
      "grad_norm": 0.0,
      "learning_rate": 0.00024324583855604305,
      "loss": 5.0246,
      "step": 5944
    },
    {
      "epoch": 0.6816878798302947,
      "grad_norm": 0.0,
      "learning_rate": 0.00024308654676937419,
      "loss": 5.2093,
      "step": 5945
    },
    {
      "epoch": 0.6818025455796354,
      "grad_norm": 0.0,
      "learning_rate": 0.00024292729042591513,
      "loss": 4.8618,
      "step": 5946
    },
    {
      "epoch": 0.681917211328976,
      "grad_norm": 0.0,
      "learning_rate": 0.0002427680695476331,
      "loss": 4.9413,
      "step": 5947
    },
    {
      "epoch": 0.6820318770783167,
      "grad_norm": 0.0,
      "learning_rate": 0.00024260888415648872,
      "loss": 5.0305,
      "step": 5948
    },
    {
      "epoch": 0.6821465428276574,
      "grad_norm": 0.0,
      "learning_rate": 0.00024244973427443934,
      "loss": 5.0123,
      "step": 5949
    },
    {
      "epoch": 0.682261208576998,
      "grad_norm": 0.0,
      "learning_rate": 0.0002422906199234364,
      "loss": 4.7899,
      "step": 5950
    },
    {
      "epoch": 0.6823758743263387,
      "grad_norm": 0.0,
      "learning_rate": 0.00024213154112542615,
      "loss": 4.7049,
      "step": 5951
    },
    {
      "epoch": 0.6824905400756794,
      "grad_norm": 0.0,
      "learning_rate": 0.0002419724979023513,
      "loss": 4.8816,
      "step": 5952
    },
    {
      "epoch": 0.68260520582502,
      "grad_norm": 0.0,
      "learning_rate": 0.00024181349027614811,
      "loss": 5.0463,
      "step": 5953
    },
    {
      "epoch": 0.6827198715743608,
      "grad_norm": 0.0,
      "learning_rate": 0.00024165451826874937,
      "loss": 4.8699,
      "step": 5954
    },
    {
      "epoch": 0.6828345373237014,
      "grad_norm": 0.0,
      "learning_rate": 0.0002414955819020817,
      "loss": 5.1019,
      "step": 5955
    },
    {
      "epoch": 0.6829492030730421,
      "grad_norm": 0.0,
      "learning_rate": 0.0002413366811980675,
      "loss": 4.8784,
      "step": 5956
    },
    {
      "epoch": 0.6830638688223828,
      "grad_norm": 0.0,
      "learning_rate": 0.0002411778161786241,
      "loss": 5.1354,
      "step": 5957
    },
    {
      "epoch": 0.6831785345717234,
      "grad_norm": 0.0,
      "learning_rate": 0.0002410189868656639,
      "loss": 5.0691,
      "step": 5958
    },
    {
      "epoch": 0.6832932003210641,
      "grad_norm": 0.0,
      "learning_rate": 0.00024086019328109438,
      "loss": 5.0759,
      "step": 5959
    },
    {
      "epoch": 0.6834078660704048,
      "grad_norm": 0.0,
      "learning_rate": 0.00024070143544681807,
      "loss": 4.9421,
      "step": 5960
    },
    {
      "epoch": 0.6835225318197454,
      "grad_norm": 0.0,
      "learning_rate": 0.00024054271338473288,
      "loss": 5.0436,
      "step": 5961
    },
    {
      "epoch": 0.6836371975690861,
      "grad_norm": 0.0,
      "learning_rate": 0.000240384027116731,
      "loss": 4.8691,
      "step": 5962
    },
    {
      "epoch": 0.6837518633184267,
      "grad_norm": 0.0,
      "learning_rate": 0.00024022537666470035,
      "loss": 5.1274,
      "step": 5963
    },
    {
      "epoch": 0.6838665290677675,
      "grad_norm": 0.0,
      "learning_rate": 0.0002400667620505238,
      "loss": 5.0614,
      "step": 5964
    },
    {
      "epoch": 0.6839811948171082,
      "grad_norm": 0.0,
      "learning_rate": 0.00023990818329607916,
      "loss": 5.108,
      "step": 5965
    },
    {
      "epoch": 0.6840958605664488,
      "grad_norm": 0.0,
      "learning_rate": 0.00023974964042323946,
      "loss": 4.8393,
      "step": 5966
    },
    {
      "epoch": 0.6842105263157895,
      "grad_norm": 0.0,
      "learning_rate": 0.0002395911334538727,
      "loss": 5.1058,
      "step": 5967
    },
    {
      "epoch": 0.6843251920651301,
      "grad_norm": 0.0,
      "learning_rate": 0.00023943266240984145,
      "loss": 4.9886,
      "step": 5968
    },
    {
      "epoch": 0.6844398578144708,
      "grad_norm": 0.0,
      "learning_rate": 0.00023927422731300448,
      "loss": 5.2933,
      "step": 5969
    },
    {
      "epoch": 0.6845545235638115,
      "grad_norm": 0.0,
      "learning_rate": 0.00023911582818521426,
      "loss": 5.0211,
      "step": 5970
    },
    {
      "epoch": 0.6846691893131521,
      "grad_norm": 0.0,
      "learning_rate": 0.00023895746504831925,
      "loss": 4.9383,
      "step": 5971
    },
    {
      "epoch": 0.6847838550624928,
      "grad_norm": 0.0,
      "learning_rate": 0.00023879913792416275,
      "loss": 4.8702,
      "step": 5972
    },
    {
      "epoch": 0.6848985208118336,
      "grad_norm": 0.0,
      "learning_rate": 0.00023864084683458236,
      "loss": 4.9606,
      "step": 5973
    },
    {
      "epoch": 0.6850131865611742,
      "grad_norm": 0.0,
      "learning_rate": 0.0002384825918014122,
      "loss": 4.9756,
      "step": 5974
    },
    {
      "epoch": 0.6851278523105149,
      "grad_norm": 0.0,
      "learning_rate": 0.0002383243728464796,
      "loss": 5.0325,
      "step": 5975
    },
    {
      "epoch": 0.6852425180598555,
      "grad_norm": 0.0,
      "learning_rate": 0.00023816618999160873,
      "loss": 4.6371,
      "step": 5976
    },
    {
      "epoch": 0.6853571838091962,
      "grad_norm": 0.0,
      "learning_rate": 0.00023800804325861729,
      "loss": 4.6896,
      "step": 5977
    },
    {
      "epoch": 0.6854718495585369,
      "grad_norm": 0.0,
      "learning_rate": 0.00023784993266931883,
      "loss": 5.2314,
      "step": 5978
    },
    {
      "epoch": 0.6855865153078775,
      "grad_norm": 0.0,
      "learning_rate": 0.00023769185824552163,
      "loss": 4.8817,
      "step": 5979
    },
    {
      "epoch": 0.6857011810572182,
      "grad_norm": 0.0,
      "learning_rate": 0.00023753382000902916,
      "loss": 5.4129,
      "step": 5980
    },
    {
      "epoch": 0.6858158468065588,
      "grad_norm": 0.0,
      "learning_rate": 0.00023737581798163984,
      "loss": 4.8847,
      "step": 5981
    },
    {
      "epoch": 0.6859305125558995,
      "grad_norm": 0.0,
      "learning_rate": 0.00023721785218514655,
      "loss": 5.082,
      "step": 5982
    },
    {
      "epoch": 0.6860451783052403,
      "grad_norm": 0.0,
      "learning_rate": 0.00023705992264133838,
      "loss": 5.0518,
      "step": 5983
    },
    {
      "epoch": 0.6861598440545809,
      "grad_norm": 0.0,
      "learning_rate": 0.00023690202937199815,
      "loss": 4.9911,
      "step": 5984
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.0,
      "learning_rate": 0.00023674417239890442,
      "loss": 4.9664,
      "step": 5985
    },
    {
      "epoch": 0.6863891755532623,
      "grad_norm": 0.0,
      "learning_rate": 0.00023658635174383054,
      "loss": 4.9927,
      "step": 5986
    },
    {
      "epoch": 0.6865038413026029,
      "grad_norm": 0.0,
      "learning_rate": 0.00023642856742854486,
      "loss": 5.2446,
      "step": 5987
    },
    {
      "epoch": 0.6866185070519436,
      "grad_norm": 0.0,
      "learning_rate": 0.0002362708194748107,
      "loss": 4.8663,
      "step": 5988
    },
    {
      "epoch": 0.6867331728012842,
      "grad_norm": 0.0,
      "learning_rate": 0.0002361131079043866,
      "loss": 5.135,
      "step": 5989
    },
    {
      "epoch": 0.6868478385506249,
      "grad_norm": 0.0,
      "learning_rate": 0.0002359554327390255,
      "loss": 4.9372,
      "step": 5990
    },
    {
      "epoch": 0.6869625042999656,
      "grad_norm": 0.0,
      "learning_rate": 0.00023579779400047582,
      "loss": 5.0292,
      "step": 5991
    },
    {
      "epoch": 0.6870771700493062,
      "grad_norm": 0.0,
      "learning_rate": 0.00023564019171048086,
      "loss": 5.0194,
      "step": 5992
    },
    {
      "epoch": 0.687191835798647,
      "grad_norm": 0.0,
      "learning_rate": 0.00023548262589077887,
      "loss": 5.1175,
      "step": 5993
    },
    {
      "epoch": 0.6873065015479877,
      "grad_norm": 0.0,
      "learning_rate": 0.00023532509656310326,
      "loss": 5.0961,
      "step": 5994
    },
    {
      "epoch": 0.6874211672973283,
      "grad_norm": 0.0,
      "learning_rate": 0.00023516760374918147,
      "loss": 5.0191,
      "step": 5995
    },
    {
      "epoch": 0.687535833046669,
      "grad_norm": 0.0,
      "learning_rate": 0.00023501014747073757,
      "loss": 4.9029,
      "step": 5996
    },
    {
      "epoch": 0.6876504987960096,
      "grad_norm": 0.0,
      "learning_rate": 0.00023485272774948884,
      "loss": 4.6844,
      "step": 5997
    },
    {
      "epoch": 0.6877651645453503,
      "grad_norm": 0.0,
      "learning_rate": 0.00023469534460714904,
      "loss": 4.8649,
      "step": 5998
    },
    {
      "epoch": 0.687879830294691,
      "grad_norm": 0.0,
      "learning_rate": 0.00023453799806542566,
      "loss": 5.0572,
      "step": 5999
    },
    {
      "epoch": 0.6879944960440316,
      "grad_norm": 0.0,
      "learning_rate": 0.00023438068814602184,
      "loss": 4.8306,
      "step": 6000
    },
    {
      "epoch": 0.6881091617933723,
      "grad_norm": 0.0,
      "learning_rate": 0.00023422341487063563,
      "loss": 5.0712,
      "step": 6001
    },
    {
      "epoch": 0.6882238275427129,
      "grad_norm": 0.0,
      "learning_rate": 0.00023406617826095938,
      "loss": 5.1092,
      "step": 6002
    },
    {
      "epoch": 0.6883384932920537,
      "grad_norm": 0.0,
      "learning_rate": 0.0002339089783386816,
      "loss": 4.9346,
      "step": 6003
    },
    {
      "epoch": 0.6884531590413944,
      "grad_norm": 0.0,
      "learning_rate": 0.00023375181512548426,
      "loss": 4.9816,
      "step": 6004
    },
    {
      "epoch": 0.688567824790735,
      "grad_norm": 0.0,
      "learning_rate": 0.0002335946886430458,
      "loss": 5.1451,
      "step": 6005
    },
    {
      "epoch": 0.6886824905400757,
      "grad_norm": 0.0,
      "learning_rate": 0.0002334375989130382,
      "loss": 4.9917,
      "step": 6006
    },
    {
      "epoch": 0.6887971562894164,
      "grad_norm": 0.0,
      "learning_rate": 0.00023328054595712927,
      "loss": 4.8541,
      "step": 6007
    },
    {
      "epoch": 0.688911822038757,
      "grad_norm": 0.0,
      "learning_rate": 0.0002331235297969815,
      "loss": 5.1628,
      "step": 6008
    },
    {
      "epoch": 0.6890264877880977,
      "grad_norm": 0.0,
      "learning_rate": 0.00023296655045425214,
      "loss": 5.02,
      "step": 6009
    },
    {
      "epoch": 0.6891411535374383,
      "grad_norm": 0.0,
      "learning_rate": 0.00023280960795059378,
      "loss": 4.8158,
      "step": 6010
    },
    {
      "epoch": 0.689255819286779,
      "grad_norm": 0.0,
      "learning_rate": 0.0002326527023076533,
      "loss": 4.854,
      "step": 6011
    },
    {
      "epoch": 0.6893704850361198,
      "grad_norm": 0.0,
      "learning_rate": 0.0002324958335470729,
      "loss": 5.2674,
      "step": 6012
    },
    {
      "epoch": 0.6894851507854604,
      "grad_norm": 0.0,
      "learning_rate": 0.00023233900169048976,
      "loss": 5.0398,
      "step": 6013
    },
    {
      "epoch": 0.6895998165348011,
      "grad_norm": 0.0,
      "learning_rate": 0.00023218220675953576,
      "loss": 4.908,
      "step": 6014
    },
    {
      "epoch": 0.6897144822841417,
      "grad_norm": 0.0,
      "learning_rate": 0.00023202544877583788,
      "loss": 4.8998,
      "step": 6015
    },
    {
      "epoch": 0.6898291480334824,
      "grad_norm": 0.0,
      "learning_rate": 0.00023186872776101796,
      "loss": 5.2225,
      "step": 6016
    },
    {
      "epoch": 0.6899438137828231,
      "grad_norm": 0.0,
      "learning_rate": 0.00023171204373669219,
      "loss": 4.9396,
      "step": 6017
    },
    {
      "epoch": 0.6900584795321637,
      "grad_norm": 0.0,
      "learning_rate": 0.00023155539672447284,
      "loss": 5.1914,
      "step": 6018
    },
    {
      "epoch": 0.6901731452815044,
      "grad_norm": 0.0,
      "learning_rate": 0.00023139878674596572,
      "loss": 4.8944,
      "step": 6019
    },
    {
      "epoch": 0.6902878110308451,
      "grad_norm": 0.0,
      "learning_rate": 0.00023124221382277285,
      "loss": 5.0025,
      "step": 6020
    },
    {
      "epoch": 0.6904024767801857,
      "grad_norm": 0.0,
      "learning_rate": 0.00023108567797649015,
      "loss": 5.0928,
      "step": 6021
    },
    {
      "epoch": 0.6905171425295265,
      "grad_norm": 0.0,
      "learning_rate": 0.00023092917922870837,
      "loss": 4.8115,
      "step": 6022
    },
    {
      "epoch": 0.690631808278867,
      "grad_norm": 0.0,
      "learning_rate": 0.00023077271760101427,
      "loss": 4.9325,
      "step": 6023
    },
    {
      "epoch": 0.6907464740282078,
      "grad_norm": 0.0,
      "learning_rate": 0.00023061629311498804,
      "loss": 4.8848,
      "step": 6024
    },
    {
      "epoch": 0.6908611397775485,
      "grad_norm": 0.0,
      "learning_rate": 0.00023045990579220618,
      "loss": 4.9978,
      "step": 6025
    },
    {
      "epoch": 0.6909758055268891,
      "grad_norm": 0.0,
      "learning_rate": 0.00023030355565423856,
      "loss": 5.0625,
      "step": 6026
    },
    {
      "epoch": 0.6910904712762298,
      "grad_norm": 0.0,
      "learning_rate": 0.00023014724272265148,
      "loss": 5.1117,
      "step": 6027
    },
    {
      "epoch": 0.6912051370255705,
      "grad_norm": 0.0,
      "learning_rate": 0.00022999096701900481,
      "loss": 5.0231,
      "step": 6028
    },
    {
      "epoch": 0.6913198027749111,
      "grad_norm": 0.0,
      "learning_rate": 0.00022983472856485387,
      "loss": 5.1217,
      "step": 6029
    },
    {
      "epoch": 0.6914344685242518,
      "grad_norm": 0.0,
      "learning_rate": 0.0002296785273817489,
      "loss": 4.9622,
      "step": 6030
    },
    {
      "epoch": 0.6915491342735924,
      "grad_norm": 0.0,
      "learning_rate": 0.0002295223634912348,
      "loss": 4.9019,
      "step": 6031
    },
    {
      "epoch": 0.6916638000229332,
      "grad_norm": 0.0,
      "learning_rate": 0.00022936623691485167,
      "loss": 5.1394,
      "step": 6032
    },
    {
      "epoch": 0.6917784657722739,
      "grad_norm": 0.0,
      "learning_rate": 0.0002292101476741337,
      "loss": 5.0431,
      "step": 6033
    },
    {
      "epoch": 0.6918931315216145,
      "grad_norm": 0.0,
      "learning_rate": 0.00022905409579061076,
      "loss": 5.1013,
      "step": 6034
    },
    {
      "epoch": 0.6920077972709552,
      "grad_norm": 0.0,
      "learning_rate": 0.00022889808128580708,
      "loss": 4.7667,
      "step": 6035
    },
    {
      "epoch": 0.6921224630202958,
      "grad_norm": 0.0,
      "learning_rate": 0.00022874210418124196,
      "loss": 5.0523,
      "step": 6036
    },
    {
      "epoch": 0.6922371287696365,
      "grad_norm": 0.0,
      "learning_rate": 0.00022858616449842952,
      "loss": 5.2671,
      "step": 6037
    },
    {
      "epoch": 0.6923517945189772,
      "grad_norm": 0.0,
      "learning_rate": 0.0002284302622588788,
      "loss": 5.0228,
      "step": 6038
    },
    {
      "epoch": 0.6924664602683178,
      "grad_norm": 0.0,
      "learning_rate": 0.00022827439748409297,
      "loss": 4.9407,
      "step": 6039
    },
    {
      "epoch": 0.6925811260176585,
      "grad_norm": 0.0,
      "learning_rate": 0.00022811857019557134,
      "loss": 5.2213,
      "step": 6040
    },
    {
      "epoch": 0.6926957917669992,
      "grad_norm": 0.0,
      "learning_rate": 0.00022796278041480682,
      "loss": 5.0655,
      "step": 6041
    },
    {
      "epoch": 0.6928104575163399,
      "grad_norm": 0.0,
      "learning_rate": 0.00022780702816328774,
      "loss": 4.9273,
      "step": 6042
    },
    {
      "epoch": 0.6929251232656806,
      "grad_norm": 0.0,
      "learning_rate": 0.00022765131346249746,
      "loss": 4.9636,
      "step": 6043
    },
    {
      "epoch": 0.6930397890150212,
      "grad_norm": 0.0,
      "learning_rate": 0.00022749563633391316,
      "loss": 4.799,
      "step": 6044
    },
    {
      "epoch": 0.6931544547643619,
      "grad_norm": 0.0,
      "learning_rate": 0.0002273399967990084,
      "loss": 5.0257,
      "step": 6045
    },
    {
      "epoch": 0.6932691205137026,
      "grad_norm": 0.0,
      "learning_rate": 0.0002271843948792498,
      "loss": 5.0586,
      "step": 6046
    },
    {
      "epoch": 0.6933837862630432,
      "grad_norm": 0.0,
      "learning_rate": 0.00022702883059610057,
      "loss": 5.2733,
      "step": 6047
    },
    {
      "epoch": 0.6934984520123839,
      "grad_norm": 0.0,
      "learning_rate": 0.00022687330397101703,
      "loss": 4.9944,
      "step": 6048
    },
    {
      "epoch": 0.6936131177617245,
      "grad_norm": 0.0,
      "learning_rate": 0.00022671781502545184,
      "loss": 4.729,
      "step": 6049
    },
    {
      "epoch": 0.6937277835110652,
      "grad_norm": 0.0,
      "learning_rate": 0.00022656236378085118,
      "loss": 5.3859,
      "step": 6050
    },
    {
      "epoch": 0.693842449260406,
      "grad_norm": 0.0,
      "learning_rate": 0.0002264069502586568,
      "loss": 4.9589,
      "step": 6051
    },
    {
      "epoch": 0.6939571150097466,
      "grad_norm": 0.0,
      "learning_rate": 0.00022625157448030522,
      "loss": 5.0453,
      "step": 6052
    },
    {
      "epoch": 0.6940717807590873,
      "grad_norm": 0.0,
      "learning_rate": 0.00022609623646722697,
      "loss": 5.0169,
      "step": 6053
    },
    {
      "epoch": 0.694186446508428,
      "grad_norm": 0.0,
      "learning_rate": 0.00022594093624084879,
      "loss": 5.171,
      "step": 6054
    },
    {
      "epoch": 0.6943011122577686,
      "grad_norm": 0.0,
      "learning_rate": 0.0002257856738225907,
      "loss": 4.8514,
      "step": 6055
    },
    {
      "epoch": 0.6944157780071093,
      "grad_norm": 0.0,
      "learning_rate": 0.0002256304492338685,
      "loss": 4.9476,
      "step": 6056
    },
    {
      "epoch": 0.6945304437564499,
      "grad_norm": 0.0,
      "learning_rate": 0.00022547526249609243,
      "loss": 4.9475,
      "step": 6057
    },
    {
      "epoch": 0.6946451095057906,
      "grad_norm": 0.0,
      "learning_rate": 0.00022532011363066747,
      "loss": 4.9794,
      "step": 6058
    },
    {
      "epoch": 0.6947597752551313,
      "grad_norm": 0.0,
      "learning_rate": 0.0002251650026589936,
      "loss": 4.9951,
      "step": 6059
    },
    {
      "epoch": 0.6948744410044719,
      "grad_norm": 0.0,
      "learning_rate": 0.00022500992960246543,
      "loss": 4.7675,
      "step": 6060
    },
    {
      "epoch": 0.6949891067538126,
      "grad_norm": 0.0,
      "learning_rate": 0.00022485489448247209,
      "loss": 4.8934,
      "step": 6061
    },
    {
      "epoch": 0.6951037725031534,
      "grad_norm": 0.0,
      "learning_rate": 0.0002246998973203978,
      "loss": 5.1771,
      "step": 6062
    },
    {
      "epoch": 0.695218438252494,
      "grad_norm": 0.0,
      "learning_rate": 0.00022454493813762162,
      "loss": 5.1945,
      "step": 6063
    },
    {
      "epoch": 0.6953331040018347,
      "grad_norm": 0.0,
      "learning_rate": 0.00022439001695551703,
      "loss": 5.0391,
      "step": 6064
    },
    {
      "epoch": 0.6954477697511753,
      "grad_norm": 0.0,
      "learning_rate": 0.00022423513379545278,
      "loss": 5.1285,
      "step": 6065
    },
    {
      "epoch": 0.695562435500516,
      "grad_norm": 0.0,
      "learning_rate": 0.00022408028867879144,
      "loss": 4.8838,
      "step": 6066
    },
    {
      "epoch": 0.6956771012498567,
      "grad_norm": 0.0,
      "learning_rate": 0.00022392548162689164,
      "loss": 4.9107,
      "step": 6067
    },
    {
      "epoch": 0.6957917669991973,
      "grad_norm": 0.0,
      "learning_rate": 0.00022377071266110543,
      "loss": 4.9902,
      "step": 6068
    },
    {
      "epoch": 0.695906432748538,
      "grad_norm": 0.0,
      "learning_rate": 0.00022361598180278087,
      "loss": 5.0598,
      "step": 6069
    },
    {
      "epoch": 0.6960210984978786,
      "grad_norm": 0.0,
      "learning_rate": 0.0002234612890732595,
      "loss": 4.9949,
      "step": 6070
    },
    {
      "epoch": 0.6961357642472193,
      "grad_norm": 0.0,
      "learning_rate": 0.00022330663449387884,
      "loss": 5.1848,
      "step": 6071
    },
    {
      "epoch": 0.6962504299965601,
      "grad_norm": 0.0,
      "learning_rate": 0.00022315201808597028,
      "loss": 5.0193,
      "step": 6072
    },
    {
      "epoch": 0.6963650957459007,
      "grad_norm": 0.0,
      "learning_rate": 0.00022299743987085977,
      "loss": 5.2024,
      "step": 6073
    },
    {
      "epoch": 0.6964797614952414,
      "grad_norm": 0.0,
      "learning_rate": 0.00022284289986986922,
      "loss": 4.9881,
      "step": 6074
    },
    {
      "epoch": 0.6965944272445821,
      "grad_norm": 0.0,
      "learning_rate": 0.00022268839810431375,
      "loss": 4.892,
      "step": 6075
    },
    {
      "epoch": 0.6967090929939227,
      "grad_norm": 0.0,
      "learning_rate": 0.00022253393459550455,
      "loss": 4.998,
      "step": 6076
    },
    {
      "epoch": 0.6968237587432634,
      "grad_norm": 0.0,
      "learning_rate": 0.00022237950936474654,
      "loss": 4.9586,
      "step": 6077
    },
    {
      "epoch": 0.696938424492604,
      "grad_norm": 0.0,
      "learning_rate": 0.00022222512243333977,
      "loss": 4.8777,
      "step": 6078
    },
    {
      "epoch": 0.6970530902419447,
      "grad_norm": 0.0,
      "learning_rate": 0.0002220707738225791,
      "loss": 5.133,
      "step": 6079
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 0.0,
      "learning_rate": 0.00022191646355375382,
      "loss": 5.3938,
      "step": 6080
    },
    {
      "epoch": 0.697282421740626,
      "grad_norm": 0.0,
      "learning_rate": 0.00022176219164814827,
      "loss": 4.9184,
      "step": 6081
    },
    {
      "epoch": 0.6973970874899668,
      "grad_norm": 0.0,
      "learning_rate": 0.00022160795812704138,
      "loss": 5.0311,
      "step": 6082
    },
    {
      "epoch": 0.6975117532393074,
      "grad_norm": 0.0,
      "learning_rate": 0.00022145376301170642,
      "loss": 5.2782,
      "step": 6083
    },
    {
      "epoch": 0.6976264189886481,
      "grad_norm": 0.0,
      "learning_rate": 0.00022129960632341178,
      "loss": 4.6764,
      "step": 6084
    },
    {
      "epoch": 0.6977410847379888,
      "grad_norm": 0.0,
      "learning_rate": 0.00022114548808342056,
      "loss": 5.0863,
      "step": 6085
    },
    {
      "epoch": 0.6978557504873294,
      "grad_norm": 0.0,
      "learning_rate": 0.0002209914083129903,
      "loss": 4.9076,
      "step": 6086
    },
    {
      "epoch": 0.6979704162366701,
      "grad_norm": 0.0,
      "learning_rate": 0.0002208373670333736,
      "loss": 4.885,
      "step": 6087
    },
    {
      "epoch": 0.6980850819860108,
      "grad_norm": 0.0,
      "learning_rate": 0.00022068336426581697,
      "loss": 5.1409,
      "step": 6088
    },
    {
      "epoch": 0.6981997477353514,
      "grad_norm": 0.0,
      "learning_rate": 0.00022052940003156288,
      "loss": 4.8433,
      "step": 6089
    },
    {
      "epoch": 0.6983144134846921,
      "grad_norm": 0.0,
      "learning_rate": 0.00022037547435184714,
      "loss": 5.0171,
      "step": 6090
    },
    {
      "epoch": 0.6984290792340327,
      "grad_norm": 0.0,
      "learning_rate": 0.00022022158724790137,
      "loss": 5.0275,
      "step": 6091
    },
    {
      "epoch": 0.6985437449833735,
      "grad_norm": 0.0,
      "learning_rate": 0.00022006773874095099,
      "loss": 5.0981,
      "step": 6092
    },
    {
      "epoch": 0.6986584107327142,
      "grad_norm": 0.0,
      "learning_rate": 0.00021991392885221662,
      "loss": 4.8969,
      "step": 6093
    },
    {
      "epoch": 0.6987730764820548,
      "grad_norm": 0.0,
      "learning_rate": 0.00021976015760291357,
      "loss": 4.879,
      "step": 6094
    },
    {
      "epoch": 0.6988877422313955,
      "grad_norm": 0.0,
      "learning_rate": 0.00021960642501425113,
      "loss": 4.6841,
      "step": 6095
    },
    {
      "epoch": 0.6990024079807362,
      "grad_norm": 0.0,
      "learning_rate": 0.0002194527311074344,
      "loss": 4.8364,
      "step": 6096
    },
    {
      "epoch": 0.6991170737300768,
      "grad_norm": 0.0,
      "learning_rate": 0.00021929907590366194,
      "loss": 5.1442,
      "step": 6097
    },
    {
      "epoch": 0.6992317394794175,
      "grad_norm": 0.0,
      "learning_rate": 0.00021914545942412823,
      "loss": 5.2252,
      "step": 6098
    },
    {
      "epoch": 0.6993464052287581,
      "grad_norm": 0.0,
      "learning_rate": 0.00021899188169002115,
      "loss": 4.6153,
      "step": 6099
    },
    {
      "epoch": 0.6994610709780988,
      "grad_norm": 0.0,
      "learning_rate": 0.00021883834272252403,
      "loss": 5.1884,
      "step": 6100
    },
    {
      "epoch": 0.6995757367274396,
      "grad_norm": 0.0,
      "learning_rate": 0.0002186848425428147,
      "loss": 5.0626,
      "step": 6101
    },
    {
      "epoch": 0.6996904024767802,
      "grad_norm": 0.0,
      "learning_rate": 0.00021853138117206548,
      "loss": 4.89,
      "step": 6102
    },
    {
      "epoch": 0.6998050682261209,
      "grad_norm": 0.0,
      "learning_rate": 0.00021837795863144372,
      "loss": 5.1564,
      "step": 6103
    },
    {
      "epoch": 0.6999197339754615,
      "grad_norm": 0.0,
      "learning_rate": 0.00021822457494211067,
      "loss": 4.9917,
      "step": 6104
    },
    {
      "epoch": 0.7000343997248022,
      "grad_norm": 0.0,
      "learning_rate": 0.00021807123012522296,
      "loss": 4.9668,
      "step": 6105
    },
    {
      "epoch": 0.7001490654741429,
      "grad_norm": 0.0,
      "learning_rate": 0.00021791792420193155,
      "loss": 4.971,
      "step": 6106
    },
    {
      "epoch": 0.7002637312234835,
      "grad_norm": 0.0,
      "learning_rate": 0.00021776465719338208,
      "loss": 5.029,
      "step": 6107
    },
    {
      "epoch": 0.7003783969728242,
      "grad_norm": 0.0,
      "learning_rate": 0.0002176114291207148,
      "loss": 5.0723,
      "step": 6108
    },
    {
      "epoch": 0.7004930627221649,
      "grad_norm": 0.0,
      "learning_rate": 0.00021745824000506478,
      "loss": 4.7973,
      "step": 6109
    },
    {
      "epoch": 0.7006077284715055,
      "grad_norm": 0.0,
      "learning_rate": 0.00021730508986756098,
      "loss": 4.7521,
      "step": 6110
    },
    {
      "epoch": 0.7007223942208463,
      "grad_norm": 0.0,
      "learning_rate": 0.00021715197872932836,
      "loss": 4.9926,
      "step": 6111
    },
    {
      "epoch": 0.7008370599701869,
      "grad_norm": 0.0,
      "learning_rate": 0.00021699890661148498,
      "loss": 5.2231,
      "step": 6112
    },
    {
      "epoch": 0.7009517257195276,
      "grad_norm": 0.0,
      "learning_rate": 0.00021684587353514452,
      "loss": 5.198,
      "step": 6113
    },
    {
      "epoch": 0.7010663914688683,
      "grad_norm": 0.0,
      "learning_rate": 0.00021669287952141492,
      "loss": 5.001,
      "step": 6114
    },
    {
      "epoch": 0.7011810572182089,
      "grad_norm": 0.0,
      "learning_rate": 0.00021653992459139888,
      "loss": 5.0173,
      "step": 6115
    },
    {
      "epoch": 0.7012957229675496,
      "grad_norm": 0.0,
      "learning_rate": 0.00021638700876619365,
      "loss": 4.8914,
      "step": 6116
    },
    {
      "epoch": 0.7014103887168902,
      "grad_norm": 0.0,
      "learning_rate": 0.00021623413206689064,
      "loss": 4.8641,
      "step": 6117
    },
    {
      "epoch": 0.7015250544662309,
      "grad_norm": 0.0,
      "learning_rate": 0.00021608129451457692,
      "loss": 4.8479,
      "step": 6118
    },
    {
      "epoch": 0.7016397202155716,
      "grad_norm": 0.0,
      "learning_rate": 0.00021592849613033283,
      "loss": 5.0053,
      "step": 6119
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 0.0,
      "learning_rate": 0.00021577573693523473,
      "loss": 5.1155,
      "step": 6120
    },
    {
      "epoch": 0.701869051714253,
      "grad_norm": 0.0,
      "learning_rate": 0.00021562301695035225,
      "loss": 4.9436,
      "step": 6121
    },
    {
      "epoch": 0.7019837174635937,
      "grad_norm": 0.0,
      "learning_rate": 0.00021547033619675047,
      "loss": 4.969,
      "step": 6122
    },
    {
      "epoch": 0.7020983832129343,
      "grad_norm": 0.0,
      "learning_rate": 0.0002153176946954889,
      "loss": 4.8856,
      "step": 6123
    },
    {
      "epoch": 0.702213048962275,
      "grad_norm": 0.0,
      "learning_rate": 0.00021516509246762093,
      "loss": 4.9065,
      "step": 6124
    },
    {
      "epoch": 0.7023277147116156,
      "grad_norm": 0.0,
      "learning_rate": 0.00021501252953419595,
      "loss": 4.6957,
      "step": 6125
    },
    {
      "epoch": 0.7024423804609563,
      "grad_norm": 0.0,
      "learning_rate": 0.00021486000591625654,
      "loss": 5.0202,
      "step": 6126
    },
    {
      "epoch": 0.702557046210297,
      "grad_norm": 0.0,
      "learning_rate": 0.0002147075216348406,
      "loss": 4.9396,
      "step": 6127
    },
    {
      "epoch": 0.7026717119596376,
      "grad_norm": 0.0,
      "learning_rate": 0.0002145550767109804,
      "loss": 4.8919,
      "step": 6128
    },
    {
      "epoch": 0.7027863777089783,
      "grad_norm": 0.0,
      "learning_rate": 0.00021440267116570286,
      "loss": 4.7355,
      "step": 6129
    },
    {
      "epoch": 0.702901043458319,
      "grad_norm": 0.0,
      "learning_rate": 0.00021425030502002937,
      "loss": 4.9389,
      "step": 6130
    },
    {
      "epoch": 0.7030157092076597,
      "grad_norm": 0.0,
      "learning_rate": 0.00021409797829497618,
      "loss": 4.9927,
      "step": 6131
    },
    {
      "epoch": 0.7031303749570004,
      "grad_norm": 0.0,
      "learning_rate": 0.00021394569101155345,
      "loss": 5.0648,
      "step": 6132
    },
    {
      "epoch": 0.703245040706341,
      "grad_norm": 0.0,
      "learning_rate": 0.00021379344319076652,
      "loss": 4.9555,
      "step": 6133
    },
    {
      "epoch": 0.7033597064556817,
      "grad_norm": 0.0,
      "learning_rate": 0.00021364123485361503,
      "loss": 4.9598,
      "step": 6134
    },
    {
      "epoch": 0.7034743722050224,
      "grad_norm": 0.0,
      "learning_rate": 0.00021348906602109324,
      "loss": 4.9906,
      "step": 6135
    },
    {
      "epoch": 0.703589037954363,
      "grad_norm": 0.0,
      "learning_rate": 0.00021333693671418994,
      "loss": 4.9881,
      "step": 6136
    },
    {
      "epoch": 0.7037037037037037,
      "grad_norm": 0.0,
      "learning_rate": 0.00021318484695388853,
      "loss": 5.0593,
      "step": 6137
    },
    {
      "epoch": 0.7038183694530443,
      "grad_norm": 0.0,
      "learning_rate": 0.000213032796761167,
      "loss": 4.9671,
      "step": 6138
    },
    {
      "epoch": 0.703933035202385,
      "grad_norm": 0.0,
      "learning_rate": 0.0002128807861569972,
      "loss": 4.9628,
      "step": 6139
    },
    {
      "epoch": 0.7040477009517258,
      "grad_norm": 0.0,
      "learning_rate": 0.00021272881516234688,
      "loss": 4.9902,
      "step": 6140
    },
    {
      "epoch": 0.7041623667010664,
      "grad_norm": 0.0,
      "learning_rate": 0.0002125768837981768,
      "loss": 4.9978,
      "step": 6141
    },
    {
      "epoch": 0.7042770324504071,
      "grad_norm": 0.0,
      "learning_rate": 0.00021242499208544378,
      "loss": 5.1167,
      "step": 6142
    },
    {
      "epoch": 0.7043916981997478,
      "grad_norm": 0.0,
      "learning_rate": 0.00021227314004509793,
      "loss": 5.1108,
      "step": 6143
    },
    {
      "epoch": 0.7045063639490884,
      "grad_norm": 0.0,
      "learning_rate": 0.000212121327698084,
      "loss": 4.7916,
      "step": 6144
    },
    {
      "epoch": 0.7046210296984291,
      "grad_norm": 0.0,
      "learning_rate": 0.0002119695550653424,
      "loss": 5.1449,
      "step": 6145
    },
    {
      "epoch": 0.7047356954477697,
      "grad_norm": 0.0,
      "learning_rate": 0.00021181782216780651,
      "loss": 5.1106,
      "step": 6146
    },
    {
      "epoch": 0.7048503611971104,
      "grad_norm": 0.0,
      "learning_rate": 0.0002116661290264057,
      "loss": 5.1074,
      "step": 6147
    },
    {
      "epoch": 0.7049650269464511,
      "grad_norm": 0.0,
      "learning_rate": 0.00021151447566206255,
      "loss": 4.9081,
      "step": 6148
    },
    {
      "epoch": 0.7050796926957917,
      "grad_norm": 0.0,
      "learning_rate": 0.00021136286209569508,
      "loss": 5.0825,
      "step": 6149
    },
    {
      "epoch": 0.7051943584451325,
      "grad_norm": 0.0,
      "learning_rate": 0.00021121128834821536,
      "loss": 4.8914,
      "step": 6150
    },
    {
      "epoch": 0.705309024194473,
      "grad_norm": 0.0,
      "learning_rate": 0.00021105975444053016,
      "loss": 5.0053,
      "step": 6151
    },
    {
      "epoch": 0.7054236899438138,
      "grad_norm": 0.0,
      "learning_rate": 0.0002109082603935407,
      "loss": 4.8286,
      "step": 6152
    },
    {
      "epoch": 0.7055383556931545,
      "grad_norm": 0.0,
      "learning_rate": 0.00021075680622814283,
      "loss": 4.9867,
      "step": 6153
    },
    {
      "epoch": 0.7056530214424951,
      "grad_norm": 0.0,
      "learning_rate": 0.0002106053919652264,
      "loss": 4.7228,
      "step": 6154
    },
    {
      "epoch": 0.7057676871918358,
      "grad_norm": 0.0,
      "learning_rate": 0.00021045401762567642,
      "loss": 4.8947,
      "step": 6155
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 0.0,
      "learning_rate": 0.0002103026832303719,
      "loss": 5.0639,
      "step": 6156
    },
    {
      "epoch": 0.7059970186905171,
      "grad_norm": 0.0,
      "learning_rate": 0.00021015138880018676,
      "loss": 4.8164,
      "step": 6157
    },
    {
      "epoch": 0.7061116844398578,
      "grad_norm": 0.0,
      "learning_rate": 0.00021000013435598894,
      "loss": 4.9573,
      "step": 6158
    },
    {
      "epoch": 0.7062263501891984,
      "grad_norm": 0.0,
      "learning_rate": 0.0002098489199186413,
      "loss": 4.9427,
      "step": 6159
    },
    {
      "epoch": 0.7063410159385392,
      "grad_norm": 0.0,
      "learning_rate": 0.0002096977455090011,
      "loss": 4.9608,
      "step": 6160
    },
    {
      "epoch": 0.7064556816878799,
      "grad_norm": 0.0,
      "learning_rate": 0.00020954661114791942,
      "loss": 5.1603,
      "step": 6161
    },
    {
      "epoch": 0.7065703474372205,
      "grad_norm": 0.0,
      "learning_rate": 0.00020939551685624308,
      "loss": 5.1224,
      "step": 6162
    },
    {
      "epoch": 0.7066850131865612,
      "grad_norm": 0.0,
      "learning_rate": 0.0002092444626548122,
      "loss": 5.2286,
      "step": 6163
    },
    {
      "epoch": 0.7067996789359019,
      "grad_norm": 0.0,
      "learning_rate": 0.00020909344856446187,
      "loss": 4.969,
      "step": 6164
    },
    {
      "epoch": 0.7069143446852425,
      "grad_norm": 0.0,
      "learning_rate": 0.0002089424746060219,
      "loss": 4.9356,
      "step": 6165
    },
    {
      "epoch": 0.7070290104345832,
      "grad_norm": 0.0,
      "learning_rate": 0.00020879154080031566,
      "loss": 4.8979,
      "step": 6166
    },
    {
      "epoch": 0.7071436761839238,
      "grad_norm": 0.0,
      "learning_rate": 0.0002086406471681623,
      "loss": 5.4177,
      "step": 6167
    },
    {
      "epoch": 0.7072583419332645,
      "grad_norm": 0.0,
      "learning_rate": 0.00020848979373037409,
      "loss": 5.1262,
      "step": 6168
    },
    {
      "epoch": 0.7073730076826052,
      "grad_norm": 0.0,
      "learning_rate": 0.00020833898050775902,
      "loss": 4.8273,
      "step": 6169
    },
    {
      "epoch": 0.7074876734319459,
      "grad_norm": 0.0,
      "learning_rate": 0.0002081882075211184,
      "loss": 4.9247,
      "step": 6170
    },
    {
      "epoch": 0.7076023391812866,
      "grad_norm": 0.0,
      "learning_rate": 0.00020803747479124864,
      "loss": 5.1805,
      "step": 6171
    },
    {
      "epoch": 0.7077170049306272,
      "grad_norm": 0.0,
      "learning_rate": 0.0002078867823389405,
      "loss": 5.0169,
      "step": 6172
    },
    {
      "epoch": 0.7078316706799679,
      "grad_norm": 0.0,
      "learning_rate": 0.0002077361301849791,
      "loss": 4.9553,
      "step": 6173
    },
    {
      "epoch": 0.7079463364293086,
      "grad_norm": 0.0,
      "learning_rate": 0.00020758551835014415,
      "loss": 4.7663,
      "step": 6174
    },
    {
      "epoch": 0.7080610021786492,
      "grad_norm": 0.0,
      "learning_rate": 0.00020743494685520947,
      "loss": 4.8605,
      "step": 6175
    },
    {
      "epoch": 0.7081756679279899,
      "grad_norm": 0.0,
      "learning_rate": 0.00020728441572094358,
      "loss": 5.2176,
      "step": 6176
    },
    {
      "epoch": 0.7082903336773306,
      "grad_norm": 0.0,
      "learning_rate": 0.0002071339249681094,
      "loss": 4.7678,
      "step": 6177
    },
    {
      "epoch": 0.7084049994266712,
      "grad_norm": 0.0,
      "learning_rate": 0.00020698347461746433,
      "loss": 5.008,
      "step": 6178
    },
    {
      "epoch": 0.708519665176012,
      "grad_norm": 0.0,
      "learning_rate": 0.00020683306468976008,
      "loss": 4.9687,
      "step": 6179
    },
    {
      "epoch": 0.7086343309253526,
      "grad_norm": 0.0,
      "learning_rate": 0.00020668269520574282,
      "loss": 4.8853,
      "step": 6180
    },
    {
      "epoch": 0.7087489966746933,
      "grad_norm": 0.0,
      "learning_rate": 0.0002065323661861531,
      "loss": 5.1174,
      "step": 6181
    },
    {
      "epoch": 0.708863662424034,
      "grad_norm": 0.0,
      "learning_rate": 0.0002063820776517263,
      "loss": 5.0718,
      "step": 6182
    },
    {
      "epoch": 0.7089783281733746,
      "grad_norm": 0.0,
      "learning_rate": 0.00020623182962319132,
      "loss": 5.1204,
      "step": 6183
    },
    {
      "epoch": 0.7090929939227153,
      "grad_norm": 0.0,
      "learning_rate": 0.00020608162212127227,
      "loss": 4.9354,
      "step": 6184
    },
    {
      "epoch": 0.709207659672056,
      "grad_norm": 0.0,
      "learning_rate": 0.00020593145516668737,
      "loss": 5.19,
      "step": 6185
    },
    {
      "epoch": 0.7093223254213966,
      "grad_norm": 0.0,
      "learning_rate": 0.00020578132878014936,
      "loss": 4.9632,
      "step": 6186
    },
    {
      "epoch": 0.7094369911707373,
      "grad_norm": 0.0,
      "learning_rate": 0.00020563124298236544,
      "loss": 4.7931,
      "step": 6187
    },
    {
      "epoch": 0.7095516569200779,
      "grad_norm": 0.0,
      "learning_rate": 0.00020548119779403664,
      "loss": 4.9934,
      "step": 6188
    },
    {
      "epoch": 0.7096663226694186,
      "grad_norm": 0.0,
      "learning_rate": 0.00020533119323585936,
      "loss": 5.1543,
      "step": 6189
    },
    {
      "epoch": 0.7097809884187594,
      "grad_norm": 0.0,
      "learning_rate": 0.00020518122932852332,
      "loss": 4.9094,
      "step": 6190
    },
    {
      "epoch": 0.7098956541681,
      "grad_norm": 0.0,
      "learning_rate": 0.00020503130609271378,
      "loss": 4.7951,
      "step": 6191
    },
    {
      "epoch": 0.7100103199174407,
      "grad_norm": 0.0,
      "learning_rate": 0.00020488142354910935,
      "loss": 5.0227,
      "step": 6192
    },
    {
      "epoch": 0.7101249856667813,
      "grad_norm": 0.0,
      "learning_rate": 0.00020473158171838366,
      "loss": 5.069,
      "step": 6193
    },
    {
      "epoch": 0.710239651416122,
      "grad_norm": 0.0,
      "learning_rate": 0.00020458178062120468,
      "loss": 4.9881,
      "step": 6194
    },
    {
      "epoch": 0.7103543171654627,
      "grad_norm": 0.0,
      "learning_rate": 0.00020443202027823395,
      "loss": 4.9756,
      "step": 6195
    },
    {
      "epoch": 0.7104689829148033,
      "grad_norm": 0.0,
      "learning_rate": 0.00020428230071012902,
      "loss": 5.097,
      "step": 6196
    },
    {
      "epoch": 0.710583648664144,
      "grad_norm": 0.0,
      "learning_rate": 0.00020413262193754011,
      "loss": 4.9739,
      "step": 6197
    },
    {
      "epoch": 0.7106983144134847,
      "grad_norm": 0.0,
      "learning_rate": 0.0002039829839811128,
      "loss": 4.894,
      "step": 6198
    },
    {
      "epoch": 0.7108129801628253,
      "grad_norm": 0.0,
      "learning_rate": 0.00020383338686148685,
      "loss": 4.8421,
      "step": 6199
    },
    {
      "epoch": 0.7109276459121661,
      "grad_norm": 0.0,
      "learning_rate": 0.00020368383059929626,
      "loss": 5.2391,
      "step": 6200
    },
    {
      "epoch": 0.7110423116615067,
      "grad_norm": 0.0,
      "learning_rate": 0.00020353431521516943,
      "loss": 5.2807,
      "step": 6201
    },
    {
      "epoch": 0.7111569774108474,
      "grad_norm": 0.0,
      "learning_rate": 0.0002033848407297293,
      "loss": 5.2657,
      "step": 6202
    },
    {
      "epoch": 0.7112716431601881,
      "grad_norm": 0.0,
      "learning_rate": 0.00020323540716359287,
      "loss": 4.7371,
      "step": 6203
    },
    {
      "epoch": 0.7113863089095287,
      "grad_norm": 0.0,
      "learning_rate": 0.00020308601453737193,
      "loss": 4.9095,
      "step": 6204
    },
    {
      "epoch": 0.7115009746588694,
      "grad_norm": 0.0,
      "learning_rate": 0.000202936662871672,
      "loss": 4.7061,
      "step": 6205
    },
    {
      "epoch": 0.71161564040821,
      "grad_norm": 0.0,
      "learning_rate": 0.00020278735218709338,
      "loss": 4.7102,
      "step": 6206
    },
    {
      "epoch": 0.7117303061575507,
      "grad_norm": 0.0,
      "learning_rate": 0.0002026380825042307,
      "loss": 4.999,
      "step": 6207
    },
    {
      "epoch": 0.7118449719068914,
      "grad_norm": 0.0,
      "learning_rate": 0.00020248885384367287,
      "loss": 4.9349,
      "step": 6208
    },
    {
      "epoch": 0.711959637656232,
      "grad_norm": 0.0,
      "learning_rate": 0.00020233966622600324,
      "loss": 5.0684,
      "step": 6209
    },
    {
      "epoch": 0.7120743034055728,
      "grad_norm": 0.0,
      "learning_rate": 0.00020219051967179896,
      "loss": 4.9832,
      "step": 6210
    },
    {
      "epoch": 0.7121889691549135,
      "grad_norm": 0.0,
      "learning_rate": 0.00020204141420163263,
      "loss": 5.0722,
      "step": 6211
    },
    {
      "epoch": 0.7123036349042541,
      "grad_norm": 0.0,
      "learning_rate": 0.00020189234983606976,
      "loss": 4.8665,
      "step": 6212
    },
    {
      "epoch": 0.7124183006535948,
      "grad_norm": 0.0,
      "learning_rate": 0.0002017433265956717,
      "loss": 4.9259,
      "step": 6213
    },
    {
      "epoch": 0.7125329664029354,
      "grad_norm": 0.0,
      "learning_rate": 0.00020159434450099306,
      "loss": 4.7812,
      "step": 6214
    },
    {
      "epoch": 0.7126476321522761,
      "grad_norm": 0.0,
      "learning_rate": 0.0002014454035725826,
      "loss": 4.9529,
      "step": 6215
    },
    {
      "epoch": 0.7127622979016168,
      "grad_norm": 0.0,
      "learning_rate": 0.00020129650383098467,
      "loss": 4.9226,
      "step": 6216
    },
    {
      "epoch": 0.7128769636509574,
      "grad_norm": 0.0,
      "learning_rate": 0.0002011476452967364,
      "loss": 4.9265,
      "step": 6217
    },
    {
      "epoch": 0.7129916294002981,
      "grad_norm": 0.0,
      "learning_rate": 0.00020099882799037069,
      "loss": 5.2427,
      "step": 6218
    },
    {
      "epoch": 0.7131062951496389,
      "grad_norm": 0.0,
      "learning_rate": 0.0002008500519324136,
      "loss": 5.0736,
      "step": 6219
    },
    {
      "epoch": 0.7132209608989795,
      "grad_norm": 0.0,
      "learning_rate": 0.00020070131714338606,
      "loss": 5.2062,
      "step": 6220
    },
    {
      "epoch": 0.7133356266483202,
      "grad_norm": 0.0,
      "learning_rate": 0.0002005526236438032,
      "loss": 4.7768,
      "step": 6221
    },
    {
      "epoch": 0.7134502923976608,
      "grad_norm": 0.0,
      "learning_rate": 0.0002004039714541745,
      "loss": 4.932,
      "step": 6222
    },
    {
      "epoch": 0.7135649581470015,
      "grad_norm": 0.0,
      "learning_rate": 0.00020025536059500366,
      "loss": 4.7214,
      "step": 6223
    },
    {
      "epoch": 0.7136796238963422,
      "grad_norm": 0.0,
      "learning_rate": 0.0002001067910867887,
      "loss": 4.867,
      "step": 6224
    },
    {
      "epoch": 0.7137942896456828,
      "grad_norm": 0.0,
      "learning_rate": 0.00019995826295002216,
      "loss": 5.1389,
      "step": 6225
    },
    {
      "epoch": 0.7139089553950235,
      "grad_norm": 0.0,
      "learning_rate": 0.0001998097762051903,
      "loss": 5.0533,
      "step": 6226
    },
    {
      "epoch": 0.7140236211443641,
      "grad_norm": 0.0,
      "learning_rate": 0.0001996613308727742,
      "loss": 5.0764,
      "step": 6227
    },
    {
      "epoch": 0.7141382868937048,
      "grad_norm": 0.0,
      "learning_rate": 0.00019951292697324913,
      "loss": 5.1847,
      "step": 6228
    },
    {
      "epoch": 0.7142529526430456,
      "grad_norm": 0.0,
      "learning_rate": 0.00019936456452708447,
      "loss": 5.0335,
      "step": 6229
    },
    {
      "epoch": 0.7143676183923862,
      "grad_norm": 0.0,
      "learning_rate": 0.00019921624355474408,
      "loss": 4.8024,
      "step": 6230
    },
    {
      "epoch": 0.7144822841417269,
      "grad_norm": 0.0,
      "learning_rate": 0.00019906796407668611,
      "loss": 4.9199,
      "step": 6231
    },
    {
      "epoch": 0.7145969498910676,
      "grad_norm": 0.0,
      "learning_rate": 0.00019891972611336245,
      "loss": 5.0719,
      "step": 6232
    },
    {
      "epoch": 0.7147116156404082,
      "grad_norm": 0.0,
      "learning_rate": 0.00019877152968522034,
      "loss": 5.1102,
      "step": 6233
    },
    {
      "epoch": 0.7148262813897489,
      "grad_norm": 0.0,
      "learning_rate": 0.00019862337481270015,
      "loss": 5.0558,
      "step": 6234
    },
    {
      "epoch": 0.7149409471390895,
      "grad_norm": 0.0,
      "learning_rate": 0.0001984752615162372,
      "loss": 5.1759,
      "step": 6235
    },
    {
      "epoch": 0.7150556128884302,
      "grad_norm": 0.0,
      "learning_rate": 0.00019832718981626106,
      "loss": 4.7804,
      "step": 6236
    },
    {
      "epoch": 0.7151702786377709,
      "grad_norm": 0.0,
      "learning_rate": 0.00019817915973319487,
      "loss": 5.0419,
      "step": 6237
    },
    {
      "epoch": 0.7152849443871115,
      "grad_norm": 0.0,
      "learning_rate": 0.00019803117128745724,
      "loss": 4.844,
      "step": 6238
    },
    {
      "epoch": 0.7153996101364523,
      "grad_norm": 0.0,
      "learning_rate": 0.00019788322449945967,
      "loss": 4.76,
      "step": 6239
    },
    {
      "epoch": 0.7155142758857929,
      "grad_norm": 0.0,
      "learning_rate": 0.00019773531938960931,
      "loss": 4.8747,
      "step": 6240
    },
    {
      "epoch": 0.7156289416351336,
      "grad_norm": 0.0,
      "learning_rate": 0.00019758745597830635,
      "loss": 5.16,
      "step": 6241
    },
    {
      "epoch": 0.7157436073844743,
      "grad_norm": 0.0,
      "learning_rate": 0.0001974396342859459,
      "loss": 5.1398,
      "step": 6242
    },
    {
      "epoch": 0.7158582731338149,
      "grad_norm": 0.0,
      "learning_rate": 0.00019729185433291707,
      "loss": 4.9449,
      "step": 6243
    },
    {
      "epoch": 0.7159729388831556,
      "grad_norm": 0.0,
      "learning_rate": 0.00019714411613960337,
      "loss": 4.9536,
      "step": 6244
    },
    {
      "epoch": 0.7160876046324963,
      "grad_norm": 0.0,
      "learning_rate": 0.0001969964197263826,
      "loss": 5.206,
      "step": 6245
    },
    {
      "epoch": 0.7162022703818369,
      "grad_norm": 0.0,
      "learning_rate": 0.00019684876511362614,
      "loss": 5.0366,
      "step": 6246
    },
    {
      "epoch": 0.7163169361311776,
      "grad_norm": 0.0,
      "learning_rate": 0.0001967011523217009,
      "loss": 5.1103,
      "step": 6247
    },
    {
      "epoch": 0.7164316018805182,
      "grad_norm": 0.0,
      "learning_rate": 0.0001965535813709666,
      "loss": 5.0663,
      "step": 6248
    },
    {
      "epoch": 0.716546267629859,
      "grad_norm": 0.0,
      "learning_rate": 0.0001964060522817781,
      "loss": 5.0967,
      "step": 6249
    },
    {
      "epoch": 0.7166609333791997,
      "grad_norm": 0.0,
      "learning_rate": 0.0001962585650744843,
      "loss": 4.9167,
      "step": 6250
    },
    {
      "epoch": 0.7167755991285403,
      "grad_norm": 0.0,
      "learning_rate": 0.00019611111976942802,
      "loss": 5.1304,
      "step": 6251
    },
    {
      "epoch": 0.716890264877881,
      "grad_norm": 0.0,
      "learning_rate": 0.00019596371638694668,
      "loss": 4.8707,
      "step": 6252
    },
    {
      "epoch": 0.7170049306272217,
      "grad_norm": 0.0,
      "learning_rate": 0.00019581635494737203,
      "loss": 5.1533,
      "step": 6253
    },
    {
      "epoch": 0.7171195963765623,
      "grad_norm": 0.0,
      "learning_rate": 0.0001956690354710292,
      "loss": 5.1089,
      "step": 6254
    },
    {
      "epoch": 0.717234262125903,
      "grad_norm": 0.0,
      "learning_rate": 0.00019552175797823848,
      "loss": 5.0517,
      "step": 6255
    },
    {
      "epoch": 0.7173489278752436,
      "grad_norm": 0.0,
      "learning_rate": 0.00019537452248931386,
      "loss": 4.9408,
      "step": 6256
    },
    {
      "epoch": 0.7174635936245843,
      "grad_norm": 0.0,
      "learning_rate": 0.00019522732902456374,
      "loss": 5.0692,
      "step": 6257
    },
    {
      "epoch": 0.717578259373925,
      "grad_norm": 0.0,
      "learning_rate": 0.00019508017760429085,
      "loss": 4.9202,
      "step": 6258
    },
    {
      "epoch": 0.7176929251232657,
      "grad_norm": 0.0,
      "learning_rate": 0.00019493306824879127,
      "loss": 5.1727,
      "step": 6259
    },
    {
      "epoch": 0.7178075908726064,
      "grad_norm": 0.0,
      "learning_rate": 0.00019478600097835684,
      "loss": 5.002,
      "step": 6260
    },
    {
      "epoch": 0.717922256621947,
      "grad_norm": 0.0,
      "learning_rate": 0.00019463897581327173,
      "loss": 5.0123,
      "step": 6261
    },
    {
      "epoch": 0.7180369223712877,
      "grad_norm": 0.0,
      "learning_rate": 0.00019449199277381615,
      "loss": 4.9825,
      "step": 6262
    },
    {
      "epoch": 0.7181515881206284,
      "grad_norm": 0.0,
      "learning_rate": 0.00019434505188026304,
      "loss": 5.1274,
      "step": 6263
    },
    {
      "epoch": 0.718266253869969,
      "grad_norm": 0.0,
      "learning_rate": 0.00019419815315288022,
      "loss": 4.9043,
      "step": 6264
    },
    {
      "epoch": 0.7183809196193097,
      "grad_norm": 0.0,
      "learning_rate": 0.0001940512966119298,
      "loss": 5.1628,
      "step": 6265
    },
    {
      "epoch": 0.7184955853686504,
      "grad_norm": 0.0,
      "learning_rate": 0.00019390448227766735,
      "loss": 5.1045,
      "step": 6266
    },
    {
      "epoch": 0.718610251117991,
      "grad_norm": 0.0,
      "learning_rate": 0.00019375771017034367,
      "loss": 4.9341,
      "step": 6267
    },
    {
      "epoch": 0.7187249168673318,
      "grad_norm": 0.0,
      "learning_rate": 0.0001936109803102026,
      "loss": 5.2872,
      "step": 6268
    },
    {
      "epoch": 0.7188395826166724,
      "grad_norm": 0.0,
      "learning_rate": 0.00019346429271748335,
      "loss": 4.817,
      "step": 6269
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.0,
      "learning_rate": 0.00019331764741241825,
      "loss": 4.859,
      "step": 6270
    },
    {
      "epoch": 0.7190689141153538,
      "grad_norm": 0.0,
      "learning_rate": 0.00019317104441523433,
      "loss": 4.8873,
      "step": 6271
    },
    {
      "epoch": 0.7191835798646944,
      "grad_norm": 0.0,
      "learning_rate": 0.00019302448374615267,
      "loss": 5.046,
      "step": 6272
    },
    {
      "epoch": 0.7192982456140351,
      "grad_norm": 0.0,
      "learning_rate": 0.00019287796542538855,
      "loss": 4.8955,
      "step": 6273
    },
    {
      "epoch": 0.7194129113633757,
      "grad_norm": 0.0,
      "learning_rate": 0.00019273148947315132,
      "loss": 5.1006,
      "step": 6274
    },
    {
      "epoch": 0.7195275771127164,
      "grad_norm": 0.0,
      "learning_rate": 0.00019258505590964478,
      "loss": 4.9753,
      "step": 6275
    },
    {
      "epoch": 0.7196422428620571,
      "grad_norm": 0.0,
      "learning_rate": 0.00019243866475506636,
      "loss": 4.9327,
      "step": 6276
    },
    {
      "epoch": 0.7197569086113977,
      "grad_norm": 0.0,
      "learning_rate": 0.00019229231602960794,
      "loss": 4.6011,
      "step": 6277
    },
    {
      "epoch": 0.7198715743607385,
      "grad_norm": 0.0,
      "learning_rate": 0.0001921460097534557,
      "loss": 4.804,
      "step": 6278
    },
    {
      "epoch": 0.7199862401100792,
      "grad_norm": 0.0,
      "learning_rate": 0.00019199974594678968,
      "loss": 4.9183,
      "step": 6279
    },
    {
      "epoch": 0.7201009058594198,
      "grad_norm": 0.0,
      "learning_rate": 0.00019185352462978443,
      "loss": 4.9536,
      "step": 6280
    },
    {
      "epoch": 0.7202155716087605,
      "grad_norm": 0.0,
      "learning_rate": 0.00019170734582260785,
      "loss": 4.9938,
      "step": 6281
    },
    {
      "epoch": 0.7203302373581011,
      "grad_norm": 0.0,
      "learning_rate": 0.00019156120954542325,
      "loss": 4.8836,
      "step": 6282
    },
    {
      "epoch": 0.7204449031074418,
      "grad_norm": 0.0,
      "learning_rate": 0.00019141511581838655,
      "loss": 5.1397,
      "step": 6283
    },
    {
      "epoch": 0.7205595688567825,
      "grad_norm": 0.0,
      "learning_rate": 0.0001912690646616494,
      "loss": 4.9007,
      "step": 6284
    },
    {
      "epoch": 0.7206742346061231,
      "grad_norm": 0.0,
      "learning_rate": 0.00019112305609535635,
      "loss": 4.8473,
      "step": 6285
    },
    {
      "epoch": 0.7207889003554638,
      "grad_norm": 0.0,
      "learning_rate": 0.0001909770901396462,
      "loss": 4.8924,
      "step": 6286
    },
    {
      "epoch": 0.7209035661048045,
      "grad_norm": 0.0,
      "learning_rate": 0.0001908311668146528,
      "loss": 5.251,
      "step": 6287
    },
    {
      "epoch": 0.7210182318541452,
      "grad_norm": 0.0,
      "learning_rate": 0.00019068528614050293,
      "loss": 4.9918,
      "step": 6288
    },
    {
      "epoch": 0.7211328976034859,
      "grad_norm": 0.0,
      "learning_rate": 0.0001905394481373186,
      "loss": 5.0799,
      "step": 6289
    },
    {
      "epoch": 0.7212475633528265,
      "grad_norm": 0.0,
      "learning_rate": 0.00019039365282521475,
      "loss": 4.8022,
      "step": 6290
    },
    {
      "epoch": 0.7213622291021672,
      "grad_norm": 0.0,
      "learning_rate": 0.00019024790022430176,
      "loss": 5.1727,
      "step": 6291
    },
    {
      "epoch": 0.7214768948515079,
      "grad_norm": 0.0,
      "learning_rate": 0.0001901021903546829,
      "loss": 4.911,
      "step": 6292
    },
    {
      "epoch": 0.7215915606008485,
      "grad_norm": 0.0,
      "learning_rate": 0.00018995652323645625,
      "loss": 5.0042,
      "step": 6293
    },
    {
      "epoch": 0.7217062263501892,
      "grad_norm": 0.0,
      "learning_rate": 0.00018981089888971378,
      "loss": 5.0814,
      "step": 6294
    },
    {
      "epoch": 0.7218208920995298,
      "grad_norm": 0.0,
      "learning_rate": 0.0001896653173345416,
      "loss": 5.0364,
      "step": 6295
    },
    {
      "epoch": 0.7219355578488705,
      "grad_norm": 0.0,
      "learning_rate": 0.0001895197785910201,
      "loss": 5.1205,
      "step": 6296
    },
    {
      "epoch": 0.7220502235982112,
      "grad_norm": 0.0,
      "learning_rate": 0.00018937428267922326,
      "loss": 4.8526,
      "step": 6297
    },
    {
      "epoch": 0.7221648893475519,
      "grad_norm": 0.0,
      "learning_rate": 0.0001892288296192196,
      "loss": 5.0754,
      "step": 6298
    },
    {
      "epoch": 0.7222795550968926,
      "grad_norm": 0.0,
      "learning_rate": 0.00018908341943107157,
      "loss": 5.0684,
      "step": 6299
    },
    {
      "epoch": 0.7223942208462333,
      "grad_norm": 0.0,
      "learning_rate": 0.0001889380521348358,
      "loss": 4.8258,
      "step": 6300
    },
    {
      "epoch": 0.7225088865955739,
      "grad_norm": 0.0,
      "learning_rate": 0.00018879272775056285,
      "loss": 4.9828,
      "step": 6301
    },
    {
      "epoch": 0.7226235523449146,
      "grad_norm": 0.0,
      "learning_rate": 0.00018864744629829775,
      "loss": 4.8687,
      "step": 6302
    },
    {
      "epoch": 0.7227382180942552,
      "grad_norm": 0.0,
      "learning_rate": 0.00018850220779807864,
      "loss": 4.9612,
      "step": 6303
    },
    {
      "epoch": 0.7228528838435959,
      "grad_norm": 0.0,
      "learning_rate": 0.00018835701226993927,
      "loss": 5.068,
      "step": 6304
    },
    {
      "epoch": 0.7229675495929366,
      "grad_norm": 0.0,
      "learning_rate": 0.0001882118597339059,
      "loss": 4.8743,
      "step": 6305
    },
    {
      "epoch": 0.7230822153422772,
      "grad_norm": 0.0,
      "learning_rate": 0.00018806675020999978,
      "loss": 4.8102,
      "step": 6306
    },
    {
      "epoch": 0.723196881091618,
      "grad_norm": 0.0,
      "learning_rate": 0.0001879216837182363,
      "loss": 4.986,
      "step": 6307
    },
    {
      "epoch": 0.7233115468409586,
      "grad_norm": 0.0,
      "learning_rate": 0.00018777666027862392,
      "loss": 4.9172,
      "step": 6308
    },
    {
      "epoch": 0.7234262125902993,
      "grad_norm": 0.0,
      "learning_rate": 0.00018763167991116665,
      "loss": 5.0376,
      "step": 6309
    },
    {
      "epoch": 0.72354087833964,
      "grad_norm": 0.0,
      "learning_rate": 0.000187486742635861,
      "loss": 4.9714,
      "step": 6310
    },
    {
      "epoch": 0.7236555440889806,
      "grad_norm": 0.0,
      "learning_rate": 0.00018734184847269913,
      "loss": 5.0915,
      "step": 6311
    },
    {
      "epoch": 0.7237702098383213,
      "grad_norm": 0.0,
      "learning_rate": 0.00018719699744166565,
      "loss": 4.978,
      "step": 6312
    },
    {
      "epoch": 0.723884875587662,
      "grad_norm": 0.0,
      "learning_rate": 0.00018705218956274066,
      "loss": 5.2746,
      "step": 6313
    },
    {
      "epoch": 0.7239995413370026,
      "grad_norm": 0.0,
      "learning_rate": 0.00018690742485589717,
      "loss": 4.7107,
      "step": 6314
    },
    {
      "epoch": 0.7241142070863433,
      "grad_norm": 0.0,
      "learning_rate": 0.00018676270334110293,
      "loss": 4.9096,
      "step": 6315
    },
    {
      "epoch": 0.7242288728356839,
      "grad_norm": 0.0,
      "learning_rate": 0.00018661802503831958,
      "loss": 4.8169,
      "step": 6316
    },
    {
      "epoch": 0.7243435385850246,
      "grad_norm": 0.0,
      "learning_rate": 0.00018647338996750232,
      "loss": 4.8414,
      "step": 6317
    },
    {
      "epoch": 0.7244582043343654,
      "grad_norm": 0.0,
      "learning_rate": 0.00018632879814860136,
      "loss": 5.0305,
      "step": 6318
    },
    {
      "epoch": 0.724572870083706,
      "grad_norm": 0.0,
      "learning_rate": 0.00018618424960156006,
      "loss": 4.8942,
      "step": 6319
    },
    {
      "epoch": 0.7246875358330467,
      "grad_norm": 0.0,
      "learning_rate": 0.00018603974434631615,
      "loss": 5.04,
      "step": 6320
    },
    {
      "epoch": 0.7248022015823874,
      "grad_norm": 0.0,
      "learning_rate": 0.00018589528240280144,
      "loss": 4.7166,
      "step": 6321
    },
    {
      "epoch": 0.724916867331728,
      "grad_norm": 0.0,
      "learning_rate": 0.0001857508637909417,
      "loss": 4.9897,
      "step": 6322
    },
    {
      "epoch": 0.7250315330810687,
      "grad_norm": 0.0,
      "learning_rate": 0.00018560648853065665,
      "loss": 4.9587,
      "step": 6323
    },
    {
      "epoch": 0.7251461988304093,
      "grad_norm": 0.0,
      "learning_rate": 0.0001854621566418604,
      "loss": 4.7978,
      "step": 6324
    },
    {
      "epoch": 0.72526086457975,
      "grad_norm": 0.0,
      "learning_rate": 0.0001853178681444602,
      "loss": 5.1037,
      "step": 6325
    },
    {
      "epoch": 0.7253755303290907,
      "grad_norm": 0.0,
      "learning_rate": 0.0001851736230583586,
      "loss": 5.19,
      "step": 6326
    },
    {
      "epoch": 0.7254901960784313,
      "grad_norm": 0.0,
      "learning_rate": 0.00018502942140345095,
      "loss": 5.1929,
      "step": 6327
    },
    {
      "epoch": 0.7256048618277721,
      "grad_norm": 0.0,
      "learning_rate": 0.0001848852631996272,
      "loss": 4.8751,
      "step": 6328
    },
    {
      "epoch": 0.7257195275771127,
      "grad_norm": 0.0,
      "learning_rate": 0.00018474114846677158,
      "loss": 4.9018,
      "step": 6329
    },
    {
      "epoch": 0.7258341933264534,
      "grad_norm": 0.0,
      "learning_rate": 0.00018459707722476128,
      "loss": 5.1097,
      "step": 6330
    },
    {
      "epoch": 0.7259488590757941,
      "grad_norm": 0.0,
      "learning_rate": 0.00018445304949346895,
      "loss": 5.1048,
      "step": 6331
    },
    {
      "epoch": 0.7260635248251347,
      "grad_norm": 0.0,
      "learning_rate": 0.00018430906529275982,
      "loss": 4.869,
      "step": 6332
    },
    {
      "epoch": 0.7261781905744754,
      "grad_norm": 0.0,
      "learning_rate": 0.00018416512464249435,
      "loss": 4.8335,
      "step": 6333
    },
    {
      "epoch": 0.7262928563238161,
      "grad_norm": 0.0,
      "learning_rate": 0.00018402122756252582,
      "loss": 5.1866,
      "step": 6334
    },
    {
      "epoch": 0.7264075220731567,
      "grad_norm": 0.0,
      "learning_rate": 0.00018387737407270268,
      "loss": 4.8382,
      "step": 6335
    },
    {
      "epoch": 0.7265221878224974,
      "grad_norm": 0.0,
      "learning_rate": 0.00018373356419286652,
      "loss": 4.964,
      "step": 6336
    },
    {
      "epoch": 0.726636853571838,
      "grad_norm": 0.0,
      "learning_rate": 0.0001835897979428528,
      "loss": 5.1355,
      "step": 6337
    },
    {
      "epoch": 0.7267515193211788,
      "grad_norm": 0.0,
      "learning_rate": 0.00018344607534249204,
      "loss": 5.1126,
      "step": 6338
    },
    {
      "epoch": 0.7268661850705195,
      "grad_norm": 0.0,
      "learning_rate": 0.0001833023964116073,
      "loss": 4.9002,
      "step": 6339
    },
    {
      "epoch": 0.7269808508198601,
      "grad_norm": 0.0,
      "learning_rate": 0.0001831587611700171,
      "loss": 5.017,
      "step": 6340
    },
    {
      "epoch": 0.7270955165692008,
      "grad_norm": 0.0,
      "learning_rate": 0.00018301516963753256,
      "loss": 4.9199,
      "step": 6341
    },
    {
      "epoch": 0.7272101823185414,
      "grad_norm": 0.0,
      "learning_rate": 0.00018287162183395963,
      "loss": 4.9981,
      "step": 6342
    },
    {
      "epoch": 0.7273248480678821,
      "grad_norm": 0.0,
      "learning_rate": 0.00018272811777909808,
      "loss": 5.2973,
      "step": 6343
    },
    {
      "epoch": 0.7274395138172228,
      "grad_norm": 0.0,
      "learning_rate": 0.00018258465749274144,
      "loss": 5.0197,
      "step": 6344
    },
    {
      "epoch": 0.7275541795665634,
      "grad_norm": 0.0,
      "learning_rate": 0.00018244124099467735,
      "loss": 4.9834,
      "step": 6345
    },
    {
      "epoch": 0.7276688453159041,
      "grad_norm": 0.0,
      "learning_rate": 0.0001822978683046875,
      "loss": 4.9171,
      "step": 6346
    },
    {
      "epoch": 0.7277835110652449,
      "grad_norm": 0.0,
      "learning_rate": 0.00018215453944254724,
      "loss": 5.2073,
      "step": 6347
    },
    {
      "epoch": 0.7278981768145855,
      "grad_norm": 0.0,
      "learning_rate": 0.00018201125442802608,
      "loss": 4.9026,
      "step": 6348
    },
    {
      "epoch": 0.7280128425639262,
      "grad_norm": 0.0,
      "learning_rate": 0.00018186801328088747,
      "loss": 5.2737,
      "step": 6349
    },
    {
      "epoch": 0.7281275083132668,
      "grad_norm": 0.0,
      "learning_rate": 0.00018172481602088888,
      "loss": 5.2256,
      "step": 6350
    },
    {
      "epoch": 0.7282421740626075,
      "grad_norm": 0.0,
      "learning_rate": 0.00018158166266778178,
      "loss": 4.8499,
      "step": 6351
    },
    {
      "epoch": 0.7283568398119482,
      "grad_norm": 0.0,
      "learning_rate": 0.00018143855324131086,
      "loss": 4.8853,
      "step": 6352
    },
    {
      "epoch": 0.7284715055612888,
      "grad_norm": 0.0,
      "learning_rate": 0.0001812954877612161,
      "loss": 4.6868,
      "step": 6353
    },
    {
      "epoch": 0.7285861713106295,
      "grad_norm": 0.0,
      "learning_rate": 0.00018115246624722991,
      "loss": 5.1377,
      "step": 6354
    },
    {
      "epoch": 0.7287008370599702,
      "grad_norm": 0.0,
      "learning_rate": 0.00018100948871908022,
      "loss": 5.0836,
      "step": 6355
    },
    {
      "epoch": 0.7288155028093108,
      "grad_norm": 0.0,
      "learning_rate": 0.00018086655519648732,
      "loss": 4.9642,
      "step": 6356
    },
    {
      "epoch": 0.7289301685586516,
      "grad_norm": 0.0,
      "learning_rate": 0.00018072366569916643,
      "loss": 4.9736,
      "step": 6357
    },
    {
      "epoch": 0.7290448343079922,
      "grad_norm": 0.0,
      "learning_rate": 0.00018058082024682666,
      "loss": 5.1848,
      "step": 6358
    },
    {
      "epoch": 0.7291595000573329,
      "grad_norm": 0.0,
      "learning_rate": 0.00018043801885917024,
      "loss": 5.0638,
      "step": 6359
    },
    {
      "epoch": 0.7292741658066736,
      "grad_norm": 0.0,
      "learning_rate": 0.0001802952615558946,
      "loss": 5.1409,
      "step": 6360
    },
    {
      "epoch": 0.7293888315560142,
      "grad_norm": 0.0,
      "learning_rate": 0.0001801525483566897,
      "loss": 5.0765,
      "step": 6361
    },
    {
      "epoch": 0.7295034973053549,
      "grad_norm": 0.0,
      "learning_rate": 0.00018000987928124083,
      "loss": 5.0937,
      "step": 6362
    },
    {
      "epoch": 0.7296181630546955,
      "grad_norm": 0.0,
      "learning_rate": 0.00017986725434922588,
      "loss": 4.8804,
      "step": 6363
    },
    {
      "epoch": 0.7297328288040362,
      "grad_norm": 0.0,
      "learning_rate": 0.00017972467358031747,
      "loss": 4.9271,
      "step": 6364
    },
    {
      "epoch": 0.7298474945533769,
      "grad_norm": 0.0,
      "learning_rate": 0.00017958213699418194,
      "loss": 5.1783,
      "step": 6365
    },
    {
      "epoch": 0.7299621603027175,
      "grad_norm": 0.0,
      "learning_rate": 0.00017943964461047938,
      "loss": 5.2103,
      "step": 6366
    },
    {
      "epoch": 0.7300768260520583,
      "grad_norm": 0.0,
      "learning_rate": 0.00017929719644886415,
      "loss": 5.0504,
      "step": 6367
    },
    {
      "epoch": 0.730191491801399,
      "grad_norm": 0.0,
      "learning_rate": 0.00017915479252898385,
      "loss": 4.7761,
      "step": 6368
    },
    {
      "epoch": 0.7303061575507396,
      "grad_norm": 0.0,
      "learning_rate": 0.00017901243287048063,
      "loss": 4.9202,
      "step": 6369
    },
    {
      "epoch": 0.7304208233000803,
      "grad_norm": 0.0,
      "learning_rate": 0.0001788701174929903,
      "loss": 4.9692,
      "step": 6370
    },
    {
      "epoch": 0.7305354890494209,
      "grad_norm": 0.0,
      "learning_rate": 0.00017872784641614244,
      "loss": 5.1625,
      "step": 6371
    },
    {
      "epoch": 0.7306501547987616,
      "grad_norm": 0.0,
      "learning_rate": 0.00017858561965956074,
      "loss": 5.2348,
      "step": 6372
    },
    {
      "epoch": 0.7307648205481023,
      "grad_norm": 0.0,
      "learning_rate": 0.00017844343724286282,
      "loss": 4.9778,
      "step": 6373
    },
    {
      "epoch": 0.7308794862974429,
      "grad_norm": 0.0,
      "learning_rate": 0.0001783012991856595,
      "loss": 4.8362,
      "step": 6374
    },
    {
      "epoch": 0.7309941520467836,
      "grad_norm": 0.0,
      "learning_rate": 0.00017815920550755675,
      "loss": 4.9729,
      "step": 6375
    },
    {
      "epoch": 0.7311088177961242,
      "grad_norm": 0.0,
      "learning_rate": 0.0001780171562281531,
      "loss": 4.9985,
      "step": 6376
    },
    {
      "epoch": 0.731223483545465,
      "grad_norm": 0.0,
      "learning_rate": 0.00017787515136704173,
      "loss": 5.0324,
      "step": 6377
    },
    {
      "epoch": 0.7313381492948057,
      "grad_norm": 0.0,
      "learning_rate": 0.00017773319094380955,
      "loss": 5.1101,
      "step": 6378
    },
    {
      "epoch": 0.7314528150441463,
      "grad_norm": 0.0,
      "learning_rate": 0.00017759127497803725,
      "loss": 4.8711,
      "step": 6379
    },
    {
      "epoch": 0.731567480793487,
      "grad_norm": 0.0,
      "learning_rate": 0.0001774494034892996,
      "loss": 4.949,
      "step": 6380
    },
    {
      "epoch": 0.7316821465428277,
      "grad_norm": 0.0,
      "learning_rate": 0.0001773075764971646,
      "loss": 5.2759,
      "step": 6381
    },
    {
      "epoch": 0.7317968122921683,
      "grad_norm": 0.0,
      "learning_rate": 0.00017716579402119516,
      "loss": 5.0756,
      "step": 6382
    },
    {
      "epoch": 0.731911478041509,
      "grad_norm": 0.0,
      "learning_rate": 0.00017702405608094698,
      "loss": 4.9675,
      "step": 6383
    },
    {
      "epoch": 0.7320261437908496,
      "grad_norm": 0.0,
      "learning_rate": 0.0001768823626959706,
      "loss": 4.8856,
      "step": 6384
    },
    {
      "epoch": 0.7321408095401903,
      "grad_norm": 0.0,
      "learning_rate": 0.00017674071388580945,
      "loss": 5.0843,
      "step": 6385
    },
    {
      "epoch": 0.732255475289531,
      "grad_norm": 0.0,
      "learning_rate": 0.0001765991096700016,
      "loss": 4.7772,
      "step": 6386
    },
    {
      "epoch": 0.7323701410388717,
      "grad_norm": 0.0,
      "learning_rate": 0.0001764575500680786,
      "loss": 5.2657,
      "step": 6387
    },
    {
      "epoch": 0.7324848067882124,
      "grad_norm": 0.0,
      "learning_rate": 0.00017631603509956552,
      "loss": 5.0274,
      "step": 6388
    },
    {
      "epoch": 0.7325994725375531,
      "grad_norm": 0.0,
      "learning_rate": 0.0001761745647839823,
      "loss": 5.0689,
      "step": 6389
    },
    {
      "epoch": 0.7327141382868937,
      "grad_norm": 0.0,
      "learning_rate": 0.00017603313914084156,
      "loss": 5.2057,
      "step": 6390
    },
    {
      "epoch": 0.7328288040362344,
      "grad_norm": 0.0,
      "learning_rate": 0.00017589175818965048,
      "loss": 5.1794,
      "step": 6391
    },
    {
      "epoch": 0.732943469785575,
      "grad_norm": 0.0,
      "learning_rate": 0.00017575042194990982,
      "loss": 5.139,
      "step": 6392
    },
    {
      "epoch": 0.7330581355349157,
      "grad_norm": 0.0,
      "learning_rate": 0.00017560913044111425,
      "loss": 4.9825,
      "step": 6393
    },
    {
      "epoch": 0.7331728012842564,
      "grad_norm": 0.0,
      "learning_rate": 0.00017546788368275228,
      "loss": 5.2528,
      "step": 6394
    },
    {
      "epoch": 0.733287467033597,
      "grad_norm": 0.0,
      "learning_rate": 0.00017532668169430626,
      "loss": 4.8615,
      "step": 6395
    },
    {
      "epoch": 0.7334021327829378,
      "grad_norm": 0.0,
      "learning_rate": 0.00017518552449525185,
      "loss": 4.8463,
      "step": 6396
    },
    {
      "epoch": 0.7335167985322784,
      "grad_norm": 0.0,
      "learning_rate": 0.00017504441210505978,
      "loss": 4.8778,
      "step": 6397
    },
    {
      "epoch": 0.7336314642816191,
      "grad_norm": 0.0,
      "learning_rate": 0.00017490334454319315,
      "loss": 5.1548,
      "step": 6398
    },
    {
      "epoch": 0.7337461300309598,
      "grad_norm": 0.0,
      "learning_rate": 0.00017476232182910982,
      "loss": 4.8117,
      "step": 6399
    },
    {
      "epoch": 0.7338607957803004,
      "grad_norm": 0.0,
      "learning_rate": 0.00017462134398226115,
      "loss": 5.2066,
      "step": 6400
    },
    {
      "epoch": 0.7339754615296411,
      "grad_norm": 0.0,
      "learning_rate": 0.0001744804110220923,
      "loss": 4.8797,
      "step": 6401
    },
    {
      "epoch": 0.7340901272789818,
      "grad_norm": 0.0,
      "learning_rate": 0.00017433952296804257,
      "loss": 4.9682,
      "step": 6402
    },
    {
      "epoch": 0.7342047930283224,
      "grad_norm": 0.0,
      "learning_rate": 0.00017419867983954412,
      "loss": 5.0161,
      "step": 6403
    },
    {
      "epoch": 0.7343194587776631,
      "grad_norm": 0.0,
      "learning_rate": 0.00017405788165602437,
      "loss": 5.0948,
      "step": 6404
    },
    {
      "epoch": 0.7344341245270037,
      "grad_norm": 0.0,
      "learning_rate": 0.000173917128436903,
      "loss": 4.8485,
      "step": 6405
    },
    {
      "epoch": 0.7345487902763445,
      "grad_norm": 0.0,
      "learning_rate": 0.00017377642020159503,
      "loss": 4.6154,
      "step": 6406
    },
    {
      "epoch": 0.7346634560256852,
      "grad_norm": 0.0,
      "learning_rate": 0.000173635756969508,
      "loss": 5.0291,
      "step": 6407
    },
    {
      "epoch": 0.7347781217750258,
      "grad_norm": 0.0,
      "learning_rate": 0.0001734951387600434,
      "loss": 4.9295,
      "step": 6408
    },
    {
      "epoch": 0.7348927875243665,
      "grad_norm": 0.0,
      "learning_rate": 0.00017335456559259757,
      "loss": 4.9763,
      "step": 6409
    },
    {
      "epoch": 0.7350074532737071,
      "grad_norm": 0.0,
      "learning_rate": 0.00017321403748655922,
      "loss": 4.8605,
      "step": 6410
    },
    {
      "epoch": 0.7351221190230478,
      "grad_norm": 0.0,
      "learning_rate": 0.00017307355446131214,
      "loss": 4.8943,
      "step": 6411
    },
    {
      "epoch": 0.7352367847723885,
      "grad_norm": 0.0,
      "learning_rate": 0.0001729331165362329,
      "loss": 5.0515,
      "step": 6412
    },
    {
      "epoch": 0.7353514505217291,
      "grad_norm": 0.0,
      "learning_rate": 0.00017279272373069222,
      "loss": 4.7861,
      "step": 6413
    },
    {
      "epoch": 0.7354661162710698,
      "grad_norm": 0.0,
      "learning_rate": 0.00017265237606405476,
      "loss": 5.2417,
      "step": 6414
    },
    {
      "epoch": 0.7355807820204106,
      "grad_norm": 0.0,
      "learning_rate": 0.0001725120735556787,
      "loss": 4.9829,
      "step": 6415
    },
    {
      "epoch": 0.7356954477697512,
      "grad_norm": 0.0,
      "learning_rate": 0.0001723718162249162,
      "loss": 5.0057,
      "step": 6416
    },
    {
      "epoch": 0.7358101135190919,
      "grad_norm": 0.0,
      "learning_rate": 0.00017223160409111308,
      "loss": 5.1172,
      "step": 6417
    },
    {
      "epoch": 0.7359247792684325,
      "grad_norm": 0.0,
      "learning_rate": 0.00017209143717360898,
      "loss": 5.0004,
      "step": 6418
    },
    {
      "epoch": 0.7360394450177732,
      "grad_norm": 0.0,
      "learning_rate": 0.000171951315491737,
      "loss": 4.8736,
      "step": 6419
    },
    {
      "epoch": 0.7361541107671139,
      "grad_norm": 0.0,
      "learning_rate": 0.00017181123906482445,
      "loss": 4.9039,
      "step": 6420
    },
    {
      "epoch": 0.7362687765164545,
      "grad_norm": 0.0,
      "learning_rate": 0.00017167120791219219,
      "loss": 4.9745,
      "step": 6421
    },
    {
      "epoch": 0.7363834422657952,
      "grad_norm": 0.0,
      "learning_rate": 0.00017153122205315478,
      "loss": 4.9644,
      "step": 6422
    },
    {
      "epoch": 0.7364981080151359,
      "grad_norm": 0.0,
      "learning_rate": 0.00017139128150702067,
      "loss": 4.9199,
      "step": 6423
    },
    {
      "epoch": 0.7366127737644765,
      "grad_norm": 0.0,
      "learning_rate": 0.00017125138629309214,
      "loss": 4.8382,
      "step": 6424
    },
    {
      "epoch": 0.7367274395138173,
      "grad_norm": 0.0,
      "learning_rate": 0.00017111153643066459,
      "loss": 5.2209,
      "step": 6425
    },
    {
      "epoch": 0.7368421052631579,
      "grad_norm": 0.0,
      "learning_rate": 0.00017097173193902823,
      "loss": 5.0997,
      "step": 6426
    },
    {
      "epoch": 0.7369567710124986,
      "grad_norm": 0.0,
      "learning_rate": 0.00017083197283746603,
      "loss": 4.9121,
      "step": 6427
    },
    {
      "epoch": 0.7370714367618393,
      "grad_norm": 0.0,
      "learning_rate": 0.00017069225914525518,
      "loss": 5.0496,
      "step": 6428
    },
    {
      "epoch": 0.7371861025111799,
      "grad_norm": 0.0,
      "learning_rate": 0.00017055259088166673,
      "loss": 4.7418,
      "step": 6429
    },
    {
      "epoch": 0.7373007682605206,
      "grad_norm": 0.0,
      "learning_rate": 0.0001704129680659647,
      "loss": 4.9499,
      "step": 6430
    },
    {
      "epoch": 0.7374154340098612,
      "grad_norm": 0.0,
      "learning_rate": 0.00017027339071740816,
      "loss": 4.7731,
      "step": 6431
    },
    {
      "epoch": 0.7375300997592019,
      "grad_norm": 0.0,
      "learning_rate": 0.00017013385885524844,
      "loss": 4.9375,
      "step": 6432
    },
    {
      "epoch": 0.7376447655085426,
      "grad_norm": 0.0,
      "learning_rate": 0.0001699943724987319,
      "loss": 5.1728,
      "step": 6433
    },
    {
      "epoch": 0.7377594312578832,
      "grad_norm": 0.0,
      "learning_rate": 0.00016985493166709757,
      "loss": 4.8777,
      "step": 6434
    },
    {
      "epoch": 0.737874097007224,
      "grad_norm": 0.0,
      "learning_rate": 0.0001697155363795789,
      "loss": 5.1199,
      "step": 6435
    },
    {
      "epoch": 0.7379887627565647,
      "grad_norm": 0.0,
      "learning_rate": 0.00016957618665540267,
      "loss": 4.8943,
      "step": 6436
    },
    {
      "epoch": 0.7381034285059053,
      "grad_norm": 0.0,
      "learning_rate": 0.0001694368825137896,
      "loss": 4.8492,
      "step": 6437
    },
    {
      "epoch": 0.738218094255246,
      "grad_norm": 0.0,
      "learning_rate": 0.00016929762397395421,
      "loss": 4.9188,
      "step": 6438
    },
    {
      "epoch": 0.7383327600045866,
      "grad_norm": 0.0,
      "learning_rate": 0.00016915841105510403,
      "loss": 5.1041,
      "step": 6439
    },
    {
      "epoch": 0.7384474257539273,
      "grad_norm": 0.0,
      "learning_rate": 0.0001690192437764415,
      "loss": 4.839,
      "step": 6440
    },
    {
      "epoch": 0.738562091503268,
      "grad_norm": 0.0,
      "learning_rate": 0.0001688801221571616,
      "loss": 5.131,
      "step": 6441
    },
    {
      "epoch": 0.7386767572526086,
      "grad_norm": 0.0,
      "learning_rate": 0.00016874104621645374,
      "loss": 5.3267,
      "step": 6442
    },
    {
      "epoch": 0.7387914230019493,
      "grad_norm": 0.0,
      "learning_rate": 0.00016860201597350066,
      "loss": 4.9274,
      "step": 6443
    },
    {
      "epoch": 0.7389060887512899,
      "grad_norm": 0.0,
      "learning_rate": 0.00016846303144747908,
      "loss": 5.1096,
      "step": 6444
    },
    {
      "epoch": 0.7390207545006306,
      "grad_norm": 0.0,
      "learning_rate": 0.0001683240926575591,
      "loss": 4.9065,
      "step": 6445
    },
    {
      "epoch": 0.7391354202499714,
      "grad_norm": 0.0,
      "learning_rate": 0.00016818519962290496,
      "loss": 4.8815,
      "step": 6446
    },
    {
      "epoch": 0.739250085999312,
      "grad_norm": 0.0,
      "learning_rate": 0.00016804635236267383,
      "loss": 4.9663,
      "step": 6447
    },
    {
      "epoch": 0.7393647517486527,
      "grad_norm": 0.0,
      "learning_rate": 0.0001679075508960176,
      "loss": 4.8984,
      "step": 6448
    },
    {
      "epoch": 0.7394794174979934,
      "grad_norm": 0.0,
      "learning_rate": 0.0001677687952420809,
      "loss": 4.9729,
      "step": 6449
    },
    {
      "epoch": 0.739594083247334,
      "grad_norm": 0.0,
      "learning_rate": 0.00016763008542000247,
      "loss": 5.0103,
      "step": 6450
    },
    {
      "epoch": 0.7397087489966747,
      "grad_norm": 0.0,
      "learning_rate": 0.00016749142144891496,
      "loss": 4.8146,
      "step": 6451
    },
    {
      "epoch": 0.7398234147460153,
      "grad_norm": 0.0,
      "learning_rate": 0.00016735280334794392,
      "loss": 5.4561,
      "step": 6452
    },
    {
      "epoch": 0.739938080495356,
      "grad_norm": 0.0,
      "learning_rate": 0.00016721423113620967,
      "loss": 5.5077,
      "step": 6453
    },
    {
      "epoch": 0.7400527462446967,
      "grad_norm": 0.0,
      "learning_rate": 0.00016707570483282498,
      "loss": 4.8677,
      "step": 6454
    },
    {
      "epoch": 0.7401674119940373,
      "grad_norm": 0.0,
      "learning_rate": 0.00016693722445689754,
      "loss": 4.9807,
      "step": 6455
    },
    {
      "epoch": 0.7402820777433781,
      "grad_norm": 0.0,
      "learning_rate": 0.00016679879002752768,
      "loss": 5.2489,
      "step": 6456
    },
    {
      "epoch": 0.7403967434927188,
      "grad_norm": 0.0,
      "learning_rate": 0.00016666040156380985,
      "loss": 4.8193,
      "step": 6457
    },
    {
      "epoch": 0.7405114092420594,
      "grad_norm": 0.0,
      "learning_rate": 0.00016652205908483227,
      "loss": 5.0332,
      "step": 6458
    },
    {
      "epoch": 0.7406260749914001,
      "grad_norm": 0.0,
      "learning_rate": 0.00016638376260967624,
      "loss": 4.9178,
      "step": 6459
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.0,
      "learning_rate": 0.00016624551215741772,
      "loss": 4.8904,
      "step": 6460
    },
    {
      "epoch": 0.7408554064900814,
      "grad_norm": 0.0,
      "learning_rate": 0.00016610730774712507,
      "loss": 5.3832,
      "step": 6461
    },
    {
      "epoch": 0.7409700722394221,
      "grad_norm": 0.0,
      "learning_rate": 0.00016596914939786162,
      "loss": 5.0712,
      "step": 6462
    },
    {
      "epoch": 0.7410847379887627,
      "grad_norm": 0.0,
      "learning_rate": 0.0001658310371286832,
      "loss": 4.7959,
      "step": 6463
    },
    {
      "epoch": 0.7411994037381034,
      "grad_norm": 0.0,
      "learning_rate": 0.00016569297095863988,
      "loss": 4.9921,
      "step": 6464
    },
    {
      "epoch": 0.741314069487444,
      "grad_norm": 0.0,
      "learning_rate": 0.00016555495090677535,
      "loss": 5.2058,
      "step": 6465
    },
    {
      "epoch": 0.7414287352367848,
      "grad_norm": 0.0,
      "learning_rate": 0.00016541697699212673,
      "loss": 4.8772,
      "step": 6466
    },
    {
      "epoch": 0.7415434009861255,
      "grad_norm": 0.0,
      "learning_rate": 0.00016527904923372498,
      "loss": 4.8959,
      "step": 6467
    },
    {
      "epoch": 0.7416580667354661,
      "grad_norm": 0.0,
      "learning_rate": 0.00016514116765059474,
      "loss": 4.991,
      "step": 6468
    },
    {
      "epoch": 0.7417727324848068,
      "grad_norm": 0.0,
      "learning_rate": 0.0001650033322617538,
      "loss": 5.058,
      "step": 6469
    },
    {
      "epoch": 0.7418873982341475,
      "grad_norm": 0.0,
      "learning_rate": 0.00016486554308621412,
      "loss": 4.9823,
      "step": 6470
    },
    {
      "epoch": 0.7420020639834881,
      "grad_norm": 0.0,
      "learning_rate": 0.00016472780014298102,
      "loss": 4.8223,
      "step": 6471
    },
    {
      "epoch": 0.7421167297328288,
      "grad_norm": 0.0,
      "learning_rate": 0.00016459010345105365,
      "loss": 4.967,
      "step": 6472
    },
    {
      "epoch": 0.7422313954821694,
      "grad_norm": 0.0,
      "learning_rate": 0.00016445245302942467,
      "loss": 4.8729,
      "step": 6473
    },
    {
      "epoch": 0.7423460612315101,
      "grad_norm": 0.0,
      "learning_rate": 0.0001643148488970799,
      "loss": 5.0672,
      "step": 6474
    },
    {
      "epoch": 0.7424607269808509,
      "grad_norm": 0.0,
      "learning_rate": 0.00016417729107299987,
      "loss": 4.8427,
      "step": 6475
    },
    {
      "epoch": 0.7425753927301915,
      "grad_norm": 0.0,
      "learning_rate": 0.0001640397795761574,
      "loss": 4.9914,
      "step": 6476
    },
    {
      "epoch": 0.7426900584795322,
      "grad_norm": 0.0,
      "learning_rate": 0.0001639023144255202,
      "loss": 4.8932,
      "step": 6477
    },
    {
      "epoch": 0.7428047242288728,
      "grad_norm": 0.0,
      "learning_rate": 0.0001637648956400485,
      "loss": 5.1509,
      "step": 6478
    },
    {
      "epoch": 0.7429193899782135,
      "grad_norm": 0.0,
      "learning_rate": 0.00016362752323869685,
      "loss": 5.0372,
      "step": 6479
    },
    {
      "epoch": 0.7430340557275542,
      "grad_norm": 0.0,
      "learning_rate": 0.00016349019724041315,
      "loss": 5.0135,
      "step": 6480
    },
    {
      "epoch": 0.7431487214768948,
      "grad_norm": 0.0,
      "learning_rate": 0.00016335291766413857,
      "loss": 5.1021,
      "step": 6481
    },
    {
      "epoch": 0.7432633872262355,
      "grad_norm": 0.0,
      "learning_rate": 0.00016321568452880875,
      "loss": 5.0282,
      "step": 6482
    },
    {
      "epoch": 0.7433780529755762,
      "grad_norm": 0.0,
      "learning_rate": 0.00016307849785335176,
      "loss": 4.8825,
      "step": 6483
    },
    {
      "epoch": 0.7434927187249168,
      "grad_norm": 0.0,
      "learning_rate": 0.0001629413576566906,
      "loss": 4.9664,
      "step": 6484
    },
    {
      "epoch": 0.7436073844742576,
      "grad_norm": 0.0,
      "learning_rate": 0.00016280426395774052,
      "loss": 4.8451,
      "step": 6485
    },
    {
      "epoch": 0.7437220502235982,
      "grad_norm": 0.0,
      "learning_rate": 0.00016266721677541136,
      "loss": 5.022,
      "step": 6486
    },
    {
      "epoch": 0.7438367159729389,
      "grad_norm": 0.0,
      "learning_rate": 0.00016253021612860596,
      "loss": 5.165,
      "step": 6487
    },
    {
      "epoch": 0.7439513817222796,
      "grad_norm": 0.0,
      "learning_rate": 0.0001623932620362211,
      "loss": 5.2057,
      "step": 6488
    },
    {
      "epoch": 0.7440660474716202,
      "grad_norm": 0.0,
      "learning_rate": 0.00016225635451714703,
      "loss": 4.9117,
      "step": 6489
    },
    {
      "epoch": 0.7441807132209609,
      "grad_norm": 0.0,
      "learning_rate": 0.00016211949359026728,
      "loss": 5.1723,
      "step": 6490
    },
    {
      "epoch": 0.7442953789703016,
      "grad_norm": 0.0,
      "learning_rate": 0.00016198267927445935,
      "loss": 5.0008,
      "step": 6491
    },
    {
      "epoch": 0.7444100447196422,
      "grad_norm": 0.0,
      "learning_rate": 0.00016184591158859417,
      "loss": 5.1667,
      "step": 6492
    },
    {
      "epoch": 0.7445247104689829,
      "grad_norm": 0.0,
      "learning_rate": 0.0001617091905515362,
      "loss": 4.9744,
      "step": 6493
    },
    {
      "epoch": 0.7446393762183235,
      "grad_norm": 0.0,
      "learning_rate": 0.00016157251618214351,
      "loss": 5.2268,
      "step": 6494
    },
    {
      "epoch": 0.7447540419676643,
      "grad_norm": 0.0,
      "learning_rate": 0.000161435888499268,
      "loss": 4.9695,
      "step": 6495
    },
    {
      "epoch": 0.744868707717005,
      "grad_norm": 0.0,
      "learning_rate": 0.0001612993075217542,
      "loss": 5.0191,
      "step": 6496
    },
    {
      "epoch": 0.7449833734663456,
      "grad_norm": 0.0,
      "learning_rate": 0.00016116277326844161,
      "loss": 5.0721,
      "step": 6497
    },
    {
      "epoch": 0.7450980392156863,
      "grad_norm": 0.0,
      "learning_rate": 0.000161026285758162,
      "loss": 5.106,
      "step": 6498
    },
    {
      "epoch": 0.7452127049650269,
      "grad_norm": 0.0,
      "learning_rate": 0.00016088984500974138,
      "loss": 4.8985,
      "step": 6499
    },
    {
      "epoch": 0.7453273707143676,
      "grad_norm": 0.0,
      "learning_rate": 0.00016075345104199932,
      "loss": 4.6493,
      "step": 6500
    },
    {
      "epoch": 0.7454420364637083,
      "grad_norm": 0.0,
      "learning_rate": 0.0001606171038737483,
      "loss": 5.1044,
      "step": 6501
    },
    {
      "epoch": 0.7455567022130489,
      "grad_norm": 0.0,
      "learning_rate": 0.00016048080352379544,
      "loss": 5.0717,
      "step": 6502
    },
    {
      "epoch": 0.7456713679623896,
      "grad_norm": 0.0,
      "learning_rate": 0.00016034455001094012,
      "loss": 4.8874,
      "step": 6503
    },
    {
      "epoch": 0.7457860337117304,
      "grad_norm": 0.0,
      "learning_rate": 0.00016020834335397658,
      "loss": 4.9408,
      "step": 6504
    },
    {
      "epoch": 0.745900699461071,
      "grad_norm": 0.0,
      "learning_rate": 0.00016007218357169128,
      "loss": 5.1032,
      "step": 6505
    },
    {
      "epoch": 0.7460153652104117,
      "grad_norm": 0.0,
      "learning_rate": 0.0001599360706828655,
      "loss": 4.9735,
      "step": 6506
    },
    {
      "epoch": 0.7461300309597523,
      "grad_norm": 0.0,
      "learning_rate": 0.00015980000470627298,
      "loss": 5.0245,
      "step": 6507
    },
    {
      "epoch": 0.746244696709093,
      "grad_norm": 0.0,
      "learning_rate": 0.00015966398566068157,
      "loss": 4.9273,
      "step": 6508
    },
    {
      "epoch": 0.7463593624584337,
      "grad_norm": 0.0,
      "learning_rate": 0.0001595280135648526,
      "loss": 4.9455,
      "step": 6509
    },
    {
      "epoch": 0.7464740282077743,
      "grad_norm": 0.0,
      "learning_rate": 0.00015939208843754042,
      "loss": 5.0403,
      "step": 6510
    },
    {
      "epoch": 0.746588693957115,
      "grad_norm": 0.0,
      "learning_rate": 0.00015925621029749392,
      "loss": 5.0433,
      "step": 6511
    },
    {
      "epoch": 0.7467033597064556,
      "grad_norm": 0.0,
      "learning_rate": 0.00015912037916345444,
      "loss": 5.242,
      "step": 6512
    },
    {
      "epoch": 0.7468180254557963,
      "grad_norm": 0.0,
      "learning_rate": 0.0001589845950541574,
      "loss": 5.1121,
      "step": 6513
    },
    {
      "epoch": 0.7469326912051371,
      "grad_norm": 0.0,
      "learning_rate": 0.00015884885798833173,
      "loss": 4.8571,
      "step": 6514
    },
    {
      "epoch": 0.7470473569544777,
      "grad_norm": 0.0,
      "learning_rate": 0.00015871316798469974,
      "loss": 4.7604,
      "step": 6515
    },
    {
      "epoch": 0.7471620227038184,
      "grad_norm": 0.0,
      "learning_rate": 0.00015857752506197718,
      "loss": 5.2446,
      "step": 6516
    },
    {
      "epoch": 0.7472766884531591,
      "grad_norm": 0.0,
      "learning_rate": 0.00015844192923887367,
      "loss": 5.2326,
      "step": 6517
    },
    {
      "epoch": 0.7473913542024997,
      "grad_norm": 0.0,
      "learning_rate": 0.00015830638053409155,
      "loss": 5.0794,
      "step": 6518
    },
    {
      "epoch": 0.7475060199518404,
      "grad_norm": 0.0,
      "learning_rate": 0.00015817087896632788,
      "loss": 4.863,
      "step": 6519
    },
    {
      "epoch": 0.747620685701181,
      "grad_norm": 0.0,
      "learning_rate": 0.00015803542455427192,
      "loss": 4.9603,
      "step": 6520
    },
    {
      "epoch": 0.7477353514505217,
      "grad_norm": 0.0,
      "learning_rate": 0.00015790001731660728,
      "loss": 4.9294,
      "step": 6521
    },
    {
      "epoch": 0.7478500171998624,
      "grad_norm": 0.0,
      "learning_rate": 0.00015776465727201095,
      "loss": 5.0636,
      "step": 6522
    },
    {
      "epoch": 0.747964682949203,
      "grad_norm": 0.0,
      "learning_rate": 0.00015762934443915274,
      "loss": 5.1833,
      "step": 6523
    },
    {
      "epoch": 0.7480793486985438,
      "grad_norm": 0.0,
      "learning_rate": 0.0001574940788366972,
      "loss": 4.9076,
      "step": 6524
    },
    {
      "epoch": 0.7481940144478845,
      "grad_norm": 0.0,
      "learning_rate": 0.00015735886048330093,
      "loss": 4.9572,
      "step": 6525
    },
    {
      "epoch": 0.7483086801972251,
      "grad_norm": 0.0,
      "learning_rate": 0.00015722368939761545,
      "loss": 5.2794,
      "step": 6526
    },
    {
      "epoch": 0.7484233459465658,
      "grad_norm": 0.0,
      "learning_rate": 0.00015708856559828427,
      "loss": 4.9621,
      "step": 6527
    },
    {
      "epoch": 0.7485380116959064,
      "grad_norm": 0.0,
      "learning_rate": 0.00015695348910394583,
      "loss": 5.0708,
      "step": 6528
    },
    {
      "epoch": 0.7486526774452471,
      "grad_norm": 0.0,
      "learning_rate": 0.0001568184599332311,
      "loss": 5.0701,
      "step": 6529
    },
    {
      "epoch": 0.7487673431945878,
      "grad_norm": 0.0,
      "learning_rate": 0.00015668347810476435,
      "loss": 5.112,
      "step": 6530
    },
    {
      "epoch": 0.7488820089439284,
      "grad_norm": 0.0,
      "learning_rate": 0.0001565485436371645,
      "loss": 5.1402,
      "step": 6531
    },
    {
      "epoch": 0.7489966746932691,
      "grad_norm": 0.0,
      "learning_rate": 0.00015641365654904256,
      "loss": 5.1578,
      "step": 6532
    },
    {
      "epoch": 0.7491113404426097,
      "grad_norm": 0.0,
      "learning_rate": 0.00015627881685900414,
      "loss": 4.9445,
      "step": 6533
    },
    {
      "epoch": 0.7492260061919505,
      "grad_norm": 0.0,
      "learning_rate": 0.0001561440245856474,
      "loss": 5.0934,
      "step": 6534
    },
    {
      "epoch": 0.7493406719412912,
      "grad_norm": 0.0,
      "learning_rate": 0.00015600927974756455,
      "loss": 4.9279,
      "step": 6535
    },
    {
      "epoch": 0.7494553376906318,
      "grad_norm": 0.0,
      "learning_rate": 0.00015587458236334103,
      "loss": 5.0559,
      "step": 6536
    },
    {
      "epoch": 0.7495700034399725,
      "grad_norm": 0.0,
      "learning_rate": 0.00015573993245155575,
      "loss": 5.0745,
      "step": 6537
    },
    {
      "epoch": 0.7496846691893132,
      "grad_norm": 0.0,
      "learning_rate": 0.00015560533003078123,
      "loss": 5.0602,
      "step": 6538
    },
    {
      "epoch": 0.7497993349386538,
      "grad_norm": 0.0,
      "learning_rate": 0.0001554707751195833,
      "loss": 4.7815,
      "step": 6539
    },
    {
      "epoch": 0.7499140006879945,
      "grad_norm": 0.0,
      "learning_rate": 0.00015533626773652108,
      "loss": 5.1835,
      "step": 6540
    },
    {
      "epoch": 0.7500286664373351,
      "grad_norm": 0.0,
      "learning_rate": 0.00015520180790014736,
      "loss": 4.9789,
      "step": 6541
    },
    {
      "epoch": 0.7501433321866758,
      "grad_norm": 0.0,
      "learning_rate": 0.00015506739562900828,
      "loss": 4.9328,
      "step": 6542
    },
    {
      "epoch": 0.7502579979360166,
      "grad_norm": 0.0,
      "learning_rate": 0.00015493303094164356,
      "loss": 4.8663,
      "step": 6543
    },
    {
      "epoch": 0.7503726636853572,
      "grad_norm": 0.0,
      "learning_rate": 0.0001547987138565863,
      "loss": 4.9433,
      "step": 6544
    },
    {
      "epoch": 0.7504873294346979,
      "grad_norm": 0.0,
      "learning_rate": 0.00015466444439236264,
      "loss": 4.9649,
      "step": 6545
    },
    {
      "epoch": 0.7506019951840385,
      "grad_norm": 0.0,
      "learning_rate": 0.000154530222567493,
      "loss": 5.269,
      "step": 6546
    },
    {
      "epoch": 0.7507166609333792,
      "grad_norm": 0.0,
      "learning_rate": 0.00015439604840049014,
      "loss": 5.1175,
      "step": 6547
    },
    {
      "epoch": 0.7508313266827199,
      "grad_norm": 0.0,
      "learning_rate": 0.00015426192190986146,
      "loss": 4.9705,
      "step": 6548
    },
    {
      "epoch": 0.7509459924320605,
      "grad_norm": 0.0,
      "learning_rate": 0.00015412784311410666,
      "loss": 4.9864,
      "step": 6549
    },
    {
      "epoch": 0.7510606581814012,
      "grad_norm": 0.0,
      "learning_rate": 0.0001539938120317195,
      "loss": 4.7924,
      "step": 6550
    },
    {
      "epoch": 0.7511753239307419,
      "grad_norm": 0.0,
      "learning_rate": 0.0001538598286811873,
      "loss": 5.3767,
      "step": 6551
    },
    {
      "epoch": 0.7512899896800825,
      "grad_norm": 0.0,
      "learning_rate": 0.00015372589308098984,
      "loss": 4.9284,
      "step": 6552
    },
    {
      "epoch": 0.7514046554294233,
      "grad_norm": 0.0,
      "learning_rate": 0.00015359200524960167,
      "loss": 4.9928,
      "step": 6553
    },
    {
      "epoch": 0.7515193211787639,
      "grad_norm": 0.0,
      "learning_rate": 0.00015345816520548957,
      "loss": 4.8312,
      "step": 6554
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.0,
      "learning_rate": 0.00015332437296711472,
      "loss": 4.9864,
      "step": 6555
    },
    {
      "epoch": 0.7517486526774453,
      "grad_norm": 0.0,
      "learning_rate": 0.00015319062855293075,
      "loss": 4.9246,
      "step": 6556
    },
    {
      "epoch": 0.7518633184267859,
      "grad_norm": 0.0,
      "learning_rate": 0.00015305693198138532,
      "loss": 5.1481,
      "step": 6557
    },
    {
      "epoch": 0.7519779841761266,
      "grad_norm": 0.0,
      "learning_rate": 0.0001529232832709194,
      "loss": 4.9667,
      "step": 6558
    },
    {
      "epoch": 0.7520926499254673,
      "grad_norm": 0.0,
      "learning_rate": 0.00015278968243996718,
      "loss": 5.0805,
      "step": 6559
    },
    {
      "epoch": 0.7522073156748079,
      "grad_norm": 0.0,
      "learning_rate": 0.00015265612950695652,
      "loss": 4.9058,
      "step": 6560
    },
    {
      "epoch": 0.7523219814241486,
      "grad_norm": 0.0,
      "learning_rate": 0.0001525226244903082,
      "loss": 5.0456,
      "step": 6561
    },
    {
      "epoch": 0.7524366471734892,
      "grad_norm": 0.0,
      "learning_rate": 0.00015238916740843687,
      "loss": 4.7339,
      "step": 6562
    },
    {
      "epoch": 0.75255131292283,
      "grad_norm": 0.0,
      "learning_rate": 0.0001522557582797504,
      "loss": 4.9538,
      "step": 6563
    },
    {
      "epoch": 0.7526659786721707,
      "grad_norm": 0.0,
      "learning_rate": 0.00015212239712265,
      "loss": 4.9809,
      "step": 6564
    },
    {
      "epoch": 0.7527806444215113,
      "grad_norm": 0.0,
      "learning_rate": 0.0001519890839555303,
      "loss": 5.0665,
      "step": 6565
    },
    {
      "epoch": 0.752895310170852,
      "grad_norm": 0.0,
      "learning_rate": 0.0001518558187967795,
      "loss": 4.8348,
      "step": 6566
    },
    {
      "epoch": 0.7530099759201926,
      "grad_norm": 0.0,
      "learning_rate": 0.0001517226016647785,
      "loss": 4.6674,
      "step": 6567
    },
    {
      "epoch": 0.7531246416695333,
      "grad_norm": 0.0,
      "learning_rate": 0.0001515894325779027,
      "loss": 5.1174,
      "step": 6568
    },
    {
      "epoch": 0.753239307418874,
      "grad_norm": 0.0,
      "learning_rate": 0.00015145631155451955,
      "loss": 5.0742,
      "step": 6569
    },
    {
      "epoch": 0.7533539731682146,
      "grad_norm": 0.0,
      "learning_rate": 0.0001513232386129913,
      "loss": 5.0533,
      "step": 6570
    },
    {
      "epoch": 0.7534686389175553,
      "grad_norm": 0.0,
      "learning_rate": 0.00015119021377167226,
      "loss": 5.2667,
      "step": 6571
    },
    {
      "epoch": 0.753583304666896,
      "grad_norm": 0.0,
      "learning_rate": 0.00015105723704891084,
      "loss": 5.1362,
      "step": 6572
    },
    {
      "epoch": 0.7536979704162367,
      "grad_norm": 0.0,
      "learning_rate": 0.0001509243084630488,
      "loss": 4.9792,
      "step": 6573
    },
    {
      "epoch": 0.7538126361655774,
      "grad_norm": 0.0,
      "learning_rate": 0.00015079142803242073,
      "loss": 4.828,
      "step": 6574
    },
    {
      "epoch": 0.753927301914918,
      "grad_norm": 0.0,
      "learning_rate": 0.00015065859577535542,
      "loss": 4.9835,
      "step": 6575
    },
    {
      "epoch": 0.7540419676642587,
      "grad_norm": 0.0,
      "learning_rate": 0.0001505258117101741,
      "loss": 5.1054,
      "step": 6576
    },
    {
      "epoch": 0.7541566334135994,
      "grad_norm": 0.0,
      "learning_rate": 0.0001503930758551922,
      "loss": 4.9762,
      "step": 6577
    },
    {
      "epoch": 0.75427129916294,
      "grad_norm": 0.0,
      "learning_rate": 0.00015026038822871785,
      "loss": 4.7487,
      "step": 6578
    },
    {
      "epoch": 0.7543859649122807,
      "grad_norm": 0.0,
      "learning_rate": 0.00015012774884905284,
      "loss": 5.1176,
      "step": 6579
    },
    {
      "epoch": 0.7545006306616213,
      "grad_norm": 0.0,
      "learning_rate": 0.00014999515773449242,
      "loss": 4.9249,
      "step": 6580
    },
    {
      "epoch": 0.754615296410962,
      "grad_norm": 0.0,
      "learning_rate": 0.0001498626149033245,
      "loss": 4.9425,
      "step": 6581
    },
    {
      "epoch": 0.7547299621603027,
      "grad_norm": 0.0,
      "learning_rate": 0.00014973012037383147,
      "loss": 5.0027,
      "step": 6582
    },
    {
      "epoch": 0.7548446279096434,
      "grad_norm": 0.0,
      "learning_rate": 0.000149597674164288,
      "loss": 5.2622,
      "step": 6583
    },
    {
      "epoch": 0.7549592936589841,
      "grad_norm": 0.0,
      "learning_rate": 0.00014946527629296265,
      "loss": 5.3453,
      "step": 6584
    },
    {
      "epoch": 0.7550739594083248,
      "grad_norm": 0.0,
      "learning_rate": 0.00014933292677811718,
      "loss": 5.0426,
      "step": 6585
    },
    {
      "epoch": 0.7551886251576654,
      "grad_norm": 0.0,
      "learning_rate": 0.0001492006256380067,
      "loss": 5.069,
      "step": 6586
    },
    {
      "epoch": 0.7553032909070061,
      "grad_norm": 0.0,
      "learning_rate": 0.00014906837289087958,
      "loss": 5.0214,
      "step": 6587
    },
    {
      "epoch": 0.7554179566563467,
      "grad_norm": 0.0,
      "learning_rate": 0.0001489361685549778,
      "loss": 5.2103,
      "step": 6588
    },
    {
      "epoch": 0.7555326224056874,
      "grad_norm": 0.0,
      "learning_rate": 0.00014880401264853586,
      "loss": 4.7361,
      "step": 6589
    },
    {
      "epoch": 0.7556472881550281,
      "grad_norm": 0.0,
      "learning_rate": 0.00014867190518978284,
      "loss": 5.0586,
      "step": 6590
    },
    {
      "epoch": 0.7557619539043687,
      "grad_norm": 0.0,
      "learning_rate": 0.00014853984619694001,
      "loss": 5.0113,
      "step": 6591
    },
    {
      "epoch": 0.7558766196537094,
      "grad_norm": 0.0,
      "learning_rate": 0.00014840783568822254,
      "loss": 5.1042,
      "step": 6592
    },
    {
      "epoch": 0.7559912854030502,
      "grad_norm": 0.0,
      "learning_rate": 0.0001482758736818386,
      "loss": 4.8939,
      "step": 6593
    },
    {
      "epoch": 0.7561059511523908,
      "grad_norm": 0.0,
      "learning_rate": 0.00014814396019599004,
      "loss": 5.0632,
      "step": 6594
    },
    {
      "epoch": 0.7562206169017315,
      "grad_norm": 0.0,
      "learning_rate": 0.0001480120952488719,
      "loss": 5.0359,
      "step": 6595
    },
    {
      "epoch": 0.7563352826510721,
      "grad_norm": 0.0,
      "learning_rate": 0.00014788027885867194,
      "loss": 5.2897,
      "step": 6596
    },
    {
      "epoch": 0.7564499484004128,
      "grad_norm": 0.0,
      "learning_rate": 0.00014774851104357238,
      "loss": 4.8887,
      "step": 6597
    },
    {
      "epoch": 0.7565646141497535,
      "grad_norm": 0.0,
      "learning_rate": 0.00014761679182174743,
      "loss": 5.0138,
      "step": 6598
    },
    {
      "epoch": 0.7566792798990941,
      "grad_norm": 0.0,
      "learning_rate": 0.00014748512121136578,
      "loss": 4.7798,
      "step": 6599
    },
    {
      "epoch": 0.7567939456484348,
      "grad_norm": 0.0,
      "learning_rate": 0.00014735349923058864,
      "loss": 4.8383,
      "step": 6600
    },
    {
      "epoch": 0.7569086113977754,
      "grad_norm": 0.0,
      "learning_rate": 0.0001472219258975707,
      "loss": 5.0962,
      "step": 6601
    },
    {
      "epoch": 0.7570232771471161,
      "grad_norm": 0.0,
      "learning_rate": 0.00014709040123046018,
      "loss": 4.9247,
      "step": 6602
    },
    {
      "epoch": 0.7571379428964569,
      "grad_norm": 0.0,
      "learning_rate": 0.00014695892524739808,
      "loss": 5.0851,
      "step": 6603
    },
    {
      "epoch": 0.7572526086457975,
      "grad_norm": 0.0,
      "learning_rate": 0.00014682749796651943,
      "loss": 4.9028,
      "step": 6604
    },
    {
      "epoch": 0.7573672743951382,
      "grad_norm": 0.0,
      "learning_rate": 0.00014669611940595182,
      "loss": 5.0408,
      "step": 6605
    },
    {
      "epoch": 0.7574819401444789,
      "grad_norm": 0.0,
      "learning_rate": 0.00014656478958381645,
      "loss": 5.2088,
      "step": 6606
    },
    {
      "epoch": 0.7575966058938195,
      "grad_norm": 0.0,
      "learning_rate": 0.0001464335085182278,
      "loss": 4.9857,
      "step": 6607
    },
    {
      "epoch": 0.7577112716431602,
      "grad_norm": 0.0,
      "learning_rate": 0.00014630227622729365,
      "loss": 4.9486,
      "step": 6608
    },
    {
      "epoch": 0.7578259373925008,
      "grad_norm": 0.0,
      "learning_rate": 0.000146171092729115,
      "loss": 5.2158,
      "step": 6609
    },
    {
      "epoch": 0.7579406031418415,
      "grad_norm": 0.0,
      "learning_rate": 0.0001460399580417861,
      "loss": 5.213,
      "step": 6610
    },
    {
      "epoch": 0.7580552688911822,
      "grad_norm": 0.0,
      "learning_rate": 0.00014590887218339437,
      "loss": 4.88,
      "step": 6611
    },
    {
      "epoch": 0.7581699346405228,
      "grad_norm": 0.0,
      "learning_rate": 0.00014577783517202064,
      "loss": 4.6126,
      "step": 6612
    },
    {
      "epoch": 0.7582846003898636,
      "grad_norm": 0.0,
      "learning_rate": 0.00014564684702573905,
      "loss": 4.5429,
      "step": 6613
    },
    {
      "epoch": 0.7583992661392042,
      "grad_norm": 0.0,
      "learning_rate": 0.00014551590776261684,
      "loss": 5.3705,
      "step": 6614
    },
    {
      "epoch": 0.7585139318885449,
      "grad_norm": 0.0,
      "learning_rate": 0.00014538501740071457,
      "loss": 4.7283,
      "step": 6615
    },
    {
      "epoch": 0.7586285976378856,
      "grad_norm": 0.0,
      "learning_rate": 0.00014525417595808617,
      "loss": 5.3618,
      "step": 6616
    },
    {
      "epoch": 0.7587432633872262,
      "grad_norm": 0.0,
      "learning_rate": 0.00014512338345277887,
      "loss": 4.9222,
      "step": 6617
    },
    {
      "epoch": 0.7588579291365669,
      "grad_norm": 0.0,
      "learning_rate": 0.00014499263990283245,
      "loss": 5.0607,
      "step": 6618
    },
    {
      "epoch": 0.7589725948859076,
      "grad_norm": 0.0,
      "learning_rate": 0.00014486194532628118,
      "loss": 4.8697,
      "step": 6619
    },
    {
      "epoch": 0.7590872606352482,
      "grad_norm": 0.0,
      "learning_rate": 0.00014473129974115138,
      "loss": 5.0475,
      "step": 6620
    },
    {
      "epoch": 0.7592019263845889,
      "grad_norm": 0.0,
      "learning_rate": 0.00014460070316546332,
      "loss": 4.8642,
      "step": 6621
    },
    {
      "epoch": 0.7593165921339295,
      "grad_norm": 0.0,
      "learning_rate": 0.0001444701556172304,
      "loss": 5.0663,
      "step": 6622
    },
    {
      "epoch": 0.7594312578832703,
      "grad_norm": 0.0,
      "learning_rate": 0.00014433965711445871,
      "loss": 4.914,
      "step": 6623
    },
    {
      "epoch": 0.759545923632611,
      "grad_norm": 0.0,
      "learning_rate": 0.0001442092076751487,
      "loss": 5.1545,
      "step": 6624
    },
    {
      "epoch": 0.7596605893819516,
      "grad_norm": 0.0,
      "learning_rate": 0.00014407880731729275,
      "loss": 5.3343,
      "step": 6625
    },
    {
      "epoch": 0.7597752551312923,
      "grad_norm": 0.0,
      "learning_rate": 0.00014394845605887773,
      "loss": 4.8962,
      "step": 6626
    },
    {
      "epoch": 0.759889920880633,
      "grad_norm": 0.0,
      "learning_rate": 0.00014381815391788257,
      "loss": 5.1223,
      "step": 6627
    },
    {
      "epoch": 0.7600045866299736,
      "grad_norm": 0.0,
      "learning_rate": 0.00014368790091228022,
      "loss": 4.8907,
      "step": 6628
    },
    {
      "epoch": 0.7601192523793143,
      "grad_norm": 0.0,
      "learning_rate": 0.00014355769706003659,
      "loss": 4.9098,
      "step": 6629
    },
    {
      "epoch": 0.7602339181286549,
      "grad_norm": 0.0,
      "learning_rate": 0.0001434275423791107,
      "loss": 5.0666,
      "step": 6630
    },
    {
      "epoch": 0.7603485838779956,
      "grad_norm": 0.0,
      "learning_rate": 0.00014329743688745524,
      "loss": 5.0725,
      "step": 6631
    },
    {
      "epoch": 0.7604632496273364,
      "grad_norm": 0.0,
      "learning_rate": 0.00014316738060301534,
      "loss": 5.0757,
      "step": 6632
    },
    {
      "epoch": 0.760577915376677,
      "grad_norm": 0.0,
      "learning_rate": 0.00014303737354372998,
      "loss": 4.963,
      "step": 6633
    },
    {
      "epoch": 0.7606925811260177,
      "grad_norm": 0.0,
      "learning_rate": 0.00014290741572753115,
      "loss": 4.8398,
      "step": 6634
    },
    {
      "epoch": 0.7608072468753583,
      "grad_norm": 0.0,
      "learning_rate": 0.00014277750717234415,
      "loss": 4.7217,
      "step": 6635
    },
    {
      "epoch": 0.760921912624699,
      "grad_norm": 0.0,
      "learning_rate": 0.00014264764789608724,
      "loss": 4.9869,
      "step": 6636
    },
    {
      "epoch": 0.7610365783740397,
      "grad_norm": 0.0,
      "learning_rate": 0.00014251783791667207,
      "loss": 5.2212,
      "step": 6637
    },
    {
      "epoch": 0.7611512441233803,
      "grad_norm": 0.0,
      "learning_rate": 0.0001423880772520035,
      "loss": 5.1119,
      "step": 6638
    },
    {
      "epoch": 0.761265909872721,
      "grad_norm": 0.0,
      "learning_rate": 0.00014225836591997968,
      "loss": 4.8882,
      "step": 6639
    },
    {
      "epoch": 0.7613805756220617,
      "grad_norm": 0.0,
      "learning_rate": 0.0001421287039384913,
      "loss": 5.3088,
      "step": 6640
    },
    {
      "epoch": 0.7614952413714023,
      "grad_norm": 0.0,
      "learning_rate": 0.00014199909132542348,
      "loss": 5.076,
      "step": 6641
    },
    {
      "epoch": 0.7616099071207431,
      "grad_norm": 0.0,
      "learning_rate": 0.00014186952809865322,
      "loss": 4.8712,
      "step": 6642
    },
    {
      "epoch": 0.7617245728700837,
      "grad_norm": 0.0,
      "learning_rate": 0.0001417400142760516,
      "loss": 4.838,
      "step": 6643
    },
    {
      "epoch": 0.7618392386194244,
      "grad_norm": 0.0,
      "learning_rate": 0.0001416105498754826,
      "loss": 5.0131,
      "step": 6644
    },
    {
      "epoch": 0.7619539043687651,
      "grad_norm": 0.0,
      "learning_rate": 0.00014148113491480296,
      "loss": 5.1565,
      "step": 6645
    },
    {
      "epoch": 0.7620685701181057,
      "grad_norm": 0.0,
      "learning_rate": 0.00014135176941186363,
      "loss": 4.7689,
      "step": 6646
    },
    {
      "epoch": 0.7621832358674464,
      "grad_norm": 0.0,
      "learning_rate": 0.00014122245338450752,
      "loss": 5.3676,
      "step": 6647
    },
    {
      "epoch": 0.762297901616787,
      "grad_norm": 0.0,
      "learning_rate": 0.00014109318685057184,
      "loss": 5.1489,
      "step": 6648
    },
    {
      "epoch": 0.7624125673661277,
      "grad_norm": 0.0,
      "learning_rate": 0.0001409639698278861,
      "loss": 5.0866,
      "step": 6649
    },
    {
      "epoch": 0.7625272331154684,
      "grad_norm": 0.0,
      "learning_rate": 0.00014083480233427337,
      "loss": 4.8204,
      "step": 6650
    },
    {
      "epoch": 0.762641898864809,
      "grad_norm": 0.0,
      "learning_rate": 0.0001407056843875501,
      "loss": 5.1899,
      "step": 6651
    },
    {
      "epoch": 0.7627565646141498,
      "grad_norm": 0.0,
      "learning_rate": 0.00014057661600552508,
      "loss": 5.233,
      "step": 6652
    },
    {
      "epoch": 0.7628712303634905,
      "grad_norm": 0.0,
      "learning_rate": 0.00014044759720600156,
      "loss": 4.928,
      "step": 6653
    },
    {
      "epoch": 0.7629858961128311,
      "grad_norm": 0.0,
      "learning_rate": 0.00014031862800677466,
      "loss": 4.8913,
      "step": 6654
    },
    {
      "epoch": 0.7631005618621718,
      "grad_norm": 0.0,
      "learning_rate": 0.00014018970842563343,
      "loss": 4.8876,
      "step": 6655
    },
    {
      "epoch": 0.7632152276115124,
      "grad_norm": 0.0,
      "learning_rate": 0.00014006083848035986,
      "loss": 5.2459,
      "step": 6656
    },
    {
      "epoch": 0.7633298933608531,
      "grad_norm": 0.0,
      "learning_rate": 0.00013993201818872914,
      "loss": 4.9526,
      "step": 6657
    },
    {
      "epoch": 0.7634445591101938,
      "grad_norm": 0.0,
      "learning_rate": 0.0001398032475685095,
      "loss": 5.1892,
      "step": 6658
    },
    {
      "epoch": 0.7635592248595344,
      "grad_norm": 0.0,
      "learning_rate": 0.00013967452663746243,
      "loss": 5.0455,
      "step": 6659
    },
    {
      "epoch": 0.7636738906088751,
      "grad_norm": 0.0,
      "learning_rate": 0.00013954585541334254,
      "loss": 5.0979,
      "step": 6660
    },
    {
      "epoch": 0.7637885563582159,
      "grad_norm": 0.0,
      "learning_rate": 0.00013941723391389772,
      "loss": 5.0925,
      "step": 6661
    },
    {
      "epoch": 0.7639032221075565,
      "grad_norm": 0.0,
      "learning_rate": 0.00013928866215686856,
      "loss": 5.0471,
      "step": 6662
    },
    {
      "epoch": 0.7640178878568972,
      "grad_norm": 0.0,
      "learning_rate": 0.00013916014015998918,
      "loss": 4.9187,
      "step": 6663
    },
    {
      "epoch": 0.7641325536062378,
      "grad_norm": 0.0,
      "learning_rate": 0.00013903166794098683,
      "loss": 4.9759,
      "step": 6664
    },
    {
      "epoch": 0.7642472193555785,
      "grad_norm": 0.0,
      "learning_rate": 0.00013890324551758164,
      "loss": 4.9747,
      "step": 6665
    },
    {
      "epoch": 0.7643618851049192,
      "grad_norm": 0.0,
      "learning_rate": 0.00013877487290748743,
      "loss": 4.9118,
      "step": 6666
    },
    {
      "epoch": 0.7644765508542598,
      "grad_norm": 0.0,
      "learning_rate": 0.00013864655012841014,
      "loss": 4.9825,
      "step": 6667
    },
    {
      "epoch": 0.7645912166036005,
      "grad_norm": 0.0,
      "learning_rate": 0.00013851827719805004,
      "loss": 5.0884,
      "step": 6668
    },
    {
      "epoch": 0.7647058823529411,
      "grad_norm": 0.0,
      "learning_rate": 0.0001383900541340994,
      "loss": 5.1706,
      "step": 6669
    },
    {
      "epoch": 0.7648205481022818,
      "grad_norm": 0.0,
      "learning_rate": 0.0001382618809542447,
      "loss": 4.87,
      "step": 6670
    },
    {
      "epoch": 0.7649352138516226,
      "grad_norm": 0.0,
      "learning_rate": 0.0001381337576761646,
      "loss": 4.9709,
      "step": 6671
    },
    {
      "epoch": 0.7650498796009632,
      "grad_norm": 0.0,
      "learning_rate": 0.00013800568431753134,
      "loss": 5.0683,
      "step": 6672
    },
    {
      "epoch": 0.7651645453503039,
      "grad_norm": 0.0,
      "learning_rate": 0.00013787766089601048,
      "loss": 4.8861,
      "step": 6673
    },
    {
      "epoch": 0.7652792110996446,
      "grad_norm": 0.0,
      "learning_rate": 0.00013774968742925975,
      "loss": 5.0298,
      "step": 6674
    },
    {
      "epoch": 0.7653938768489852,
      "grad_norm": 0.0,
      "learning_rate": 0.0001376217639349314,
      "loss": 5.2098,
      "step": 6675
    },
    {
      "epoch": 0.7655085425983259,
      "grad_norm": 0.0,
      "learning_rate": 0.00013749389043066955,
      "loss": 4.9671,
      "step": 6676
    },
    {
      "epoch": 0.7656232083476665,
      "grad_norm": 0.0,
      "learning_rate": 0.0001373660669341121,
      "loss": 4.883,
      "step": 6677
    },
    {
      "epoch": 0.7657378740970072,
      "grad_norm": 0.0,
      "learning_rate": 0.00013723829346288987,
      "loss": 5.0438,
      "step": 6678
    },
    {
      "epoch": 0.7658525398463479,
      "grad_norm": 0.0,
      "learning_rate": 0.00013711057003462667,
      "loss": 4.8857,
      "step": 6679
    },
    {
      "epoch": 0.7659672055956885,
      "grad_norm": 0.0,
      "learning_rate": 0.0001369828966669396,
      "loss": 4.6858,
      "step": 6680
    },
    {
      "epoch": 0.7660818713450293,
      "grad_norm": 0.0,
      "learning_rate": 0.00013685527337743876,
      "loss": 4.9651,
      "step": 6681
    },
    {
      "epoch": 0.76619653709437,
      "grad_norm": 0.0,
      "learning_rate": 0.00013672770018372744,
      "loss": 5.1489,
      "step": 6682
    },
    {
      "epoch": 0.7663112028437106,
      "grad_norm": 0.0,
      "learning_rate": 0.0001366001771034017,
      "loss": 5.0204,
      "step": 6683
    },
    {
      "epoch": 0.7664258685930513,
      "grad_norm": 0.0,
      "learning_rate": 0.00013647270415405104,
      "loss": 4.9747,
      "step": 6684
    },
    {
      "epoch": 0.7665405343423919,
      "grad_norm": 0.0,
      "learning_rate": 0.00013634528135325798,
      "loss": 4.7372,
      "step": 6685
    },
    {
      "epoch": 0.7666552000917326,
      "grad_norm": 0.0,
      "learning_rate": 0.00013621790871859796,
      "loss": 5.1819,
      "step": 6686
    },
    {
      "epoch": 0.7667698658410733,
      "grad_norm": 0.0,
      "learning_rate": 0.00013609058626763967,
      "loss": 4.772,
      "step": 6687
    },
    {
      "epoch": 0.7668845315904139,
      "grad_norm": 0.0,
      "learning_rate": 0.00013596331401794496,
      "loss": 5.0915,
      "step": 6688
    },
    {
      "epoch": 0.7669991973397546,
      "grad_norm": 0.0,
      "learning_rate": 0.00013583609198706813,
      "loss": 5.0856,
      "step": 6689
    },
    {
      "epoch": 0.7671138630890952,
      "grad_norm": 0.0,
      "learning_rate": 0.00013570892019255769,
      "loss": 4.6124,
      "step": 6690
    },
    {
      "epoch": 0.767228528838436,
      "grad_norm": 0.0,
      "learning_rate": 0.00013558179865195394,
      "loss": 4.8867,
      "step": 6691
    },
    {
      "epoch": 0.7673431945877767,
      "grad_norm": 0.0,
      "learning_rate": 0.00013545472738279147,
      "loss": 4.8161,
      "step": 6692
    },
    {
      "epoch": 0.7674578603371173,
      "grad_norm": 0.0,
      "learning_rate": 0.00013532770640259706,
      "loss": 4.7534,
      "step": 6693
    },
    {
      "epoch": 0.767572526086458,
      "grad_norm": 0.0,
      "learning_rate": 0.00013520073572889044,
      "loss": 4.9643,
      "step": 6694
    },
    {
      "epoch": 0.7676871918357987,
      "grad_norm": 0.0,
      "learning_rate": 0.00013507381537918554,
      "loss": 4.9709,
      "step": 6695
    },
    {
      "epoch": 0.7678018575851393,
      "grad_norm": 0.0,
      "learning_rate": 0.00013494694537098792,
      "loss": 4.8467,
      "step": 6696
    },
    {
      "epoch": 0.76791652333448,
      "grad_norm": 0.0,
      "learning_rate": 0.00013482012572179743,
      "loss": 4.9231,
      "step": 6697
    },
    {
      "epoch": 0.7680311890838206,
      "grad_norm": 0.0,
      "learning_rate": 0.0001346933564491061,
      "loss": 4.7813,
      "step": 6698
    },
    {
      "epoch": 0.7681458548331613,
      "grad_norm": 0.0,
      "learning_rate": 0.0001345666375703994,
      "loss": 5.0538,
      "step": 6699
    },
    {
      "epoch": 0.768260520582502,
      "grad_norm": 0.0,
      "learning_rate": 0.0001344399691031558,
      "loss": 5.2633,
      "step": 6700
    },
    {
      "epoch": 0.7683751863318427,
      "grad_norm": 0.0,
      "learning_rate": 0.00013431335106484673,
      "loss": 4.9624,
      "step": 6701
    },
    {
      "epoch": 0.7684898520811834,
      "grad_norm": 0.0,
      "learning_rate": 0.00013418678347293706,
      "loss": 4.9174,
      "step": 6702
    },
    {
      "epoch": 0.768604517830524,
      "grad_norm": 0.0,
      "learning_rate": 0.00013406026634488378,
      "loss": 5.1466,
      "step": 6703
    },
    {
      "epoch": 0.7687191835798647,
      "grad_norm": 0.0,
      "learning_rate": 0.00013393379969813817,
      "loss": 5.1124,
      "step": 6704
    },
    {
      "epoch": 0.7688338493292054,
      "grad_norm": 0.0,
      "learning_rate": 0.00013380738355014344,
      "loss": 5.0826,
      "step": 6705
    },
    {
      "epoch": 0.768948515078546,
      "grad_norm": 0.0,
      "learning_rate": 0.00013368101791833638,
      "loss": 5.1477,
      "step": 6706
    },
    {
      "epoch": 0.7690631808278867,
      "grad_norm": 0.0,
      "learning_rate": 0.0001335547028201468,
      "loss": 4.7601,
      "step": 6707
    },
    {
      "epoch": 0.7691778465772274,
      "grad_norm": 0.0,
      "learning_rate": 0.00013342843827299745,
      "loss": 5.3662,
      "step": 6708
    },
    {
      "epoch": 0.769292512326568,
      "grad_norm": 0.0,
      "learning_rate": 0.00013330222429430404,
      "loss": 4.9913,
      "step": 6709
    },
    {
      "epoch": 0.7694071780759087,
      "grad_norm": 0.0,
      "learning_rate": 0.00013317606090147564,
      "loss": 4.9854,
      "step": 6710
    },
    {
      "epoch": 0.7695218438252494,
      "grad_norm": 0.0,
      "learning_rate": 0.00013304994811191357,
      "loss": 5.0125,
      "step": 6711
    },
    {
      "epoch": 0.7696365095745901,
      "grad_norm": 0.0,
      "learning_rate": 0.00013292388594301333,
      "loss": 5.0104,
      "step": 6712
    },
    {
      "epoch": 0.7697511753239308,
      "grad_norm": 0.0,
      "learning_rate": 0.00013279787441216223,
      "loss": 5.0252,
      "step": 6713
    },
    {
      "epoch": 0.7698658410732714,
      "grad_norm": 0.0,
      "learning_rate": 0.00013267191353674146,
      "loss": 4.8229,
      "step": 6714
    },
    {
      "epoch": 0.7699805068226121,
      "grad_norm": 0.0,
      "learning_rate": 0.00013254600333412504,
      "loss": 5.0503,
      "step": 6715
    },
    {
      "epoch": 0.7700951725719528,
      "grad_norm": 0.0,
      "learning_rate": 0.00013242014382167935,
      "loss": 5.0735,
      "step": 6716
    },
    {
      "epoch": 0.7702098383212934,
      "grad_norm": 0.0,
      "learning_rate": 0.00013229433501676493,
      "loss": 5.1122,
      "step": 6717
    },
    {
      "epoch": 0.7703245040706341,
      "grad_norm": 0.0,
      "learning_rate": 0.00013216857693673417,
      "loss": 4.8503,
      "step": 6718
    },
    {
      "epoch": 0.7704391698199747,
      "grad_norm": 0.0,
      "learning_rate": 0.00013204286959893355,
      "loss": 5.0337,
      "step": 6719
    },
    {
      "epoch": 0.7705538355693154,
      "grad_norm": 0.0,
      "learning_rate": 0.00013191721302070156,
      "loss": 5.0072,
      "step": 6720
    },
    {
      "epoch": 0.7706685013186562,
      "grad_norm": 0.0,
      "learning_rate": 0.00013179160721937032,
      "loss": 4.9603,
      "step": 6721
    },
    {
      "epoch": 0.7707831670679968,
      "grad_norm": 0.0,
      "learning_rate": 0.0001316660522122647,
      "loss": 4.8044,
      "step": 6722
    },
    {
      "epoch": 0.7708978328173375,
      "grad_norm": 0.0,
      "learning_rate": 0.00013154054801670263,
      "loss": 4.8946,
      "step": 6723
    },
    {
      "epoch": 0.7710124985666781,
      "grad_norm": 0.0,
      "learning_rate": 0.00013141509464999519,
      "loss": 4.8908,
      "step": 6724
    },
    {
      "epoch": 0.7711271643160188,
      "grad_norm": 0.0,
      "learning_rate": 0.0001312896921294458,
      "loss": 4.9523,
      "step": 6725
    },
    {
      "epoch": 0.7712418300653595,
      "grad_norm": 0.0,
      "learning_rate": 0.00013116434047235205,
      "loss": 5.0409,
      "step": 6726
    },
    {
      "epoch": 0.7713564958147001,
      "grad_norm": 0.0,
      "learning_rate": 0.0001310390396960032,
      "loss": 4.9994,
      "step": 6727
    },
    {
      "epoch": 0.7714711615640408,
      "grad_norm": 0.0,
      "learning_rate": 0.00013091378981768234,
      "loss": 5.0518,
      "step": 6728
    },
    {
      "epoch": 0.7715858273133815,
      "grad_norm": 0.0,
      "learning_rate": 0.00013078859085466533,
      "loss": 5.0007,
      "step": 6729
    },
    {
      "epoch": 0.7717004930627221,
      "grad_norm": 0.0,
      "learning_rate": 0.00013066344282422091,
      "loss": 5.0234,
      "step": 6730
    },
    {
      "epoch": 0.7718151588120629,
      "grad_norm": 0.0,
      "learning_rate": 0.00013053834574361094,
      "loss": 5.1894,
      "step": 6731
    },
    {
      "epoch": 0.7719298245614035,
      "grad_norm": 0.0,
      "learning_rate": 0.0001304132996300903,
      "loss": 4.918,
      "step": 6732
    },
    {
      "epoch": 0.7720444903107442,
      "grad_norm": 0.0,
      "learning_rate": 0.00013028830450090634,
      "loss": 5.1261,
      "step": 6733
    },
    {
      "epoch": 0.7721591560600849,
      "grad_norm": 0.0,
      "learning_rate": 0.00013016336037330006,
      "loss": 4.8663,
      "step": 6734
    },
    {
      "epoch": 0.7722738218094255,
      "grad_norm": 0.0,
      "learning_rate": 0.000130038467264505,
      "loss": 4.9726,
      "step": 6735
    },
    {
      "epoch": 0.7723884875587662,
      "grad_norm": 0.0,
      "learning_rate": 0.00012991362519174782,
      "loss": 4.9548,
      "step": 6736
    },
    {
      "epoch": 0.7725031533081068,
      "grad_norm": 0.0,
      "learning_rate": 0.00012978883417224824,
      "loss": 4.9353,
      "step": 6737
    },
    {
      "epoch": 0.7726178190574475,
      "grad_norm": 0.0,
      "learning_rate": 0.0001296640942232184,
      "loss": 4.985,
      "step": 6738
    },
    {
      "epoch": 0.7727324848067882,
      "grad_norm": 0.0,
      "learning_rate": 0.00012953940536186432,
      "loss": 5.2854,
      "step": 6739
    },
    {
      "epoch": 0.7728471505561288,
      "grad_norm": 0.0,
      "learning_rate": 0.00012941476760538394,
      "loss": 4.7931,
      "step": 6740
    },
    {
      "epoch": 0.7729618163054696,
      "grad_norm": 0.0,
      "learning_rate": 0.00012929018097096917,
      "loss": 5.1414,
      "step": 6741
    },
    {
      "epoch": 0.7730764820548103,
      "grad_norm": 0.0,
      "learning_rate": 0.00012916564547580398,
      "loss": 5.1155,
      "step": 6742
    },
    {
      "epoch": 0.7731911478041509,
      "grad_norm": 0.0,
      "learning_rate": 0.00012904116113706586,
      "loss": 4.8583,
      "step": 6743
    },
    {
      "epoch": 0.7733058135534916,
      "grad_norm": 0.0,
      "learning_rate": 0.00012891672797192506,
      "loss": 5.0714,
      "step": 6744
    },
    {
      "epoch": 0.7734204793028322,
      "grad_norm": 0.0,
      "learning_rate": 0.00012879234599754444,
      "loss": 5.2328,
      "step": 6745
    },
    {
      "epoch": 0.7735351450521729,
      "grad_norm": 0.0,
      "learning_rate": 0.0001286680152310806,
      "loss": 4.9456,
      "step": 6746
    },
    {
      "epoch": 0.7736498108015136,
      "grad_norm": 0.0,
      "learning_rate": 0.00012854373568968217,
      "loss": 5.029,
      "step": 6747
    },
    {
      "epoch": 0.7737644765508542,
      "grad_norm": 0.0,
      "learning_rate": 0.0001284195073904916,
      "loss": 5.1293,
      "step": 6748
    },
    {
      "epoch": 0.7738791423001949,
      "grad_norm": 0.0,
      "learning_rate": 0.0001282953303506434,
      "loss": 4.9809,
      "step": 6749
    },
    {
      "epoch": 0.7739938080495357,
      "grad_norm": 0.0,
      "learning_rate": 0.00012817120458726562,
      "loss": 5.0984,
      "step": 6750
    },
    {
      "epoch": 0.7741084737988763,
      "grad_norm": 0.0,
      "learning_rate": 0.000128047130117479,
      "loss": 5.0752,
      "step": 6751
    },
    {
      "epoch": 0.774223139548217,
      "grad_norm": 0.0,
      "learning_rate": 0.00012792310695839725,
      "loss": 4.8272,
      "step": 6752
    },
    {
      "epoch": 0.7743378052975576,
      "grad_norm": 0.0,
      "learning_rate": 0.00012779913512712718,
      "loss": 5.0317,
      "step": 6753
    },
    {
      "epoch": 0.7744524710468983,
      "grad_norm": 0.0,
      "learning_rate": 0.00012767521464076802,
      "loss": 4.8563,
      "step": 6754
    },
    {
      "epoch": 0.774567136796239,
      "grad_norm": 0.0,
      "learning_rate": 0.00012755134551641238,
      "loss": 4.9569,
      "step": 6755
    },
    {
      "epoch": 0.7746818025455796,
      "grad_norm": 0.0,
      "learning_rate": 0.00012742752777114563,
      "loss": 5.0265,
      "step": 6756
    },
    {
      "epoch": 0.7747964682949203,
      "grad_norm": 0.0,
      "learning_rate": 0.00012730376142204618,
      "loss": 5.019,
      "step": 6757
    },
    {
      "epoch": 0.7749111340442609,
      "grad_norm": 0.0,
      "learning_rate": 0.00012718004648618508,
      "loss": 4.9964,
      "step": 6758
    },
    {
      "epoch": 0.7750257997936016,
      "grad_norm": 0.0,
      "learning_rate": 0.0001270563829806267,
      "loss": 5.3249,
      "step": 6759
    },
    {
      "epoch": 0.7751404655429424,
      "grad_norm": 0.0,
      "learning_rate": 0.00012693277092242752,
      "loss": 4.973,
      "step": 6760
    },
    {
      "epoch": 0.775255131292283,
      "grad_norm": 0.0,
      "learning_rate": 0.00012680921032863818,
      "loss": 5.1937,
      "step": 6761
    },
    {
      "epoch": 0.7753697970416237,
      "grad_norm": 0.0,
      "learning_rate": 0.00012668570121630087,
      "loss": 4.9079,
      "step": 6762
    },
    {
      "epoch": 0.7754844627909644,
      "grad_norm": 0.0,
      "learning_rate": 0.00012656224360245192,
      "loss": 5.2377,
      "step": 6763
    },
    {
      "epoch": 0.775599128540305,
      "grad_norm": 0.0,
      "learning_rate": 0.00012643883750411961,
      "loss": 4.9855,
      "step": 6764
    },
    {
      "epoch": 0.7757137942896457,
      "grad_norm": 0.0,
      "learning_rate": 0.0001263154829383252,
      "loss": 5.0988,
      "step": 6765
    },
    {
      "epoch": 0.7758284600389863,
      "grad_norm": 0.0,
      "learning_rate": 0.00012619217992208365,
      "loss": 5.2112,
      "step": 6766
    },
    {
      "epoch": 0.775943125788327,
      "grad_norm": 0.0,
      "learning_rate": 0.00012606892847240179,
      "loss": 5.1676,
      "step": 6767
    },
    {
      "epoch": 0.7760577915376677,
      "grad_norm": 0.0,
      "learning_rate": 0.0001259457286062802,
      "loss": 4.8099,
      "step": 6768
    },
    {
      "epoch": 0.7761724572870083,
      "grad_norm": 0.0,
      "learning_rate": 0.00012582258034071157,
      "loss": 4.9953,
      "step": 6769
    },
    {
      "epoch": 0.7762871230363491,
      "grad_norm": 0.0,
      "learning_rate": 0.0001256994836926823,
      "loss": 4.982,
      "step": 6770
    },
    {
      "epoch": 0.7764017887856897,
      "grad_norm": 0.0,
      "learning_rate": 0.0001255764386791709,
      "loss": 5.3545,
      "step": 6771
    },
    {
      "epoch": 0.7765164545350304,
      "grad_norm": 0.0,
      "learning_rate": 0.0001254534453171491,
      "loss": 4.9133,
      "step": 6772
    },
    {
      "epoch": 0.7766311202843711,
      "grad_norm": 0.0,
      "learning_rate": 0.00012533050362358172,
      "loss": 5.1689,
      "step": 6773
    },
    {
      "epoch": 0.7767457860337117,
      "grad_norm": 0.0,
      "learning_rate": 0.00012520761361542581,
      "loss": 5.1962,
      "step": 6774
    },
    {
      "epoch": 0.7768604517830524,
      "grad_norm": 0.0,
      "learning_rate": 0.00012508477530963222,
      "loss": 5.1348,
      "step": 6775
    },
    {
      "epoch": 0.7769751175323931,
      "grad_norm": 0.0,
      "learning_rate": 0.00012496198872314373,
      "loss": 4.9339,
      "step": 6776
    },
    {
      "epoch": 0.7770897832817337,
      "grad_norm": 0.0,
      "learning_rate": 0.0001248392538728966,
      "loss": 5.1001,
      "step": 6777
    },
    {
      "epoch": 0.7772044490310744,
      "grad_norm": 0.0,
      "learning_rate": 0.00012471657077581973,
      "loss": 4.8249,
      "step": 6778
    },
    {
      "epoch": 0.777319114780415,
      "grad_norm": 0.0,
      "learning_rate": 0.00012459393944883485,
      "loss": 5.1637,
      "step": 6779
    },
    {
      "epoch": 0.7774337805297558,
      "grad_norm": 0.0,
      "learning_rate": 0.00012447135990885675,
      "loss": 5.2411,
      "step": 6780
    },
    {
      "epoch": 0.7775484462790965,
      "grad_norm": 0.0,
      "learning_rate": 0.00012434883217279303,
      "loss": 5.0158,
      "step": 6781
    },
    {
      "epoch": 0.7776631120284371,
      "grad_norm": 0.0,
      "learning_rate": 0.00012422635625754355,
      "loss": 5.0404,
      "step": 6782
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 0.0,
      "learning_rate": 0.00012410393218000216,
      "loss": 4.8779,
      "step": 6783
    },
    {
      "epoch": 0.7778924435271185,
      "grad_norm": 0.0,
      "learning_rate": 0.00012398155995705452,
      "loss": 5.1662,
      "step": 6784
    },
    {
      "epoch": 0.7780071092764591,
      "grad_norm": 0.0,
      "learning_rate": 0.0001238592396055797,
      "loss": 4.9387,
      "step": 6785
    },
    {
      "epoch": 0.7781217750257998,
      "grad_norm": 0.0,
      "learning_rate": 0.00012373697114244955,
      "loss": 5.0659,
      "step": 6786
    },
    {
      "epoch": 0.7782364407751404,
      "grad_norm": 0.0,
      "learning_rate": 0.00012361475458452822,
      "loss": 4.9329,
      "step": 6787
    },
    {
      "epoch": 0.7783511065244811,
      "grad_norm": 0.0,
      "learning_rate": 0.00012349258994867385,
      "loss": 5.1675,
      "step": 6788
    },
    {
      "epoch": 0.7784657722738219,
      "grad_norm": 0.0,
      "learning_rate": 0.000123370477251736,
      "loss": 4.9306,
      "step": 6789
    },
    {
      "epoch": 0.7785804380231625,
      "grad_norm": 0.0,
      "learning_rate": 0.00012324841651055845,
      "loss": 5.2311,
      "step": 6790
    },
    {
      "epoch": 0.7786951037725032,
      "grad_norm": 0.0,
      "learning_rate": 0.0001231264077419766,
      "loss": 4.6393,
      "step": 6791
    },
    {
      "epoch": 0.7788097695218438,
      "grad_norm": 0.0,
      "learning_rate": 0.00012300445096281976,
      "loss": 4.9658,
      "step": 6792
    },
    {
      "epoch": 0.7789244352711845,
      "grad_norm": 0.0,
      "learning_rate": 0.0001228825461899091,
      "loss": 5.1213,
      "step": 6793
    },
    {
      "epoch": 0.7790391010205252,
      "grad_norm": 0.0,
      "learning_rate": 0.00012276069344005928,
      "loss": 5.003,
      "step": 6794
    },
    {
      "epoch": 0.7791537667698658,
      "grad_norm": 0.0,
      "learning_rate": 0.0001226388927300776,
      "loss": 5.1252,
      "step": 6795
    },
    {
      "epoch": 0.7792684325192065,
      "grad_norm": 0.0,
      "learning_rate": 0.00012251714407676375,
      "loss": 5.0786,
      "step": 6796
    },
    {
      "epoch": 0.7793830982685472,
      "grad_norm": 0.0,
      "learning_rate": 0.0001223954474969113,
      "loss": 4.8405,
      "step": 6797
    },
    {
      "epoch": 0.7794977640178878,
      "grad_norm": 0.0,
      "learning_rate": 0.00012227380300730545,
      "loss": 5.0993,
      "step": 6798
    },
    {
      "epoch": 0.7796124297672286,
      "grad_norm": 0.0,
      "learning_rate": 0.00012215221062472487,
      "loss": 4.8416,
      "step": 6799
    },
    {
      "epoch": 0.7797270955165692,
      "grad_norm": 0.0,
      "learning_rate": 0.00012203067036594099,
      "loss": 5.3004,
      "step": 6800
    },
    {
      "epoch": 0.7798417612659099,
      "grad_norm": 0.0,
      "learning_rate": 0.0001219091822477179,
      "loss": 5.1615,
      "step": 6801
    },
    {
      "epoch": 0.7799564270152506,
      "grad_norm": 0.0,
      "learning_rate": 0.00012178774628681263,
      "loss": 4.9022,
      "step": 6802
    },
    {
      "epoch": 0.7800710927645912,
      "grad_norm": 0.0,
      "learning_rate": 0.00012166636249997502,
      "loss": 5.1669,
      "step": 6803
    },
    {
      "epoch": 0.7801857585139319,
      "grad_norm": 0.0,
      "learning_rate": 0.0001215450309039475,
      "loss": 5.2349,
      "step": 6804
    },
    {
      "epoch": 0.7803004242632725,
      "grad_norm": 0.0,
      "learning_rate": 0.00012142375151546542,
      "loss": 5.1658,
      "step": 6805
    },
    {
      "epoch": 0.7804150900126132,
      "grad_norm": 0.0,
      "learning_rate": 0.0001213025243512571,
      "loss": 4.9372,
      "step": 6806
    },
    {
      "epoch": 0.7805297557619539,
      "grad_norm": 0.0,
      "learning_rate": 0.00012118134942804342,
      "loss": 4.9188,
      "step": 6807
    },
    {
      "epoch": 0.7806444215112945,
      "grad_norm": 0.0,
      "learning_rate": 0.00012106022676253836,
      "loss": 4.9757,
      "step": 6808
    },
    {
      "epoch": 0.7807590872606353,
      "grad_norm": 0.0,
      "learning_rate": 0.000120939156371448,
      "loss": 4.8492,
      "step": 6809
    },
    {
      "epoch": 0.780873753009976,
      "grad_norm": 0.0,
      "learning_rate": 0.00012081813827147234,
      "loss": 4.921,
      "step": 6810
    },
    {
      "epoch": 0.7809884187593166,
      "grad_norm": 0.0,
      "learning_rate": 0.00012069717247930287,
      "loss": 4.9511,
      "step": 6811
    },
    {
      "epoch": 0.7811030845086573,
      "grad_norm": 0.0,
      "learning_rate": 0.00012057625901162516,
      "loss": 4.8456,
      "step": 6812
    },
    {
      "epoch": 0.7812177502579979,
      "grad_norm": 0.0,
      "learning_rate": 0.00012045539788511622,
      "loss": 5.0258,
      "step": 6813
    },
    {
      "epoch": 0.7813324160073386,
      "grad_norm": 0.0,
      "learning_rate": 0.00012033458911644725,
      "loss": 4.7897,
      "step": 6814
    },
    {
      "epoch": 0.7814470817566793,
      "grad_norm": 0.0,
      "learning_rate": 0.0001202138327222812,
      "loss": 4.8355,
      "step": 6815
    },
    {
      "epoch": 0.7815617475060199,
      "grad_norm": 0.0,
      "learning_rate": 0.00012009312871927382,
      "loss": 4.9429,
      "step": 6816
    },
    {
      "epoch": 0.7816764132553606,
      "grad_norm": 0.0,
      "learning_rate": 0.00011997247712407443,
      "loss": 4.8002,
      "step": 6817
    },
    {
      "epoch": 0.7817910790047014,
      "grad_norm": 0.0,
      "learning_rate": 0.0001198518779533241,
      "loss": 4.9904,
      "step": 6818
    },
    {
      "epoch": 0.781905744754042,
      "grad_norm": 0.0,
      "learning_rate": 0.00011973133122365776,
      "loss": 4.9066,
      "step": 6819
    },
    {
      "epoch": 0.7820204105033827,
      "grad_norm": 0.0,
      "learning_rate": 0.00011961083695170215,
      "loss": 5.1006,
      "step": 6820
    },
    {
      "epoch": 0.7821350762527233,
      "grad_norm": 0.0,
      "learning_rate": 0.00011949039515407721,
      "loss": 5.2189,
      "step": 6821
    },
    {
      "epoch": 0.782249742002064,
      "grad_norm": 0.0,
      "learning_rate": 0.0001193700058473956,
      "loss": 4.8963,
      "step": 6822
    },
    {
      "epoch": 0.7823644077514047,
      "grad_norm": 0.0,
      "learning_rate": 0.00011924966904826282,
      "loss": 4.9982,
      "step": 6823
    },
    {
      "epoch": 0.7824790735007453,
      "grad_norm": 0.0,
      "learning_rate": 0.0001191293847732771,
      "loss": 4.9391,
      "step": 6824
    },
    {
      "epoch": 0.782593739250086,
      "grad_norm": 0.0,
      "learning_rate": 0.00011900915303902911,
      "loss": 5.1429,
      "step": 6825
    },
    {
      "epoch": 0.7827084049994266,
      "grad_norm": 0.0,
      "learning_rate": 0.00011888897386210265,
      "loss": 5.0499,
      "step": 6826
    },
    {
      "epoch": 0.7828230707487673,
      "grad_norm": 0.0,
      "learning_rate": 0.00011876884725907415,
      "loss": 4.97,
      "step": 6827
    },
    {
      "epoch": 0.782937736498108,
      "grad_norm": 0.0,
      "learning_rate": 0.00011864877324651278,
      "loss": 4.9261,
      "step": 6828
    },
    {
      "epoch": 0.7830524022474487,
      "grad_norm": 0.0,
      "learning_rate": 0.00011852875184098049,
      "loss": 4.8457,
      "step": 6829
    },
    {
      "epoch": 0.7831670679967894,
      "grad_norm": 0.0,
      "learning_rate": 0.00011840878305903211,
      "loss": 4.9109,
      "step": 6830
    },
    {
      "epoch": 0.7832817337461301,
      "grad_norm": 0.0,
      "learning_rate": 0.00011828886691721449,
      "loss": 4.8532,
      "step": 6831
    },
    {
      "epoch": 0.7833963994954707,
      "grad_norm": 0.0,
      "learning_rate": 0.00011816900343206849,
      "loss": 5.1494,
      "step": 6832
    },
    {
      "epoch": 0.7835110652448114,
      "grad_norm": 0.0,
      "learning_rate": 0.00011804919262012635,
      "loss": 4.9355,
      "step": 6833
    },
    {
      "epoch": 0.783625730994152,
      "grad_norm": 0.0,
      "learning_rate": 0.00011792943449791428,
      "loss": 4.9427,
      "step": 6834
    },
    {
      "epoch": 0.7837403967434927,
      "grad_norm": 0.0,
      "learning_rate": 0.00011780972908195022,
      "loss": 5.0091,
      "step": 6835
    },
    {
      "epoch": 0.7838550624928334,
      "grad_norm": 0.0,
      "learning_rate": 0.00011769007638874535,
      "loss": 4.9805,
      "step": 6836
    },
    {
      "epoch": 0.783969728242174,
      "grad_norm": 0.0,
      "learning_rate": 0.00011757047643480365,
      "loss": 4.7962,
      "step": 6837
    },
    {
      "epoch": 0.7840843939915147,
      "grad_norm": 0.0,
      "learning_rate": 0.00011745092923662123,
      "loss": 5.1398,
      "step": 6838
    },
    {
      "epoch": 0.7841990597408554,
      "grad_norm": 0.0,
      "learning_rate": 0.00011733143481068784,
      "loss": 4.9225,
      "step": 6839
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.0,
      "learning_rate": 0.00011721199317348505,
      "loss": 4.9791,
      "step": 6840
    },
    {
      "epoch": 0.7844283912395368,
      "grad_norm": 0.0,
      "learning_rate": 0.00011709260434148797,
      "loss": 4.8883,
      "step": 6841
    },
    {
      "epoch": 0.7845430569888774,
      "grad_norm": 0.0,
      "learning_rate": 0.00011697326833116362,
      "loss": 4.9561,
      "step": 6842
    },
    {
      "epoch": 0.7846577227382181,
      "grad_norm": 0.0,
      "learning_rate": 0.00011685398515897234,
      "loss": 5.2122,
      "step": 6843
    },
    {
      "epoch": 0.7847723884875588,
      "grad_norm": 0.0,
      "learning_rate": 0.00011673475484136694,
      "loss": 5.0827,
      "step": 6844
    },
    {
      "epoch": 0.7848870542368994,
      "grad_norm": 0.0,
      "learning_rate": 0.00011661557739479291,
      "loss": 5.1822,
      "step": 6845
    },
    {
      "epoch": 0.7850017199862401,
      "grad_norm": 0.0,
      "learning_rate": 0.00011649645283568879,
      "loss": 5.0458,
      "step": 6846
    },
    {
      "epoch": 0.7851163857355807,
      "grad_norm": 0.0,
      "learning_rate": 0.00011637738118048509,
      "loss": 4.9171,
      "step": 6847
    },
    {
      "epoch": 0.7852310514849214,
      "grad_norm": 0.0,
      "learning_rate": 0.00011625836244560566,
      "loss": 4.9555,
      "step": 6848
    },
    {
      "epoch": 0.7853457172342622,
      "grad_norm": 0.0,
      "learning_rate": 0.00011613939664746695,
      "loss": 4.9709,
      "step": 6849
    },
    {
      "epoch": 0.7854603829836028,
      "grad_norm": 0.0,
      "learning_rate": 0.00011602048380247793,
      "loss": 5.1175,
      "step": 6850
    },
    {
      "epoch": 0.7855750487329435,
      "grad_norm": 0.0,
      "learning_rate": 0.00011590162392704042,
      "loss": 4.9277,
      "step": 6851
    },
    {
      "epoch": 0.7856897144822842,
      "grad_norm": 0.0,
      "learning_rate": 0.00011578281703754901,
      "loss": 5.0665,
      "step": 6852
    },
    {
      "epoch": 0.7858043802316248,
      "grad_norm": 0.0,
      "learning_rate": 0.00011566406315039039,
      "loss": 5.0783,
      "step": 6853
    },
    {
      "epoch": 0.7859190459809655,
      "grad_norm": 0.0,
      "learning_rate": 0.00011554536228194501,
      "loss": 5.2223,
      "step": 6854
    },
    {
      "epoch": 0.7860337117303061,
      "grad_norm": 0.0,
      "learning_rate": 0.00011542671444858493,
      "loss": 4.9638,
      "step": 6855
    },
    {
      "epoch": 0.7861483774796468,
      "grad_norm": 0.0,
      "learning_rate": 0.00011530811966667546,
      "loss": 4.845,
      "step": 6856
    },
    {
      "epoch": 0.7862630432289875,
      "grad_norm": 0.0,
      "learning_rate": 0.00011518957795257456,
      "loss": 4.9635,
      "step": 6857
    },
    {
      "epoch": 0.7863777089783281,
      "grad_norm": 0.0,
      "learning_rate": 0.00011507108932263282,
      "loss": 5.1065,
      "step": 6858
    },
    {
      "epoch": 0.7864923747276689,
      "grad_norm": 0.0,
      "learning_rate": 0.00011495265379319353,
      "loss": 4.7942,
      "step": 6859
    },
    {
      "epoch": 0.7866070404770095,
      "grad_norm": 0.0,
      "learning_rate": 0.00011483427138059225,
      "loss": 4.9865,
      "step": 6860
    },
    {
      "epoch": 0.7867217062263502,
      "grad_norm": 0.0,
      "learning_rate": 0.00011471594210115814,
      "loss": 4.9935,
      "step": 6861
    },
    {
      "epoch": 0.7868363719756909,
      "grad_norm": 0.0,
      "learning_rate": 0.00011459766597121188,
      "loss": 5.0459,
      "step": 6862
    },
    {
      "epoch": 0.7869510377250315,
      "grad_norm": 0.0,
      "learning_rate": 0.00011447944300706801,
      "loss": 5.0738,
      "step": 6863
    },
    {
      "epoch": 0.7870657034743722,
      "grad_norm": 0.0,
      "learning_rate": 0.0001143612732250327,
      "loss": 5.1115,
      "step": 6864
    },
    {
      "epoch": 0.7871803692237129,
      "grad_norm": 0.0,
      "learning_rate": 0.00011424315664140538,
      "loss": 4.8349,
      "step": 6865
    },
    {
      "epoch": 0.7872950349730535,
      "grad_norm": 0.0,
      "learning_rate": 0.00011412509327247806,
      "loss": 4.839,
      "step": 6866
    },
    {
      "epoch": 0.7874097007223942,
      "grad_norm": 0.0,
      "learning_rate": 0.00011400708313453492,
      "loss": 5.112,
      "step": 6867
    },
    {
      "epoch": 0.7875243664717348,
      "grad_norm": 0.0,
      "learning_rate": 0.00011388912624385385,
      "loss": 5.1724,
      "step": 6868
    },
    {
      "epoch": 0.7876390322210756,
      "grad_norm": 0.0,
      "learning_rate": 0.00011377122261670422,
      "loss": 4.774,
      "step": 6869
    },
    {
      "epoch": 0.7877536979704163,
      "grad_norm": 0.0,
      "learning_rate": 0.00011365337226934886,
      "loss": 5.0063,
      "step": 6870
    },
    {
      "epoch": 0.7878683637197569,
      "grad_norm": 0.0,
      "learning_rate": 0.00011353557521804286,
      "loss": 4.896,
      "step": 6871
    },
    {
      "epoch": 0.7879830294690976,
      "grad_norm": 0.0,
      "learning_rate": 0.00011341783147903409,
      "loss": 5.0546,
      "step": 6872
    },
    {
      "epoch": 0.7880976952184382,
      "grad_norm": 0.0,
      "learning_rate": 0.00011330014106856315,
      "loss": 4.8602,
      "step": 6873
    },
    {
      "epoch": 0.7882123609677789,
      "grad_norm": 0.0,
      "learning_rate": 0.00011318250400286325,
      "loss": 5.148,
      "step": 6874
    },
    {
      "epoch": 0.7883270267171196,
      "grad_norm": 0.0,
      "learning_rate": 0.00011306492029815989,
      "loss": 5.066,
      "step": 6875
    },
    {
      "epoch": 0.7884416924664602,
      "grad_norm": 0.0,
      "learning_rate": 0.00011294738997067167,
      "loss": 4.7121,
      "step": 6876
    },
    {
      "epoch": 0.788556358215801,
      "grad_norm": 0.0,
      "learning_rate": 0.0001128299130366097,
      "loss": 5.1502,
      "step": 6877
    },
    {
      "epoch": 0.7886710239651417,
      "grad_norm": 0.0,
      "learning_rate": 0.0001127124895121776,
      "loss": 4.9175,
      "step": 6878
    },
    {
      "epoch": 0.7887856897144823,
      "grad_norm": 0.0,
      "learning_rate": 0.00011259511941357179,
      "loss": 5.1865,
      "step": 6879
    },
    {
      "epoch": 0.788900355463823,
      "grad_norm": 0.0,
      "learning_rate": 0.00011247780275698116,
      "loss": 5.0632,
      "step": 6880
    },
    {
      "epoch": 0.7890150212131636,
      "grad_norm": 0.0,
      "learning_rate": 0.0001123605395585875,
      "loss": 5.0377,
      "step": 6881
    },
    {
      "epoch": 0.7891296869625043,
      "grad_norm": 0.0,
      "learning_rate": 0.00011224332983456456,
      "loss": 4.8598,
      "step": 6882
    },
    {
      "epoch": 0.789244352711845,
      "grad_norm": 0.0,
      "learning_rate": 0.00011212617360107982,
      "loss": 5.1165,
      "step": 6883
    },
    {
      "epoch": 0.7893590184611856,
      "grad_norm": 0.0,
      "learning_rate": 0.0001120090708742921,
      "loss": 4.9036,
      "step": 6884
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 0.0,
      "learning_rate": 0.00011189202167035417,
      "loss": 4.9255,
      "step": 6885
    },
    {
      "epoch": 0.789588349959867,
      "grad_norm": 0.0,
      "learning_rate": 0.0001117750260054103,
      "loss": 5.0584,
      "step": 6886
    },
    {
      "epoch": 0.7897030157092076,
      "grad_norm": 0.0,
      "learning_rate": 0.00011165808389559771,
      "loss": 4.9071,
      "step": 6887
    },
    {
      "epoch": 0.7898176814585484,
      "grad_norm": 0.0,
      "learning_rate": 0.00011154119535704676,
      "loss": 4.9433,
      "step": 6888
    },
    {
      "epoch": 0.789932347207889,
      "grad_norm": 0.0,
      "learning_rate": 0.00011142436040587945,
      "loss": 4.9494,
      "step": 6889
    },
    {
      "epoch": 0.7900470129572297,
      "grad_norm": 0.0,
      "learning_rate": 0.00011130757905821155,
      "loss": 4.947,
      "step": 6890
    },
    {
      "epoch": 0.7901616787065704,
      "grad_norm": 0.0,
      "learning_rate": 0.0001111908513301504,
      "loss": 5.0718,
      "step": 6891
    },
    {
      "epoch": 0.790276344455911,
      "grad_norm": 0.0,
      "learning_rate": 0.00011107417723779645,
      "loss": 5.1575,
      "step": 6892
    },
    {
      "epoch": 0.7903910102052517,
      "grad_norm": 0.0,
      "learning_rate": 0.00011095755679724271,
      "loss": 4.9565,
      "step": 6893
    },
    {
      "epoch": 0.7905056759545923,
      "grad_norm": 0.0,
      "learning_rate": 0.00011084099002457472,
      "loss": 5.0498,
      "step": 6894
    },
    {
      "epoch": 0.790620341703933,
      "grad_norm": 0.0,
      "learning_rate": 0.00011072447693587082,
      "loss": 5.1085,
      "step": 6895
    },
    {
      "epoch": 0.7907350074532737,
      "grad_norm": 0.0,
      "learning_rate": 0.00011060801754720144,
      "loss": 4.8479,
      "step": 6896
    },
    {
      "epoch": 0.7908496732026143,
      "grad_norm": 0.0,
      "learning_rate": 0.0001104916118746301,
      "loss": 5.2016,
      "step": 6897
    },
    {
      "epoch": 0.7909643389519551,
      "grad_norm": 0.0,
      "learning_rate": 0.00011037525993421274,
      "loss": 5.0525,
      "step": 6898
    },
    {
      "epoch": 0.7910790047012958,
      "grad_norm": 0.0,
      "learning_rate": 0.00011025896174199792,
      "loss": 4.898,
      "step": 6899
    },
    {
      "epoch": 0.7911936704506364,
      "grad_norm": 0.0,
      "learning_rate": 0.00011014271731402676,
      "loss": 5.2886,
      "step": 6900
    },
    {
      "epoch": 0.7913083361999771,
      "grad_norm": 0.0,
      "learning_rate": 0.00011002652666633291,
      "loss": 4.8372,
      "step": 6901
    },
    {
      "epoch": 0.7914230019493177,
      "grad_norm": 0.0,
      "learning_rate": 0.00010991038981494266,
      "loss": 4.9458,
      "step": 6902
    },
    {
      "epoch": 0.7915376676986584,
      "grad_norm": 0.0,
      "learning_rate": 0.00010979430677587506,
      "loss": 5.1395,
      "step": 6903
    },
    {
      "epoch": 0.7916523334479991,
      "grad_norm": 0.0,
      "learning_rate": 0.00010967827756514107,
      "loss": 4.9224,
      "step": 6904
    },
    {
      "epoch": 0.7917669991973397,
      "grad_norm": 0.0,
      "learning_rate": 0.00010956230219874532,
      "loss": 5.0721,
      "step": 6905
    },
    {
      "epoch": 0.7918816649466804,
      "grad_norm": 0.0,
      "learning_rate": 0.00010944638069268402,
      "loss": 5.1358,
      "step": 6906
    },
    {
      "epoch": 0.791996330696021,
      "grad_norm": 0.0,
      "learning_rate": 0.0001093305130629464,
      "loss": 4.8304,
      "step": 6907
    },
    {
      "epoch": 0.7921109964453618,
      "grad_norm": 0.0,
      "learning_rate": 0.00010921469932551434,
      "loss": 5.0866,
      "step": 6908
    },
    {
      "epoch": 0.7922256621947025,
      "grad_norm": 0.0,
      "learning_rate": 0.0001090989394963617,
      "loss": 5.1294,
      "step": 6909
    },
    {
      "epoch": 0.7923403279440431,
      "grad_norm": 0.0,
      "learning_rate": 0.00010898323359145596,
      "loss": 4.8573,
      "step": 6910
    },
    {
      "epoch": 0.7924549936933838,
      "grad_norm": 0.0,
      "learning_rate": 0.00010886758162675601,
      "loss": 5.0996,
      "step": 6911
    },
    {
      "epoch": 0.7925696594427245,
      "grad_norm": 0.0,
      "learning_rate": 0.00010875198361821425,
      "loss": 5.0905,
      "step": 6912
    },
    {
      "epoch": 0.7926843251920651,
      "grad_norm": 0.0,
      "learning_rate": 0.00010863643958177496,
      "loss": 4.5246,
      "step": 6913
    },
    {
      "epoch": 0.7927989909414058,
      "grad_norm": 0.0,
      "learning_rate": 0.00010852094953337526,
      "loss": 4.9423,
      "step": 6914
    },
    {
      "epoch": 0.7929136566907464,
      "grad_norm": 0.0,
      "learning_rate": 0.00010840551348894488,
      "loss": 4.8632,
      "step": 6915
    },
    {
      "epoch": 0.7930283224400871,
      "grad_norm": 0.0,
      "learning_rate": 0.00010829013146440598,
      "loss": 4.9409,
      "step": 6916
    },
    {
      "epoch": 0.7931429881894279,
      "grad_norm": 0.0,
      "learning_rate": 0.00010817480347567343,
      "loss": 5.1149,
      "step": 6917
    },
    {
      "epoch": 0.7932576539387685,
      "grad_norm": 0.0,
      "learning_rate": 0.00010805952953865421,
      "loss": 4.912,
      "step": 6918
    },
    {
      "epoch": 0.7933723196881092,
      "grad_norm": 0.0,
      "learning_rate": 0.00010794430966924859,
      "loss": 4.8923,
      "step": 6919
    },
    {
      "epoch": 0.7934869854374499,
      "grad_norm": 0.0,
      "learning_rate": 0.00010782914388334864,
      "loss": 4.9197,
      "step": 6920
    },
    {
      "epoch": 0.7936016511867905,
      "grad_norm": 0.0,
      "learning_rate": 0.00010771403219683936,
      "loss": 5.1625,
      "step": 6921
    },
    {
      "epoch": 0.7937163169361312,
      "grad_norm": 0.0,
      "learning_rate": 0.00010759897462559821,
      "loss": 5.0094,
      "step": 6922
    },
    {
      "epoch": 0.7938309826854718,
      "grad_norm": 0.0,
      "learning_rate": 0.00010748397118549527,
      "loss": 4.8913,
      "step": 6923
    },
    {
      "epoch": 0.7939456484348125,
      "grad_norm": 0.0,
      "learning_rate": 0.00010736902189239298,
      "loss": 5.153,
      "step": 6924
    },
    {
      "epoch": 0.7940603141841532,
      "grad_norm": 0.0,
      "learning_rate": 0.00010725412676214654,
      "loss": 5.3232,
      "step": 6925
    },
    {
      "epoch": 0.7941749799334938,
      "grad_norm": 0.0,
      "learning_rate": 0.00010713928581060334,
      "loss": 5.0757,
      "step": 6926
    },
    {
      "epoch": 0.7942896456828346,
      "grad_norm": 0.0,
      "learning_rate": 0.00010702449905360366,
      "loss": 5.1218,
      "step": 6927
    },
    {
      "epoch": 0.7944043114321752,
      "grad_norm": 0.0,
      "learning_rate": 0.00010690976650698001,
      "loss": 5.0833,
      "step": 6928
    },
    {
      "epoch": 0.7945189771815159,
      "grad_norm": 0.0,
      "learning_rate": 0.00010679508818655765,
      "loss": 5.1423,
      "step": 6929
    },
    {
      "epoch": 0.7946336429308566,
      "grad_norm": 0.0,
      "learning_rate": 0.00010668046410815443,
      "loss": 5.0091,
      "step": 6930
    },
    {
      "epoch": 0.7947483086801972,
      "grad_norm": 0.0,
      "learning_rate": 0.00010656589428758009,
      "loss": 4.998,
      "step": 6931
    },
    {
      "epoch": 0.7948629744295379,
      "grad_norm": 0.0,
      "learning_rate": 0.00010645137874063788,
      "loss": 4.981,
      "step": 6932
    },
    {
      "epoch": 0.7949776401788786,
      "grad_norm": 0.0,
      "learning_rate": 0.00010633691748312255,
      "loss": 5.0495,
      "step": 6933
    },
    {
      "epoch": 0.7950923059282192,
      "grad_norm": 0.0,
      "learning_rate": 0.00010622251053082241,
      "loss": 5.1463,
      "step": 6934
    },
    {
      "epoch": 0.7952069716775599,
      "grad_norm": 0.0,
      "learning_rate": 0.0001061081578995172,
      "loss": 5.1781,
      "step": 6935
    },
    {
      "epoch": 0.7953216374269005,
      "grad_norm": 0.0,
      "learning_rate": 0.00010599385960497996,
      "loss": 5.1676,
      "step": 6936
    },
    {
      "epoch": 0.7954363031762413,
      "grad_norm": 0.0,
      "learning_rate": 0.00010587961566297598,
      "loss": 5.1621,
      "step": 6937
    },
    {
      "epoch": 0.795550968925582,
      "grad_norm": 0.0,
      "learning_rate": 0.00010576542608926271,
      "loss": 4.9707,
      "step": 6938
    },
    {
      "epoch": 0.7956656346749226,
      "grad_norm": 0.0,
      "learning_rate": 0.00010565129089959091,
      "loss": 4.96,
      "step": 6939
    },
    {
      "epoch": 0.7957803004242633,
      "grad_norm": 0.0,
      "learning_rate": 0.00010553721010970285,
      "loss": 5.0494,
      "step": 6940
    },
    {
      "epoch": 0.7958949661736039,
      "grad_norm": 0.0,
      "learning_rate": 0.00010542318373533434,
      "loss": 4.9248,
      "step": 6941
    },
    {
      "epoch": 0.7960096319229446,
      "grad_norm": 0.0,
      "learning_rate": 0.00010530921179221269,
      "loss": 4.9469,
      "step": 6942
    },
    {
      "epoch": 0.7961242976722853,
      "grad_norm": 0.0,
      "learning_rate": 0.00010519529429605839,
      "loss": 4.9475,
      "step": 6943
    },
    {
      "epoch": 0.7962389634216259,
      "grad_norm": 0.0,
      "learning_rate": 0.0001050814312625841,
      "loss": 4.7657,
      "step": 6944
    },
    {
      "epoch": 0.7963536291709666,
      "grad_norm": 0.0,
      "learning_rate": 0.00010496762270749505,
      "loss": 4.9638,
      "step": 6945
    },
    {
      "epoch": 0.7964682949203074,
      "grad_norm": 0.0,
      "learning_rate": 0.00010485386864648915,
      "loss": 4.9315,
      "step": 6946
    },
    {
      "epoch": 0.796582960669648,
      "grad_norm": 0.0,
      "learning_rate": 0.00010474016909525629,
      "loss": 5.0916,
      "step": 6947
    },
    {
      "epoch": 0.7966976264189887,
      "grad_norm": 0.0,
      "learning_rate": 0.00010462652406947935,
      "loss": 4.6553,
      "step": 6948
    },
    {
      "epoch": 0.7968122921683293,
      "grad_norm": 0.0,
      "learning_rate": 0.00010451293358483344,
      "loss": 5.124,
      "step": 6949
    },
    {
      "epoch": 0.79692695791767,
      "grad_norm": 0.0,
      "learning_rate": 0.00010439939765698624,
      "loss": 5.1416,
      "step": 6950
    },
    {
      "epoch": 0.7970416236670107,
      "grad_norm": 0.0,
      "learning_rate": 0.00010428591630159783,
      "loss": 5.0717,
      "step": 6951
    },
    {
      "epoch": 0.7971562894163513,
      "grad_norm": 0.0,
      "learning_rate": 0.00010417248953432095,
      "loss": 5.119,
      "step": 6952
    },
    {
      "epoch": 0.797270955165692,
      "grad_norm": 0.0,
      "learning_rate": 0.00010405911737080023,
      "loss": 4.9769,
      "step": 6953
    },
    {
      "epoch": 0.7973856209150327,
      "grad_norm": 0.0,
      "learning_rate": 0.00010394579982667377,
      "loss": 5.1589,
      "step": 6954
    },
    {
      "epoch": 0.7975002866643733,
      "grad_norm": 0.0,
      "learning_rate": 0.00010383253691757108,
      "loss": 4.8417,
      "step": 6955
    },
    {
      "epoch": 0.797614952413714,
      "grad_norm": 0.0,
      "learning_rate": 0.00010371932865911502,
      "loss": 5.437,
      "step": 6956
    },
    {
      "epoch": 0.7977296181630547,
      "grad_norm": 0.0,
      "learning_rate": 0.00010360617506692036,
      "loss": 5.1027,
      "step": 6957
    },
    {
      "epoch": 0.7978442839123954,
      "grad_norm": 0.0,
      "learning_rate": 0.00010349307615659422,
      "loss": 4.7823,
      "step": 6958
    },
    {
      "epoch": 0.7979589496617361,
      "grad_norm": 0.0,
      "learning_rate": 0.00010338003194373687,
      "loss": 4.898,
      "step": 6959
    },
    {
      "epoch": 0.7980736154110767,
      "grad_norm": 0.0,
      "learning_rate": 0.00010326704244394017,
      "loss": 5.0831,
      "step": 6960
    },
    {
      "epoch": 0.7981882811604174,
      "grad_norm": 0.0,
      "learning_rate": 0.00010315410767278934,
      "loss": 4.8536,
      "step": 6961
    },
    {
      "epoch": 0.798302946909758,
      "grad_norm": 0.0,
      "learning_rate": 0.00010304122764586104,
      "loss": 4.7995,
      "step": 6962
    },
    {
      "epoch": 0.7984176126590987,
      "grad_norm": 0.0,
      "learning_rate": 0.00010292840237872549,
      "loss": 4.8046,
      "step": 6963
    },
    {
      "epoch": 0.7985322784084394,
      "grad_norm": 0.0,
      "learning_rate": 0.00010281563188694438,
      "loss": 5.0958,
      "step": 6964
    },
    {
      "epoch": 0.79864694415778,
      "grad_norm": 0.0,
      "learning_rate": 0.00010270291618607238,
      "loss": 4.9843,
      "step": 6965
    },
    {
      "epoch": 0.7987616099071208,
      "grad_norm": 0.0,
      "learning_rate": 0.00010259025529165647,
      "loss": 5.0099,
      "step": 6966
    },
    {
      "epoch": 0.7988762756564615,
      "grad_norm": 0.0,
      "learning_rate": 0.00010247764921923604,
      "loss": 5.1784,
      "step": 6967
    },
    {
      "epoch": 0.7989909414058021,
      "grad_norm": 0.0,
      "learning_rate": 0.00010236509798434315,
      "loss": 5.0843,
      "step": 6968
    },
    {
      "epoch": 0.7991056071551428,
      "grad_norm": 0.0,
      "learning_rate": 0.00010225260160250178,
      "loss": 5.1698,
      "step": 6969
    },
    {
      "epoch": 0.7992202729044834,
      "grad_norm": 0.0,
      "learning_rate": 0.00010214016008922883,
      "loss": 5.0577,
      "step": 6970
    },
    {
      "epoch": 0.7993349386538241,
      "grad_norm": 0.0,
      "learning_rate": 0.00010202777346003341,
      "loss": 4.929,
      "step": 6971
    },
    {
      "epoch": 0.7994496044031648,
      "grad_norm": 0.0,
      "learning_rate": 0.0001019154417304172,
      "loss": 5.1837,
      "step": 6972
    },
    {
      "epoch": 0.7995642701525054,
      "grad_norm": 0.0,
      "learning_rate": 0.00010180316491587413,
      "loss": 4.8277,
      "step": 6973
    },
    {
      "epoch": 0.7996789359018461,
      "grad_norm": 0.0,
      "learning_rate": 0.00010169094303189083,
      "loss": 5.1823,
      "step": 6974
    },
    {
      "epoch": 0.7997936016511867,
      "grad_norm": 0.0,
      "learning_rate": 0.00010157877609394571,
      "loss": 5.0569,
      "step": 6975
    },
    {
      "epoch": 0.7999082674005275,
      "grad_norm": 0.0,
      "learning_rate": 0.00010146666411751072,
      "loss": 5.0866,
      "step": 6976
    },
    {
      "epoch": 0.8000229331498682,
      "grad_norm": 0.0,
      "learning_rate": 0.00010135460711804906,
      "loss": 5.0978,
      "step": 6977
    },
    {
      "epoch": 0.8001375988992088,
      "grad_norm": 0.0,
      "learning_rate": 0.00010124260511101699,
      "loss": 4.9627,
      "step": 6978
    },
    {
      "epoch": 0.8002522646485495,
      "grad_norm": 0.0,
      "learning_rate": 0.00010113065811186325,
      "loss": 4.8553,
      "step": 6979
    },
    {
      "epoch": 0.8003669303978902,
      "grad_norm": 0.0,
      "learning_rate": 0.00010101876613602837,
      "loss": 4.7823,
      "step": 6980
    },
    {
      "epoch": 0.8004815961472308,
      "grad_norm": 0.0,
      "learning_rate": 0.00010090692919894626,
      "loss": 4.8009,
      "step": 6981
    },
    {
      "epoch": 0.8005962618965715,
      "grad_norm": 0.0,
      "learning_rate": 0.0001007951473160421,
      "loss": 4.9634,
      "step": 6982
    },
    {
      "epoch": 0.8007109276459121,
      "grad_norm": 0.0,
      "learning_rate": 0.00010068342050273464,
      "loss": 5.1649,
      "step": 6983
    },
    {
      "epoch": 0.8008255933952528,
      "grad_norm": 0.0,
      "learning_rate": 0.00010057174877443393,
      "loss": 4.9459,
      "step": 6984
    },
    {
      "epoch": 0.8009402591445935,
      "grad_norm": 0.0,
      "learning_rate": 0.00010046013214654353,
      "loss": 4.705,
      "step": 6985
    },
    {
      "epoch": 0.8010549248939342,
      "grad_norm": 0.0,
      "learning_rate": 0.00010034857063445838,
      "loss": 5.042,
      "step": 6986
    },
    {
      "epoch": 0.8011695906432749,
      "grad_norm": 0.0,
      "learning_rate": 0.00010023706425356638,
      "loss": 4.9418,
      "step": 6987
    },
    {
      "epoch": 0.8012842563926156,
      "grad_norm": 0.0,
      "learning_rate": 0.0001001256130192479,
      "loss": 5.0549,
      "step": 6988
    },
    {
      "epoch": 0.8013989221419562,
      "grad_norm": 0.0,
      "learning_rate": 0.00010001421694687509,
      "loss": 4.8375,
      "step": 6989
    },
    {
      "epoch": 0.8015135878912969,
      "grad_norm": 0.0,
      "learning_rate": 9.990287605181344e-05,
      "loss": 4.9104,
      "step": 6990
    },
    {
      "epoch": 0.8016282536406375,
      "grad_norm": 0.0,
      "learning_rate": 9.979159034941992e-05,
      "loss": 4.8916,
      "step": 6991
    },
    {
      "epoch": 0.8017429193899782,
      "grad_norm": 0.0,
      "learning_rate": 9.968035985504436e-05,
      "loss": 5.1212,
      "step": 6992
    },
    {
      "epoch": 0.8018575851393189,
      "grad_norm": 0.0,
      "learning_rate": 9.956918458402891e-05,
      "loss": 5.0615,
      "step": 6993
    },
    {
      "epoch": 0.8019722508886595,
      "grad_norm": 0.0,
      "learning_rate": 9.945806455170814e-05,
      "loss": 5.0728,
      "step": 6994
    },
    {
      "epoch": 0.8020869166380002,
      "grad_norm": 0.0,
      "learning_rate": 9.934699977340884e-05,
      "loss": 5.1407,
      "step": 6995
    },
    {
      "epoch": 0.8022015823873409,
      "grad_norm": 0.0,
      "learning_rate": 9.923599026445047e-05,
      "loss": 4.6897,
      "step": 6996
    },
    {
      "epoch": 0.8023162481366816,
      "grad_norm": 0.0,
      "learning_rate": 9.91250360401444e-05,
      "loss": 5.1757,
      "step": 6997
    },
    {
      "epoch": 0.8024309138860223,
      "grad_norm": 0.0,
      "learning_rate": 9.90141371157948e-05,
      "loss": 5.119,
      "step": 6998
    },
    {
      "epoch": 0.8025455796353629,
      "grad_norm": 0.0,
      "learning_rate": 9.890329350669803e-05,
      "loss": 4.8077,
      "step": 6999
    },
    {
      "epoch": 0.8026602453847036,
      "grad_norm": 0.0,
      "learning_rate": 9.879250522814293e-05,
      "loss": 5.1498,
      "step": 7000
    },
    {
      "epoch": 0.8027749111340443,
      "grad_norm": 0.0,
      "learning_rate": 9.868177229541063e-05,
      "loss": 4.9785,
      "step": 7001
    },
    {
      "epoch": 0.8028895768833849,
      "grad_norm": 0.0,
      "learning_rate": 9.857109472377433e-05,
      "loss": 4.9426,
      "step": 7002
    },
    {
      "epoch": 0.8030042426327256,
      "grad_norm": 0.0,
      "learning_rate": 9.846047252850037e-05,
      "loss": 4.7829,
      "step": 7003
    },
    {
      "epoch": 0.8031189083820662,
      "grad_norm": 0.0,
      "learning_rate": 9.834990572484647e-05,
      "loss": 5.013,
      "step": 7004
    },
    {
      "epoch": 0.803233574131407,
      "grad_norm": 0.0,
      "learning_rate": 9.823939432806378e-05,
      "loss": 5.0376,
      "step": 7005
    },
    {
      "epoch": 0.8033482398807477,
      "grad_norm": 0.0,
      "learning_rate": 9.812893835339463e-05,
      "loss": 4.9983,
      "step": 7006
    },
    {
      "epoch": 0.8034629056300883,
      "grad_norm": 0.0,
      "learning_rate": 9.801853781607489e-05,
      "loss": 5.0275,
      "step": 7007
    },
    {
      "epoch": 0.803577571379429,
      "grad_norm": 0.0,
      "learning_rate": 9.790819273133195e-05,
      "loss": 5.0044,
      "step": 7008
    },
    {
      "epoch": 0.8036922371287696,
      "grad_norm": 0.0,
      "learning_rate": 9.779790311438553e-05,
      "loss": 4.9556,
      "step": 7009
    },
    {
      "epoch": 0.8038069028781103,
      "grad_norm": 0.0,
      "learning_rate": 9.768766898044857e-05,
      "loss": 5.2535,
      "step": 7010
    },
    {
      "epoch": 0.803921568627451,
      "grad_norm": 0.0,
      "learning_rate": 9.757749034472513e-05,
      "loss": 5.1354,
      "step": 7011
    },
    {
      "epoch": 0.8040362343767916,
      "grad_norm": 0.0,
      "learning_rate": 9.746736722241286e-05,
      "loss": 4.7729,
      "step": 7012
    },
    {
      "epoch": 0.8041509001261323,
      "grad_norm": 0.0,
      "learning_rate": 9.73572996287007e-05,
      "loss": 5.0416,
      "step": 7013
    },
    {
      "epoch": 0.804265565875473,
      "grad_norm": 0.0,
      "learning_rate": 9.724728757877052e-05,
      "loss": 5.1876,
      "step": 7014
    },
    {
      "epoch": 0.8043802316248136,
      "grad_norm": 0.0,
      "learning_rate": 9.713733108779645e-05,
      "loss": 4.8848,
      "step": 7015
    },
    {
      "epoch": 0.8044948973741544,
      "grad_norm": 0.0,
      "learning_rate": 9.702743017094481e-05,
      "loss": 4.8688,
      "step": 7016
    },
    {
      "epoch": 0.804609563123495,
      "grad_norm": 0.0,
      "learning_rate": 9.691758484337454e-05,
      "loss": 4.8978,
      "step": 7017
    },
    {
      "epoch": 0.8047242288728357,
      "grad_norm": 0.0,
      "learning_rate": 9.680779512023639e-05,
      "loss": 4.9261,
      "step": 7018
    },
    {
      "epoch": 0.8048388946221764,
      "grad_norm": 0.0,
      "learning_rate": 9.669806101667387e-05,
      "loss": 5.1193,
      "step": 7019
    },
    {
      "epoch": 0.804953560371517,
      "grad_norm": 0.0,
      "learning_rate": 9.658838254782276e-05,
      "loss": 5.2219,
      "step": 7020
    },
    {
      "epoch": 0.8050682261208577,
      "grad_norm": 0.0,
      "learning_rate": 9.647875972881112e-05,
      "loss": 5.0643,
      "step": 7021
    },
    {
      "epoch": 0.8051828918701984,
      "grad_norm": 0.0,
      "learning_rate": 9.636919257475929e-05,
      "loss": 4.8837,
      "step": 7022
    },
    {
      "epoch": 0.805297557619539,
      "grad_norm": 0.0,
      "learning_rate": 9.625968110078016e-05,
      "loss": 5.0801,
      "step": 7023
    },
    {
      "epoch": 0.8054122233688797,
      "grad_norm": 0.0,
      "learning_rate": 9.615022532197826e-05,
      "loss": 4.7461,
      "step": 7024
    },
    {
      "epoch": 0.8055268891182203,
      "grad_norm": 0.0,
      "learning_rate": 9.604082525345158e-05,
      "loss": 5.184,
      "step": 7025
    },
    {
      "epoch": 0.8056415548675611,
      "grad_norm": 0.0,
      "learning_rate": 9.593148091028912e-05,
      "loss": 5.1973,
      "step": 7026
    },
    {
      "epoch": 0.8057562206169018,
      "grad_norm": 0.0,
      "learning_rate": 9.582219230757341e-05,
      "loss": 4.9374,
      "step": 7027
    },
    {
      "epoch": 0.8058708863662424,
      "grad_norm": 0.0,
      "learning_rate": 9.57129594603784e-05,
      "loss": 4.7635,
      "step": 7028
    },
    {
      "epoch": 0.8059855521155831,
      "grad_norm": 0.0,
      "learning_rate": 9.560378238377078e-05,
      "loss": 4.8758,
      "step": 7029
    },
    {
      "epoch": 0.8061002178649237,
      "grad_norm": 0.0,
      "learning_rate": 9.549466109280951e-05,
      "loss": 4.7517,
      "step": 7030
    },
    {
      "epoch": 0.8062148836142644,
      "grad_norm": 0.0,
      "learning_rate": 9.538559560254551e-05,
      "loss": 5.1838,
      "step": 7031
    },
    {
      "epoch": 0.8063295493636051,
      "grad_norm": 0.0,
      "learning_rate": 9.527658592802275e-05,
      "loss": 5.0972,
      "step": 7032
    },
    {
      "epoch": 0.8064442151129457,
      "grad_norm": 0.0,
      "learning_rate": 9.516763208427645e-05,
      "loss": 5.0999,
      "step": 7033
    },
    {
      "epoch": 0.8065588808622864,
      "grad_norm": 0.0,
      "learning_rate": 9.505873408633536e-05,
      "loss": 4.7313,
      "step": 7034
    },
    {
      "epoch": 0.8066735466116272,
      "grad_norm": 0.0,
      "learning_rate": 9.494989194921947e-05,
      "loss": 5.0547,
      "step": 7035
    },
    {
      "epoch": 0.8067882123609678,
      "grad_norm": 0.0,
      "learning_rate": 9.484110568794152e-05,
      "loss": 5.008,
      "step": 7036
    },
    {
      "epoch": 0.8069028781103085,
      "grad_norm": 0.0,
      "learning_rate": 9.473237531750657e-05,
      "loss": 4.9109,
      "step": 7037
    },
    {
      "epoch": 0.8070175438596491,
      "grad_norm": 0.0,
      "learning_rate": 9.462370085291186e-05,
      "loss": 4.9153,
      "step": 7038
    },
    {
      "epoch": 0.8071322096089898,
      "grad_norm": 0.0,
      "learning_rate": 9.451508230914717e-05,
      "loss": 5.0135,
      "step": 7039
    },
    {
      "epoch": 0.8072468753583305,
      "grad_norm": 0.0,
      "learning_rate": 9.440651970119402e-05,
      "loss": 5.0612,
      "step": 7040
    },
    {
      "epoch": 0.8073615411076711,
      "grad_norm": 0.0,
      "learning_rate": 9.429801304402669e-05,
      "loss": 5.0817,
      "step": 7041
    },
    {
      "epoch": 0.8074762068570118,
      "grad_norm": 0.0,
      "learning_rate": 9.418956235261168e-05,
      "loss": 5.0435,
      "step": 7042
    },
    {
      "epoch": 0.8075908726063524,
      "grad_norm": 0.0,
      "learning_rate": 9.408116764190762e-05,
      "loss": 5.1387,
      "step": 7043
    },
    {
      "epoch": 0.8077055383556931,
      "grad_norm": 0.0,
      "learning_rate": 9.397282892686545e-05,
      "loss": 5.0826,
      "step": 7044
    },
    {
      "epoch": 0.8078202041050339,
      "grad_norm": 0.0,
      "learning_rate": 9.386454622242866e-05,
      "loss": 4.9161,
      "step": 7045
    },
    {
      "epoch": 0.8079348698543745,
      "grad_norm": 0.0,
      "learning_rate": 9.37563195435324e-05,
      "loss": 5.2469,
      "step": 7046
    },
    {
      "epoch": 0.8080495356037152,
      "grad_norm": 0.0,
      "learning_rate": 9.364814890510496e-05,
      "loss": 4.7854,
      "step": 7047
    },
    {
      "epoch": 0.8081642013530559,
      "grad_norm": 0.0,
      "learning_rate": 9.354003432206598e-05,
      "loss": 5.1637,
      "step": 7048
    },
    {
      "epoch": 0.8082788671023965,
      "grad_norm": 0.0,
      "learning_rate": 9.3431975809328e-05,
      "loss": 5.0679,
      "step": 7049
    },
    {
      "epoch": 0.8083935328517372,
      "grad_norm": 0.0,
      "learning_rate": 9.33239733817956e-05,
      "loss": 4.8999,
      "step": 7050
    },
    {
      "epoch": 0.8085081986010778,
      "grad_norm": 0.0,
      "learning_rate": 9.32160270543657e-05,
      "loss": 4.7105,
      "step": 7051
    },
    {
      "epoch": 0.8086228643504185,
      "grad_norm": 0.0,
      "learning_rate": 9.310813684192752e-05,
      "loss": 5.2102,
      "step": 7052
    },
    {
      "epoch": 0.8087375300997592,
      "grad_norm": 0.0,
      "learning_rate": 9.300030275936205e-05,
      "loss": 4.8641,
      "step": 7053
    },
    {
      "epoch": 0.8088521958490998,
      "grad_norm": 0.0,
      "learning_rate": 9.289252482154351e-05,
      "loss": 4.9452,
      "step": 7054
    },
    {
      "epoch": 0.8089668615984406,
      "grad_norm": 0.0,
      "learning_rate": 9.278480304333731e-05,
      "loss": 4.8232,
      "step": 7055
    },
    {
      "epoch": 0.8090815273477813,
      "grad_norm": 0.0,
      "learning_rate": 9.267713743960213e-05,
      "loss": 4.679,
      "step": 7056
    },
    {
      "epoch": 0.8091961930971219,
      "grad_norm": 0.0,
      "learning_rate": 9.256952802518792e-05,
      "loss": 5.0852,
      "step": 7057
    },
    {
      "epoch": 0.8093108588464626,
      "grad_norm": 0.0,
      "learning_rate": 9.246197481493757e-05,
      "loss": 5.0994,
      "step": 7058
    },
    {
      "epoch": 0.8094255245958032,
      "grad_norm": 0.0,
      "learning_rate": 9.235447782368611e-05,
      "loss": 5.0787,
      "step": 7059
    },
    {
      "epoch": 0.8095401903451439,
      "grad_norm": 0.0,
      "learning_rate": 9.224703706626024e-05,
      "loss": 5.1349,
      "step": 7060
    },
    {
      "epoch": 0.8096548560944846,
      "grad_norm": 0.0,
      "learning_rate": 9.213965255747996e-05,
      "loss": 4.8624,
      "step": 7061
    },
    {
      "epoch": 0.8097695218438252,
      "grad_norm": 0.0,
      "learning_rate": 9.203232431215649e-05,
      "loss": 5.0607,
      "step": 7062
    },
    {
      "epoch": 0.8098841875931659,
      "grad_norm": 0.0,
      "learning_rate": 9.192505234509392e-05,
      "loss": 5.1735,
      "step": 7063
    },
    {
      "epoch": 0.8099988533425065,
      "grad_norm": 0.0,
      "learning_rate": 9.181783667108824e-05,
      "loss": 4.8263,
      "step": 7064
    },
    {
      "epoch": 0.8101135190918473,
      "grad_norm": 0.0,
      "learning_rate": 9.171067730492787e-05,
      "loss": 4.9338,
      "step": 7065
    },
    {
      "epoch": 0.810228184841188,
      "grad_norm": 0.0,
      "learning_rate": 9.160357426139345e-05,
      "loss": 5.0482,
      "step": 7066
    },
    {
      "epoch": 0.8103428505905286,
      "grad_norm": 0.0,
      "learning_rate": 9.149652755525788e-05,
      "loss": 4.8782,
      "step": 7067
    },
    {
      "epoch": 0.8104575163398693,
      "grad_norm": 0.0,
      "learning_rate": 9.138953720128598e-05,
      "loss": 5.1623,
      "step": 7068
    },
    {
      "epoch": 0.81057218208921,
      "grad_norm": 0.0,
      "learning_rate": 9.128260321423514e-05,
      "loss": 5.0018,
      "step": 7069
    },
    {
      "epoch": 0.8106868478385506,
      "grad_norm": 0.0,
      "learning_rate": 9.117572560885481e-05,
      "loss": 5.1712,
      "step": 7070
    },
    {
      "epoch": 0.8108015135878913,
      "grad_norm": 0.0,
      "learning_rate": 9.106890439988687e-05,
      "loss": 5.1157,
      "step": 7071
    },
    {
      "epoch": 0.8109161793372319,
      "grad_norm": 0.0,
      "learning_rate": 9.096213960206511e-05,
      "loss": 4.9783,
      "step": 7072
    },
    {
      "epoch": 0.8110308450865726,
      "grad_norm": 0.0,
      "learning_rate": 9.085543123011582e-05,
      "loss": 5.224,
      "step": 7073
    },
    {
      "epoch": 0.8111455108359134,
      "grad_norm": 0.0,
      "learning_rate": 9.074877929875742e-05,
      "loss": 5.4622,
      "step": 7074
    },
    {
      "epoch": 0.811260176585254,
      "grad_norm": 0.0,
      "learning_rate": 9.064218382270024e-05,
      "loss": 4.8872,
      "step": 7075
    },
    {
      "epoch": 0.8113748423345947,
      "grad_norm": 0.0,
      "learning_rate": 9.053564481664748e-05,
      "loss": 4.9411,
      "step": 7076
    },
    {
      "epoch": 0.8114895080839353,
      "grad_norm": 0.0,
      "learning_rate": 9.042916229529368e-05,
      "loss": 5.046,
      "step": 7077
    },
    {
      "epoch": 0.811604173833276,
      "grad_norm": 0.0,
      "learning_rate": 9.032273627332667e-05,
      "loss": 4.7957,
      "step": 7078
    },
    {
      "epoch": 0.8117188395826167,
      "grad_norm": 0.0,
      "learning_rate": 9.021636676542552e-05,
      "loss": 4.7466,
      "step": 7079
    },
    {
      "epoch": 0.8118335053319573,
      "grad_norm": 0.0,
      "learning_rate": 9.01100537862617e-05,
      "loss": 4.8498,
      "step": 7080
    },
    {
      "epoch": 0.811948171081298,
      "grad_norm": 0.0,
      "learning_rate": 9.00037973504996e-05,
      "loss": 5.2046,
      "step": 7081
    },
    {
      "epoch": 0.8120628368306387,
      "grad_norm": 0.0,
      "learning_rate": 8.989759747279466e-05,
      "loss": 4.8905,
      "step": 7082
    },
    {
      "epoch": 0.8121775025799793,
      "grad_norm": 0.0,
      "learning_rate": 8.979145416779572e-05,
      "loss": 4.9818,
      "step": 7083
    },
    {
      "epoch": 0.81229216832932,
      "grad_norm": 0.0,
      "learning_rate": 8.968536745014276e-05,
      "loss": 5.0333,
      "step": 7084
    },
    {
      "epoch": 0.8124068340786607,
      "grad_norm": 0.0,
      "learning_rate": 8.957933733446866e-05,
      "loss": 4.9435,
      "step": 7085
    },
    {
      "epoch": 0.8125214998280014,
      "grad_norm": 0.0,
      "learning_rate": 8.947336383539816e-05,
      "loss": 4.8485,
      "step": 7086
    },
    {
      "epoch": 0.8126361655773421,
      "grad_norm": 0.0,
      "learning_rate": 8.936744696754833e-05,
      "loss": 5.1043,
      "step": 7087
    },
    {
      "epoch": 0.8127508313266827,
      "grad_norm": 0.0,
      "learning_rate": 8.926158674552833e-05,
      "loss": 4.9083,
      "step": 7088
    },
    {
      "epoch": 0.8128654970760234,
      "grad_norm": 0.0,
      "learning_rate": 8.915578318393976e-05,
      "loss": 5.0408,
      "step": 7089
    },
    {
      "epoch": 0.8129801628253641,
      "grad_norm": 0.0,
      "learning_rate": 8.905003629737592e-05,
      "loss": 4.88,
      "step": 7090
    },
    {
      "epoch": 0.8130948285747047,
      "grad_norm": 0.0,
      "learning_rate": 8.894434610042269e-05,
      "loss": 4.9689,
      "step": 7091
    },
    {
      "epoch": 0.8132094943240454,
      "grad_norm": 0.0,
      "learning_rate": 8.883871260765803e-05,
      "loss": 5.2476,
      "step": 7092
    },
    {
      "epoch": 0.813324160073386,
      "grad_norm": 0.0,
      "learning_rate": 8.873313583365206e-05,
      "loss": 5.1063,
      "step": 7093
    },
    {
      "epoch": 0.8134388258227268,
      "grad_norm": 0.0,
      "learning_rate": 8.862761579296708e-05,
      "loss": 4.9551,
      "step": 7094
    },
    {
      "epoch": 0.8135534915720675,
      "grad_norm": 0.0,
      "learning_rate": 8.85221525001576e-05,
      "loss": 5.1255,
      "step": 7095
    },
    {
      "epoch": 0.8136681573214081,
      "grad_norm": 0.0,
      "learning_rate": 8.841674596977037e-05,
      "loss": 4.7192,
      "step": 7096
    },
    {
      "epoch": 0.8137828230707488,
      "grad_norm": 0.0,
      "learning_rate": 8.831139621634381e-05,
      "loss": 5.1429,
      "step": 7097
    },
    {
      "epoch": 0.8138974888200894,
      "grad_norm": 0.0,
      "learning_rate": 8.820610325440949e-05,
      "loss": 4.8277,
      "step": 7098
    },
    {
      "epoch": 0.8140121545694301,
      "grad_norm": 0.0,
      "learning_rate": 8.810086709849012e-05,
      "loss": 4.9424,
      "step": 7099
    },
    {
      "epoch": 0.8141268203187708,
      "grad_norm": 0.0,
      "learning_rate": 8.799568776310114e-05,
      "loss": 4.8049,
      "step": 7100
    },
    {
      "epoch": 0.8142414860681114,
      "grad_norm": 0.0,
      "learning_rate": 8.789056526275024e-05,
      "loss": 4.9432,
      "step": 7101
    },
    {
      "epoch": 0.8143561518174521,
      "grad_norm": 0.0,
      "learning_rate": 8.778549961193661e-05,
      "loss": 4.7814,
      "step": 7102
    },
    {
      "epoch": 0.8144708175667928,
      "grad_norm": 0.0,
      "learning_rate": 8.768049082515255e-05,
      "loss": 4.8937,
      "step": 7103
    },
    {
      "epoch": 0.8145854833161335,
      "grad_norm": 0.0,
      "learning_rate": 8.757553891688158e-05,
      "loss": 4.7574,
      "step": 7104
    },
    {
      "epoch": 0.8147001490654742,
      "grad_norm": 0.0,
      "learning_rate": 8.74706439016003e-05,
      "loss": 4.9857,
      "step": 7105
    },
    {
      "epoch": 0.8148148148148148,
      "grad_norm": 0.0,
      "learning_rate": 8.736580579377662e-05,
      "loss": 5.1697,
      "step": 7106
    },
    {
      "epoch": 0.8149294805641555,
      "grad_norm": 0.0,
      "learning_rate": 8.726102460787103e-05,
      "loss": 5.109,
      "step": 7107
    },
    {
      "epoch": 0.8150441463134962,
      "grad_norm": 0.0,
      "learning_rate": 8.715630035833607e-05,
      "loss": 5.1969,
      "step": 7108
    },
    {
      "epoch": 0.8151588120628368,
      "grad_norm": 0.0,
      "learning_rate": 8.705163305961659e-05,
      "loss": 4.9931,
      "step": 7109
    },
    {
      "epoch": 0.8152734778121775,
      "grad_norm": 0.0,
      "learning_rate": 8.694702272614939e-05,
      "loss": 5.1115,
      "step": 7110
    },
    {
      "epoch": 0.8153881435615181,
      "grad_norm": 0.0,
      "learning_rate": 8.684246937236341e-05,
      "loss": 5.0308,
      "step": 7111
    },
    {
      "epoch": 0.8155028093108588,
      "grad_norm": 0.0,
      "learning_rate": 8.673797301267978e-05,
      "loss": 4.9908,
      "step": 7112
    },
    {
      "epoch": 0.8156174750601995,
      "grad_norm": 0.0,
      "learning_rate": 8.663353366151185e-05,
      "loss": 4.9431,
      "step": 7113
    },
    {
      "epoch": 0.8157321408095402,
      "grad_norm": 0.0,
      "learning_rate": 8.6529151333265e-05,
      "loss": 4.9338,
      "step": 7114
    },
    {
      "epoch": 0.8158468065588809,
      "grad_norm": 0.0,
      "learning_rate": 8.642482604233681e-05,
      "loss": 4.9034,
      "step": 7115
    },
    {
      "epoch": 0.8159614723082216,
      "grad_norm": 0.0,
      "learning_rate": 8.632055780311696e-05,
      "loss": 4.9742,
      "step": 7116
    },
    {
      "epoch": 0.8160761380575622,
      "grad_norm": 0.0,
      "learning_rate": 8.621634662998726e-05,
      "loss": 5.1307,
      "step": 7117
    },
    {
      "epoch": 0.8161908038069029,
      "grad_norm": 0.0,
      "learning_rate": 8.611219253732178e-05,
      "loss": 5.0929,
      "step": 7118
    },
    {
      "epoch": 0.8163054695562435,
      "grad_norm": 0.0,
      "learning_rate": 8.600809553948635e-05,
      "loss": 5.185,
      "step": 7119
    },
    {
      "epoch": 0.8164201353055842,
      "grad_norm": 0.0,
      "learning_rate": 8.590405565083928e-05,
      "loss": 5.0048,
      "step": 7120
    },
    {
      "epoch": 0.8165348010549249,
      "grad_norm": 0.0,
      "learning_rate": 8.580007288573088e-05,
      "loss": 5.0696,
      "step": 7121
    },
    {
      "epoch": 0.8166494668042655,
      "grad_norm": 0.0,
      "learning_rate": 8.569614725850361e-05,
      "loss": 5.0653,
      "step": 7122
    },
    {
      "epoch": 0.8167641325536062,
      "grad_norm": 0.0,
      "learning_rate": 8.559227878349214e-05,
      "loss": 5.0435,
      "step": 7123
    },
    {
      "epoch": 0.816878798302947,
      "grad_norm": 0.0,
      "learning_rate": 8.548846747502277e-05,
      "loss": 5.2538,
      "step": 7124
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.0,
      "learning_rate": 8.538471334741482e-05,
      "loss": 5.095,
      "step": 7125
    },
    {
      "epoch": 0.8171081298016283,
      "grad_norm": 0.0,
      "learning_rate": 8.52810164149787e-05,
      "loss": 5.2423,
      "step": 7126
    },
    {
      "epoch": 0.8172227955509689,
      "grad_norm": 0.0,
      "learning_rate": 8.517737669201784e-05,
      "loss": 4.8402,
      "step": 7127
    },
    {
      "epoch": 0.8173374613003096,
      "grad_norm": 0.0,
      "learning_rate": 8.507379419282708e-05,
      "loss": 4.823,
      "step": 7128
    },
    {
      "epoch": 0.8174521270496503,
      "grad_norm": 0.0,
      "learning_rate": 8.497026893169371e-05,
      "loss": 5.1209,
      "step": 7129
    },
    {
      "epoch": 0.8175667927989909,
      "grad_norm": 0.0,
      "learning_rate": 8.486680092289727e-05,
      "loss": 5.0435,
      "step": 7130
    },
    {
      "epoch": 0.8176814585483316,
      "grad_norm": 0.0,
      "learning_rate": 8.476339018070875e-05,
      "loss": 4.9287,
      "step": 7131
    },
    {
      "epoch": 0.8177961242976722,
      "grad_norm": 0.0,
      "learning_rate": 8.466003671939225e-05,
      "loss": 4.7556,
      "step": 7132
    },
    {
      "epoch": 0.817910790047013,
      "grad_norm": 0.0,
      "learning_rate": 8.455674055320302e-05,
      "loss": 4.8762,
      "step": 7133
    },
    {
      "epoch": 0.8180254557963537,
      "grad_norm": 0.0,
      "learning_rate": 8.445350169638886e-05,
      "loss": 5.0972,
      "step": 7134
    },
    {
      "epoch": 0.8181401215456943,
      "grad_norm": 0.0,
      "learning_rate": 8.43503201631897e-05,
      "loss": 4.9873,
      "step": 7135
    },
    {
      "epoch": 0.818254787295035,
      "grad_norm": 0.0,
      "learning_rate": 8.424719596783737e-05,
      "loss": 5.0973,
      "step": 7136
    },
    {
      "epoch": 0.8183694530443757,
      "grad_norm": 0.0,
      "learning_rate": 8.414412912455596e-05,
      "loss": 4.8178,
      "step": 7137
    },
    {
      "epoch": 0.8184841187937163,
      "grad_norm": 0.0,
      "learning_rate": 8.404111964756154e-05,
      "loss": 5.0882,
      "step": 7138
    },
    {
      "epoch": 0.818598784543057,
      "grad_norm": 0.0,
      "learning_rate": 8.393816755106233e-05,
      "loss": 4.9018,
      "step": 7139
    },
    {
      "epoch": 0.8187134502923976,
      "grad_norm": 0.0,
      "learning_rate": 8.383527284925876e-05,
      "loss": 5.1999,
      "step": 7140
    },
    {
      "epoch": 0.8188281160417383,
      "grad_norm": 0.0,
      "learning_rate": 8.373243555634281e-05,
      "loss": 4.8997,
      "step": 7141
    },
    {
      "epoch": 0.818942781791079,
      "grad_norm": 0.0,
      "learning_rate": 8.36296556864992e-05,
      "loss": 5.0855,
      "step": 7142
    },
    {
      "epoch": 0.8190574475404196,
      "grad_norm": 0.0,
      "learning_rate": 8.352693325390437e-05,
      "loss": 5.0006,
      "step": 7143
    },
    {
      "epoch": 0.8191721132897604,
      "grad_norm": 0.0,
      "learning_rate": 8.342426827272697e-05,
      "loss": 5.193,
      "step": 7144
    },
    {
      "epoch": 0.819286779039101,
      "grad_norm": 0.0,
      "learning_rate": 8.332166075712773e-05,
      "loss": 4.9774,
      "step": 7145
    },
    {
      "epoch": 0.8194014447884417,
      "grad_norm": 0.0,
      "learning_rate": 8.321911072125911e-05,
      "loss": 4.7026,
      "step": 7146
    },
    {
      "epoch": 0.8195161105377824,
      "grad_norm": 0.0,
      "learning_rate": 8.311661817926636e-05,
      "loss": 4.9192,
      "step": 7147
    },
    {
      "epoch": 0.819630776287123,
      "grad_norm": 0.0,
      "learning_rate": 8.301418314528593e-05,
      "loss": 5.019,
      "step": 7148
    },
    {
      "epoch": 0.8197454420364637,
      "grad_norm": 0.0,
      "learning_rate": 8.291180563344728e-05,
      "loss": 5.201,
      "step": 7149
    },
    {
      "epoch": 0.8198601077858044,
      "grad_norm": 0.0,
      "learning_rate": 8.280948565787118e-05,
      "loss": 4.8781,
      "step": 7150
    },
    {
      "epoch": 0.819974773535145,
      "grad_norm": 0.0,
      "learning_rate": 8.270722323267043e-05,
      "loss": 4.8263,
      "step": 7151
    },
    {
      "epoch": 0.8200894392844857,
      "grad_norm": 0.0,
      "learning_rate": 8.26050183719507e-05,
      "loss": 4.671,
      "step": 7152
    },
    {
      "epoch": 0.8202041050338263,
      "grad_norm": 0.0,
      "learning_rate": 8.250287108980871e-05,
      "loss": 5.1264,
      "step": 7153
    },
    {
      "epoch": 0.8203187707831671,
      "grad_norm": 0.0,
      "learning_rate": 8.240078140033425e-05,
      "loss": 4.8263,
      "step": 7154
    },
    {
      "epoch": 0.8204334365325078,
      "grad_norm": 0.0,
      "learning_rate": 8.229874931760824e-05,
      "loss": 4.8049,
      "step": 7155
    },
    {
      "epoch": 0.8205481022818484,
      "grad_norm": 0.0,
      "learning_rate": 8.219677485570417e-05,
      "loss": 4.9375,
      "step": 7156
    },
    {
      "epoch": 0.8206627680311891,
      "grad_norm": 0.0,
      "learning_rate": 8.209485802868753e-05,
      "loss": 5.0532,
      "step": 7157
    },
    {
      "epoch": 0.8207774337805298,
      "grad_norm": 0.0,
      "learning_rate": 8.199299885061575e-05,
      "loss": 5.0871,
      "step": 7158
    },
    {
      "epoch": 0.8208920995298704,
      "grad_norm": 0.0,
      "learning_rate": 8.189119733553843e-05,
      "loss": 5.0525,
      "step": 7159
    },
    {
      "epoch": 0.8210067652792111,
      "grad_norm": 0.0,
      "learning_rate": 8.178945349749712e-05,
      "loss": 5.1894,
      "step": 7160
    },
    {
      "epoch": 0.8211214310285517,
      "grad_norm": 0.0,
      "learning_rate": 8.168776735052551e-05,
      "loss": 4.966,
      "step": 7161
    },
    {
      "epoch": 0.8212360967778924,
      "grad_norm": 0.0,
      "learning_rate": 8.158613890864904e-05,
      "loss": 4.9564,
      "step": 7162
    },
    {
      "epoch": 0.8213507625272332,
      "grad_norm": 0.0,
      "learning_rate": 8.148456818588564e-05,
      "loss": 5.174,
      "step": 7163
    },
    {
      "epoch": 0.8214654282765738,
      "grad_norm": 0.0,
      "learning_rate": 8.138305519624489e-05,
      "loss": 4.9789,
      "step": 7164
    },
    {
      "epoch": 0.8215800940259145,
      "grad_norm": 0.0,
      "learning_rate": 8.12815999537287e-05,
      "loss": 4.9221,
      "step": 7165
    },
    {
      "epoch": 0.8216947597752551,
      "grad_norm": 0.0,
      "learning_rate": 8.118020247233082e-05,
      "loss": 4.8814,
      "step": 7166
    },
    {
      "epoch": 0.8218094255245958,
      "grad_norm": 0.0,
      "learning_rate": 8.107886276603732e-05,
      "loss": 4.906,
      "step": 7167
    },
    {
      "epoch": 0.8219240912739365,
      "grad_norm": 0.0,
      "learning_rate": 8.097758084882556e-05,
      "loss": 5.1944,
      "step": 7168
    },
    {
      "epoch": 0.8220387570232771,
      "grad_norm": 0.0,
      "learning_rate": 8.087635673466603e-05,
      "loss": 4.9494,
      "step": 7169
    },
    {
      "epoch": 0.8221534227726178,
      "grad_norm": 0.0,
      "learning_rate": 8.077519043752033e-05,
      "loss": 4.9571,
      "step": 7170
    },
    {
      "epoch": 0.8222680885219585,
      "grad_norm": 0.0,
      "learning_rate": 8.067408197134251e-05,
      "loss": 5.0673,
      "step": 7171
    },
    {
      "epoch": 0.8223827542712991,
      "grad_norm": 0.0,
      "learning_rate": 8.057303135007861e-05,
      "loss": 4.9008,
      "step": 7172
    },
    {
      "epoch": 0.8224974200206399,
      "grad_norm": 0.0,
      "learning_rate": 8.047203858766634e-05,
      "loss": 5.1941,
      "step": 7173
    },
    {
      "epoch": 0.8226120857699805,
      "grad_norm": 0.0,
      "learning_rate": 8.037110369803625e-05,
      "loss": 4.8785,
      "step": 7174
    },
    {
      "epoch": 0.8227267515193212,
      "grad_norm": 0.0,
      "learning_rate": 8.027022669510984e-05,
      "loss": 5.0465,
      "step": 7175
    },
    {
      "epoch": 0.8228414172686619,
      "grad_norm": 0.0,
      "learning_rate": 8.016940759280167e-05,
      "loss": 4.8739,
      "step": 7176
    },
    {
      "epoch": 0.8229560830180025,
      "grad_norm": 0.0,
      "learning_rate": 8.006864640501746e-05,
      "loss": 5.1172,
      "step": 7177
    },
    {
      "epoch": 0.8230707487673432,
      "grad_norm": 0.0,
      "learning_rate": 7.996794314565537e-05,
      "loss": 5.0445,
      "step": 7178
    },
    {
      "epoch": 0.8231854145166838,
      "grad_norm": 0.0,
      "learning_rate": 7.986729782860554e-05,
      "loss": 4.9817,
      "step": 7179
    },
    {
      "epoch": 0.8233000802660245,
      "grad_norm": 0.0,
      "learning_rate": 7.976671046775007e-05,
      "loss": 5.27,
      "step": 7180
    },
    {
      "epoch": 0.8234147460153652,
      "grad_norm": 0.0,
      "learning_rate": 7.966618107696322e-05,
      "loss": 4.9104,
      "step": 7181
    },
    {
      "epoch": 0.8235294117647058,
      "grad_norm": 0.0,
      "learning_rate": 7.956570967011063e-05,
      "loss": 5.0005,
      "step": 7182
    },
    {
      "epoch": 0.8236440775140466,
      "grad_norm": 0.0,
      "learning_rate": 7.946529626105102e-05,
      "loss": 5.1375,
      "step": 7183
    },
    {
      "epoch": 0.8237587432633873,
      "grad_norm": 0.0,
      "learning_rate": 7.936494086363411e-05,
      "loss": 5.0309,
      "step": 7184
    },
    {
      "epoch": 0.8238734090127279,
      "grad_norm": 0.0,
      "learning_rate": 7.926464349170212e-05,
      "loss": 5.2116,
      "step": 7185
    },
    {
      "epoch": 0.8239880747620686,
      "grad_norm": 0.0,
      "learning_rate": 7.91644041590891e-05,
      "loss": 4.9203,
      "step": 7186
    },
    {
      "epoch": 0.8241027405114092,
      "grad_norm": 0.0,
      "learning_rate": 7.90642228796213e-05,
      "loss": 4.9397,
      "step": 7187
    },
    {
      "epoch": 0.8242174062607499,
      "grad_norm": 0.0,
      "learning_rate": 7.89640996671167e-05,
      "loss": 4.9623,
      "step": 7188
    },
    {
      "epoch": 0.8243320720100906,
      "grad_norm": 0.0,
      "learning_rate": 7.886403453538553e-05,
      "loss": 5.0245,
      "step": 7189
    },
    {
      "epoch": 0.8244467377594312,
      "grad_norm": 0.0,
      "learning_rate": 7.876402749822965e-05,
      "loss": 5.4428,
      "step": 7190
    },
    {
      "epoch": 0.8245614035087719,
      "grad_norm": 0.0,
      "learning_rate": 7.866407856944322e-05,
      "loss": 4.9777,
      "step": 7191
    },
    {
      "epoch": 0.8246760692581127,
      "grad_norm": 0.0,
      "learning_rate": 7.856418776281233e-05,
      "loss": 5.1879,
      "step": 7192
    },
    {
      "epoch": 0.8247907350074533,
      "grad_norm": 0.0,
      "learning_rate": 7.8464355092115e-05,
      "loss": 5.18,
      "step": 7193
    },
    {
      "epoch": 0.824905400756794,
      "grad_norm": 0.0,
      "learning_rate": 7.83645805711213e-05,
      "loss": 4.9573,
      "step": 7194
    },
    {
      "epoch": 0.8250200665061346,
      "grad_norm": 0.0,
      "learning_rate": 7.826486421359294e-05,
      "loss": 4.8535,
      "step": 7195
    },
    {
      "epoch": 0.8251347322554753,
      "grad_norm": 0.0,
      "learning_rate": 7.816520603328435e-05,
      "loss": 5.1266,
      "step": 7196
    },
    {
      "epoch": 0.825249398004816,
      "grad_norm": 0.0,
      "learning_rate": 7.806560604394102e-05,
      "loss": 4.5897,
      "step": 7197
    },
    {
      "epoch": 0.8253640637541566,
      "grad_norm": 0.0,
      "learning_rate": 7.796606425930125e-05,
      "loss": 4.9318,
      "step": 7198
    },
    {
      "epoch": 0.8254787295034973,
      "grad_norm": 0.0,
      "learning_rate": 7.786658069309471e-05,
      "loss": 4.7321,
      "step": 7199
    },
    {
      "epoch": 0.8255933952528379,
      "grad_norm": 0.0,
      "learning_rate": 7.77671553590433e-05,
      "loss": 5.2477,
      "step": 7200
    },
    {
      "epoch": 0.8257080610021786,
      "grad_norm": 0.0,
      "learning_rate": 7.766778827086098e-05,
      "loss": 5.1352,
      "step": 7201
    },
    {
      "epoch": 0.8258227267515194,
      "grad_norm": 0.0,
      "learning_rate": 7.756847944225316e-05,
      "loss": 4.8866,
      "step": 7202
    },
    {
      "epoch": 0.82593739250086,
      "grad_norm": 0.0,
      "learning_rate": 7.746922888691815e-05,
      "loss": 5.0311,
      "step": 7203
    },
    {
      "epoch": 0.8260520582502007,
      "grad_norm": 0.0,
      "learning_rate": 7.737003661854514e-05,
      "loss": 4.8848,
      "step": 7204
    },
    {
      "epoch": 0.8261667239995414,
      "grad_norm": 0.0,
      "learning_rate": 7.727090265081634e-05,
      "loss": 4.6135,
      "step": 7205
    },
    {
      "epoch": 0.826281389748882,
      "grad_norm": 0.0,
      "learning_rate": 7.717182699740495e-05,
      "loss": 5.0845,
      "step": 7206
    },
    {
      "epoch": 0.8263960554982227,
      "grad_norm": 0.0,
      "learning_rate": 7.707280967197673e-05,
      "loss": 5.0342,
      "step": 7207
    },
    {
      "epoch": 0.8265107212475633,
      "grad_norm": 0.0,
      "learning_rate": 7.69738506881893e-05,
      "loss": 4.9094,
      "step": 7208
    },
    {
      "epoch": 0.826625386996904,
      "grad_norm": 0.0,
      "learning_rate": 7.687495005969206e-05,
      "loss": 4.8465,
      "step": 7209
    },
    {
      "epoch": 0.8267400527462447,
      "grad_norm": 0.0,
      "learning_rate": 7.677610780012648e-05,
      "loss": 4.9039,
      "step": 7210
    },
    {
      "epoch": 0.8268547184955853,
      "grad_norm": 0.0,
      "learning_rate": 7.667732392312611e-05,
      "loss": 5.0138,
      "step": 7211
    },
    {
      "epoch": 0.826969384244926,
      "grad_norm": 0.0,
      "learning_rate": 7.657859844231614e-05,
      "loss": 5.0051,
      "step": 7212
    },
    {
      "epoch": 0.8270840499942668,
      "grad_norm": 0.0,
      "learning_rate": 7.647993137131386e-05,
      "loss": 5.1255,
      "step": 7213
    },
    {
      "epoch": 0.8271987157436074,
      "grad_norm": 0.0,
      "learning_rate": 7.638132272372861e-05,
      "loss": 5.0665,
      "step": 7214
    },
    {
      "epoch": 0.8273133814929481,
      "grad_norm": 0.0,
      "learning_rate": 7.628277251316148e-05,
      "loss": 4.9024,
      "step": 7215
    },
    {
      "epoch": 0.8274280472422887,
      "grad_norm": 0.0,
      "learning_rate": 7.61842807532058e-05,
      "loss": 5.0695,
      "step": 7216
    },
    {
      "epoch": 0.8275427129916294,
      "grad_norm": 0.0,
      "learning_rate": 7.608584745744618e-05,
      "loss": 4.6094,
      "step": 7217
    },
    {
      "epoch": 0.8276573787409701,
      "grad_norm": 0.0,
      "learning_rate": 7.598747263946019e-05,
      "loss": 5.1549,
      "step": 7218
    },
    {
      "epoch": 0.8277720444903107,
      "grad_norm": 0.0,
      "learning_rate": 7.588915631281627e-05,
      "loss": 4.8842,
      "step": 7219
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.0,
      "learning_rate": 7.579089849107571e-05,
      "loss": 5.1494,
      "step": 7220
    },
    {
      "epoch": 0.828001375988992,
      "grad_norm": 0.0,
      "learning_rate": 7.569269918779107e-05,
      "loss": 5.1351,
      "step": 7221
    },
    {
      "epoch": 0.8281160417383328,
      "grad_norm": 0.0,
      "learning_rate": 7.559455841650688e-05,
      "loss": 5.0511,
      "step": 7222
    },
    {
      "epoch": 0.8282307074876735,
      "grad_norm": 0.0,
      "learning_rate": 7.549647619076023e-05,
      "loss": 5.0324,
      "step": 7223
    },
    {
      "epoch": 0.8283453732370141,
      "grad_norm": 0.0,
      "learning_rate": 7.539845252407922e-05,
      "loss": 5.225,
      "step": 7224
    },
    {
      "epoch": 0.8284600389863548,
      "grad_norm": 0.0,
      "learning_rate": 7.530048742998484e-05,
      "loss": 5.0333,
      "step": 7225
    },
    {
      "epoch": 0.8285747047356955,
      "grad_norm": 0.0,
      "learning_rate": 7.520258092198901e-05,
      "loss": 5.0888,
      "step": 7226
    },
    {
      "epoch": 0.8286893704850361,
      "grad_norm": 0.0,
      "learning_rate": 7.510473301359655e-05,
      "loss": 5.2229,
      "step": 7227
    },
    {
      "epoch": 0.8288040362343768,
      "grad_norm": 0.0,
      "learning_rate": 7.500694371830333e-05,
      "loss": 5.296,
      "step": 7228
    },
    {
      "epoch": 0.8289187019837174,
      "grad_norm": 0.0,
      "learning_rate": 7.49092130495977e-05,
      "loss": 5.033,
      "step": 7229
    },
    {
      "epoch": 0.8290333677330581,
      "grad_norm": 0.0,
      "learning_rate": 7.481154102095975e-05,
      "loss": 5.1813,
      "step": 7230
    },
    {
      "epoch": 0.8291480334823988,
      "grad_norm": 0.0,
      "learning_rate": 7.471392764586136e-05,
      "loss": 5.1534,
      "step": 7231
    },
    {
      "epoch": 0.8292626992317395,
      "grad_norm": 0.0,
      "learning_rate": 7.461637293776664e-05,
      "loss": 4.9935,
      "step": 7232
    },
    {
      "epoch": 0.8293773649810802,
      "grad_norm": 0.0,
      "learning_rate": 7.451887691013119e-05,
      "loss": 4.9675,
      "step": 7233
    },
    {
      "epoch": 0.8294920307304208,
      "grad_norm": 0.0,
      "learning_rate": 7.442143957640275e-05,
      "loss": 5.204,
      "step": 7234
    },
    {
      "epoch": 0.8296066964797615,
      "grad_norm": 0.0,
      "learning_rate": 7.432406095002105e-05,
      "loss": 5.1903,
      "step": 7235
    },
    {
      "epoch": 0.8297213622291022,
      "grad_norm": 0.0,
      "learning_rate": 7.422674104441756e-05,
      "loss": 5.1994,
      "step": 7236
    },
    {
      "epoch": 0.8298360279784428,
      "grad_norm": 0.0,
      "learning_rate": 7.41294798730157e-05,
      "loss": 4.8878,
      "step": 7237
    },
    {
      "epoch": 0.8299506937277835,
      "grad_norm": 0.0,
      "learning_rate": 7.403227744923095e-05,
      "loss": 5.1222,
      "step": 7238
    },
    {
      "epoch": 0.8300653594771242,
      "grad_norm": 0.0,
      "learning_rate": 7.393513378647015e-05,
      "loss": 4.9716,
      "step": 7239
    },
    {
      "epoch": 0.8301800252264648,
      "grad_norm": 0.0,
      "learning_rate": 7.383804889813286e-05,
      "loss": 4.9104,
      "step": 7240
    },
    {
      "epoch": 0.8302946909758055,
      "grad_norm": 0.0,
      "learning_rate": 7.37410227976098e-05,
      "loss": 4.9987,
      "step": 7241
    },
    {
      "epoch": 0.8304093567251462,
      "grad_norm": 0.0,
      "learning_rate": 7.364405549828396e-05,
      "loss": 5.3204,
      "step": 7242
    },
    {
      "epoch": 0.8305240224744869,
      "grad_norm": 0.0,
      "learning_rate": 7.35471470135302e-05,
      "loss": 5.0158,
      "step": 7243
    },
    {
      "epoch": 0.8306386882238276,
      "grad_norm": 0.0,
      "learning_rate": 7.34502973567149e-05,
      "loss": 5.2033,
      "step": 7244
    },
    {
      "epoch": 0.8307533539731682,
      "grad_norm": 0.0,
      "learning_rate": 7.335350654119716e-05,
      "loss": 4.719,
      "step": 7245
    },
    {
      "epoch": 0.8308680197225089,
      "grad_norm": 0.0,
      "learning_rate": 7.325677458032679e-05,
      "loss": 5.0896,
      "step": 7246
    },
    {
      "epoch": 0.8309826854718496,
      "grad_norm": 0.0,
      "learning_rate": 7.316010148744674e-05,
      "loss": 5.0603,
      "step": 7247
    },
    {
      "epoch": 0.8310973512211902,
      "grad_norm": 0.0,
      "learning_rate": 7.306348727589066e-05,
      "loss": 4.7907,
      "step": 7248
    },
    {
      "epoch": 0.8312120169705309,
      "grad_norm": 0.0,
      "learning_rate": 7.296693195898517e-05,
      "loss": 5.0308,
      "step": 7249
    },
    {
      "epoch": 0.8313266827198715,
      "grad_norm": 0.0,
      "learning_rate": 7.287043555004781e-05,
      "loss": 4.9703,
      "step": 7250
    },
    {
      "epoch": 0.8314413484692122,
      "grad_norm": 0.0,
      "learning_rate": 7.27739980623886e-05,
      "loss": 5.133,
      "step": 7251
    },
    {
      "epoch": 0.831556014218553,
      "grad_norm": 0.0,
      "learning_rate": 7.267761950930941e-05,
      "loss": 5.2022,
      "step": 7252
    },
    {
      "epoch": 0.8316706799678936,
      "grad_norm": 0.0,
      "learning_rate": 7.258129990410337e-05,
      "loss": 4.7823,
      "step": 7253
    },
    {
      "epoch": 0.8317853457172343,
      "grad_norm": 0.0,
      "learning_rate": 7.248503926005641e-05,
      "loss": 5.0645,
      "step": 7254
    },
    {
      "epoch": 0.8319000114665749,
      "grad_norm": 0.0,
      "learning_rate": 7.23888375904456e-05,
      "loss": 5.1258,
      "step": 7255
    },
    {
      "epoch": 0.8320146772159156,
      "grad_norm": 0.0,
      "learning_rate": 7.229269490854014e-05,
      "loss": 4.8811,
      "step": 7256
    },
    {
      "epoch": 0.8321293429652563,
      "grad_norm": 0.0,
      "learning_rate": 7.219661122760111e-05,
      "loss": 5.0686,
      "step": 7257
    },
    {
      "epoch": 0.8322440087145969,
      "grad_norm": 0.0,
      "learning_rate": 7.210058656088148e-05,
      "loss": 4.9058,
      "step": 7258
    },
    {
      "epoch": 0.8323586744639376,
      "grad_norm": 0.0,
      "learning_rate": 7.200462092162598e-05,
      "loss": 5.2963,
      "step": 7259
    },
    {
      "epoch": 0.8324733402132783,
      "grad_norm": 0.0,
      "learning_rate": 7.190871432307132e-05,
      "loss": 5.109,
      "step": 7260
    },
    {
      "epoch": 0.832588005962619,
      "grad_norm": 0.0,
      "learning_rate": 7.181286677844569e-05,
      "loss": 4.9998,
      "step": 7261
    },
    {
      "epoch": 0.8327026717119597,
      "grad_norm": 0.0,
      "learning_rate": 7.171707830096987e-05,
      "loss": 5.1435,
      "step": 7262
    },
    {
      "epoch": 0.8328173374613003,
      "grad_norm": 0.0,
      "learning_rate": 7.162134890385569e-05,
      "loss": 5.0905,
      "step": 7263
    },
    {
      "epoch": 0.832932003210641,
      "grad_norm": 0.0,
      "learning_rate": 7.152567860030737e-05,
      "loss": 4.8113,
      "step": 7264
    },
    {
      "epoch": 0.8330466689599817,
      "grad_norm": 0.0,
      "learning_rate": 7.143006740352087e-05,
      "loss": 5.2118,
      "step": 7265
    },
    {
      "epoch": 0.8331613347093223,
      "grad_norm": 0.0,
      "learning_rate": 7.13345153266836e-05,
      "loss": 4.9928,
      "step": 7266
    },
    {
      "epoch": 0.833276000458663,
      "grad_norm": 0.0,
      "learning_rate": 7.123902238297561e-05,
      "loss": 5.1659,
      "step": 7267
    },
    {
      "epoch": 0.8333906662080036,
      "grad_norm": 0.0,
      "learning_rate": 7.114358858556789e-05,
      "loss": 4.8904,
      "step": 7268
    },
    {
      "epoch": 0.8335053319573443,
      "grad_norm": 0.0,
      "learning_rate": 7.104821394762413e-05,
      "loss": 4.8963,
      "step": 7269
    },
    {
      "epoch": 0.833619997706685,
      "grad_norm": 0.0,
      "learning_rate": 7.095289848229903e-05,
      "loss": 5.0666,
      "step": 7270
    },
    {
      "epoch": 0.8337346634560256,
      "grad_norm": 0.0,
      "learning_rate": 7.085764220273998e-05,
      "loss": 5.1642,
      "step": 7271
    },
    {
      "epoch": 0.8338493292053664,
      "grad_norm": 0.0,
      "learning_rate": 7.076244512208554e-05,
      "loss": 4.9177,
      "step": 7272
    },
    {
      "epoch": 0.8339639949547071,
      "grad_norm": 0.0,
      "learning_rate": 7.066730725346607e-05,
      "loss": 4.816,
      "step": 7273
    },
    {
      "epoch": 0.8340786607040477,
      "grad_norm": 0.0,
      "learning_rate": 7.057222861000452e-05,
      "loss": 4.9326,
      "step": 7274
    },
    {
      "epoch": 0.8341933264533884,
      "grad_norm": 0.0,
      "learning_rate": 7.047720920481472e-05,
      "loss": 4.9788,
      "step": 7275
    },
    {
      "epoch": 0.834307992202729,
      "grad_norm": 0.0,
      "learning_rate": 7.038224905100327e-05,
      "loss": 5.1642,
      "step": 7276
    },
    {
      "epoch": 0.8344226579520697,
      "grad_norm": 0.0,
      "learning_rate": 7.028734816166772e-05,
      "loss": 5.2376,
      "step": 7277
    },
    {
      "epoch": 0.8345373237014104,
      "grad_norm": 0.0,
      "learning_rate": 7.019250654989797e-05,
      "loss": 4.8354,
      "step": 7278
    },
    {
      "epoch": 0.834651989450751,
      "grad_norm": 0.0,
      "learning_rate": 7.009772422877557e-05,
      "loss": 4.9059,
      "step": 7279
    },
    {
      "epoch": 0.8347666552000917,
      "grad_norm": 0.0,
      "learning_rate": 7.0003001211374e-05,
      "loss": 5.3699,
      "step": 7280
    },
    {
      "epoch": 0.8348813209494325,
      "grad_norm": 0.0,
      "learning_rate": 6.99083375107585e-05,
      "loss": 4.923,
      "step": 7281
    },
    {
      "epoch": 0.8349959866987731,
      "grad_norm": 0.0,
      "learning_rate": 6.981373313998617e-05,
      "loss": 5.1002,
      "step": 7282
    },
    {
      "epoch": 0.8351106524481138,
      "grad_norm": 0.0,
      "learning_rate": 6.971918811210571e-05,
      "loss": 4.863,
      "step": 7283
    },
    {
      "epoch": 0.8352253181974544,
      "grad_norm": 0.0,
      "learning_rate": 6.962470244015793e-05,
      "loss": 4.8678,
      "step": 7284
    },
    {
      "epoch": 0.8353399839467951,
      "grad_norm": 0.0,
      "learning_rate": 6.953027613717523e-05,
      "loss": 4.9702,
      "step": 7285
    },
    {
      "epoch": 0.8354546496961358,
      "grad_norm": 0.0,
      "learning_rate": 6.943590921618205e-05,
      "loss": 5.0793,
      "step": 7286
    },
    {
      "epoch": 0.8355693154454764,
      "grad_norm": 0.0,
      "learning_rate": 6.934160169019452e-05,
      "loss": 4.987,
      "step": 7287
    },
    {
      "epoch": 0.8356839811948171,
      "grad_norm": 0.0,
      "learning_rate": 6.924735357222023e-05,
      "loss": 4.9494,
      "step": 7288
    },
    {
      "epoch": 0.8357986469441577,
      "grad_norm": 0.0,
      "learning_rate": 6.915316487525943e-05,
      "loss": 5.2781,
      "step": 7289
    },
    {
      "epoch": 0.8359133126934984,
      "grad_norm": 0.0,
      "learning_rate": 6.905903561230318e-05,
      "loss": 4.8982,
      "step": 7290
    },
    {
      "epoch": 0.8360279784428392,
      "grad_norm": 0.0,
      "learning_rate": 6.896496579633524e-05,
      "loss": 5.1957,
      "step": 7291
    },
    {
      "epoch": 0.8361426441921798,
      "grad_norm": 0.0,
      "learning_rate": 6.887095544033046e-05,
      "loss": 4.969,
      "step": 7292
    },
    {
      "epoch": 0.8362573099415205,
      "grad_norm": 0.0,
      "learning_rate": 6.87770045572558e-05,
      "loss": 5.0253,
      "step": 7293
    },
    {
      "epoch": 0.8363719756908612,
      "grad_norm": 0.0,
      "learning_rate": 6.868311316007019e-05,
      "loss": 5.0079,
      "step": 7294
    },
    {
      "epoch": 0.8364866414402018,
      "grad_norm": 0.0,
      "learning_rate": 6.858928126172378e-05,
      "loss": 4.78,
      "step": 7295
    },
    {
      "epoch": 0.8366013071895425,
      "grad_norm": 0.0,
      "learning_rate": 6.849550887515943e-05,
      "loss": 5.1206,
      "step": 7296
    },
    {
      "epoch": 0.8367159729388831,
      "grad_norm": 0.0,
      "learning_rate": 6.840179601331066e-05,
      "loss": 5.2144,
      "step": 7297
    },
    {
      "epoch": 0.8368306386882238,
      "grad_norm": 0.0,
      "learning_rate": 6.830814268910387e-05,
      "loss": 5.0181,
      "step": 7298
    },
    {
      "epoch": 0.8369453044375645,
      "grad_norm": 0.0,
      "learning_rate": 6.821454891545649e-05,
      "loss": 5.331,
      "step": 7299
    },
    {
      "epoch": 0.8370599701869051,
      "grad_norm": 0.0,
      "learning_rate": 6.812101470527805e-05,
      "loss": 5.0784,
      "step": 7300
    },
    {
      "epoch": 0.8371746359362459,
      "grad_norm": 0.0,
      "learning_rate": 6.802754007146977e-05,
      "loss": 5.0167,
      "step": 7301
    },
    {
      "epoch": 0.8372893016855865,
      "grad_norm": 0.0,
      "learning_rate": 6.793412502692474e-05,
      "loss": 5.1627,
      "step": 7302
    },
    {
      "epoch": 0.8374039674349272,
      "grad_norm": 0.0,
      "learning_rate": 6.784076958452797e-05,
      "loss": 5.2005,
      "step": 7303
    },
    {
      "epoch": 0.8375186331842679,
      "grad_norm": 0.0,
      "learning_rate": 6.774747375715573e-05,
      "loss": 5.0776,
      "step": 7304
    },
    {
      "epoch": 0.8376332989336085,
      "grad_norm": 0.0,
      "learning_rate": 6.76542375576765e-05,
      "loss": 5.0532,
      "step": 7305
    },
    {
      "epoch": 0.8377479646829492,
      "grad_norm": 0.0,
      "learning_rate": 6.756106099895053e-05,
      "loss": 5.3003,
      "step": 7306
    },
    {
      "epoch": 0.8378626304322899,
      "grad_norm": 0.0,
      "learning_rate": 6.74679440938297e-05,
      "loss": 4.8383,
      "step": 7307
    },
    {
      "epoch": 0.8379772961816305,
      "grad_norm": 0.0,
      "learning_rate": 6.737488685515775e-05,
      "loss": 4.8254,
      "step": 7308
    },
    {
      "epoch": 0.8380919619309712,
      "grad_norm": 0.0,
      "learning_rate": 6.728188929577018e-05,
      "loss": 5.0873,
      "step": 7309
    },
    {
      "epoch": 0.8382066276803118,
      "grad_norm": 0.0,
      "learning_rate": 6.718895142849397e-05,
      "loss": 4.9495,
      "step": 7310
    },
    {
      "epoch": 0.8383212934296526,
      "grad_norm": 0.0,
      "learning_rate": 6.709607326614853e-05,
      "loss": 4.9688,
      "step": 7311
    },
    {
      "epoch": 0.8384359591789933,
      "grad_norm": 0.0,
      "learning_rate": 6.700325482154435e-05,
      "loss": 5.2444,
      "step": 7312
    },
    {
      "epoch": 0.8385506249283339,
      "grad_norm": 0.0,
      "learning_rate": 6.691049610748407e-05,
      "loss": 5.0926,
      "step": 7313
    },
    {
      "epoch": 0.8386652906776746,
      "grad_norm": 0.0,
      "learning_rate": 6.681779713676188e-05,
      "loss": 5.0872,
      "step": 7314
    },
    {
      "epoch": 0.8387799564270153,
      "grad_norm": 0.0,
      "learning_rate": 6.672515792216398e-05,
      "loss": 4.9379,
      "step": 7315
    },
    {
      "epoch": 0.8388946221763559,
      "grad_norm": 0.0,
      "learning_rate": 6.663257847646825e-05,
      "loss": 4.7415,
      "step": 7316
    },
    {
      "epoch": 0.8390092879256966,
      "grad_norm": 0.0,
      "learning_rate": 6.654005881244386e-05,
      "loss": 5.2285,
      "step": 7317
    },
    {
      "epoch": 0.8391239536750372,
      "grad_norm": 0.0,
      "learning_rate": 6.644759894285267e-05,
      "loss": 5.2085,
      "step": 7318
    },
    {
      "epoch": 0.8392386194243779,
      "grad_norm": 0.0,
      "learning_rate": 6.635519888044724e-05,
      "loss": 5.2526,
      "step": 7319
    },
    {
      "epoch": 0.8393532851737187,
      "grad_norm": 0.0,
      "learning_rate": 6.626285863797284e-05,
      "loss": 5.0258,
      "step": 7320
    },
    {
      "epoch": 0.8394679509230593,
      "grad_norm": 0.0,
      "learning_rate": 6.617057822816581e-05,
      "loss": 5.1242,
      "step": 7321
    },
    {
      "epoch": 0.8395826166724,
      "grad_norm": 0.0,
      "learning_rate": 6.607835766375446e-05,
      "loss": 4.9385,
      "step": 7322
    },
    {
      "epoch": 0.8396972824217406,
      "grad_norm": 0.0,
      "learning_rate": 6.598619695745908e-05,
      "loss": 5.1698,
      "step": 7323
    },
    {
      "epoch": 0.8398119481710813,
      "grad_norm": 0.0,
      "learning_rate": 6.58940961219911e-05,
      "loss": 4.9445,
      "step": 7324
    },
    {
      "epoch": 0.839926613920422,
      "grad_norm": 0.0,
      "learning_rate": 6.580205517005444e-05,
      "loss": 4.9627,
      "step": 7325
    },
    {
      "epoch": 0.8400412796697626,
      "grad_norm": 0.0,
      "learning_rate": 6.57100741143442e-05,
      "loss": 4.9972,
      "step": 7326
    },
    {
      "epoch": 0.8401559454191033,
      "grad_norm": 0.0,
      "learning_rate": 6.56181529675475e-05,
      "loss": 5.0494,
      "step": 7327
    },
    {
      "epoch": 0.840270611168444,
      "grad_norm": 0.0,
      "learning_rate": 6.5526291742343e-05,
      "loss": 4.7109,
      "step": 7328
    },
    {
      "epoch": 0.8403852769177846,
      "grad_norm": 0.0,
      "learning_rate": 6.543449045140133e-05,
      "loss": 5.2864,
      "step": 7329
    },
    {
      "epoch": 0.8404999426671254,
      "grad_norm": 0.0,
      "learning_rate": 6.534274910738467e-05,
      "loss": 5.0184,
      "step": 7330
    },
    {
      "epoch": 0.840614608416466,
      "grad_norm": 0.0,
      "learning_rate": 6.525106772294706e-05,
      "loss": 5.1117,
      "step": 7331
    },
    {
      "epoch": 0.8407292741658067,
      "grad_norm": 0.0,
      "learning_rate": 6.515944631073398e-05,
      "loss": 4.8906,
      "step": 7332
    },
    {
      "epoch": 0.8408439399151474,
      "grad_norm": 0.0,
      "learning_rate": 6.506788488338318e-05,
      "loss": 5.2501,
      "step": 7333
    },
    {
      "epoch": 0.840958605664488,
      "grad_norm": 0.0,
      "learning_rate": 6.497638345352355e-05,
      "loss": 4.7432,
      "step": 7334
    },
    {
      "epoch": 0.8410732714138287,
      "grad_norm": 0.0,
      "learning_rate": 6.488494203377612e-05,
      "loss": 5.2577,
      "step": 7335
    },
    {
      "epoch": 0.8411879371631693,
      "grad_norm": 0.0,
      "learning_rate": 6.479356063675336e-05,
      "loss": 4.9602,
      "step": 7336
    },
    {
      "epoch": 0.84130260291251,
      "grad_norm": 0.0,
      "learning_rate": 6.470223927505975e-05,
      "loss": 5.1287,
      "step": 7337
    },
    {
      "epoch": 0.8414172686618507,
      "grad_norm": 0.0,
      "learning_rate": 6.46109779612913e-05,
      "loss": 5.0191,
      "step": 7338
    },
    {
      "epoch": 0.8415319344111913,
      "grad_norm": 0.0,
      "learning_rate": 6.45197767080355e-05,
      "loss": 5.1472,
      "step": 7339
    },
    {
      "epoch": 0.841646600160532,
      "grad_norm": 0.0,
      "learning_rate": 6.442863552787223e-05,
      "loss": 4.976,
      "step": 7340
    },
    {
      "epoch": 0.8417612659098728,
      "grad_norm": 0.0,
      "learning_rate": 6.433755443337232e-05,
      "loss": 4.9407,
      "step": 7341
    },
    {
      "epoch": 0.8418759316592134,
      "grad_norm": 0.0,
      "learning_rate": 6.424653343709907e-05,
      "loss": 4.9259,
      "step": 7342
    },
    {
      "epoch": 0.8419905974085541,
      "grad_norm": 0.0,
      "learning_rate": 6.415557255160683e-05,
      "loss": 4.6873,
      "step": 7343
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 0.0,
      "learning_rate": 6.406467178944174e-05,
      "loss": 4.8606,
      "step": 7344
    },
    {
      "epoch": 0.8422199289072354,
      "grad_norm": 0.0,
      "learning_rate": 6.397383116314226e-05,
      "loss": 5.1921,
      "step": 7345
    },
    {
      "epoch": 0.8423345946565761,
      "grad_norm": 0.0,
      "learning_rate": 6.388305068523769e-05,
      "loss": 4.9714,
      "step": 7346
    },
    {
      "epoch": 0.8424492604059167,
      "grad_norm": 0.0,
      "learning_rate": 6.379233036824992e-05,
      "loss": 5.2761,
      "step": 7347
    },
    {
      "epoch": 0.8425639261552574,
      "grad_norm": 0.0,
      "learning_rate": 6.370167022469172e-05,
      "loss": 4.9178,
      "step": 7348
    },
    {
      "epoch": 0.8426785919045982,
      "grad_norm": 0.0,
      "learning_rate": 6.361107026706804e-05,
      "loss": 5.1927,
      "step": 7349
    },
    {
      "epoch": 0.8427932576539388,
      "grad_norm": 0.0,
      "learning_rate": 6.352053050787545e-05,
      "loss": 4.8476,
      "step": 7350
    },
    {
      "epoch": 0.8429079234032795,
      "grad_norm": 0.0,
      "learning_rate": 6.343005095960215e-05,
      "loss": 4.8062,
      "step": 7351
    },
    {
      "epoch": 0.8430225891526201,
      "grad_norm": 0.0,
      "learning_rate": 6.333963163472808e-05,
      "loss": 5.0815,
      "step": 7352
    },
    {
      "epoch": 0.8431372549019608,
      "grad_norm": 0.0,
      "learning_rate": 6.324927254572503e-05,
      "loss": 5.012,
      "step": 7353
    },
    {
      "epoch": 0.8432519206513015,
      "grad_norm": 0.0,
      "learning_rate": 6.315897370505603e-05,
      "loss": 5.2633,
      "step": 7354
    },
    {
      "epoch": 0.8433665864006421,
      "grad_norm": 0.0,
      "learning_rate": 6.306873512517617e-05,
      "loss": 4.8545,
      "step": 7355
    },
    {
      "epoch": 0.8434812521499828,
      "grad_norm": 0.0,
      "learning_rate": 6.297855681853218e-05,
      "loss": 4.9591,
      "step": 7356
    },
    {
      "epoch": 0.8435959178993234,
      "grad_norm": 0.0,
      "learning_rate": 6.288843879756249e-05,
      "loss": 4.9959,
      "step": 7357
    },
    {
      "epoch": 0.8437105836486641,
      "grad_norm": 0.0,
      "learning_rate": 6.279838107469707e-05,
      "loss": 5.0285,
      "step": 7358
    },
    {
      "epoch": 0.8438252493980049,
      "grad_norm": 0.0,
      "learning_rate": 6.270838366235769e-05,
      "loss": 5.0866,
      "step": 7359
    },
    {
      "epoch": 0.8439399151473455,
      "grad_norm": 0.0,
      "learning_rate": 6.261844657295795e-05,
      "loss": 5.0337,
      "step": 7360
    },
    {
      "epoch": 0.8440545808966862,
      "grad_norm": 0.0,
      "learning_rate": 6.252856981890257e-05,
      "loss": 4.9289,
      "step": 7361
    },
    {
      "epoch": 0.8441692466460269,
      "grad_norm": 0.0,
      "learning_rate": 6.243875341258875e-05,
      "loss": 5.1261,
      "step": 7362
    },
    {
      "epoch": 0.8442839123953675,
      "grad_norm": 0.0,
      "learning_rate": 6.23489973664047e-05,
      "loss": 4.8682,
      "step": 7363
    },
    {
      "epoch": 0.8443985781447082,
      "grad_norm": 0.0,
      "learning_rate": 6.225930169273056e-05,
      "loss": 5.0782,
      "step": 7364
    },
    {
      "epoch": 0.8445132438940488,
      "grad_norm": 0.0,
      "learning_rate": 6.216966640393839e-05,
      "loss": 4.9295,
      "step": 7365
    },
    {
      "epoch": 0.8446279096433895,
      "grad_norm": 0.0,
      "learning_rate": 6.208009151239125e-05,
      "loss": 4.8775,
      "step": 7366
    },
    {
      "epoch": 0.8447425753927302,
      "grad_norm": 0.0,
      "learning_rate": 6.199057703044471e-05,
      "loss": 5.0996,
      "step": 7367
    },
    {
      "epoch": 0.8448572411420708,
      "grad_norm": 0.0,
      "learning_rate": 6.190112297044515e-05,
      "loss": 4.8242,
      "step": 7368
    },
    {
      "epoch": 0.8449719068914116,
      "grad_norm": 0.0,
      "learning_rate": 6.181172934473156e-05,
      "loss": 5.1671,
      "step": 7369
    },
    {
      "epoch": 0.8450865726407522,
      "grad_norm": 0.0,
      "learning_rate": 6.172239616563371e-05,
      "loss": 4.9136,
      "step": 7370
    },
    {
      "epoch": 0.8452012383900929,
      "grad_norm": 0.0,
      "learning_rate": 6.163312344547354e-05,
      "loss": 4.964,
      "step": 7371
    },
    {
      "epoch": 0.8453159041394336,
      "grad_norm": 0.0,
      "learning_rate": 6.154391119656448e-05,
      "loss": 5.0541,
      "step": 7372
    },
    {
      "epoch": 0.8454305698887742,
      "grad_norm": 0.0,
      "learning_rate": 6.145475943121172e-05,
      "loss": 5.2692,
      "step": 7373
    },
    {
      "epoch": 0.8455452356381149,
      "grad_norm": 0.0,
      "learning_rate": 6.136566816171204e-05,
      "loss": 4.8408,
      "step": 7374
    },
    {
      "epoch": 0.8456599013874556,
      "grad_norm": 0.0,
      "learning_rate": 6.127663740035383e-05,
      "loss": 5.0217,
      "step": 7375
    },
    {
      "epoch": 0.8457745671367962,
      "grad_norm": 0.0,
      "learning_rate": 6.118766715941717e-05,
      "loss": 4.9012,
      "step": 7376
    },
    {
      "epoch": 0.8458892328861369,
      "grad_norm": 0.0,
      "learning_rate": 6.109875745117384e-05,
      "loss": 5.1934,
      "step": 7377
    },
    {
      "epoch": 0.8460038986354775,
      "grad_norm": 0.0,
      "learning_rate": 6.100990828788726e-05,
      "loss": 5.217,
      "step": 7378
    },
    {
      "epoch": 0.8461185643848183,
      "grad_norm": 0.0,
      "learning_rate": 6.092111968181249e-05,
      "loss": 4.9078,
      "step": 7379
    },
    {
      "epoch": 0.846233230134159,
      "grad_norm": 0.0,
      "learning_rate": 6.083239164519616e-05,
      "loss": 5.104,
      "step": 7380
    },
    {
      "epoch": 0.8463478958834996,
      "grad_norm": 0.0,
      "learning_rate": 6.07437241902767e-05,
      "loss": 4.8775,
      "step": 7381
    },
    {
      "epoch": 0.8464625616328403,
      "grad_norm": 0.0,
      "learning_rate": 6.06551173292841e-05,
      "loss": 5.0351,
      "step": 7382
    },
    {
      "epoch": 0.846577227382181,
      "grad_norm": 0.0,
      "learning_rate": 6.0566571074439754e-05,
      "loss": 5.0262,
      "step": 7383
    },
    {
      "epoch": 0.8466918931315216,
      "grad_norm": 0.0,
      "learning_rate": 6.0478085437957334e-05,
      "loss": 5.0589,
      "step": 7384
    },
    {
      "epoch": 0.8468065588808623,
      "grad_norm": 0.0,
      "learning_rate": 6.038966043204141e-05,
      "loss": 5.0282,
      "step": 7385
    },
    {
      "epoch": 0.8469212246302029,
      "grad_norm": 0.0,
      "learning_rate": 6.030129606888862e-05,
      "loss": 5.1411,
      "step": 7386
    },
    {
      "epoch": 0.8470358903795436,
      "grad_norm": 0.0,
      "learning_rate": 6.021299236068728e-05,
      "loss": 4.9986,
      "step": 7387
    },
    {
      "epoch": 0.8471505561288843,
      "grad_norm": 0.0,
      "learning_rate": 6.012474931961691e-05,
      "loss": 5.0626,
      "step": 7388
    },
    {
      "epoch": 0.847265221878225,
      "grad_norm": 0.0,
      "learning_rate": 6.0036566957849286e-05,
      "loss": 4.8145,
      "step": 7389
    },
    {
      "epoch": 0.8473798876275657,
      "grad_norm": 0.0,
      "learning_rate": 5.994844528754719e-05,
      "loss": 4.9078,
      "step": 7390
    },
    {
      "epoch": 0.8474945533769063,
      "grad_norm": 0.0,
      "learning_rate": 5.986038432086562e-05,
      "loss": 4.9661,
      "step": 7391
    },
    {
      "epoch": 0.847609219126247,
      "grad_norm": 0.0,
      "learning_rate": 5.977238406995069e-05,
      "loss": 4.9784,
      "step": 7392
    },
    {
      "epoch": 0.8477238848755877,
      "grad_norm": 0.0,
      "learning_rate": 5.968444454694038e-05,
      "loss": 4.9693,
      "step": 7393
    },
    {
      "epoch": 0.8478385506249283,
      "grad_norm": 0.0,
      "learning_rate": 5.959656576396445e-05,
      "loss": 5.1979,
      "step": 7394
    },
    {
      "epoch": 0.847953216374269,
      "grad_norm": 0.0,
      "learning_rate": 5.950874773314374e-05,
      "loss": 4.7982,
      "step": 7395
    },
    {
      "epoch": 0.8480678821236097,
      "grad_norm": 0.0,
      "learning_rate": 5.942099046659153e-05,
      "loss": 4.894,
      "step": 7396
    },
    {
      "epoch": 0.8481825478729503,
      "grad_norm": 0.0,
      "learning_rate": 5.933329397641193e-05,
      "loss": 4.9807,
      "step": 7397
    },
    {
      "epoch": 0.848297213622291,
      "grad_norm": 0.0,
      "learning_rate": 5.9245658274701044e-05,
      "loss": 4.832,
      "step": 7398
    },
    {
      "epoch": 0.8484118793716316,
      "grad_norm": 0.0,
      "learning_rate": 5.9158083373546665e-05,
      "loss": 4.7456,
      "step": 7399
    },
    {
      "epoch": 0.8485265451209724,
      "grad_norm": 0.0,
      "learning_rate": 5.907056928502804e-05,
      "loss": 4.7795,
      "step": 7400
    },
    {
      "epoch": 0.8486412108703131,
      "grad_norm": 0.0,
      "learning_rate": 5.898311602121601e-05,
      "loss": 4.7009,
      "step": 7401
    },
    {
      "epoch": 0.8487558766196537,
      "grad_norm": 0.0,
      "learning_rate": 5.8895723594173117e-05,
      "loss": 5.1217,
      "step": 7402
    },
    {
      "epoch": 0.8488705423689944,
      "grad_norm": 0.0,
      "learning_rate": 5.880839201595346e-05,
      "loss": 4.9143,
      "step": 7403
    },
    {
      "epoch": 0.848985208118335,
      "grad_norm": 0.0,
      "learning_rate": 5.872112129860297e-05,
      "loss": 4.9693,
      "step": 7404
    },
    {
      "epoch": 0.8490998738676757,
      "grad_norm": 0.0,
      "learning_rate": 5.8633911454158654e-05,
      "loss": 5.1831,
      "step": 7405
    },
    {
      "epoch": 0.8492145396170164,
      "grad_norm": 0.0,
      "learning_rate": 5.854676249464962e-05,
      "loss": 4.9283,
      "step": 7406
    },
    {
      "epoch": 0.849329205366357,
      "grad_norm": 0.0,
      "learning_rate": 5.845967443209638e-05,
      "loss": 5.2569,
      "step": 7407
    },
    {
      "epoch": 0.8494438711156977,
      "grad_norm": 0.0,
      "learning_rate": 5.837264727851103e-05,
      "loss": 5.2537,
      "step": 7408
    },
    {
      "epoch": 0.8495585368650385,
      "grad_norm": 0.0,
      "learning_rate": 5.8285681045897535e-05,
      "loss": 4.9219,
      "step": 7409
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.0,
      "learning_rate": 5.8198775746250766e-05,
      "loss": 5.2359,
      "step": 7410
    },
    {
      "epoch": 0.8497878683637198,
      "grad_norm": 0.0,
      "learning_rate": 5.8111931391558144e-05,
      "loss": 5.2589,
      "step": 7411
    },
    {
      "epoch": 0.8499025341130604,
      "grad_norm": 0.0,
      "learning_rate": 5.8025147993797854e-05,
      "loss": 5.0277,
      "step": 7412
    },
    {
      "epoch": 0.8500171998624011,
      "grad_norm": 0.0,
      "learning_rate": 5.7938425564940275e-05,
      "loss": 4.7326,
      "step": 7413
    },
    {
      "epoch": 0.8501318656117418,
      "grad_norm": 0.0,
      "learning_rate": 5.785176411694687e-05,
      "loss": 5.1201,
      "step": 7414
    },
    {
      "epoch": 0.8502465313610824,
      "grad_norm": 0.0,
      "learning_rate": 5.776516366177105e-05,
      "loss": 5.1388,
      "step": 7415
    },
    {
      "epoch": 0.8503611971104231,
      "grad_norm": 0.0,
      "learning_rate": 5.7678624211357833e-05,
      "loss": 5.0714,
      "step": 7416
    },
    {
      "epoch": 0.8504758628597638,
      "grad_norm": 0.0,
      "learning_rate": 5.759214577764326e-05,
      "loss": 4.9779,
      "step": 7417
    },
    {
      "epoch": 0.8505905286091044,
      "grad_norm": 0.0,
      "learning_rate": 5.750572837255593e-05,
      "loss": 4.8138,
      "step": 7418
    },
    {
      "epoch": 0.8507051943584452,
      "grad_norm": 0.0,
      "learning_rate": 5.741937200801505e-05,
      "loss": 5.0276,
      "step": 7419
    },
    {
      "epoch": 0.8508198601077858,
      "grad_norm": 0.0,
      "learning_rate": 5.733307669593203e-05,
      "loss": 4.8294,
      "step": 7420
    },
    {
      "epoch": 0.8509345258571265,
      "grad_norm": 0.0,
      "learning_rate": 5.724684244820964e-05,
      "loss": 5.0868,
      "step": 7421
    },
    {
      "epoch": 0.8510491916064672,
      "grad_norm": 0.0,
      "learning_rate": 5.716066927674224e-05,
      "loss": 5.0741,
      "step": 7422
    },
    {
      "epoch": 0.8511638573558078,
      "grad_norm": 0.0,
      "learning_rate": 5.707455719341573e-05,
      "loss": 4.9187,
      "step": 7423
    },
    {
      "epoch": 0.8512785231051485,
      "grad_norm": 0.0,
      "learning_rate": 5.698850621010772e-05,
      "loss": 4.7669,
      "step": 7424
    },
    {
      "epoch": 0.8513931888544891,
      "grad_norm": 0.0,
      "learning_rate": 5.6902516338687354e-05,
      "loss": 4.9622,
      "step": 7425
    },
    {
      "epoch": 0.8515078546038298,
      "grad_norm": 0.0,
      "learning_rate": 5.6816587591015056e-05,
      "loss": 5.0533,
      "step": 7426
    },
    {
      "epoch": 0.8516225203531705,
      "grad_norm": 0.0,
      "learning_rate": 5.673071997894327e-05,
      "loss": 5.1008,
      "step": 7427
    },
    {
      "epoch": 0.8517371861025111,
      "grad_norm": 0.0,
      "learning_rate": 5.664491351431569e-05,
      "loss": 4.8032,
      "step": 7428
    },
    {
      "epoch": 0.8518518518518519,
      "grad_norm": 0.0,
      "learning_rate": 5.65591682089677e-05,
      "loss": 4.9308,
      "step": 7429
    },
    {
      "epoch": 0.8519665176011926,
      "grad_norm": 0.0,
      "learning_rate": 5.6473484074726273e-05,
      "loss": 4.8975,
      "step": 7430
    },
    {
      "epoch": 0.8520811833505332,
      "grad_norm": 0.0,
      "learning_rate": 5.6387861123410006e-05,
      "loss": 5.159,
      "step": 7431
    },
    {
      "epoch": 0.8521958490998739,
      "grad_norm": 0.0,
      "learning_rate": 5.6302299366828586e-05,
      "loss": 4.9882,
      "step": 7432
    },
    {
      "epoch": 0.8523105148492145,
      "grad_norm": 0.0,
      "learning_rate": 5.6216798816784115e-05,
      "loss": 4.8614,
      "step": 7433
    },
    {
      "epoch": 0.8524251805985552,
      "grad_norm": 0.0,
      "learning_rate": 5.613135948506938e-05,
      "loss": 5.2323,
      "step": 7434
    },
    {
      "epoch": 0.8525398463478959,
      "grad_norm": 0.0,
      "learning_rate": 5.604598138346921e-05,
      "loss": 5.2006,
      "step": 7435
    },
    {
      "epoch": 0.8526545120972365,
      "grad_norm": 0.0,
      "learning_rate": 5.596066452376007e-05,
      "loss": 5.068,
      "step": 7436
    },
    {
      "epoch": 0.8527691778465772,
      "grad_norm": 0.0,
      "learning_rate": 5.5875408917709457e-05,
      "loss": 4.7862,
      "step": 7437
    },
    {
      "epoch": 0.8528838435959178,
      "grad_norm": 0.0,
      "learning_rate": 5.57902145770771e-05,
      "loss": 5.0762,
      "step": 7438
    },
    {
      "epoch": 0.8529985093452586,
      "grad_norm": 0.0,
      "learning_rate": 5.5705081513613624e-05,
      "loss": 5.0299,
      "step": 7439
    },
    {
      "epoch": 0.8531131750945993,
      "grad_norm": 0.0,
      "learning_rate": 5.562000973906185e-05,
      "loss": 4.8036,
      "step": 7440
    },
    {
      "epoch": 0.8532278408439399,
      "grad_norm": 0.0,
      "learning_rate": 5.553499926515545e-05,
      "loss": 4.7787,
      "step": 7441
    },
    {
      "epoch": 0.8533425065932806,
      "grad_norm": 0.0,
      "learning_rate": 5.5450050103620355e-05,
      "loss": 5.0599,
      "step": 7442
    },
    {
      "epoch": 0.8534571723426213,
      "grad_norm": 0.0,
      "learning_rate": 5.536516226617337e-05,
      "loss": 5.0581,
      "step": 7443
    },
    {
      "epoch": 0.8535718380919619,
      "grad_norm": 0.0,
      "learning_rate": 5.528033576452333e-05,
      "loss": 5.0337,
      "step": 7444
    },
    {
      "epoch": 0.8536865038413026,
      "grad_norm": 0.0,
      "learning_rate": 5.5195570610370494e-05,
      "loss": 4.8073,
      "step": 7445
    },
    {
      "epoch": 0.8538011695906432,
      "grad_norm": 0.0,
      "learning_rate": 5.511086681540627e-05,
      "loss": 4.8969,
      "step": 7446
    },
    {
      "epoch": 0.8539158353399839,
      "grad_norm": 0.0,
      "learning_rate": 5.502622439131433e-05,
      "loss": 4.7638,
      "step": 7447
    },
    {
      "epoch": 0.8540305010893247,
      "grad_norm": 0.0,
      "learning_rate": 5.4941643349769266e-05,
      "loss": 4.8322,
      "step": 7448
    },
    {
      "epoch": 0.8541451668386653,
      "grad_norm": 0.0,
      "learning_rate": 5.4857123702437474e-05,
      "loss": 5.1461,
      "step": 7449
    },
    {
      "epoch": 0.854259832588006,
      "grad_norm": 0.0,
      "learning_rate": 5.4772665460976786e-05,
      "loss": 4.9455,
      "step": 7450
    },
    {
      "epoch": 0.8543744983373467,
      "grad_norm": 0.0,
      "learning_rate": 5.46882686370366e-05,
      "loss": 4.9749,
      "step": 7451
    },
    {
      "epoch": 0.8544891640866873,
      "grad_norm": 0.0,
      "learning_rate": 5.460393324225796e-05,
      "loss": 5.002,
      "step": 7452
    },
    {
      "epoch": 0.854603829836028,
      "grad_norm": 0.0,
      "learning_rate": 5.4519659288273325e-05,
      "loss": 5.1858,
      "step": 7453
    },
    {
      "epoch": 0.8547184955853686,
      "grad_norm": 0.0,
      "learning_rate": 5.443544678670641e-05,
      "loss": 5.0684,
      "step": 7454
    },
    {
      "epoch": 0.8548331613347093,
      "grad_norm": 0.0,
      "learning_rate": 5.435129574917314e-05,
      "loss": 4.9931,
      "step": 7455
    },
    {
      "epoch": 0.85494782708405,
      "grad_norm": 0.0,
      "learning_rate": 5.426720618728019e-05,
      "loss": 4.9566,
      "step": 7456
    },
    {
      "epoch": 0.8550624928333906,
      "grad_norm": 0.0,
      "learning_rate": 5.418317811262628e-05,
      "loss": 4.9411,
      "step": 7457
    },
    {
      "epoch": 0.8551771585827314,
      "grad_norm": 0.0,
      "learning_rate": 5.409921153680159e-05,
      "loss": 5.0873,
      "step": 7458
    },
    {
      "epoch": 0.855291824332072,
      "grad_norm": 0.0,
      "learning_rate": 5.4015306471387314e-05,
      "loss": 4.9871,
      "step": 7459
    },
    {
      "epoch": 0.8554064900814127,
      "grad_norm": 0.0,
      "learning_rate": 5.3931462927957025e-05,
      "loss": 5.0282,
      "step": 7460
    },
    {
      "epoch": 0.8555211558307534,
      "grad_norm": 0.0,
      "learning_rate": 5.384768091807499e-05,
      "loss": 4.9712,
      "step": 7461
    },
    {
      "epoch": 0.855635821580094,
      "grad_norm": 0.0,
      "learning_rate": 5.3763960453297596e-05,
      "loss": 5.1316,
      "step": 7462
    },
    {
      "epoch": 0.8557504873294347,
      "grad_norm": 0.0,
      "learning_rate": 5.368030154517226e-05,
      "loss": 5.0692,
      "step": 7463
    },
    {
      "epoch": 0.8558651530787754,
      "grad_norm": 0.0,
      "learning_rate": 5.359670420523839e-05,
      "loss": 4.9991,
      "step": 7464
    },
    {
      "epoch": 0.855979818828116,
      "grad_norm": 0.0,
      "learning_rate": 5.3513168445026496e-05,
      "loss": 4.7637,
      "step": 7465
    },
    {
      "epoch": 0.8560944845774567,
      "grad_norm": 0.0,
      "learning_rate": 5.342969427605854e-05,
      "loss": 5.099,
      "step": 7466
    },
    {
      "epoch": 0.8562091503267973,
      "grad_norm": 0.0,
      "learning_rate": 5.334628170984865e-05,
      "loss": 4.91,
      "step": 7467
    },
    {
      "epoch": 0.8563238160761381,
      "grad_norm": 0.0,
      "learning_rate": 5.326293075790155e-05,
      "loss": 4.9368,
      "step": 7468
    },
    {
      "epoch": 0.8564384818254788,
      "grad_norm": 0.0,
      "learning_rate": 5.317964143171426e-05,
      "loss": 5.0123,
      "step": 7469
    },
    {
      "epoch": 0.8565531475748194,
      "grad_norm": 0.0,
      "learning_rate": 5.309641374277473e-05,
      "loss": 5.178,
      "step": 7470
    },
    {
      "epoch": 0.8566678133241601,
      "grad_norm": 0.0,
      "learning_rate": 5.301324770256272e-05,
      "loss": 5.1512,
      "step": 7471
    },
    {
      "epoch": 0.8567824790735007,
      "grad_norm": 0.0,
      "learning_rate": 5.2930143322549436e-05,
      "loss": 4.9869,
      "step": 7472
    },
    {
      "epoch": 0.8568971448228414,
      "grad_norm": 0.0,
      "learning_rate": 5.284710061419743e-05,
      "loss": 4.8278,
      "step": 7473
    },
    {
      "epoch": 0.8570118105721821,
      "grad_norm": 0.0,
      "learning_rate": 5.276411958896101e-05,
      "loss": 5.3219,
      "step": 7474
    },
    {
      "epoch": 0.8571264763215227,
      "grad_norm": 0.0,
      "learning_rate": 5.268120025828576e-05,
      "loss": 5.2406,
      "step": 7475
    },
    {
      "epoch": 0.8572411420708634,
      "grad_norm": 0.0,
      "learning_rate": 5.259834263360879e-05,
      "loss": 4.6336,
      "step": 7476
    },
    {
      "epoch": 0.8573558078202042,
      "grad_norm": 0.0,
      "learning_rate": 5.2515546726358685e-05,
      "loss": 4.9398,
      "step": 7477
    },
    {
      "epoch": 0.8574704735695448,
      "grad_norm": 0.0,
      "learning_rate": 5.243281254795567e-05,
      "loss": 5.0325,
      "step": 7478
    },
    {
      "epoch": 0.8575851393188855,
      "grad_norm": 0.0,
      "learning_rate": 5.2350140109811264e-05,
      "loss": 4.9558,
      "step": 7479
    },
    {
      "epoch": 0.8576998050682261,
      "grad_norm": 0.0,
      "learning_rate": 5.2267529423328744e-05,
      "loss": 5.1625,
      "step": 7480
    },
    {
      "epoch": 0.8578144708175668,
      "grad_norm": 0.0,
      "learning_rate": 5.2184980499902306e-05,
      "loss": 5.0805,
      "step": 7481
    },
    {
      "epoch": 0.8579291365669075,
      "grad_norm": 0.0,
      "learning_rate": 5.210249335091844e-05,
      "loss": 5.1368,
      "step": 7482
    },
    {
      "epoch": 0.8580438023162481,
      "grad_norm": 0.0,
      "learning_rate": 5.202006798775421e-05,
      "loss": 4.9566,
      "step": 7483
    },
    {
      "epoch": 0.8581584680655888,
      "grad_norm": 0.0,
      "learning_rate": 5.193770442177912e-05,
      "loss": 4.8964,
      "step": 7484
    },
    {
      "epoch": 0.8582731338149295,
      "grad_norm": 0.0,
      "learning_rate": 5.185540266435328e-05,
      "loss": 4.7995,
      "step": 7485
    },
    {
      "epoch": 0.8583877995642701,
      "grad_norm": 0.0,
      "learning_rate": 5.177316272682882e-05,
      "loss": 5.0831,
      "step": 7486
    },
    {
      "epoch": 0.8585024653136109,
      "grad_norm": 0.0,
      "learning_rate": 5.169098462054917e-05,
      "loss": 4.916,
      "step": 7487
    },
    {
      "epoch": 0.8586171310629515,
      "grad_norm": 0.0,
      "learning_rate": 5.160886835684903e-05,
      "loss": 5.2249,
      "step": 7488
    },
    {
      "epoch": 0.8587317968122922,
      "grad_norm": 0.0,
      "learning_rate": 5.152681394705511e-05,
      "loss": 4.708,
      "step": 7489
    },
    {
      "epoch": 0.8588464625616329,
      "grad_norm": 0.0,
      "learning_rate": 5.144482140248492e-05,
      "loss": 4.8924,
      "step": 7490
    },
    {
      "epoch": 0.8589611283109735,
      "grad_norm": 0.0,
      "learning_rate": 5.1362890734448074e-05,
      "loss": 5.2925,
      "step": 7491
    },
    {
      "epoch": 0.8590757940603142,
      "grad_norm": 0.0,
      "learning_rate": 5.128102195424512e-05,
      "loss": 4.915,
      "step": 7492
    },
    {
      "epoch": 0.8591904598096548,
      "grad_norm": 0.0,
      "learning_rate": 5.119921507316835e-05,
      "loss": 4.87,
      "step": 7493
    },
    {
      "epoch": 0.8593051255589955,
      "grad_norm": 0.0,
      "learning_rate": 5.1117470102501535e-05,
      "loss": 4.8797,
      "step": 7494
    },
    {
      "epoch": 0.8594197913083362,
      "grad_norm": 0.0,
      "learning_rate": 5.103578705351976e-05,
      "loss": 4.8357,
      "step": 7495
    },
    {
      "epoch": 0.8595344570576768,
      "grad_norm": 0.0,
      "learning_rate": 5.095416593748977e-05,
      "loss": 5.1833,
      "step": 7496
    },
    {
      "epoch": 0.8596491228070176,
      "grad_norm": 0.0,
      "learning_rate": 5.087260676566944e-05,
      "loss": 5.0381,
      "step": 7497
    },
    {
      "epoch": 0.8597637885563583,
      "grad_norm": 0.0,
      "learning_rate": 5.0791109549308415e-05,
      "loss": 4.9436,
      "step": 7498
    },
    {
      "epoch": 0.8598784543056989,
      "grad_norm": 0.0,
      "learning_rate": 5.070967429964763e-05,
      "loss": 5.0353,
      "step": 7499
    },
    {
      "epoch": 0.8599931200550396,
      "grad_norm": 0.0,
      "learning_rate": 5.0628301027919596e-05,
      "loss": 5.2378,
      "step": 7500
    },
    {
      "epoch": 0.8601077858043802,
      "grad_norm": 0.0,
      "learning_rate": 5.054698974534821e-05,
      "loss": 4.9501,
      "step": 7501
    },
    {
      "epoch": 0.8602224515537209,
      "grad_norm": 0.0,
      "learning_rate": 5.0465740463148884e-05,
      "loss": 4.8247,
      "step": 7502
    },
    {
      "epoch": 0.8603371173030616,
      "grad_norm": 0.0,
      "learning_rate": 5.038455319252807e-05,
      "loss": 4.9853,
      "step": 7503
    },
    {
      "epoch": 0.8604517830524022,
      "grad_norm": 0.0,
      "learning_rate": 5.030342794468448e-05,
      "loss": 4.9312,
      "step": 7504
    },
    {
      "epoch": 0.8605664488017429,
      "grad_norm": 0.0,
      "learning_rate": 5.022236473080732e-05,
      "loss": 5.0361,
      "step": 7505
    },
    {
      "epoch": 0.8606811145510835,
      "grad_norm": 0.0,
      "learning_rate": 5.014136356207813e-05,
      "loss": 5.0045,
      "step": 7506
    },
    {
      "epoch": 0.8607957803004243,
      "grad_norm": 0.0,
      "learning_rate": 5.006042444966925e-05,
      "loss": 4.7779,
      "step": 7507
    },
    {
      "epoch": 0.860910446049765,
      "grad_norm": 0.0,
      "learning_rate": 4.99795474047447e-05,
      "loss": 4.734,
      "step": 7508
    },
    {
      "epoch": 0.8610251117991056,
      "grad_norm": 0.0,
      "learning_rate": 4.9898732438460084e-05,
      "loss": 5.0348,
      "step": 7509
    },
    {
      "epoch": 0.8611397775484463,
      "grad_norm": 0.0,
      "learning_rate": 4.9817979561961934e-05,
      "loss": 4.9677,
      "step": 7510
    },
    {
      "epoch": 0.861254443297787,
      "grad_norm": 0.0,
      "learning_rate": 4.9737288786389064e-05,
      "loss": 4.8409,
      "step": 7511
    },
    {
      "epoch": 0.8613691090471276,
      "grad_norm": 0.0,
      "learning_rate": 4.965666012287068e-05,
      "loss": 5.0809,
      "step": 7512
    },
    {
      "epoch": 0.8614837747964683,
      "grad_norm": 0.0,
      "learning_rate": 4.9576093582528534e-05,
      "loss": 4.72,
      "step": 7513
    },
    {
      "epoch": 0.8615984405458089,
      "grad_norm": 0.0,
      "learning_rate": 4.949558917647481e-05,
      "loss": 5.1611,
      "step": 7514
    },
    {
      "epoch": 0.8617131062951496,
      "grad_norm": 0.0,
      "learning_rate": 4.941514691581373e-05,
      "loss": 5.2628,
      "step": 7515
    },
    {
      "epoch": 0.8618277720444903,
      "grad_norm": 0.0,
      "learning_rate": 4.9334766811640815e-05,
      "loss": 5.0368,
      "step": 7516
    },
    {
      "epoch": 0.861942437793831,
      "grad_norm": 0.0,
      "learning_rate": 4.9254448875042794e-05,
      "loss": 5.3127,
      "step": 7517
    },
    {
      "epoch": 0.8620571035431717,
      "grad_norm": 0.0,
      "learning_rate": 4.917419311709821e-05,
      "loss": 4.9356,
      "step": 7518
    },
    {
      "epoch": 0.8621717692925124,
      "grad_norm": 0.0,
      "learning_rate": 4.9093999548876644e-05,
      "loss": 5.1164,
      "step": 7519
    },
    {
      "epoch": 0.862286435041853,
      "grad_norm": 0.0,
      "learning_rate": 4.9013868181439364e-05,
      "loss": 5.1109,
      "step": 7520
    },
    {
      "epoch": 0.8624011007911937,
      "grad_norm": 0.0,
      "learning_rate": 4.893379902583894e-05,
      "loss": 5.1524,
      "step": 7521
    },
    {
      "epoch": 0.8625157665405343,
      "grad_norm": 0.0,
      "learning_rate": 4.885379209311936e-05,
      "loss": 4.7485,
      "step": 7522
    },
    {
      "epoch": 0.862630432289875,
      "grad_norm": 0.0,
      "learning_rate": 4.877384739431603e-05,
      "loss": 4.7821,
      "step": 7523
    },
    {
      "epoch": 0.8627450980392157,
      "grad_norm": 0.0,
      "learning_rate": 4.8693964940456026e-05,
      "loss": 5.1429,
      "step": 7524
    },
    {
      "epoch": 0.8628597637885563,
      "grad_norm": 0.0,
      "learning_rate": 4.8614144742557206e-05,
      "loss": 4.8031,
      "step": 7525
    },
    {
      "epoch": 0.862974429537897,
      "grad_norm": 0.0,
      "learning_rate": 4.853438681162967e-05,
      "loss": 4.9551,
      "step": 7526
    },
    {
      "epoch": 0.8630890952872377,
      "grad_norm": 0.0,
      "learning_rate": 4.8454691158674164e-05,
      "loss": 5.2451,
      "step": 7527
    },
    {
      "epoch": 0.8632037610365784,
      "grad_norm": 0.0,
      "learning_rate": 4.837505779468338e-05,
      "loss": 5.0504,
      "step": 7528
    },
    {
      "epoch": 0.8633184267859191,
      "grad_norm": 0.0,
      "learning_rate": 4.8295486730641134e-05,
      "loss": 4.8265,
      "step": 7529
    },
    {
      "epoch": 0.8634330925352597,
      "grad_norm": 0.0,
      "learning_rate": 4.8215977977522775e-05,
      "loss": 4.6721,
      "step": 7530
    },
    {
      "epoch": 0.8635477582846004,
      "grad_norm": 0.0,
      "learning_rate": 4.813653154629509e-05,
      "loss": 5.0029,
      "step": 7531
    },
    {
      "epoch": 0.8636624240339411,
      "grad_norm": 0.0,
      "learning_rate": 4.8057147447915955e-05,
      "loss": 4.9836,
      "step": 7532
    },
    {
      "epoch": 0.8637770897832817,
      "grad_norm": 0.0,
      "learning_rate": 4.797782569333523e-05,
      "loss": 5.04,
      "step": 7533
    },
    {
      "epoch": 0.8638917555326224,
      "grad_norm": 0.0,
      "learning_rate": 4.789856629349352e-05,
      "loss": 4.9815,
      "step": 7534
    },
    {
      "epoch": 0.864006421281963,
      "grad_norm": 0.0,
      "learning_rate": 4.7819369259323474e-05,
      "loss": 5.1234,
      "step": 7535
    },
    {
      "epoch": 0.8641210870313037,
      "grad_norm": 0.0,
      "learning_rate": 4.774023460174854e-05,
      "loss": 5.0553,
      "step": 7536
    },
    {
      "epoch": 0.8642357527806445,
      "grad_norm": 0.0,
      "learning_rate": 4.7661162331683906e-05,
      "loss": 4.9099,
      "step": 7537
    },
    {
      "epoch": 0.8643504185299851,
      "grad_norm": 0.0,
      "learning_rate": 4.758215246003624e-05,
      "loss": 5.0001,
      "step": 7538
    },
    {
      "epoch": 0.8644650842793258,
      "grad_norm": 0.0,
      "learning_rate": 4.7503204997703134e-05,
      "loss": 4.881,
      "step": 7539
    },
    {
      "epoch": 0.8645797500286664,
      "grad_norm": 0.0,
      "learning_rate": 4.742431995557429e-05,
      "loss": 4.82,
      "step": 7540
    },
    {
      "epoch": 0.8646944157780071,
      "grad_norm": 0.0,
      "learning_rate": 4.734549734453001e-05,
      "loss": 5.0709,
      "step": 7541
    },
    {
      "epoch": 0.8648090815273478,
      "grad_norm": 0.0,
      "learning_rate": 4.726673717544258e-05,
      "loss": 4.9793,
      "step": 7542
    },
    {
      "epoch": 0.8649237472766884,
      "grad_norm": 0.0,
      "learning_rate": 4.718803945917544e-05,
      "loss": 4.872,
      "step": 7543
    },
    {
      "epoch": 0.8650384130260291,
      "grad_norm": 0.0,
      "learning_rate": 4.710940420658338e-05,
      "loss": 5.2182,
      "step": 7544
    },
    {
      "epoch": 0.8651530787753698,
      "grad_norm": 0.0,
      "learning_rate": 4.703083142851268e-05,
      "loss": 5.0679,
      "step": 7545
    },
    {
      "epoch": 0.8652677445247104,
      "grad_norm": 0.0,
      "learning_rate": 4.695232113580105e-05,
      "loss": 5.0122,
      "step": 7546
    },
    {
      "epoch": 0.8653824102740512,
      "grad_norm": 0.0,
      "learning_rate": 4.687387333927734e-05,
      "loss": 5.1485,
      "step": 7547
    },
    {
      "epoch": 0.8654970760233918,
      "grad_norm": 0.0,
      "learning_rate": 4.6795488049761935e-05,
      "loss": 5.1012,
      "step": 7548
    },
    {
      "epoch": 0.8656117417727325,
      "grad_norm": 0.0,
      "learning_rate": 4.671716527806665e-05,
      "loss": 4.8722,
      "step": 7549
    },
    {
      "epoch": 0.8657264075220732,
      "grad_norm": 0.0,
      "learning_rate": 4.66389050349946e-05,
      "loss": 5.1012,
      "step": 7550
    },
    {
      "epoch": 0.8658410732714138,
      "grad_norm": 0.0,
      "learning_rate": 4.6560707331340345e-05,
      "loss": 4.8505,
      "step": 7551
    },
    {
      "epoch": 0.8659557390207545,
      "grad_norm": 0.0,
      "learning_rate": 4.6482572177889676e-05,
      "loss": 5.1335,
      "step": 7552
    },
    {
      "epoch": 0.8660704047700952,
      "grad_norm": 0.0,
      "learning_rate": 4.640449958542001e-05,
      "loss": 5.0847,
      "step": 7553
    },
    {
      "epoch": 0.8661850705194358,
      "grad_norm": 0.0,
      "learning_rate": 4.6326489564699655e-05,
      "loss": 4.8158,
      "step": 7554
    },
    {
      "epoch": 0.8662997362687765,
      "grad_norm": 0.0,
      "learning_rate": 4.624854212648898e-05,
      "loss": 4.9367,
      "step": 7555
    },
    {
      "epoch": 0.8664144020181171,
      "grad_norm": 0.0,
      "learning_rate": 4.617065728153908e-05,
      "loss": 5.3612,
      "step": 7556
    },
    {
      "epoch": 0.8665290677674579,
      "grad_norm": 0.0,
      "learning_rate": 4.6092835040592796e-05,
      "loss": 5.0114,
      "step": 7557
    },
    {
      "epoch": 0.8666437335167986,
      "grad_norm": 0.0,
      "learning_rate": 4.6015075414384304e-05,
      "loss": 4.8468,
      "step": 7558
    },
    {
      "epoch": 0.8667583992661392,
      "grad_norm": 0.0,
      "learning_rate": 4.593737841363877e-05,
      "loss": 5.1449,
      "step": 7559
    },
    {
      "epoch": 0.8668730650154799,
      "grad_norm": 0.0,
      "learning_rate": 4.5859744049073394e-05,
      "loss": 4.9289,
      "step": 7560
    },
    {
      "epoch": 0.8669877307648205,
      "grad_norm": 0.0,
      "learning_rate": 4.5782172331395976e-05,
      "loss": 5.0837,
      "step": 7561
    },
    {
      "epoch": 0.8671023965141612,
      "grad_norm": 0.0,
      "learning_rate": 4.5704663271306505e-05,
      "loss": 4.7767,
      "step": 7562
    },
    {
      "epoch": 0.8672170622635019,
      "grad_norm": 0.0,
      "learning_rate": 4.5627216879495464e-05,
      "loss": 5.1892,
      "step": 7563
    },
    {
      "epoch": 0.8673317280128425,
      "grad_norm": 0.0,
      "learning_rate": 4.5549833166645295e-05,
      "loss": 5.0248,
      "step": 7564
    },
    {
      "epoch": 0.8674463937621832,
      "grad_norm": 0.0,
      "learning_rate": 4.547251214342956e-05,
      "loss": 5.0436,
      "step": 7565
    },
    {
      "epoch": 0.867561059511524,
      "grad_norm": 0.0,
      "learning_rate": 4.5395253820513274e-05,
      "loss": 4.8298,
      "step": 7566
    },
    {
      "epoch": 0.8676757252608646,
      "grad_norm": 0.0,
      "learning_rate": 4.531805820855278e-05,
      "loss": 4.802,
      "step": 7567
    },
    {
      "epoch": 0.8677903910102053,
      "grad_norm": 0.0,
      "learning_rate": 4.524092531819557e-05,
      "loss": 5.1886,
      "step": 7568
    },
    {
      "epoch": 0.8679050567595459,
      "grad_norm": 0.0,
      "learning_rate": 4.516385516008077e-05,
      "loss": 4.997,
      "step": 7569
    },
    {
      "epoch": 0.8680197225088866,
      "grad_norm": 0.0,
      "learning_rate": 4.5086847744838766e-05,
      "loss": 5.1222,
      "step": 7570
    },
    {
      "epoch": 0.8681343882582273,
      "grad_norm": 0.0,
      "learning_rate": 4.500990308309123e-05,
      "loss": 5.1276,
      "step": 7571
    },
    {
      "epoch": 0.8682490540075679,
      "grad_norm": 0.0,
      "learning_rate": 4.4933021185451144e-05,
      "loss": 4.9366,
      "step": 7572
    },
    {
      "epoch": 0.8683637197569086,
      "grad_norm": 0.0,
      "learning_rate": 4.4856202062523044e-05,
      "loss": 4.7003,
      "step": 7573
    },
    {
      "epoch": 0.8684783855062492,
      "grad_norm": 0.0,
      "learning_rate": 4.477944572490254e-05,
      "loss": 4.9389,
      "step": 7574
    },
    {
      "epoch": 0.8685930512555899,
      "grad_norm": 0.0,
      "learning_rate": 4.470275218317684e-05,
      "loss": 5.0058,
      "step": 7575
    },
    {
      "epoch": 0.8687077170049307,
      "grad_norm": 0.0,
      "learning_rate": 4.462612144792414e-05,
      "loss": 5.022,
      "step": 7576
    },
    {
      "epoch": 0.8688223827542713,
      "grad_norm": 0.0,
      "learning_rate": 4.454955352971443e-05,
      "loss": 4.9815,
      "step": 7577
    },
    {
      "epoch": 0.868937048503612,
      "grad_norm": 0.0,
      "learning_rate": 4.447304843910864e-05,
      "loss": 5.0778,
      "step": 7578
    },
    {
      "epoch": 0.8690517142529527,
      "grad_norm": 0.0,
      "learning_rate": 4.439660618665923e-05,
      "loss": 4.8691,
      "step": 7579
    },
    {
      "epoch": 0.8691663800022933,
      "grad_norm": 0.0,
      "learning_rate": 4.432022678291003e-05,
      "loss": 5.1967,
      "step": 7580
    },
    {
      "epoch": 0.869281045751634,
      "grad_norm": 0.0,
      "learning_rate": 4.424391023839585e-05,
      "loss": 5.3347,
      "step": 7581
    },
    {
      "epoch": 0.8693957115009746,
      "grad_norm": 0.0,
      "learning_rate": 4.4167656563643486e-05,
      "loss": 4.8936,
      "step": 7582
    },
    {
      "epoch": 0.8695103772503153,
      "grad_norm": 0.0,
      "learning_rate": 4.4091465769170305e-05,
      "loss": 5.0577,
      "step": 7583
    },
    {
      "epoch": 0.869625042999656,
      "grad_norm": 0.0,
      "learning_rate": 4.401533786548575e-05,
      "loss": 5.0412,
      "step": 7584
    },
    {
      "epoch": 0.8697397087489966,
      "grad_norm": 0.0,
      "learning_rate": 4.3939272863089966e-05,
      "loss": 5.081,
      "step": 7585
    },
    {
      "epoch": 0.8698543744983374,
      "grad_norm": 0.0,
      "learning_rate": 4.3863270772474677e-05,
      "loss": 5.0304,
      "step": 7586
    },
    {
      "epoch": 0.8699690402476781,
      "grad_norm": 0.0,
      "learning_rate": 4.3787331604123066e-05,
      "loss": 4.9781,
      "step": 7587
    },
    {
      "epoch": 0.8700837059970187,
      "grad_norm": 0.0,
      "learning_rate": 4.371145536850926e-05,
      "loss": 5.1004,
      "step": 7588
    },
    {
      "epoch": 0.8701983717463594,
      "grad_norm": 0.0,
      "learning_rate": 4.363564207609924e-05,
      "loss": 5.1049,
      "step": 7589
    },
    {
      "epoch": 0.8703130374957,
      "grad_norm": 0.0,
      "learning_rate": 4.355989173734979e-05,
      "loss": 4.8458,
      "step": 7590
    },
    {
      "epoch": 0.8704277032450407,
      "grad_norm": 0.0,
      "learning_rate": 4.348420436270925e-05,
      "loss": 5.0049,
      "step": 7591
    },
    {
      "epoch": 0.8705423689943814,
      "grad_norm": 0.0,
      "learning_rate": 4.340857996261727e-05,
      "loss": 4.71,
      "step": 7592
    },
    {
      "epoch": 0.870657034743722,
      "grad_norm": 0.0,
      "learning_rate": 4.3333018547504813e-05,
      "loss": 4.6375,
      "step": 7593
    },
    {
      "epoch": 0.8707717004930627,
      "grad_norm": 0.0,
      "learning_rate": 4.325752012779414e-05,
      "loss": 5.1827,
      "step": 7594
    },
    {
      "epoch": 0.8708863662424033,
      "grad_norm": 0.0,
      "learning_rate": 4.318208471389885e-05,
      "loss": 4.9032,
      "step": 7595
    },
    {
      "epoch": 0.8710010319917441,
      "grad_norm": 0.0,
      "learning_rate": 4.310671231622372e-05,
      "loss": 5.043,
      "step": 7596
    },
    {
      "epoch": 0.8711156977410848,
      "grad_norm": 0.0,
      "learning_rate": 4.3031402945165124e-05,
      "loss": 5.1945,
      "step": 7597
    },
    {
      "epoch": 0.8712303634904254,
      "grad_norm": 0.0,
      "learning_rate": 4.295615661111028e-05,
      "loss": 4.7335,
      "step": 7598
    },
    {
      "epoch": 0.8713450292397661,
      "grad_norm": 0.0,
      "learning_rate": 4.288097332443816e-05,
      "loss": 5.1872,
      "step": 7599
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.0,
      "learning_rate": 4.2805853095518836e-05,
      "loss": 5.1372,
      "step": 7600
    },
    {
      "epoch": 0.8715743607384474,
      "grad_norm": 0.0,
      "learning_rate": 4.27307959347137e-05,
      "loss": 5.0612,
      "step": 7601
    },
    {
      "epoch": 0.8716890264877881,
      "grad_norm": 0.0,
      "learning_rate": 4.26558018523756e-05,
      "loss": 5.0844,
      "step": 7602
    },
    {
      "epoch": 0.8718036922371287,
      "grad_norm": 0.0,
      "learning_rate": 4.258087085884817e-05,
      "loss": 4.8388,
      "step": 7603
    },
    {
      "epoch": 0.8719183579864694,
      "grad_norm": 0.0,
      "learning_rate": 4.2506002964467175e-05,
      "loss": 4.9424,
      "step": 7604
    },
    {
      "epoch": 0.8720330237358102,
      "grad_norm": 0.0,
      "learning_rate": 4.243119817955881e-05,
      "loss": 4.9628,
      "step": 7605
    },
    {
      "epoch": 0.8721476894851508,
      "grad_norm": 0.0,
      "learning_rate": 4.2356456514441286e-05,
      "loss": 5.0778,
      "step": 7606
    },
    {
      "epoch": 0.8722623552344915,
      "grad_norm": 0.0,
      "learning_rate": 4.22817779794236e-05,
      "loss": 5.0877,
      "step": 7607
    },
    {
      "epoch": 0.8723770209838321,
      "grad_norm": 0.0,
      "learning_rate": 4.220716258480628e-05,
      "loss": 4.9928,
      "step": 7608
    },
    {
      "epoch": 0.8724916867331728,
      "grad_norm": 0.0,
      "learning_rate": 4.2132610340881204e-05,
      "loss": 4.9868,
      "step": 7609
    },
    {
      "epoch": 0.8726063524825135,
      "grad_norm": 0.0,
      "learning_rate": 4.205812125793114e-05,
      "loss": 4.9022,
      "step": 7610
    },
    {
      "epoch": 0.8727210182318541,
      "grad_norm": 0.0,
      "learning_rate": 4.198369534623077e-05,
      "loss": 4.9077,
      "step": 7611
    },
    {
      "epoch": 0.8728356839811948,
      "grad_norm": 0.0,
      "learning_rate": 4.190933261604552e-05,
      "loss": 5.2066,
      "step": 7612
    },
    {
      "epoch": 0.8729503497305355,
      "grad_norm": 0.0,
      "learning_rate": 4.18350330776324e-05,
      "loss": 5.0713,
      "step": 7613
    },
    {
      "epoch": 0.8730650154798761,
      "grad_norm": 0.0,
      "learning_rate": 4.176079674123961e-05,
      "loss": 5.0018,
      "step": 7614
    },
    {
      "epoch": 0.8731796812292169,
      "grad_norm": 0.0,
      "learning_rate": 4.1686623617106604e-05,
      "loss": 4.9493,
      "step": 7615
    },
    {
      "epoch": 0.8732943469785575,
      "grad_norm": 0.0,
      "learning_rate": 4.1612513715464184e-05,
      "loss": 4.7796,
      "step": 7616
    },
    {
      "epoch": 0.8734090127278982,
      "grad_norm": 0.0,
      "learning_rate": 4.153846704653437e-05,
      "loss": 5.0733,
      "step": 7617
    },
    {
      "epoch": 0.8735236784772389,
      "grad_norm": 0.0,
      "learning_rate": 4.146448362053058e-05,
      "loss": 4.9204,
      "step": 7618
    },
    {
      "epoch": 0.8736383442265795,
      "grad_norm": 0.0,
      "learning_rate": 4.139056344765724e-05,
      "loss": 5.0307,
      "step": 7619
    },
    {
      "epoch": 0.8737530099759202,
      "grad_norm": 0.0,
      "learning_rate": 4.1316706538110335e-05,
      "loss": 4.973,
      "step": 7620
    },
    {
      "epoch": 0.8738676757252609,
      "grad_norm": 0.0,
      "learning_rate": 4.124291290207704e-05,
      "loss": 4.965,
      "step": 7621
    },
    {
      "epoch": 0.8739823414746015,
      "grad_norm": 0.0,
      "learning_rate": 4.1169182549735736e-05,
      "loss": 5.139,
      "step": 7622
    },
    {
      "epoch": 0.8740970072239422,
      "grad_norm": 0.0,
      "learning_rate": 4.109551549125612e-05,
      "loss": 4.8284,
      "step": 7623
    },
    {
      "epoch": 0.8742116729732828,
      "grad_norm": 0.0,
      "learning_rate": 4.1021911736799264e-05,
      "loss": 4.7372,
      "step": 7624
    },
    {
      "epoch": 0.8743263387226236,
      "grad_norm": 0.0,
      "learning_rate": 4.094837129651713e-05,
      "loss": 4.8857,
      "step": 7625
    },
    {
      "epoch": 0.8744410044719643,
      "grad_norm": 0.0,
      "learning_rate": 4.0874894180553605e-05,
      "loss": 5.1487,
      "step": 7626
    },
    {
      "epoch": 0.8745556702213049,
      "grad_norm": 0.0,
      "learning_rate": 4.080148039904306e-05,
      "loss": 5.0878,
      "step": 7627
    },
    {
      "epoch": 0.8746703359706456,
      "grad_norm": 0.0,
      "learning_rate": 4.0728129962111934e-05,
      "loss": 4.8924,
      "step": 7628
    },
    {
      "epoch": 0.8747850017199862,
      "grad_norm": 0.0,
      "learning_rate": 4.0654842879877243e-05,
      "loss": 5.0142,
      "step": 7629
    },
    {
      "epoch": 0.8748996674693269,
      "grad_norm": 0.0,
      "learning_rate": 4.058161916244749e-05,
      "loss": 4.9641,
      "step": 7630
    },
    {
      "epoch": 0.8750143332186676,
      "grad_norm": 0.0,
      "learning_rate": 4.050845881992276e-05,
      "loss": 4.9978,
      "step": 7631
    },
    {
      "epoch": 0.8751289989680082,
      "grad_norm": 0.0,
      "learning_rate": 4.043536186239379e-05,
      "loss": 5.0394,
      "step": 7632
    },
    {
      "epoch": 0.8752436647173489,
      "grad_norm": 0.0,
      "learning_rate": 4.0362328299943306e-05,
      "loss": 4.8612,
      "step": 7633
    },
    {
      "epoch": 0.8753583304666896,
      "grad_norm": 0.0,
      "learning_rate": 4.028935814264461e-05,
      "loss": 4.8662,
      "step": 7634
    },
    {
      "epoch": 0.8754729962160303,
      "grad_norm": 0.0,
      "learning_rate": 4.0216451400562595e-05,
      "loss": 4.8399,
      "step": 7635
    },
    {
      "epoch": 0.875587661965371,
      "grad_norm": 0.0,
      "learning_rate": 4.0143608083753386e-05,
      "loss": 5.0583,
      "step": 7636
    },
    {
      "epoch": 0.8757023277147116,
      "grad_norm": 0.0,
      "learning_rate": 4.007082820226431e-05,
      "loss": 5.0581,
      "step": 7637
    },
    {
      "epoch": 0.8758169934640523,
      "grad_norm": 0.0,
      "learning_rate": 3.999811176613408e-05,
      "loss": 5.115,
      "step": 7638
    },
    {
      "epoch": 0.875931659213393,
      "grad_norm": 0.0,
      "learning_rate": 3.9925458785392314e-05,
      "loss": 4.9371,
      "step": 7639
    },
    {
      "epoch": 0.8760463249627336,
      "grad_norm": 0.0,
      "learning_rate": 3.985286927006038e-05,
      "loss": 5.0796,
      "step": 7640
    },
    {
      "epoch": 0.8761609907120743,
      "grad_norm": 0.0,
      "learning_rate": 3.9780343230150345e-05,
      "loss": 4.9697,
      "step": 7641
    },
    {
      "epoch": 0.8762756564614149,
      "grad_norm": 0.0,
      "learning_rate": 3.970788067566597e-05,
      "loss": 5.0711,
      "step": 7642
    },
    {
      "epoch": 0.8763903222107556,
      "grad_norm": 0.0,
      "learning_rate": 3.963548161660204e-05,
      "loss": 5.2952,
      "step": 7643
    },
    {
      "epoch": 0.8765049879600963,
      "grad_norm": 0.0,
      "learning_rate": 3.9563146062944604e-05,
      "loss": 4.9792,
      "step": 7644
    },
    {
      "epoch": 0.876619653709437,
      "grad_norm": 0.0,
      "learning_rate": 3.9490874024670994e-05,
      "loss": 4.8249,
      "step": 7645
    },
    {
      "epoch": 0.8767343194587777,
      "grad_norm": 0.0,
      "learning_rate": 3.9418665511749877e-05,
      "loss": 5.0768,
      "step": 7646
    },
    {
      "epoch": 0.8768489852081184,
      "grad_norm": 0.0,
      "learning_rate": 3.934652053414069e-05,
      "loss": 5.145,
      "step": 7647
    },
    {
      "epoch": 0.876963650957459,
      "grad_norm": 0.0,
      "learning_rate": 3.927443910179492e-05,
      "loss": 5.0535,
      "step": 7648
    },
    {
      "epoch": 0.8770783167067997,
      "grad_norm": 0.0,
      "learning_rate": 3.9202421224654456e-05,
      "loss": 4.8346,
      "step": 7649
    },
    {
      "epoch": 0.8771929824561403,
      "grad_norm": 0.0,
      "learning_rate": 3.9130466912652964e-05,
      "loss": 4.8602,
      "step": 7650
    },
    {
      "epoch": 0.877307648205481,
      "grad_norm": 0.0,
      "learning_rate": 3.905857617571524e-05,
      "loss": 5.3572,
      "step": 7651
    },
    {
      "epoch": 0.8774223139548217,
      "grad_norm": 0.0,
      "learning_rate": 3.89867490237569e-05,
      "loss": 4.8903,
      "step": 7652
    },
    {
      "epoch": 0.8775369797041623,
      "grad_norm": 0.0,
      "learning_rate": 3.89149854666856e-05,
      "loss": 5.2326,
      "step": 7653
    },
    {
      "epoch": 0.877651645453503,
      "grad_norm": 0.0,
      "learning_rate": 3.8843285514399314e-05,
      "loss": 5.1413,
      "step": 7654
    },
    {
      "epoch": 0.8777663112028438,
      "grad_norm": 0.0,
      "learning_rate": 3.877164917678808e-05,
      "loss": 4.9339,
      "step": 7655
    },
    {
      "epoch": 0.8778809769521844,
      "grad_norm": 0.0,
      "learning_rate": 3.870007646373246e-05,
      "loss": 5.1137,
      "step": 7656
    },
    {
      "epoch": 0.8779956427015251,
      "grad_norm": 0.0,
      "learning_rate": 3.8628567385104676e-05,
      "loss": 5.0682,
      "step": 7657
    },
    {
      "epoch": 0.8781103084508657,
      "grad_norm": 0.0,
      "learning_rate": 3.855712195076807e-05,
      "loss": 4.8579,
      "step": 7658
    },
    {
      "epoch": 0.8782249742002064,
      "grad_norm": 0.0,
      "learning_rate": 3.848574017057711e-05,
      "loss": 4.9128,
      "step": 7659
    },
    {
      "epoch": 0.8783396399495471,
      "grad_norm": 0.0,
      "learning_rate": 3.841442205437765e-05,
      "loss": 5.1362,
      "step": 7660
    },
    {
      "epoch": 0.8784543056988877,
      "grad_norm": 0.0,
      "learning_rate": 3.8343167612006396e-05,
      "loss": 4.9998,
      "step": 7661
    },
    {
      "epoch": 0.8785689714482284,
      "grad_norm": 0.0,
      "learning_rate": 3.827197685329195e-05,
      "loss": 4.9858,
      "step": 7662
    },
    {
      "epoch": 0.878683637197569,
      "grad_norm": 0.0,
      "learning_rate": 3.820084978805342e-05,
      "loss": 5.2137,
      "step": 7663
    },
    {
      "epoch": 0.8787983029469097,
      "grad_norm": 0.0,
      "learning_rate": 3.812978642610153e-05,
      "loss": 4.768,
      "step": 7664
    },
    {
      "epoch": 0.8789129686962505,
      "grad_norm": 0.0,
      "learning_rate": 3.805878677723807e-05,
      "loss": 5.0587,
      "step": 7665
    },
    {
      "epoch": 0.8790276344455911,
      "grad_norm": 0.0,
      "learning_rate": 3.7987850851256165e-05,
      "loss": 4.8784,
      "step": 7666
    },
    {
      "epoch": 0.8791423001949318,
      "grad_norm": 0.0,
      "learning_rate": 3.7916978657939967e-05,
      "loss": 5.0072,
      "step": 7667
    },
    {
      "epoch": 0.8792569659442725,
      "grad_norm": 0.0,
      "learning_rate": 3.7846170207065154e-05,
      "loss": 5.1364,
      "step": 7668
    },
    {
      "epoch": 0.8793716316936131,
      "grad_norm": 0.0,
      "learning_rate": 3.777542550839813e-05,
      "loss": 4.8699,
      "step": 7669
    },
    {
      "epoch": 0.8794862974429538,
      "grad_norm": 0.0,
      "learning_rate": 3.770474457169687e-05,
      "loss": 5.0486,
      "step": 7670
    },
    {
      "epoch": 0.8796009631922944,
      "grad_norm": 0.0,
      "learning_rate": 3.763412740671056e-05,
      "loss": 4.8246,
      "step": 7671
    },
    {
      "epoch": 0.8797156289416351,
      "grad_norm": 0.0,
      "learning_rate": 3.756357402317942e-05,
      "loss": 5.2432,
      "step": 7672
    },
    {
      "epoch": 0.8798302946909758,
      "grad_norm": 0.0,
      "learning_rate": 3.749308443083498e-05,
      "loss": 4.7764,
      "step": 7673
    },
    {
      "epoch": 0.8799449604403164,
      "grad_norm": 0.0,
      "learning_rate": 3.7422658639399756e-05,
      "loss": 4.9876,
      "step": 7674
    },
    {
      "epoch": 0.8800596261896572,
      "grad_norm": 0.0,
      "learning_rate": 3.735229665858802e-05,
      "loss": 5.1736,
      "step": 7675
    },
    {
      "epoch": 0.8801742919389978,
      "grad_norm": 0.0,
      "learning_rate": 3.728199849810441e-05,
      "loss": 5.0246,
      "step": 7676
    },
    {
      "epoch": 0.8802889576883385,
      "grad_norm": 0.0,
      "learning_rate": 3.721176416764566e-05,
      "loss": 4.8093,
      "step": 7677
    },
    {
      "epoch": 0.8804036234376792,
      "grad_norm": 0.0,
      "learning_rate": 3.714159367689892e-05,
      "loss": 4.7797,
      "step": 7678
    },
    {
      "epoch": 0.8805182891870198,
      "grad_norm": 0.0,
      "learning_rate": 3.7071487035543e-05,
      "loss": 5.0061,
      "step": 7679
    },
    {
      "epoch": 0.8806329549363605,
      "grad_norm": 0.0,
      "learning_rate": 3.700144425324786e-05,
      "loss": 5.0563,
      "step": 7680
    },
    {
      "epoch": 0.8807476206857012,
      "grad_norm": 0.0,
      "learning_rate": 3.693146533967429e-05,
      "loss": 5.1634,
      "step": 7681
    },
    {
      "epoch": 0.8808622864350418,
      "grad_norm": 0.0,
      "learning_rate": 3.686155030447495e-05,
      "loss": 4.9156,
      "step": 7682
    },
    {
      "epoch": 0.8809769521843825,
      "grad_norm": 0.0,
      "learning_rate": 3.679169915729288e-05,
      "loss": 4.6772,
      "step": 7683
    },
    {
      "epoch": 0.8810916179337231,
      "grad_norm": 0.0,
      "learning_rate": 3.672191190776307e-05,
      "loss": 5.2166,
      "step": 7684
    },
    {
      "epoch": 0.8812062836830639,
      "grad_norm": 0.0,
      "learning_rate": 3.6652188565511086e-05,
      "loss": 4.7511,
      "step": 7685
    },
    {
      "epoch": 0.8813209494324046,
      "grad_norm": 0.0,
      "learning_rate": 3.6582529140154e-05,
      "loss": 5.286,
      "step": 7686
    },
    {
      "epoch": 0.8814356151817452,
      "grad_norm": 0.0,
      "learning_rate": 3.651293364130009e-05,
      "loss": 5.0562,
      "step": 7687
    },
    {
      "epoch": 0.8815502809310859,
      "grad_norm": 0.0,
      "learning_rate": 3.644340207854862e-05,
      "loss": 5.0924,
      "step": 7688
    },
    {
      "epoch": 0.8816649466804266,
      "grad_norm": 0.0,
      "learning_rate": 3.6373934461490235e-05,
      "loss": 4.861,
      "step": 7689
    },
    {
      "epoch": 0.8817796124297672,
      "grad_norm": 0.0,
      "learning_rate": 3.630453079970658e-05,
      "loss": 5.1752,
      "step": 7690
    },
    {
      "epoch": 0.8818942781791079,
      "grad_norm": 0.0,
      "learning_rate": 3.623519110277061e-05,
      "loss": 5.0455,
      "step": 7691
    },
    {
      "epoch": 0.8820089439284485,
      "grad_norm": 0.0,
      "learning_rate": 3.616591538024643e-05,
      "loss": 4.9239,
      "step": 7692
    },
    {
      "epoch": 0.8821236096777892,
      "grad_norm": 0.0,
      "learning_rate": 3.6096703641689275e-05,
      "loss": 5.0555,
      "step": 7693
    },
    {
      "epoch": 0.88223827542713,
      "grad_norm": 0.0,
      "learning_rate": 3.602755589664561e-05,
      "loss": 4.9744,
      "step": 7694
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.0,
      "learning_rate": 3.5958472154653066e-05,
      "loss": 5.1106,
      "step": 7695
    },
    {
      "epoch": 0.8824676069258113,
      "grad_norm": 0.0,
      "learning_rate": 3.5889452425240305e-05,
      "loss": 4.9633,
      "step": 7696
    },
    {
      "epoch": 0.8825822726751519,
      "grad_norm": 0.0,
      "learning_rate": 3.582049671792746e-05,
      "loss": 4.8834,
      "step": 7697
    },
    {
      "epoch": 0.8826969384244926,
      "grad_norm": 0.0,
      "learning_rate": 3.5751605042225486e-05,
      "loss": 5.02,
      "step": 7698
    },
    {
      "epoch": 0.8828116041738333,
      "grad_norm": 0.0,
      "learning_rate": 3.568277740763689e-05,
      "loss": 5.0306,
      "step": 7699
    },
    {
      "epoch": 0.8829262699231739,
      "grad_norm": 0.0,
      "learning_rate": 3.5614013823655e-05,
      "loss": 5.2123,
      "step": 7700
    },
    {
      "epoch": 0.8830409356725146,
      "grad_norm": 0.0,
      "learning_rate": 3.5545314299764294e-05,
      "loss": 5.0747,
      "step": 7701
    },
    {
      "epoch": 0.8831556014218553,
      "grad_norm": 0.0,
      "learning_rate": 3.54766788454409e-05,
      "loss": 5.1075,
      "step": 7702
    },
    {
      "epoch": 0.8832702671711959,
      "grad_norm": 0.0,
      "learning_rate": 3.540810747015142e-05,
      "loss": 4.9372,
      "step": 7703
    },
    {
      "epoch": 0.8833849329205367,
      "grad_norm": 0.0,
      "learning_rate": 3.5339600183354284e-05,
      "loss": 4.9528,
      "step": 7704
    },
    {
      "epoch": 0.8834995986698773,
      "grad_norm": 0.0,
      "learning_rate": 3.527115699449842e-05,
      "loss": 5.1315,
      "step": 7705
    },
    {
      "epoch": 0.883614264419218,
      "grad_norm": 0.0,
      "learning_rate": 3.520277791302467e-05,
      "loss": 4.934,
      "step": 7706
    },
    {
      "epoch": 0.8837289301685587,
      "grad_norm": 0.0,
      "learning_rate": 3.5134462948364335e-05,
      "loss": 4.9946,
      "step": 7707
    },
    {
      "epoch": 0.8838435959178993,
      "grad_norm": 0.0,
      "learning_rate": 3.506621210994021e-05,
      "loss": 5.1268,
      "step": 7708
    },
    {
      "epoch": 0.88395826166724,
      "grad_norm": 0.0,
      "learning_rate": 3.4998025407166306e-05,
      "loss": 4.9145,
      "step": 7709
    },
    {
      "epoch": 0.8840729274165807,
      "grad_norm": 0.0,
      "learning_rate": 3.492990284944745e-05,
      "loss": 5.1822,
      "step": 7710
    },
    {
      "epoch": 0.8841875931659213,
      "grad_norm": 0.0,
      "learning_rate": 3.486184444618018e-05,
      "loss": 5.0375,
      "step": 7711
    },
    {
      "epoch": 0.884302258915262,
      "grad_norm": 0.0,
      "learning_rate": 3.479385020675155e-05,
      "loss": 5.0962,
      "step": 7712
    },
    {
      "epoch": 0.8844169246646026,
      "grad_norm": 0.0,
      "learning_rate": 3.472592014054023e-05,
      "loss": 5.0188,
      "step": 7713
    },
    {
      "epoch": 0.8845315904139434,
      "grad_norm": 0.0,
      "learning_rate": 3.465805425691584e-05,
      "loss": 5.014,
      "step": 7714
    },
    {
      "epoch": 0.8846462561632841,
      "grad_norm": 0.0,
      "learning_rate": 3.4590252565239175e-05,
      "loss": 5.1092,
      "step": 7715
    },
    {
      "epoch": 0.8847609219126247,
      "grad_norm": 0.0,
      "learning_rate": 3.452251507486222e-05,
      "loss": 4.9148,
      "step": 7716
    },
    {
      "epoch": 0.8848755876619654,
      "grad_norm": 0.0,
      "learning_rate": 3.4454841795128116e-05,
      "loss": 4.9372,
      "step": 7717
    },
    {
      "epoch": 0.884990253411306,
      "grad_norm": 0.0,
      "learning_rate": 3.4387232735370894e-05,
      "loss": 4.9105,
      "step": 7718
    },
    {
      "epoch": 0.8851049191606467,
      "grad_norm": 0.0,
      "learning_rate": 3.431968790491618e-05,
      "loss": 5.0851,
      "step": 7719
    },
    {
      "epoch": 0.8852195849099874,
      "grad_norm": 0.0,
      "learning_rate": 3.4252207313080355e-05,
      "loss": 4.9875,
      "step": 7720
    },
    {
      "epoch": 0.885334250659328,
      "grad_norm": 0.0,
      "learning_rate": 3.41847909691711e-05,
      "loss": 5.0622,
      "step": 7721
    },
    {
      "epoch": 0.8854489164086687,
      "grad_norm": 0.0,
      "learning_rate": 3.411743888248732e-05,
      "loss": 5.1035,
      "step": 7722
    },
    {
      "epoch": 0.8855635821580095,
      "grad_norm": 0.0,
      "learning_rate": 3.405015106231872e-05,
      "loss": 4.808,
      "step": 7723
    },
    {
      "epoch": 0.8856782479073501,
      "grad_norm": 0.0,
      "learning_rate": 3.3982927517946664e-05,
      "loss": 5.2067,
      "step": 7724
    },
    {
      "epoch": 0.8857929136566908,
      "grad_norm": 0.0,
      "learning_rate": 3.391576825864308e-05,
      "loss": 5.0597,
      "step": 7725
    },
    {
      "epoch": 0.8859075794060314,
      "grad_norm": 0.0,
      "learning_rate": 3.384867329367152e-05,
      "loss": 4.8079,
      "step": 7726
    },
    {
      "epoch": 0.8860222451553721,
      "grad_norm": 0.0,
      "learning_rate": 3.378164263228627e-05,
      "loss": 5.1089,
      "step": 7727
    },
    {
      "epoch": 0.8861369109047128,
      "grad_norm": 0.0,
      "learning_rate": 3.371467628373318e-05,
      "loss": 5.1327,
      "step": 7728
    },
    {
      "epoch": 0.8862515766540534,
      "grad_norm": 0.0,
      "learning_rate": 3.364777425724877e-05,
      "loss": 4.9459,
      "step": 7729
    },
    {
      "epoch": 0.8863662424033941,
      "grad_norm": 0.0,
      "learning_rate": 3.3580936562060944e-05,
      "loss": 4.9542,
      "step": 7730
    },
    {
      "epoch": 0.8864809081527347,
      "grad_norm": 0.0,
      "learning_rate": 3.351416320738881e-05,
      "loss": 5.1282,
      "step": 7731
    },
    {
      "epoch": 0.8865955739020754,
      "grad_norm": 0.0,
      "learning_rate": 3.344745420244223e-05,
      "loss": 4.9736,
      "step": 7732
    },
    {
      "epoch": 0.8867102396514162,
      "grad_norm": 0.0,
      "learning_rate": 3.3380809556422714e-05,
      "loss": 4.929,
      "step": 7733
    },
    {
      "epoch": 0.8868249054007568,
      "grad_norm": 0.0,
      "learning_rate": 3.331422927852248e-05,
      "loss": 4.8886,
      "step": 7734
    },
    {
      "epoch": 0.8869395711500975,
      "grad_norm": 0.0,
      "learning_rate": 3.324771337792499e-05,
      "loss": 5.1538,
      "step": 7735
    },
    {
      "epoch": 0.8870542368994382,
      "grad_norm": 0.0,
      "learning_rate": 3.318126186380481e-05,
      "loss": 5.2055,
      "step": 7736
    },
    {
      "epoch": 0.8871689026487788,
      "grad_norm": 0.0,
      "learning_rate": 3.311487474532782e-05,
      "loss": 4.8513,
      "step": 7737
    },
    {
      "epoch": 0.8872835683981195,
      "grad_norm": 0.0,
      "learning_rate": 3.304855203165071e-05,
      "loss": 4.9279,
      "step": 7738
    },
    {
      "epoch": 0.8873982341474601,
      "grad_norm": 0.0,
      "learning_rate": 3.298229373192158e-05,
      "loss": 5.5095,
      "step": 7739
    },
    {
      "epoch": 0.8875128998968008,
      "grad_norm": 0.0,
      "learning_rate": 3.291609985527938e-05,
      "loss": 5.2623,
      "step": 7740
    },
    {
      "epoch": 0.8876275656461415,
      "grad_norm": 0.0,
      "learning_rate": 3.2849970410854277e-05,
      "loss": 4.9414,
      "step": 7741
    },
    {
      "epoch": 0.8877422313954821,
      "grad_norm": 0.0,
      "learning_rate": 3.2783905407767614e-05,
      "loss": 5.0735,
      "step": 7742
    },
    {
      "epoch": 0.8878568971448229,
      "grad_norm": 0.0,
      "learning_rate": 3.271790485513181e-05,
      "loss": 4.9334,
      "step": 7743
    },
    {
      "epoch": 0.8879715628941636,
      "grad_norm": 0.0,
      "learning_rate": 3.2651968762050434e-05,
      "loss": 5.1654,
      "step": 7744
    },
    {
      "epoch": 0.8880862286435042,
      "grad_norm": 0.0,
      "learning_rate": 3.258609713761787e-05,
      "loss": 5.01,
      "step": 7745
    },
    {
      "epoch": 0.8882008943928449,
      "grad_norm": 0.0,
      "learning_rate": 3.252028999092027e-05,
      "loss": 5.1866,
      "step": 7746
    },
    {
      "epoch": 0.8883155601421855,
      "grad_norm": 0.0,
      "learning_rate": 3.245454733103402e-05,
      "loss": 4.9063,
      "step": 7747
    },
    {
      "epoch": 0.8884302258915262,
      "grad_norm": 0.0,
      "learning_rate": 3.2388869167027456e-05,
      "loss": 5.0159,
      "step": 7748
    },
    {
      "epoch": 0.8885448916408669,
      "grad_norm": 0.0,
      "learning_rate": 3.232325550795927e-05,
      "loss": 5.0822,
      "step": 7749
    },
    {
      "epoch": 0.8886595573902075,
      "grad_norm": 0.0,
      "learning_rate": 3.2257706362880025e-05,
      "loss": 5.0266,
      "step": 7750
    },
    {
      "epoch": 0.8887742231395482,
      "grad_norm": 0.0,
      "learning_rate": 3.219222174083069e-05,
      "loss": 5.0374,
      "step": 7751
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.0,
      "learning_rate": 3.2126801650843604e-05,
      "loss": 5.1172,
      "step": 7752
    },
    {
      "epoch": 0.8890035546382296,
      "grad_norm": 0.0,
      "learning_rate": 3.2061446101942404e-05,
      "loss": 5.0811,
      "step": 7753
    },
    {
      "epoch": 0.8891182203875703,
      "grad_norm": 0.0,
      "learning_rate": 3.1996155103141366e-05,
      "loss": 4.9199,
      "step": 7754
    },
    {
      "epoch": 0.8892328861369109,
      "grad_norm": 0.0,
      "learning_rate": 3.193092866344651e-05,
      "loss": 4.9845,
      "step": 7755
    },
    {
      "epoch": 0.8893475518862516,
      "grad_norm": 0.0,
      "learning_rate": 3.186576679185429e-05,
      "loss": 4.8886,
      "step": 7756
    },
    {
      "epoch": 0.8894622176355923,
      "grad_norm": 0.0,
      "learning_rate": 3.180066949735266e-05,
      "loss": 5.1539,
      "step": 7757
    },
    {
      "epoch": 0.8895768833849329,
      "grad_norm": 0.0,
      "learning_rate": 3.173563678892049e-05,
      "loss": 4.8461,
      "step": 7758
    },
    {
      "epoch": 0.8896915491342736,
      "grad_norm": 0.0,
      "learning_rate": 3.1670668675527885e-05,
      "loss": 4.8819,
      "step": 7759
    },
    {
      "epoch": 0.8898062148836142,
      "grad_norm": 0.0,
      "learning_rate": 3.1605765166135984e-05,
      "loss": 5.1555,
      "step": 7760
    },
    {
      "epoch": 0.8899208806329549,
      "grad_norm": 0.0,
      "learning_rate": 3.1540926269696794e-05,
      "loss": 4.9059,
      "step": 7761
    },
    {
      "epoch": 0.8900355463822957,
      "grad_norm": 0.0,
      "learning_rate": 3.1476151995153776e-05,
      "loss": 4.8536,
      "step": 7762
    },
    {
      "epoch": 0.8901502121316363,
      "grad_norm": 0.0,
      "learning_rate": 3.141144235144126e-05,
      "loss": 5.1628,
      "step": 7763
    },
    {
      "epoch": 0.890264877880977,
      "grad_norm": 0.0,
      "learning_rate": 3.134679734748471e-05,
      "loss": 4.9172,
      "step": 7764
    },
    {
      "epoch": 0.8903795436303176,
      "grad_norm": 0.0,
      "learning_rate": 3.128221699220063e-05,
      "loss": 4.8973,
      "step": 7765
    },
    {
      "epoch": 0.8904942093796583,
      "grad_norm": 0.0,
      "learning_rate": 3.121770129449681e-05,
      "loss": 5.0555,
      "step": 7766
    },
    {
      "epoch": 0.890608875128999,
      "grad_norm": 0.0,
      "learning_rate": 3.115325026327163e-05,
      "loss": 4.6891,
      "step": 7767
    },
    {
      "epoch": 0.8907235408783396,
      "grad_norm": 0.0,
      "learning_rate": 3.1088863907415275e-05,
      "loss": 4.9871,
      "step": 7768
    },
    {
      "epoch": 0.8908382066276803,
      "grad_norm": 0.0,
      "learning_rate": 3.1024542235808296e-05,
      "loss": 4.8633,
      "step": 7769
    },
    {
      "epoch": 0.890952872377021,
      "grad_norm": 0.0,
      "learning_rate": 3.096028525732293e-05,
      "loss": 4.9667,
      "step": 7770
    },
    {
      "epoch": 0.8910675381263616,
      "grad_norm": 0.0,
      "learning_rate": 3.0896092980821986e-05,
      "loss": 5.1353,
      "step": 7771
    },
    {
      "epoch": 0.8911822038757024,
      "grad_norm": 0.0,
      "learning_rate": 3.083196541515959e-05,
      "loss": 4.9776,
      "step": 7772
    },
    {
      "epoch": 0.891296869625043,
      "grad_norm": 0.0,
      "learning_rate": 3.0767902569181014e-05,
      "loss": 4.9971,
      "step": 7773
    },
    {
      "epoch": 0.8914115353743837,
      "grad_norm": 0.0,
      "learning_rate": 3.070390445172236e-05,
      "loss": 5.1829,
      "step": 7774
    },
    {
      "epoch": 0.8915262011237244,
      "grad_norm": 0.0,
      "learning_rate": 3.063997107161113e-05,
      "loss": 5.0616,
      "step": 7775
    },
    {
      "epoch": 0.891640866873065,
      "grad_norm": 0.0,
      "learning_rate": 3.05761024376655e-05,
      "loss": 4.9285,
      "step": 7776
    },
    {
      "epoch": 0.8917555326224057,
      "grad_norm": 0.0,
      "learning_rate": 3.0512298558695197e-05,
      "loss": 5.0449,
      "step": 7777
    },
    {
      "epoch": 0.8918701983717464,
      "grad_norm": 0.0,
      "learning_rate": 3.0448559443500535e-05,
      "loss": 4.8263,
      "step": 7778
    },
    {
      "epoch": 0.891984864121087,
      "grad_norm": 0.0,
      "learning_rate": 3.0384885100873205e-05,
      "loss": 5.0651,
      "step": 7779
    },
    {
      "epoch": 0.8920995298704277,
      "grad_norm": 0.0,
      "learning_rate": 3.0321275539595806e-05,
      "loss": 4.9429,
      "step": 7780
    },
    {
      "epoch": 0.8922141956197683,
      "grad_norm": 0.0,
      "learning_rate": 3.0257730768442105e-05,
      "loss": 4.7735,
      "step": 7781
    },
    {
      "epoch": 0.892328861369109,
      "grad_norm": 0.0,
      "learning_rate": 3.0194250796176994e-05,
      "loss": 5.0418,
      "step": 7782
    },
    {
      "epoch": 0.8924435271184498,
      "grad_norm": 0.0,
      "learning_rate": 3.01308356315561e-05,
      "loss": 4.847,
      "step": 7783
    },
    {
      "epoch": 0.8925581928677904,
      "grad_norm": 0.0,
      "learning_rate": 3.006748528332648e-05,
      "loss": 5.0027,
      "step": 7784
    },
    {
      "epoch": 0.8926728586171311,
      "grad_norm": 0.0,
      "learning_rate": 3.000419976022611e-05,
      "loss": 5.1203,
      "step": 7785
    },
    {
      "epoch": 0.8927875243664717,
      "grad_norm": 0.0,
      "learning_rate": 2.994097907098397e-05,
      "loss": 5.0145,
      "step": 7786
    },
    {
      "epoch": 0.8929021901158124,
      "grad_norm": 0.0,
      "learning_rate": 2.9877823224320156e-05,
      "loss": 5.0671,
      "step": 7787
    },
    {
      "epoch": 0.8930168558651531,
      "grad_norm": 0.0,
      "learning_rate": 2.9814732228945933e-05,
      "loss": 4.9943,
      "step": 7788
    },
    {
      "epoch": 0.8931315216144937,
      "grad_norm": 0.0,
      "learning_rate": 2.97517060935632e-05,
      "loss": 4.9346,
      "step": 7789
    },
    {
      "epoch": 0.8932461873638344,
      "grad_norm": 0.0,
      "learning_rate": 2.9688744826865624e-05,
      "loss": 5.1535,
      "step": 7790
    },
    {
      "epoch": 0.8933608531131751,
      "grad_norm": 0.0,
      "learning_rate": 2.9625848437537174e-05,
      "loss": 5.1069,
      "step": 7791
    },
    {
      "epoch": 0.8934755188625157,
      "grad_norm": 0.0,
      "learning_rate": 2.956301693425337e-05,
      "loss": 4.9569,
      "step": 7792
    },
    {
      "epoch": 0.8935901846118565,
      "grad_norm": 0.0,
      "learning_rate": 2.9500250325680586e-05,
      "loss": 4.9454,
      "step": 7793
    },
    {
      "epoch": 0.8937048503611971,
      "grad_norm": 0.0,
      "learning_rate": 2.9437548620476244e-05,
      "loss": 4.9632,
      "step": 7794
    },
    {
      "epoch": 0.8938195161105378,
      "grad_norm": 0.0,
      "learning_rate": 2.9374911827288954e-05,
      "loss": 4.9854,
      "step": 7795
    },
    {
      "epoch": 0.8939341818598785,
      "grad_norm": 0.0,
      "learning_rate": 2.931233995475805e-05,
      "loss": 5.2127,
      "step": 7796
    },
    {
      "epoch": 0.8940488476092191,
      "grad_norm": 0.0,
      "learning_rate": 2.9249833011514433e-05,
      "loss": 4.8288,
      "step": 7797
    },
    {
      "epoch": 0.8941635133585598,
      "grad_norm": 0.0,
      "learning_rate": 2.9187391006179454e-05,
      "loss": 4.9705,
      "step": 7798
    },
    {
      "epoch": 0.8942781791079004,
      "grad_norm": 0.0,
      "learning_rate": 2.9125013947366025e-05,
      "loss": 4.8986,
      "step": 7799
    },
    {
      "epoch": 0.8943928448572411,
      "grad_norm": 0.0,
      "learning_rate": 2.906270184367774e-05,
      "loss": 4.8333,
      "step": 7800
    },
    {
      "epoch": 0.8945075106065818,
      "grad_norm": 0.0,
      "learning_rate": 2.900045470370941e-05,
      "loss": 5.1094,
      "step": 7801
    },
    {
      "epoch": 0.8946221763559224,
      "grad_norm": 0.0,
      "learning_rate": 2.893827253604688e-05,
      "loss": 5.0704,
      "step": 7802
    },
    {
      "epoch": 0.8947368421052632,
      "grad_norm": 0.0,
      "learning_rate": 2.887615534926681e-05,
      "loss": 4.8246,
      "step": 7803
    },
    {
      "epoch": 0.8948515078546039,
      "grad_norm": 0.0,
      "learning_rate": 2.8814103151937372e-05,
      "loss": 4.8915,
      "step": 7804
    },
    {
      "epoch": 0.8949661736039445,
      "grad_norm": 0.0,
      "learning_rate": 2.8752115952617264e-05,
      "loss": 5.1693,
      "step": 7805
    },
    {
      "epoch": 0.8950808393532852,
      "grad_norm": 0.0,
      "learning_rate": 2.8690193759856448e-05,
      "loss": 4.9148,
      "step": 7806
    },
    {
      "epoch": 0.8951955051026258,
      "grad_norm": 0.0,
      "learning_rate": 2.862833658219602e-05,
      "loss": 5.0215,
      "step": 7807
    },
    {
      "epoch": 0.8953101708519665,
      "grad_norm": 0.0,
      "learning_rate": 2.8566544428167967e-05,
      "loss": 5.2762,
      "step": 7808
    },
    {
      "epoch": 0.8954248366013072,
      "grad_norm": 0.0,
      "learning_rate": 2.8504817306295284e-05,
      "loss": 5.1181,
      "step": 7809
    },
    {
      "epoch": 0.8955395023506478,
      "grad_norm": 0.0,
      "learning_rate": 2.844315522509214e-05,
      "loss": 4.8343,
      "step": 7810
    },
    {
      "epoch": 0.8956541680999885,
      "grad_norm": 0.0,
      "learning_rate": 2.838155819306355e-05,
      "loss": 4.9078,
      "step": 7811
    },
    {
      "epoch": 0.8957688338493293,
      "grad_norm": 0.0,
      "learning_rate": 2.8320026218705697e-05,
      "loss": 4.9393,
      "step": 7812
    },
    {
      "epoch": 0.8958834995986699,
      "grad_norm": 0.0,
      "learning_rate": 2.825855931050567e-05,
      "loss": 4.9029,
      "step": 7813
    },
    {
      "epoch": 0.8959981653480106,
      "grad_norm": 0.0,
      "learning_rate": 2.819715747694178e-05,
      "loss": 5.2374,
      "step": 7814
    },
    {
      "epoch": 0.8961128310973512,
      "grad_norm": 0.0,
      "learning_rate": 2.8135820726483178e-05,
      "loss": 4.8357,
      "step": 7815
    },
    {
      "epoch": 0.8962274968466919,
      "grad_norm": 0.0,
      "learning_rate": 2.8074549067590096e-05,
      "loss": 4.8032,
      "step": 7816
    },
    {
      "epoch": 0.8963421625960326,
      "grad_norm": 0.0,
      "learning_rate": 2.8013342508713856e-05,
      "loss": 4.7922,
      "step": 7817
    },
    {
      "epoch": 0.8964568283453732,
      "grad_norm": 0.0,
      "learning_rate": 2.7952201058296595e-05,
      "loss": 5.0789,
      "step": 7818
    },
    {
      "epoch": 0.8965714940947139,
      "grad_norm": 0.0,
      "learning_rate": 2.789112472477177e-05,
      "loss": 4.9966,
      "step": 7819
    },
    {
      "epoch": 0.8966861598440545,
      "grad_norm": 0.0,
      "learning_rate": 2.7830113516563526e-05,
      "loss": 5.1137,
      "step": 7820
    },
    {
      "epoch": 0.8968008255933952,
      "grad_norm": 0.0,
      "learning_rate": 2.7769167442087398e-05,
      "loss": 5.1883,
      "step": 7821
    },
    {
      "epoch": 0.896915491342736,
      "grad_norm": 0.0,
      "learning_rate": 2.7708286509749658e-05,
      "loss": 5.0816,
      "step": 7822
    },
    {
      "epoch": 0.8970301570920766,
      "grad_norm": 0.0,
      "learning_rate": 2.7647470727947464e-05,
      "loss": 4.918,
      "step": 7823
    },
    {
      "epoch": 0.8971448228414173,
      "grad_norm": 0.0,
      "learning_rate": 2.758672010506955e-05,
      "loss": 5.1104,
      "step": 7824
    },
    {
      "epoch": 0.897259488590758,
      "grad_norm": 0.0,
      "learning_rate": 2.752603464949498e-05,
      "loss": 4.9776,
      "step": 7825
    },
    {
      "epoch": 0.8973741543400986,
      "grad_norm": 0.0,
      "learning_rate": 2.7465414369594446e-05,
      "loss": 4.8862,
      "step": 7826
    },
    {
      "epoch": 0.8974888200894393,
      "grad_norm": 0.0,
      "learning_rate": 2.7404859273729146e-05,
      "loss": 5.0926,
      "step": 7827
    },
    {
      "epoch": 0.8976034858387799,
      "grad_norm": 0.0,
      "learning_rate": 2.7344369370251563e-05,
      "loss": 4.9724,
      "step": 7828
    },
    {
      "epoch": 0.8977181515881206,
      "grad_norm": 0.0,
      "learning_rate": 2.728394466750513e-05,
      "loss": 5.2996,
      "step": 7829
    },
    {
      "epoch": 0.8978328173374613,
      "grad_norm": 0.0,
      "learning_rate": 2.7223585173824287e-05,
      "loss": 5.0618,
      "step": 7830
    },
    {
      "epoch": 0.897947483086802,
      "grad_norm": 0.0,
      "learning_rate": 2.716329089753455e-05,
      "loss": 5.2163,
      "step": 7831
    },
    {
      "epoch": 0.8980621488361427,
      "grad_norm": 0.0,
      "learning_rate": 2.710306184695226e-05,
      "loss": 5.1045,
      "step": 7832
    },
    {
      "epoch": 0.8981768145854833,
      "grad_norm": 0.0,
      "learning_rate": 2.7042898030384887e-05,
      "loss": 5.249,
      "step": 7833
    },
    {
      "epoch": 0.898291480334824,
      "grad_norm": 0.0,
      "learning_rate": 2.6982799456130853e-05,
      "loss": 5.1862,
      "step": 7834
    },
    {
      "epoch": 0.8984061460841647,
      "grad_norm": 0.0,
      "learning_rate": 2.6922766132479696e-05,
      "loss": 4.833,
      "step": 7835
    },
    {
      "epoch": 0.8985208118335053,
      "grad_norm": 0.0,
      "learning_rate": 2.6862798067711794e-05,
      "loss": 4.9829,
      "step": 7836
    },
    {
      "epoch": 0.898635477582846,
      "grad_norm": 0.0,
      "learning_rate": 2.680289527009865e-05,
      "loss": 5.1058,
      "step": 7837
    },
    {
      "epoch": 0.8987501433321867,
      "grad_norm": 0.0,
      "learning_rate": 2.674305774790272e-05,
      "loss": 5.2008,
      "step": 7838
    },
    {
      "epoch": 0.8988648090815273,
      "grad_norm": 0.0,
      "learning_rate": 2.668328550937746e-05,
      "loss": 5.1175,
      "step": 7839
    },
    {
      "epoch": 0.898979474830868,
      "grad_norm": 0.0,
      "learning_rate": 2.662357856276712e-05,
      "loss": 4.8118,
      "step": 7840
    },
    {
      "epoch": 0.8990941405802086,
      "grad_norm": 0.0,
      "learning_rate": 2.6563936916307445e-05,
      "loss": 5.0488,
      "step": 7841
    },
    {
      "epoch": 0.8992088063295494,
      "grad_norm": 0.0,
      "learning_rate": 2.6504360578224657e-05,
      "loss": 5.2555,
      "step": 7842
    },
    {
      "epoch": 0.8993234720788901,
      "grad_norm": 0.0,
      "learning_rate": 2.6444849556736185e-05,
      "loss": 5.1314,
      "step": 7843
    },
    {
      "epoch": 0.8994381378282307,
      "grad_norm": 0.0,
      "learning_rate": 2.6385403860050585e-05,
      "loss": 4.8118,
      "step": 7844
    },
    {
      "epoch": 0.8995528035775714,
      "grad_norm": 0.0,
      "learning_rate": 2.6326023496366984e-05,
      "loss": 4.9262,
      "step": 7845
    },
    {
      "epoch": 0.8996674693269121,
      "grad_norm": 0.0,
      "learning_rate": 2.6266708473876112e-05,
      "loss": 5.1563,
      "step": 7846
    },
    {
      "epoch": 0.8997821350762527,
      "grad_norm": 0.0,
      "learning_rate": 2.6207458800759003e-05,
      "loss": 5.0404,
      "step": 7847
    },
    {
      "epoch": 0.8998968008255934,
      "grad_norm": 0.0,
      "learning_rate": 2.6148274485188354e-05,
      "loss": 4.9282,
      "step": 7848
    },
    {
      "epoch": 0.900011466574934,
      "grad_norm": 0.0,
      "learning_rate": 2.608915553532726e-05,
      "loss": 4.9434,
      "step": 7849
    },
    {
      "epoch": 0.9001261323242747,
      "grad_norm": 0.0,
      "learning_rate": 2.603010195933017e-05,
      "loss": 4.8687,
      "step": 7850
    },
    {
      "epoch": 0.9002407980736155,
      "grad_norm": 0.0,
      "learning_rate": 2.5971113765342405e-05,
      "loss": 4.8921,
      "step": 7851
    },
    {
      "epoch": 0.9003554638229561,
      "grad_norm": 0.0,
      "learning_rate": 2.591219096150015e-05,
      "loss": 5.1299,
      "step": 7852
    },
    {
      "epoch": 0.9004701295722968,
      "grad_norm": 0.0,
      "learning_rate": 2.5853333555930873e-05,
      "loss": 4.9565,
      "step": 7853
    },
    {
      "epoch": 0.9005847953216374,
      "grad_norm": 0.0,
      "learning_rate": 2.579454155675265e-05,
      "loss": 4.8474,
      "step": 7854
    },
    {
      "epoch": 0.9006994610709781,
      "grad_norm": 0.0,
      "learning_rate": 2.573581497207479e-05,
      "loss": 4.9292,
      "step": 7855
    },
    {
      "epoch": 0.9008141268203188,
      "grad_norm": 0.0,
      "learning_rate": 2.5677153809997513e-05,
      "loss": 5.2101,
      "step": 7856
    },
    {
      "epoch": 0.9009287925696594,
      "grad_norm": 0.0,
      "learning_rate": 2.561855807861197e-05,
      "loss": 4.9774,
      "step": 7857
    },
    {
      "epoch": 0.9010434583190001,
      "grad_norm": 0.0,
      "learning_rate": 2.55600277860004e-05,
      "loss": 5.181,
      "step": 7858
    },
    {
      "epoch": 0.9011581240683408,
      "grad_norm": 0.0,
      "learning_rate": 2.550156294023586e-05,
      "loss": 4.7691,
      "step": 7859
    },
    {
      "epoch": 0.9012727898176814,
      "grad_norm": 0.0,
      "learning_rate": 2.5443163549382486e-05,
      "loss": 5.1975,
      "step": 7860
    },
    {
      "epoch": 0.9013874555670222,
      "grad_norm": 0.0,
      "learning_rate": 2.5384829621495467e-05,
      "loss": 4.9121,
      "step": 7861
    },
    {
      "epoch": 0.9015021213163628,
      "grad_norm": 0.0,
      "learning_rate": 2.5326561164620683e-05,
      "loss": 4.8893,
      "step": 7862
    },
    {
      "epoch": 0.9016167870657035,
      "grad_norm": 0.0,
      "learning_rate": 2.5268358186795222e-05,
      "loss": 4.8278,
      "step": 7863
    },
    {
      "epoch": 0.9017314528150442,
      "grad_norm": 0.0,
      "learning_rate": 2.521022069604715e-05,
      "loss": 4.9561,
      "step": 7864
    },
    {
      "epoch": 0.9018461185643848,
      "grad_norm": 0.0,
      "learning_rate": 2.5152148700395295e-05,
      "loss": 5.1442,
      "step": 7865
    },
    {
      "epoch": 0.9019607843137255,
      "grad_norm": 0.0,
      "learning_rate": 2.5094142207849724e-05,
      "loss": 5.1141,
      "step": 7866
    },
    {
      "epoch": 0.9020754500630661,
      "grad_norm": 0.0,
      "learning_rate": 2.5036201226411133e-05,
      "loss": 4.9836,
      "step": 7867
    },
    {
      "epoch": 0.9021901158124068,
      "grad_norm": 0.0,
      "learning_rate": 2.497832576407166e-05,
      "loss": 5.0738,
      "step": 7868
    },
    {
      "epoch": 0.9023047815617475,
      "grad_norm": 0.0,
      "learning_rate": 2.4920515828813788e-05,
      "loss": 5.1561,
      "step": 7869
    },
    {
      "epoch": 0.9024194473110881,
      "grad_norm": 0.0,
      "learning_rate": 2.486277142861156e-05,
      "loss": 5.1542,
      "step": 7870
    },
    {
      "epoch": 0.9025341130604289,
      "grad_norm": 0.0,
      "learning_rate": 2.480509257142964e-05,
      "loss": 5.0064,
      "step": 7871
    },
    {
      "epoch": 0.9026487788097696,
      "grad_norm": 0.0,
      "learning_rate": 2.474747926522365e-05,
      "loss": 5.0154,
      "step": 7872
    },
    {
      "epoch": 0.9027634445591102,
      "grad_norm": 0.0,
      "learning_rate": 2.468993151794038e-05,
      "loss": 5.1036,
      "step": 7873
    },
    {
      "epoch": 0.9028781103084509,
      "grad_norm": 0.0,
      "learning_rate": 2.463244933751724e-05,
      "loss": 5.1638,
      "step": 7874
    },
    {
      "epoch": 0.9029927760577915,
      "grad_norm": 0.0,
      "learning_rate": 2.4575032731883096e-05,
      "loss": 5.1544,
      "step": 7875
    },
    {
      "epoch": 0.9031074418071322,
      "grad_norm": 0.0,
      "learning_rate": 2.451768170895721e-05,
      "loss": 4.6427,
      "step": 7876
    },
    {
      "epoch": 0.9032221075564729,
      "grad_norm": 0.0,
      "learning_rate": 2.4460396276650132e-05,
      "loss": 4.8924,
      "step": 7877
    },
    {
      "epoch": 0.9033367733058135,
      "grad_norm": 0.0,
      "learning_rate": 2.4403176442863355e-05,
      "loss": 4.8673,
      "step": 7878
    },
    {
      "epoch": 0.9034514390551542,
      "grad_norm": 0.0,
      "learning_rate": 2.4346022215489282e-05,
      "loss": 5.1872,
      "step": 7879
    },
    {
      "epoch": 0.903566104804495,
      "grad_norm": 0.0,
      "learning_rate": 2.4288933602411144e-05,
      "loss": 5.2003,
      "step": 7880
    },
    {
      "epoch": 0.9036807705538356,
      "grad_norm": 0.0,
      "learning_rate": 2.4231910611503305e-05,
      "loss": 5.2213,
      "step": 7881
    },
    {
      "epoch": 0.9037954363031763,
      "grad_norm": 0.0,
      "learning_rate": 2.4174953250631018e-05,
      "loss": 5.0201,
      "step": 7882
    },
    {
      "epoch": 0.9039101020525169,
      "grad_norm": 0.0,
      "learning_rate": 2.4118061527650378e-05,
      "loss": 4.729,
      "step": 7883
    },
    {
      "epoch": 0.9040247678018576,
      "grad_norm": 0.0,
      "learning_rate": 2.40612354504086e-05,
      "loss": 5.0063,
      "step": 7884
    },
    {
      "epoch": 0.9041394335511983,
      "grad_norm": 0.0,
      "learning_rate": 2.4004475026743685e-05,
      "loss": 5.0697,
      "step": 7885
    },
    {
      "epoch": 0.9042540993005389,
      "grad_norm": 0.0,
      "learning_rate": 2.3947780264484645e-05,
      "loss": 4.99,
      "step": 7886
    },
    {
      "epoch": 0.9043687650498796,
      "grad_norm": 0.0,
      "learning_rate": 2.3891151171451556e-05,
      "loss": 5.1473,
      "step": 7887
    },
    {
      "epoch": 0.9044834307992202,
      "grad_norm": 0.0,
      "learning_rate": 2.3834587755455267e-05,
      "loss": 4.9937,
      "step": 7888
    },
    {
      "epoch": 0.9045980965485609,
      "grad_norm": 0.0,
      "learning_rate": 2.3778090024297484e-05,
      "loss": 4.9624,
      "step": 7889
    },
    {
      "epoch": 0.9047127622979017,
      "grad_norm": 0.0,
      "learning_rate": 2.372165798577125e-05,
      "loss": 5.1539,
      "step": 7890
    },
    {
      "epoch": 0.9048274280472423,
      "grad_norm": 0.0,
      "learning_rate": 2.3665291647660057e-05,
      "loss": 5.129,
      "step": 7891
    },
    {
      "epoch": 0.904942093796583,
      "grad_norm": 0.0,
      "learning_rate": 2.3608991017738743e-05,
      "loss": 5.0167,
      "step": 7892
    },
    {
      "epoch": 0.9050567595459237,
      "grad_norm": 0.0,
      "learning_rate": 2.355275610377288e-05,
      "loss": 5.1695,
      "step": 7893
    },
    {
      "epoch": 0.9051714252952643,
      "grad_norm": 0.0,
      "learning_rate": 2.349658691351875e-05,
      "loss": 4.9133,
      "step": 7894
    },
    {
      "epoch": 0.905286091044605,
      "grad_norm": 0.0,
      "learning_rate": 2.3440483454724173e-05,
      "loss": 4.776,
      "step": 7895
    },
    {
      "epoch": 0.9054007567939456,
      "grad_norm": 0.0,
      "learning_rate": 2.338444573512729e-05,
      "loss": 4.8488,
      "step": 7896
    },
    {
      "epoch": 0.9055154225432863,
      "grad_norm": 0.0,
      "learning_rate": 2.33284737624577e-05,
      "loss": 4.9022,
      "step": 7897
    },
    {
      "epoch": 0.905630088292627,
      "grad_norm": 0.0,
      "learning_rate": 2.327256754443539e-05,
      "loss": 5.003,
      "step": 7898
    },
    {
      "epoch": 0.9057447540419676,
      "grad_norm": 0.0,
      "learning_rate": 2.3216727088771717e-05,
      "loss": 4.8737,
      "step": 7899
    },
    {
      "epoch": 0.9058594197913084,
      "grad_norm": 0.0,
      "learning_rate": 2.316095240316873e-05,
      "loss": 5.038,
      "step": 7900
    },
    {
      "epoch": 0.905974085540649,
      "grad_norm": 0.0,
      "learning_rate": 2.3105243495319576e-05,
      "loss": 5.1669,
      "step": 7901
    },
    {
      "epoch": 0.9060887512899897,
      "grad_norm": 0.0,
      "learning_rate": 2.3049600372908163e-05,
      "loss": 5.0556,
      "step": 7902
    },
    {
      "epoch": 0.9062034170393304,
      "grad_norm": 0.0,
      "learning_rate": 2.2994023043609474e-05,
      "loss": 4.8727,
      "step": 7903
    },
    {
      "epoch": 0.906318082788671,
      "grad_norm": 0.0,
      "learning_rate": 2.2938511515089277e-05,
      "loss": 5.26,
      "step": 7904
    },
    {
      "epoch": 0.9064327485380117,
      "grad_norm": 0.0,
      "learning_rate": 2.288306579500435e-05,
      "loss": 5.0382,
      "step": 7905
    },
    {
      "epoch": 0.9065474142873524,
      "grad_norm": 0.0,
      "learning_rate": 2.282768589100231e-05,
      "loss": 4.8807,
      "step": 7906
    },
    {
      "epoch": 0.906662080036693,
      "grad_norm": 0.0,
      "learning_rate": 2.2772371810721888e-05,
      "loss": 5.0458,
      "step": 7907
    },
    {
      "epoch": 0.9067767457860337,
      "grad_norm": 0.0,
      "learning_rate": 2.271712356179245e-05,
      "loss": 4.9284,
      "step": 7908
    },
    {
      "epoch": 0.9068914115353743,
      "grad_norm": 0.0,
      "learning_rate": 2.266194115183457e-05,
      "loss": 4.7633,
      "step": 7909
    },
    {
      "epoch": 0.907006077284715,
      "grad_norm": 0.0,
      "learning_rate": 2.2606824588459624e-05,
      "loss": 4.9456,
      "step": 7910
    },
    {
      "epoch": 0.9071207430340558,
      "grad_norm": 0.0,
      "learning_rate": 2.2551773879269713e-05,
      "loss": 5.0267,
      "step": 7911
    },
    {
      "epoch": 0.9072354087833964,
      "grad_norm": 0.0,
      "learning_rate": 2.2496789031858286e-05,
      "loss": 5.0356,
      "step": 7912
    },
    {
      "epoch": 0.9073500745327371,
      "grad_norm": 0.0,
      "learning_rate": 2.2441870053809242e-05,
      "loss": 4.9939,
      "step": 7913
    },
    {
      "epoch": 0.9074647402820778,
      "grad_norm": 0.0,
      "learning_rate": 2.238701695269764e-05,
      "loss": 4.8941,
      "step": 7914
    },
    {
      "epoch": 0.9075794060314184,
      "grad_norm": 0.0,
      "learning_rate": 2.233222973608957e-05,
      "loss": 4.8544,
      "step": 7915
    },
    {
      "epoch": 0.9076940717807591,
      "grad_norm": 0.0,
      "learning_rate": 2.227750841154167e-05,
      "loss": 5.0137,
      "step": 7916
    },
    {
      "epoch": 0.9078087375300997,
      "grad_norm": 0.0,
      "learning_rate": 2.2222852986601926e-05,
      "loss": 5.257,
      "step": 7917
    },
    {
      "epoch": 0.9079234032794404,
      "grad_norm": 0.0,
      "learning_rate": 2.2168263468808777e-05,
      "loss": 5.0721,
      "step": 7918
    },
    {
      "epoch": 0.9080380690287811,
      "grad_norm": 0.0,
      "learning_rate": 2.2113739865692058e-05,
      "loss": 5.1167,
      "step": 7919
    },
    {
      "epoch": 0.9081527347781218,
      "grad_norm": 0.0,
      "learning_rate": 2.2059282184772053e-05,
      "loss": 5.1024,
      "step": 7920
    },
    {
      "epoch": 0.9082674005274625,
      "grad_norm": 0.0,
      "learning_rate": 2.2004890433560224e-05,
      "loss": 5.0974,
      "step": 7921
    },
    {
      "epoch": 0.9083820662768031,
      "grad_norm": 0.0,
      "learning_rate": 2.1950564619558876e-05,
      "loss": 4.8997,
      "step": 7922
    },
    {
      "epoch": 0.9084967320261438,
      "grad_norm": 0.0,
      "learning_rate": 2.1896304750261263e-05,
      "loss": 5.0884,
      "step": 7923
    },
    {
      "epoch": 0.9086113977754845,
      "grad_norm": 0.0,
      "learning_rate": 2.1842110833151544e-05,
      "loss": 4.8349,
      "step": 7924
    },
    {
      "epoch": 0.9087260635248251,
      "grad_norm": 0.0,
      "learning_rate": 2.1787982875704538e-05,
      "loss": 4.6492,
      "step": 7925
    },
    {
      "epoch": 0.9088407292741658,
      "grad_norm": 0.0,
      "learning_rate": 2.173392088538642e-05,
      "loss": 4.7354,
      "step": 7926
    },
    {
      "epoch": 0.9089553950235065,
      "grad_norm": 0.0,
      "learning_rate": 2.1679924869653814e-05,
      "loss": 4.9058,
      "step": 7927
    },
    {
      "epoch": 0.9090700607728471,
      "grad_norm": 0.0,
      "learning_rate": 2.1625994835954457e-05,
      "loss": 4.8298,
      "step": 7928
    },
    {
      "epoch": 0.9091847265221878,
      "grad_norm": 0.0,
      "learning_rate": 2.15721307917271e-05,
      "loss": 5.0197,
      "step": 7929
    },
    {
      "epoch": 0.9092993922715285,
      "grad_norm": 0.0,
      "learning_rate": 2.1518332744401117e-05,
      "loss": 5.1721,
      "step": 7930
    },
    {
      "epoch": 0.9094140580208692,
      "grad_norm": 0.0,
      "learning_rate": 2.1464600701397044e-05,
      "loss": 4.9116,
      "step": 7931
    },
    {
      "epoch": 0.9095287237702099,
      "grad_norm": 0.0,
      "learning_rate": 2.141093467012616e-05,
      "loss": 4.7365,
      "step": 7932
    },
    {
      "epoch": 0.9096433895195505,
      "grad_norm": 0.0,
      "learning_rate": 2.1357334657990632e-05,
      "loss": 4.9442,
      "step": 7933
    },
    {
      "epoch": 0.9097580552688912,
      "grad_norm": 0.0,
      "learning_rate": 2.1303800672383536e-05,
      "loss": 5.0772,
      "step": 7934
    },
    {
      "epoch": 0.9098727210182318,
      "grad_norm": 0.0,
      "learning_rate": 2.1250332720688886e-05,
      "loss": 4.8696,
      "step": 7935
    },
    {
      "epoch": 0.9099873867675725,
      "grad_norm": 0.0,
      "learning_rate": 2.1196930810281654e-05,
      "loss": 5.2628,
      "step": 7936
    },
    {
      "epoch": 0.9101020525169132,
      "grad_norm": 0.0,
      "learning_rate": 2.114359494852755e-05,
      "loss": 4.9078,
      "step": 7937
    },
    {
      "epoch": 0.9102167182662538,
      "grad_norm": 0.0,
      "learning_rate": 2.109032514278312e-05,
      "loss": 5.0736,
      "step": 7938
    },
    {
      "epoch": 0.9103313840155945,
      "grad_norm": 0.0,
      "learning_rate": 2.103712140039619e-05,
      "loss": 4.9637,
      "step": 7939
    },
    {
      "epoch": 0.9104460497649353,
      "grad_norm": 0.0,
      "learning_rate": 2.0983983728704882e-05,
      "loss": 4.7474,
      "step": 7940
    },
    {
      "epoch": 0.9105607155142759,
      "grad_norm": 0.0,
      "learning_rate": 2.093091213503882e-05,
      "loss": 4.7968,
      "step": 7941
    },
    {
      "epoch": 0.9106753812636166,
      "grad_norm": 0.0,
      "learning_rate": 2.087790662671803e-05,
      "loss": 5.0914,
      "step": 7942
    },
    {
      "epoch": 0.9107900470129572,
      "grad_norm": 0.0,
      "learning_rate": 2.0824967211053706e-05,
      "loss": 5.04,
      "step": 7943
    },
    {
      "epoch": 0.9109047127622979,
      "grad_norm": 0.0,
      "learning_rate": 2.077209389534783e-05,
      "loss": 5.0754,
      "step": 7944
    },
    {
      "epoch": 0.9110193785116386,
      "grad_norm": 0.0,
      "learning_rate": 2.071928668689312e-05,
      "loss": 5.2354,
      "step": 7945
    },
    {
      "epoch": 0.9111340442609792,
      "grad_norm": 0.0,
      "learning_rate": 2.0666545592973518e-05,
      "loss": 4.6847,
      "step": 7946
    },
    {
      "epoch": 0.9112487100103199,
      "grad_norm": 0.0,
      "learning_rate": 2.0613870620863482e-05,
      "loss": 5.3929,
      "step": 7947
    },
    {
      "epoch": 0.9113633757596606,
      "grad_norm": 0.0,
      "learning_rate": 2.056126177782875e-05,
      "loss": 4.8343,
      "step": 7948
    },
    {
      "epoch": 0.9114780415090012,
      "grad_norm": 0.0,
      "learning_rate": 2.050871907112545e-05,
      "loss": 4.9636,
      "step": 7949
    },
    {
      "epoch": 0.911592707258342,
      "grad_norm": 0.0,
      "learning_rate": 2.0456242508001004e-05,
      "loss": 5.0372,
      "step": 7950
    },
    {
      "epoch": 0.9117073730076826,
      "grad_norm": 0.0,
      "learning_rate": 2.040383209569352e-05,
      "loss": 4.9694,
      "step": 7951
    },
    {
      "epoch": 0.9118220387570233,
      "grad_norm": 0.0,
      "learning_rate": 2.035148784143204e-05,
      "loss": 4.9547,
      "step": 7952
    },
    {
      "epoch": 0.911936704506364,
      "grad_norm": 0.0,
      "learning_rate": 2.0299209752436455e-05,
      "loss": 5.0687,
      "step": 7953
    },
    {
      "epoch": 0.9120513702557046,
      "grad_norm": 0.0,
      "learning_rate": 2.0246997835917442e-05,
      "loss": 4.8607,
      "step": 7954
    },
    {
      "epoch": 0.9121660360050453,
      "grad_norm": 0.0,
      "learning_rate": 2.0194852099076692e-05,
      "loss": 5.1281,
      "step": 7955
    },
    {
      "epoch": 0.9122807017543859,
      "grad_norm": 0.0,
      "learning_rate": 2.0142772549106723e-05,
      "loss": 4.866,
      "step": 7956
    },
    {
      "epoch": 0.9123953675037266,
      "grad_norm": 0.0,
      "learning_rate": 2.0090759193190904e-05,
      "loss": 5.0991,
      "step": 7957
    },
    {
      "epoch": 0.9125100332530673,
      "grad_norm": 0.0,
      "learning_rate": 2.0038812038503507e-05,
      "loss": 4.9478,
      "step": 7958
    },
    {
      "epoch": 0.912624699002408,
      "grad_norm": 0.0,
      "learning_rate": 1.9986931092209743e-05,
      "loss": 5.3434,
      "step": 7959
    },
    {
      "epoch": 0.9127393647517487,
      "grad_norm": 0.0,
      "learning_rate": 1.9935116361465342e-05,
      "loss": 4.891,
      "step": 7960
    },
    {
      "epoch": 0.9128540305010894,
      "grad_norm": 0.0,
      "learning_rate": 1.988336785341743e-05,
      "loss": 4.9043,
      "step": 7961
    },
    {
      "epoch": 0.91296869625043,
      "grad_norm": 0.0,
      "learning_rate": 1.983168557520352e-05,
      "loss": 4.8774,
      "step": 7962
    },
    {
      "epoch": 0.9130833619997707,
      "grad_norm": 0.0,
      "learning_rate": 1.9780069533952425e-05,
      "loss": 4.9744,
      "step": 7963
    },
    {
      "epoch": 0.9131980277491113,
      "grad_norm": 0.0,
      "learning_rate": 1.9728519736783347e-05,
      "loss": 5.4892,
      "step": 7964
    },
    {
      "epoch": 0.913312693498452,
      "grad_norm": 0.0,
      "learning_rate": 1.9677036190806775e-05,
      "loss": 4.8733,
      "step": 7965
    },
    {
      "epoch": 0.9134273592477927,
      "grad_norm": 0.0,
      "learning_rate": 1.9625618903123818e-05,
      "loss": 5.1995,
      "step": 7966
    },
    {
      "epoch": 0.9135420249971333,
      "grad_norm": 0.0,
      "learning_rate": 1.957426788082642e-05,
      "loss": 5.0366,
      "step": 7967
    },
    {
      "epoch": 0.913656690746474,
      "grad_norm": 0.0,
      "learning_rate": 1.9522983130997717e-05,
      "loss": 4.8655,
      "step": 7968
    },
    {
      "epoch": 0.9137713564958146,
      "grad_norm": 0.0,
      "learning_rate": 1.9471764660711117e-05,
      "loss": 5.0924,
      "step": 7969
    },
    {
      "epoch": 0.9138860222451554,
      "grad_norm": 0.0,
      "learning_rate": 1.9420612477031593e-05,
      "loss": 4.9921,
      "step": 7970
    },
    {
      "epoch": 0.9140006879944961,
      "grad_norm": 0.0,
      "learning_rate": 1.9369526587014404e-05,
      "loss": 5.0615,
      "step": 7971
    },
    {
      "epoch": 0.9141153537438367,
      "grad_norm": 0.0,
      "learning_rate": 1.9318506997705883e-05,
      "loss": 4.97,
      "step": 7972
    },
    {
      "epoch": 0.9142300194931774,
      "grad_norm": 0.0,
      "learning_rate": 1.9267553716143297e-05,
      "loss": 4.7959,
      "step": 7973
    },
    {
      "epoch": 0.9143446852425181,
      "grad_norm": 0.0,
      "learning_rate": 1.921666674935461e-05,
      "loss": 4.9799,
      "step": 7974
    },
    {
      "epoch": 0.9144593509918587,
      "grad_norm": 0.0,
      "learning_rate": 1.9165846104358773e-05,
      "loss": 4.7934,
      "step": 7975
    },
    {
      "epoch": 0.9145740167411994,
      "grad_norm": 0.0,
      "learning_rate": 1.9115091788165426e-05,
      "loss": 5.206,
      "step": 7976
    },
    {
      "epoch": 0.91468868249054,
      "grad_norm": 0.0,
      "learning_rate": 1.9064403807775157e-05,
      "loss": 4.7799,
      "step": 7977
    },
    {
      "epoch": 0.9148033482398807,
      "grad_norm": 0.0,
      "learning_rate": 1.9013782170179563e-05,
      "loss": 5.0284,
      "step": 7978
    },
    {
      "epoch": 0.9149180139892215,
      "grad_norm": 0.0,
      "learning_rate": 1.8963226882360746e-05,
      "loss": 4.9828,
      "step": 7979
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.0,
      "learning_rate": 1.891273795129199e-05,
      "loss": 4.8224,
      "step": 7980
    },
    {
      "epoch": 0.9151473454879028,
      "grad_norm": 0.0,
      "learning_rate": 1.8862315383937248e-05,
      "loss": 4.8198,
      "step": 7981
    },
    {
      "epoch": 0.9152620112372435,
      "grad_norm": 0.0,
      "learning_rate": 1.8811959187251256e-05,
      "loss": 5.0842,
      "step": 7982
    },
    {
      "epoch": 0.9153766769865841,
      "grad_norm": 0.0,
      "learning_rate": 1.8761669368179827e-05,
      "loss": 5.2119,
      "step": 7983
    },
    {
      "epoch": 0.9154913427359248,
      "grad_norm": 0.0,
      "learning_rate": 1.8711445933659378e-05,
      "loss": 5.1622,
      "step": 7984
    },
    {
      "epoch": 0.9156060084852654,
      "grad_norm": 0.0,
      "learning_rate": 1.866128889061734e-05,
      "loss": 4.9719,
      "step": 7985
    },
    {
      "epoch": 0.9157206742346061,
      "grad_norm": 0.0,
      "learning_rate": 1.861119824597188e-05,
      "loss": 4.9835,
      "step": 7986
    },
    {
      "epoch": 0.9158353399839468,
      "grad_norm": 0.0,
      "learning_rate": 1.856117400663206e-05,
      "loss": 5.0673,
      "step": 7987
    },
    {
      "epoch": 0.9159500057332874,
      "grad_norm": 0.0,
      "learning_rate": 1.851121617949783e-05,
      "loss": 4.7717,
      "step": 7988
    },
    {
      "epoch": 0.9160646714826282,
      "grad_norm": 0.0,
      "learning_rate": 1.8461324771459714e-05,
      "loss": 4.7721,
      "step": 7989
    },
    {
      "epoch": 0.9161793372319688,
      "grad_norm": 0.0,
      "learning_rate": 1.8411499789399628e-05,
      "loss": 5.0645,
      "step": 7990
    },
    {
      "epoch": 0.9162940029813095,
      "grad_norm": 0.0,
      "learning_rate": 1.836174124018961e-05,
      "loss": 5.1706,
      "step": 7991
    },
    {
      "epoch": 0.9164086687306502,
      "grad_norm": 0.0,
      "learning_rate": 1.8312049130693204e-05,
      "loss": 5.0057,
      "step": 7992
    },
    {
      "epoch": 0.9165233344799908,
      "grad_norm": 0.0,
      "learning_rate": 1.82624234677643e-05,
      "loss": 4.7129,
      "step": 7993
    },
    {
      "epoch": 0.9166380002293315,
      "grad_norm": 0.0,
      "learning_rate": 1.8212864258247845e-05,
      "loss": 5.1414,
      "step": 7994
    },
    {
      "epoch": 0.9167526659786722,
      "grad_norm": 0.0,
      "learning_rate": 1.816337150897969e-05,
      "loss": 4.9343,
      "step": 7995
    },
    {
      "epoch": 0.9168673317280128,
      "grad_norm": 0.0,
      "learning_rate": 1.8113945226786247e-05,
      "loss": 4.9228,
      "step": 7996
    },
    {
      "epoch": 0.9169819974773535,
      "grad_norm": 0.0,
      "learning_rate": 1.80645854184851e-05,
      "loss": 4.904,
      "step": 7997
    },
    {
      "epoch": 0.9170966632266941,
      "grad_norm": 0.0,
      "learning_rate": 1.8015292090884397e-05,
      "loss": 4.9832,
      "step": 7998
    },
    {
      "epoch": 0.9172113289760349,
      "grad_norm": 0.0,
      "learning_rate": 1.7966065250783188e-05,
      "loss": 5.0403,
      "step": 7999
    },
    {
      "epoch": 0.9173259947253756,
      "grad_norm": 0.0,
      "learning_rate": 1.7916904904971473e-05,
      "loss": 4.785,
      "step": 8000
    },
    {
      "epoch": 0.9174406604747162,
      "grad_norm": 0.0,
      "learning_rate": 1.786781106022993e-05,
      "loss": 5.2467,
      "step": 8001
    },
    {
      "epoch": 0.9175553262240569,
      "grad_norm": 0.0,
      "learning_rate": 1.7818783723330073e-05,
      "loss": 5.0469,
      "step": 8002
    },
    {
      "epoch": 0.9176699919733975,
      "grad_norm": 0.0,
      "learning_rate": 1.776982290103443e-05,
      "loss": 4.9723,
      "step": 8003
    },
    {
      "epoch": 0.9177846577227382,
      "grad_norm": 0.0,
      "learning_rate": 1.7720928600096082e-05,
      "loss": 4.8578,
      "step": 8004
    },
    {
      "epoch": 0.9178993234720789,
      "grad_norm": 0.0,
      "learning_rate": 1.7672100827259078e-05,
      "loss": 4.8676,
      "step": 8005
    },
    {
      "epoch": 0.9180139892214195,
      "grad_norm": 0.0,
      "learning_rate": 1.7623339589258298e-05,
      "loss": 4.9865,
      "step": 8006
    },
    {
      "epoch": 0.9181286549707602,
      "grad_norm": 0.0,
      "learning_rate": 1.7574644892819465e-05,
      "loss": 5.0421,
      "step": 8007
    },
    {
      "epoch": 0.918243320720101,
      "grad_norm": 0.0,
      "learning_rate": 1.7526016744659036e-05,
      "loss": 5.2213,
      "step": 8008
    },
    {
      "epoch": 0.9183579864694416,
      "grad_norm": 0.0,
      "learning_rate": 1.7477455151484308e-05,
      "loss": 5.1465,
      "step": 8009
    },
    {
      "epoch": 0.9184726522187823,
      "grad_norm": 0.0,
      "learning_rate": 1.742896011999359e-05,
      "loss": 4.9564,
      "step": 8010
    },
    {
      "epoch": 0.9185873179681229,
      "grad_norm": 0.0,
      "learning_rate": 1.7380531656875628e-05,
      "loss": 4.9658,
      "step": 8011
    },
    {
      "epoch": 0.9187019837174636,
      "grad_norm": 0.0,
      "learning_rate": 1.7332169768810368e-05,
      "loss": 5.0212,
      "step": 8012
    },
    {
      "epoch": 0.9188166494668043,
      "grad_norm": 0.0,
      "learning_rate": 1.7283874462468244e-05,
      "loss": 5.033,
      "step": 8013
    },
    {
      "epoch": 0.9189313152161449,
      "grad_norm": 0.0,
      "learning_rate": 1.7235645744510923e-05,
      "loss": 4.9351,
      "step": 8014
    },
    {
      "epoch": 0.9190459809654856,
      "grad_norm": 0.0,
      "learning_rate": 1.718748362159048e-05,
      "loss": 4.8798,
      "step": 8015
    },
    {
      "epoch": 0.9191606467148263,
      "grad_norm": 0.0,
      "learning_rate": 1.7139388100349827e-05,
      "loss": 5.1248,
      "step": 8016
    },
    {
      "epoch": 0.9192753124641669,
      "grad_norm": 0.0,
      "learning_rate": 1.7091359187423158e-05,
      "loss": 4.9799,
      "step": 8017
    },
    {
      "epoch": 0.9193899782135077,
      "grad_norm": 0.0,
      "learning_rate": 1.7043396889434782e-05,
      "loss": 5.2037,
      "step": 8018
    },
    {
      "epoch": 0.9195046439628483,
      "grad_norm": 0.0,
      "learning_rate": 1.6995501213000478e-05,
      "loss": 5.2167,
      "step": 8019
    },
    {
      "epoch": 0.919619309712189,
      "grad_norm": 0.0,
      "learning_rate": 1.6947672164726404e-05,
      "loss": 5.0761,
      "step": 8020
    },
    {
      "epoch": 0.9197339754615297,
      "grad_norm": 0.0,
      "learning_rate": 1.689990975120968e-05,
      "loss": 4.7573,
      "step": 8021
    },
    {
      "epoch": 0.9198486412108703,
      "grad_norm": 0.0,
      "learning_rate": 1.6852213979038207e-05,
      "loss": 5.1219,
      "step": 8022
    },
    {
      "epoch": 0.919963306960211,
      "grad_norm": 0.0,
      "learning_rate": 1.680458485479074e-05,
      "loss": 5.1712,
      "step": 8023
    },
    {
      "epoch": 0.9200779727095516,
      "grad_norm": 0.0,
      "learning_rate": 1.6757022385036803e-05,
      "loss": 5.0733,
      "step": 8024
    },
    {
      "epoch": 0.9201926384588923,
      "grad_norm": 0.0,
      "learning_rate": 1.6709526576336766e-05,
      "loss": 5.0649,
      "step": 8025
    },
    {
      "epoch": 0.920307304208233,
      "grad_norm": 0.0,
      "learning_rate": 1.6662097435241686e-05,
      "loss": 5.0514,
      "step": 8026
    },
    {
      "epoch": 0.9204219699575736,
      "grad_norm": 0.0,
      "learning_rate": 1.6614734968293508e-05,
      "loss": 4.9266,
      "step": 8027
    },
    {
      "epoch": 0.9205366357069144,
      "grad_norm": 0.0,
      "learning_rate": 1.656743918202507e-05,
      "loss": 4.9192,
      "step": 8028
    },
    {
      "epoch": 0.9206513014562551,
      "grad_norm": 0.0,
      "learning_rate": 1.652021008295989e-05,
      "loss": 4.8649,
      "step": 8029
    },
    {
      "epoch": 0.9207659672055957,
      "grad_norm": 0.0,
      "learning_rate": 1.6473047677612333e-05,
      "loss": 5.0602,
      "step": 8030
    },
    {
      "epoch": 0.9208806329549364,
      "grad_norm": 0.0,
      "learning_rate": 1.6425951972487482e-05,
      "loss": 5.0688,
      "step": 8031
    },
    {
      "epoch": 0.920995298704277,
      "grad_norm": 0.0,
      "learning_rate": 1.6378922974081435e-05,
      "loss": 5.1897,
      "step": 8032
    },
    {
      "epoch": 0.9211099644536177,
      "grad_norm": 0.0,
      "learning_rate": 1.633196068888069e-05,
      "loss": 4.9871,
      "step": 8033
    },
    {
      "epoch": 0.9212246302029584,
      "grad_norm": 0.0,
      "learning_rate": 1.6285065123363144e-05,
      "loss": 4.9568,
      "step": 8034
    },
    {
      "epoch": 0.921339295952299,
      "grad_norm": 0.0,
      "learning_rate": 1.6238236283996857e-05,
      "loss": 5.1256,
      "step": 8035
    },
    {
      "epoch": 0.9214539617016397,
      "grad_norm": 0.0,
      "learning_rate": 1.6191474177241073e-05,
      "loss": 4.9173,
      "step": 8036
    },
    {
      "epoch": 0.9215686274509803,
      "grad_norm": 0.0,
      "learning_rate": 1.6144778809545876e-05,
      "loss": 4.9823,
      "step": 8037
    },
    {
      "epoch": 0.921683293200321,
      "grad_norm": 0.0,
      "learning_rate": 1.6098150187351695e-05,
      "loss": 5.0988,
      "step": 8038
    },
    {
      "epoch": 0.9217979589496618,
      "grad_norm": 0.0,
      "learning_rate": 1.605158831709035e-05,
      "loss": 5.0749,
      "step": 8039
    },
    {
      "epoch": 0.9219126246990024,
      "grad_norm": 0.0,
      "learning_rate": 1.6005093205183944e-05,
      "loss": 5.183,
      "step": 8040
    },
    {
      "epoch": 0.9220272904483431,
      "grad_norm": 0.0,
      "learning_rate": 1.5958664858045827e-05,
      "loss": 5.0941,
      "step": 8041
    },
    {
      "epoch": 0.9221419561976838,
      "grad_norm": 0.0,
      "learning_rate": 1.5912303282079676e-05,
      "loss": 5.1074,
      "step": 8042
    },
    {
      "epoch": 0.9222566219470244,
      "grad_norm": 0.0,
      "learning_rate": 1.5866008483680345e-05,
      "loss": 5.1576,
      "step": 8043
    },
    {
      "epoch": 0.9223712876963651,
      "grad_norm": 0.0,
      "learning_rate": 1.5819780469233192e-05,
      "loss": 4.8268,
      "step": 8044
    },
    {
      "epoch": 0.9224859534457057,
      "grad_norm": 0.0,
      "learning_rate": 1.57736192451146e-05,
      "loss": 4.9227,
      "step": 8045
    },
    {
      "epoch": 0.9226006191950464,
      "grad_norm": 0.0,
      "learning_rate": 1.5727524817691615e-05,
      "loss": 5.3146,
      "step": 8046
    },
    {
      "epoch": 0.9227152849443871,
      "grad_norm": 0.0,
      "learning_rate": 1.5681497193322013e-05,
      "loss": 4.8641,
      "step": 8047
    },
    {
      "epoch": 0.9228299506937278,
      "grad_norm": 0.0,
      "learning_rate": 1.5635536378354467e-05,
      "loss": 4.8859,
      "step": 8048
    },
    {
      "epoch": 0.9229446164430685,
      "grad_norm": 0.0,
      "learning_rate": 1.5589642379128385e-05,
      "loss": 5.0142,
      "step": 8049
    },
    {
      "epoch": 0.9230592821924092,
      "grad_norm": 0.0,
      "learning_rate": 1.5543815201974013e-05,
      "loss": 5.2431,
      "step": 8050
    },
    {
      "epoch": 0.9231739479417498,
      "grad_norm": 0.0,
      "learning_rate": 1.549805485321227e-05,
      "loss": 5.056,
      "step": 8051
    },
    {
      "epoch": 0.9232886136910905,
      "grad_norm": 0.0,
      "learning_rate": 1.5452361339154982e-05,
      "loss": 5.0694,
      "step": 8052
    },
    {
      "epoch": 0.9234032794404311,
      "grad_norm": 0.0,
      "learning_rate": 1.5406734666104696e-05,
      "loss": 5.1706,
      "step": 8053
    },
    {
      "epoch": 0.9235179451897718,
      "grad_norm": 0.0,
      "learning_rate": 1.5361174840354746e-05,
      "loss": 5.2656,
      "step": 8054
    },
    {
      "epoch": 0.9236326109391125,
      "grad_norm": 0.0,
      "learning_rate": 1.5315681868189145e-05,
      "loss": 5.1522,
      "step": 8055
    },
    {
      "epoch": 0.9237472766884531,
      "grad_norm": 0.0,
      "learning_rate": 1.527025575588286e-05,
      "loss": 4.9208,
      "step": 8056
    },
    {
      "epoch": 0.9238619424377938,
      "grad_norm": 0.0,
      "learning_rate": 1.5224896509701576e-05,
      "loss": 4.9102,
      "step": 8057
    },
    {
      "epoch": 0.9239766081871345,
      "grad_norm": 0.0,
      "learning_rate": 1.5179604135901726e-05,
      "loss": 5.0928,
      "step": 8058
    },
    {
      "epoch": 0.9240912739364752,
      "grad_norm": 0.0,
      "learning_rate": 1.5134378640730516e-05,
      "loss": 4.9238,
      "step": 8059
    },
    {
      "epoch": 0.9242059396858159,
      "grad_norm": 0.0,
      "learning_rate": 1.5089220030425892e-05,
      "loss": 4.9835,
      "step": 8060
    },
    {
      "epoch": 0.9243206054351565,
      "grad_norm": 0.0,
      "learning_rate": 1.5044128311216744e-05,
      "loss": 5.0678,
      "step": 8061
    },
    {
      "epoch": 0.9244352711844972,
      "grad_norm": 0.0,
      "learning_rate": 1.499910348932242e-05,
      "loss": 4.9341,
      "step": 8062
    },
    {
      "epoch": 0.9245499369338379,
      "grad_norm": 0.0,
      "learning_rate": 1.4954145570953496e-05,
      "loss": 4.9633,
      "step": 8063
    },
    {
      "epoch": 0.9246646026831785,
      "grad_norm": 0.0,
      "learning_rate": 1.490925456231084e-05,
      "loss": 4.9126,
      "step": 8064
    },
    {
      "epoch": 0.9247792684325192,
      "grad_norm": 0.0,
      "learning_rate": 1.4864430469586431e-05,
      "loss": 5.117,
      "step": 8065
    },
    {
      "epoch": 0.9248939341818598,
      "grad_norm": 0.0,
      "learning_rate": 1.481967329896287e-05,
      "loss": 4.8415,
      "step": 8066
    },
    {
      "epoch": 0.9250085999312005,
      "grad_norm": 0.0,
      "learning_rate": 1.4774983056613494e-05,
      "loss": 5.0121,
      "step": 8067
    },
    {
      "epoch": 0.9251232656805413,
      "grad_norm": 0.0,
      "learning_rate": 1.4730359748702586e-05,
      "loss": 4.9208,
      "step": 8068
    },
    {
      "epoch": 0.9252379314298819,
      "grad_norm": 0.0,
      "learning_rate": 1.4685803381384996e-05,
      "loss": 4.9932,
      "step": 8069
    },
    {
      "epoch": 0.9253525971792226,
      "grad_norm": 0.0,
      "learning_rate": 1.4641313960806413e-05,
      "loss": 5.218,
      "step": 8070
    },
    {
      "epoch": 0.9254672629285632,
      "grad_norm": 0.0,
      "learning_rate": 1.4596891493103318e-05,
      "loss": 5.1592,
      "step": 8071
    },
    {
      "epoch": 0.9255819286779039,
      "grad_norm": 0.0,
      "learning_rate": 1.4552535984403027e-05,
      "loss": 4.93,
      "step": 8072
    },
    {
      "epoch": 0.9256965944272446,
      "grad_norm": 0.0,
      "learning_rate": 1.4508247440823423e-05,
      "loss": 4.9918,
      "step": 8073
    },
    {
      "epoch": 0.9258112601765852,
      "grad_norm": 0.0,
      "learning_rate": 1.4464025868473343e-05,
      "loss": 5.0901,
      "step": 8074
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.0,
      "learning_rate": 1.4419871273452349e-05,
      "loss": 4.8842,
      "step": 8075
    },
    {
      "epoch": 0.9260405916752666,
      "grad_norm": 0.0,
      "learning_rate": 1.4375783661850576e-05,
      "loss": 5.241,
      "step": 8076
    },
    {
      "epoch": 0.9261552574246072,
      "grad_norm": 0.0,
      "learning_rate": 1.4331763039749158e-05,
      "loss": 4.8585,
      "step": 8077
    },
    {
      "epoch": 0.926269923173948,
      "grad_norm": 0.0,
      "learning_rate": 1.4287809413219911e-05,
      "loss": 4.9474,
      "step": 8078
    },
    {
      "epoch": 0.9263845889232886,
      "grad_norm": 0.0,
      "learning_rate": 1.4243922788325376e-05,
      "loss": 5.088,
      "step": 8079
    },
    {
      "epoch": 0.9264992546726293,
      "grad_norm": 0.0,
      "learning_rate": 1.4200103171118885e-05,
      "loss": 5.1804,
      "step": 8080
    },
    {
      "epoch": 0.92661392042197,
      "grad_norm": 0.0,
      "learning_rate": 1.4156350567644554e-05,
      "loss": 5.2136,
      "step": 8081
    },
    {
      "epoch": 0.9267285861713106,
      "grad_norm": 0.0,
      "learning_rate": 1.4112664983937117e-05,
      "loss": 4.9485,
      "step": 8082
    },
    {
      "epoch": 0.9268432519206513,
      "grad_norm": 0.0,
      "learning_rate": 1.4069046426022317e-05,
      "loss": 4.8529,
      "step": 8083
    },
    {
      "epoch": 0.926957917669992,
      "grad_norm": 0.0,
      "learning_rate": 1.4025494899916352e-05,
      "loss": 5.017,
      "step": 8084
    },
    {
      "epoch": 0.9270725834193326,
      "grad_norm": 0.0,
      "learning_rate": 1.3982010411626479e-05,
      "loss": 4.935,
      "step": 8085
    },
    {
      "epoch": 0.9271872491686733,
      "grad_norm": 0.0,
      "learning_rate": 1.3938592967150471e-05,
      "loss": 5.0612,
      "step": 8086
    },
    {
      "epoch": 0.927301914918014,
      "grad_norm": 0.0,
      "learning_rate": 1.3895242572476825e-05,
      "loss": 5.0083,
      "step": 8087
    },
    {
      "epoch": 0.9274165806673547,
      "grad_norm": 0.0,
      "learning_rate": 1.3851959233585104e-05,
      "loss": 4.9031,
      "step": 8088
    },
    {
      "epoch": 0.9275312464166954,
      "grad_norm": 0.0,
      "learning_rate": 1.3808742956445267e-05,
      "loss": 5.1648,
      "step": 8089
    },
    {
      "epoch": 0.927645912166036,
      "grad_norm": 0.0,
      "learning_rate": 1.3765593747018341e-05,
      "loss": 4.7396,
      "step": 8090
    },
    {
      "epoch": 0.9277605779153767,
      "grad_norm": 0.0,
      "learning_rate": 1.3722511611255746e-05,
      "loss": 5.3441,
      "step": 8091
    },
    {
      "epoch": 0.9278752436647173,
      "grad_norm": 0.0,
      "learning_rate": 1.3679496555099966e-05,
      "loss": 4.9751,
      "step": 8092
    },
    {
      "epoch": 0.927989909414058,
      "grad_norm": 0.0,
      "learning_rate": 1.363654858448405e-05,
      "loss": 5.1551,
      "step": 8093
    },
    {
      "epoch": 0.9281045751633987,
      "grad_norm": 0.0,
      "learning_rate": 1.3593667705331835e-05,
      "loss": 5.0873,
      "step": 8094
    },
    {
      "epoch": 0.9282192409127393,
      "grad_norm": 0.0,
      "learning_rate": 1.3550853923557996e-05,
      "loss": 5.0253,
      "step": 8095
    },
    {
      "epoch": 0.92833390666208,
      "grad_norm": 0.0,
      "learning_rate": 1.3508107245067829e-05,
      "loss": 5.0206,
      "step": 8096
    },
    {
      "epoch": 0.9284485724114208,
      "grad_norm": 0.0,
      "learning_rate": 1.346542767575753e-05,
      "loss": 5.178,
      "step": 8097
    },
    {
      "epoch": 0.9285632381607614,
      "grad_norm": 0.0,
      "learning_rate": 1.3422815221513745e-05,
      "loss": 4.9858,
      "step": 8098
    },
    {
      "epoch": 0.9286779039101021,
      "grad_norm": 0.0,
      "learning_rate": 1.3380269888214125e-05,
      "loss": 4.9552,
      "step": 8099
    },
    {
      "epoch": 0.9287925696594427,
      "grad_norm": 0.0,
      "learning_rate": 1.333779168172706e-05,
      "loss": 4.8964,
      "step": 8100
    },
    {
      "epoch": 0.9289072354087834,
      "grad_norm": 0.0,
      "learning_rate": 1.329538060791155e-05,
      "loss": 4.9286,
      "step": 8101
    },
    {
      "epoch": 0.9290219011581241,
      "grad_norm": 0.0,
      "learning_rate": 1.3253036672617334e-05,
      "loss": 4.8715,
      "step": 8102
    },
    {
      "epoch": 0.9291365669074647,
      "grad_norm": 0.0,
      "learning_rate": 1.3210759881685096e-05,
      "loss": 4.9392,
      "step": 8103
    },
    {
      "epoch": 0.9292512326568054,
      "grad_norm": 0.0,
      "learning_rate": 1.316855024094598e-05,
      "loss": 5.3423,
      "step": 8104
    },
    {
      "epoch": 0.929365898406146,
      "grad_norm": 0.0,
      "learning_rate": 1.3126407756222078e-05,
      "loss": 5.0172,
      "step": 8105
    },
    {
      "epoch": 0.9294805641554867,
      "grad_norm": 0.0,
      "learning_rate": 1.3084332433326103e-05,
      "loss": 4.874,
      "step": 8106
    },
    {
      "epoch": 0.9295952299048275,
      "grad_norm": 0.0,
      "learning_rate": 1.3042324278061555e-05,
      "loss": 4.766,
      "step": 8107
    },
    {
      "epoch": 0.9297098956541681,
      "grad_norm": 0.0,
      "learning_rate": 1.3000383296222718e-05,
      "loss": 4.6962,
      "step": 8108
    },
    {
      "epoch": 0.9298245614035088,
      "grad_norm": 0.0,
      "learning_rate": 1.2958509493594387e-05,
      "loss": 5.3686,
      "step": 8109
    },
    {
      "epoch": 0.9299392271528495,
      "grad_norm": 0.0,
      "learning_rate": 1.2916702875952471e-05,
      "loss": 5.0262,
      "step": 8110
    },
    {
      "epoch": 0.9300538929021901,
      "grad_norm": 0.0,
      "learning_rate": 1.287496344906323e-05,
      "loss": 5.2666,
      "step": 8111
    },
    {
      "epoch": 0.9301685586515308,
      "grad_norm": 0.0,
      "learning_rate": 1.2833291218683924e-05,
      "loss": 4.8742,
      "step": 8112
    },
    {
      "epoch": 0.9302832244008714,
      "grad_norm": 0.0,
      "learning_rate": 1.2791686190562379e-05,
      "loss": 5.0147,
      "step": 8113
    },
    {
      "epoch": 0.9303978901502121,
      "grad_norm": 0.0,
      "learning_rate": 1.275014837043721e-05,
      "loss": 5.1465,
      "step": 8114
    },
    {
      "epoch": 0.9305125558995528,
      "grad_norm": 0.0,
      "learning_rate": 1.270867776403776e-05,
      "loss": 4.6768,
      "step": 8115
    },
    {
      "epoch": 0.9306272216488934,
      "grad_norm": 0.0,
      "learning_rate": 1.2667274377084215e-05,
      "loss": 5.0653,
      "step": 8116
    },
    {
      "epoch": 0.9307418873982342,
      "grad_norm": 0.0,
      "learning_rate": 1.2625938215287323e-05,
      "loss": 5.018,
      "step": 8117
    },
    {
      "epoch": 0.9308565531475749,
      "grad_norm": 0.0,
      "learning_rate": 1.2584669284348507e-05,
      "loss": 5.0985,
      "step": 8118
    },
    {
      "epoch": 0.9309712188969155,
      "grad_norm": 0.0,
      "learning_rate": 1.2543467589960258e-05,
      "loss": 5.0015,
      "step": 8119
    },
    {
      "epoch": 0.9310858846462562,
      "grad_norm": 0.0,
      "learning_rate": 1.2502333137805346e-05,
      "loss": 4.9958,
      "step": 8120
    },
    {
      "epoch": 0.9312005503955968,
      "grad_norm": 0.0,
      "learning_rate": 1.2461265933557559e-05,
      "loss": 5.0191,
      "step": 8121
    },
    {
      "epoch": 0.9313152161449375,
      "grad_norm": 0.0,
      "learning_rate": 1.2420265982881406e-05,
      "loss": 5.0656,
      "step": 8122
    },
    {
      "epoch": 0.9314298818942782,
      "grad_norm": 0.0,
      "learning_rate": 1.2379333291431964e-05,
      "loss": 5.0222,
      "step": 8123
    },
    {
      "epoch": 0.9315445476436188,
      "grad_norm": 0.0,
      "learning_rate": 1.2338467864855154e-05,
      "loss": 4.9192,
      "step": 8124
    },
    {
      "epoch": 0.9316592133929595,
      "grad_norm": 0.0,
      "learning_rate": 1.2297669708787624e-05,
      "loss": 4.7743,
      "step": 8125
    },
    {
      "epoch": 0.9317738791423001,
      "grad_norm": 0.0,
      "learning_rate": 1.2256938828856584e-05,
      "loss": 4.7273,
      "step": 8126
    },
    {
      "epoch": 0.9318885448916409,
      "grad_norm": 0.0,
      "learning_rate": 1.2216275230680152e-05,
      "loss": 4.7449,
      "step": 8127
    },
    {
      "epoch": 0.9320032106409816,
      "grad_norm": 0.0,
      "learning_rate": 1.2175678919867107e-05,
      "loss": 4.864,
      "step": 8128
    },
    {
      "epoch": 0.9321178763903222,
      "grad_norm": 0.0,
      "learning_rate": 1.2135149902016911e-05,
      "loss": 4.9271,
      "step": 8129
    },
    {
      "epoch": 0.9322325421396629,
      "grad_norm": 0.0,
      "learning_rate": 1.2094688182719867e-05,
      "loss": 4.8036,
      "step": 8130
    },
    {
      "epoch": 0.9323472078890036,
      "grad_norm": 0.0,
      "learning_rate": 1.2054293767556672e-05,
      "loss": 5.143,
      "step": 8131
    },
    {
      "epoch": 0.9324618736383442,
      "grad_norm": 0.0,
      "learning_rate": 1.2013966662099203e-05,
      "loss": 4.8771,
      "step": 8132
    },
    {
      "epoch": 0.9325765393876849,
      "grad_norm": 0.0,
      "learning_rate": 1.1973706871909678e-05,
      "loss": 5.4069,
      "step": 8133
    },
    {
      "epoch": 0.9326912051370255,
      "grad_norm": 0.0,
      "learning_rate": 1.1933514402541258e-05,
      "loss": 5.0782,
      "step": 8134
    },
    {
      "epoch": 0.9328058708863662,
      "grad_norm": 0.0,
      "learning_rate": 1.1893389259537631e-05,
      "loss": 5.055,
      "step": 8135
    },
    {
      "epoch": 0.932920536635707,
      "grad_norm": 0.0,
      "learning_rate": 1.1853331448433363e-05,
      "loss": 5.0975,
      "step": 8136
    },
    {
      "epoch": 0.9330352023850476,
      "grad_norm": 0.0,
      "learning_rate": 1.1813340974753703e-05,
      "loss": 5.0127,
      "step": 8137
    },
    {
      "epoch": 0.9331498681343883,
      "grad_norm": 0.0,
      "learning_rate": 1.1773417844014418e-05,
      "loss": 4.9604,
      "step": 8138
    },
    {
      "epoch": 0.9332645338837289,
      "grad_norm": 0.0,
      "learning_rate": 1.173356206172232e-05,
      "loss": 4.7433,
      "step": 8139
    },
    {
      "epoch": 0.9333791996330696,
      "grad_norm": 0.0,
      "learning_rate": 1.1693773633374576e-05,
      "loss": 4.9894,
      "step": 8140
    },
    {
      "epoch": 0.9334938653824103,
      "grad_norm": 0.0,
      "learning_rate": 1.165405256445947e-05,
      "loss": 4.8878,
      "step": 8141
    },
    {
      "epoch": 0.9336085311317509,
      "grad_norm": 0.0,
      "learning_rate": 1.1614398860455573e-05,
      "loss": 5.1368,
      "step": 8142
    },
    {
      "epoch": 0.9337231968810916,
      "grad_norm": 0.0,
      "learning_rate": 1.1574812526832456e-05,
      "loss": 5.3725,
      "step": 8143
    },
    {
      "epoch": 0.9338378626304323,
      "grad_norm": 0.0,
      "learning_rate": 1.1535293569050212e-05,
      "loss": 4.9652,
      "step": 8144
    },
    {
      "epoch": 0.9339525283797729,
      "grad_norm": 0.0,
      "learning_rate": 1.1495841992559818e-05,
      "loss": 5.1094,
      "step": 8145
    },
    {
      "epoch": 0.9340671941291137,
      "grad_norm": 0.0,
      "learning_rate": 1.1456457802802825e-05,
      "loss": 4.9031,
      "step": 8146
    },
    {
      "epoch": 0.9341818598784543,
      "grad_norm": 0.0,
      "learning_rate": 1.1417141005211565e-05,
      "loss": 4.7411,
      "step": 8147
    },
    {
      "epoch": 0.934296525627795,
      "grad_norm": 0.0,
      "learning_rate": 1.1377891605208988e-05,
      "loss": 4.8931,
      "step": 8148
    },
    {
      "epoch": 0.9344111913771357,
      "grad_norm": 0.0,
      "learning_rate": 1.1338709608208836e-05,
      "loss": 4.8202,
      "step": 8149
    },
    {
      "epoch": 0.9345258571264763,
      "grad_norm": 0.0,
      "learning_rate": 1.1299595019615522e-05,
      "loss": 5.1247,
      "step": 8150
    },
    {
      "epoch": 0.934640522875817,
      "grad_norm": 0.0,
      "learning_rate": 1.126054784482408e-05,
      "loss": 5.0789,
      "step": 8151
    },
    {
      "epoch": 0.9347551886251577,
      "grad_norm": 0.0,
      "learning_rate": 1.1221568089220495e-05,
      "loss": 4.873,
      "step": 8152
    },
    {
      "epoch": 0.9348698543744983,
      "grad_norm": 0.0,
      "learning_rate": 1.1182655758181038e-05,
      "loss": 4.9223,
      "step": 8153
    },
    {
      "epoch": 0.934984520123839,
      "grad_norm": 0.0,
      "learning_rate": 1.1143810857073214e-05,
      "loss": 5.092,
      "step": 8154
    },
    {
      "epoch": 0.9350991858731796,
      "grad_norm": 0.0,
      "learning_rate": 1.1105033391254644e-05,
      "loss": 4.8763,
      "step": 8155
    },
    {
      "epoch": 0.9352138516225204,
      "grad_norm": 0.0,
      "learning_rate": 1.1066323366074183e-05,
      "loss": 4.9715,
      "step": 8156
    },
    {
      "epoch": 0.9353285173718611,
      "grad_norm": 0.0,
      "learning_rate": 1.102768078687102e-05,
      "loss": 5.0628,
      "step": 8157
    },
    {
      "epoch": 0.9354431831212017,
      "grad_norm": 0.0,
      "learning_rate": 1.0989105658975087e-05,
      "loss": 4.9522,
      "step": 8158
    },
    {
      "epoch": 0.9355578488705424,
      "grad_norm": 0.0,
      "learning_rate": 1.095059798770726e-05,
      "loss": 4.8524,
      "step": 8159
    },
    {
      "epoch": 0.935672514619883,
      "grad_norm": 0.0,
      "learning_rate": 1.0912157778378812e-05,
      "loss": 5.0166,
      "step": 8160
    },
    {
      "epoch": 0.9357871803692237,
      "grad_norm": 0.0,
      "learning_rate": 1.0873785036291972e-05,
      "loss": 5.1932,
      "step": 8161
    },
    {
      "epoch": 0.9359018461185644,
      "grad_norm": 0.0,
      "learning_rate": 1.083547976673931e-05,
      "loss": 5.0718,
      "step": 8162
    },
    {
      "epoch": 0.936016511867905,
      "grad_norm": 0.0,
      "learning_rate": 1.0797241975004516e-05,
      "loss": 5.0801,
      "step": 8163
    },
    {
      "epoch": 0.9361311776172457,
      "grad_norm": 0.0,
      "learning_rate": 1.0759071666361676e-05,
      "loss": 4.9686,
      "step": 8164
    },
    {
      "epoch": 0.9362458433665864,
      "grad_norm": 0.0,
      "learning_rate": 1.0720968846075661e-05,
      "loss": 5.1948,
      "step": 8165
    },
    {
      "epoch": 0.936360509115927,
      "grad_norm": 0.0,
      "learning_rate": 1.0682933519402022e-05,
      "loss": 5.1266,
      "step": 8166
    },
    {
      "epoch": 0.9364751748652678,
      "grad_norm": 0.0,
      "learning_rate": 1.0644965691587038e-05,
      "loss": 5.0712,
      "step": 8167
    },
    {
      "epoch": 0.9365898406146084,
      "grad_norm": 0.0,
      "learning_rate": 1.0607065367867656e-05,
      "loss": 5.2097,
      "step": 8168
    },
    {
      "epoch": 0.9367045063639491,
      "grad_norm": 0.0,
      "learning_rate": 1.0569232553471455e-05,
      "loss": 4.8882,
      "step": 8169
    },
    {
      "epoch": 0.9368191721132898,
      "grad_norm": 0.0,
      "learning_rate": 1.0531467253616737e-05,
      "loss": 4.8232,
      "step": 8170
    },
    {
      "epoch": 0.9369338378626304,
      "grad_norm": 0.0,
      "learning_rate": 1.049376947351259e-05,
      "loss": 4.8507,
      "step": 8171
    },
    {
      "epoch": 0.9370485036119711,
      "grad_norm": 0.0,
      "learning_rate": 1.0456139218358612e-05,
      "loss": 5.2913,
      "step": 8172
    },
    {
      "epoch": 0.9371631693613117,
      "grad_norm": 0.0,
      "learning_rate": 1.0418576493345246e-05,
      "loss": 5.1838,
      "step": 8173
    },
    {
      "epoch": 0.9372778351106524,
      "grad_norm": 0.0,
      "learning_rate": 1.0381081303653549e-05,
      "loss": 4.5131,
      "step": 8174
    },
    {
      "epoch": 0.9373925008599931,
      "grad_norm": 0.0,
      "learning_rate": 1.0343653654455143e-05,
      "loss": 5.0589,
      "step": 8175
    },
    {
      "epoch": 0.9375071666093338,
      "grad_norm": 0.0,
      "learning_rate": 1.0306293550912717e-05,
      "loss": 5.0913,
      "step": 8176
    },
    {
      "epoch": 0.9376218323586745,
      "grad_norm": 0.0,
      "learning_rate": 1.0269000998179132e-05,
      "loss": 5.366,
      "step": 8177
    },
    {
      "epoch": 0.9377364981080152,
      "grad_norm": 0.0,
      "learning_rate": 1.023177600139826e-05,
      "loss": 4.8758,
      "step": 8178
    },
    {
      "epoch": 0.9378511638573558,
      "grad_norm": 0.0,
      "learning_rate": 1.0194618565704701e-05,
      "loss": 5.1083,
      "step": 8179
    },
    {
      "epoch": 0.9379658296066965,
      "grad_norm": 0.0,
      "learning_rate": 1.0157528696223397e-05,
      "loss": 5.0558,
      "step": 8180
    },
    {
      "epoch": 0.9380804953560371,
      "grad_norm": 0.0,
      "learning_rate": 1.012050639807047e-05,
      "loss": 5.0185,
      "step": 8181
    },
    {
      "epoch": 0.9381951611053778,
      "grad_norm": 0.0,
      "learning_rate": 1.0083551676352095e-05,
      "loss": 4.8794,
      "step": 8182
    },
    {
      "epoch": 0.9383098268547185,
      "grad_norm": 0.0,
      "learning_rate": 1.0046664536165802e-05,
      "loss": 5.0875,
      "step": 8183
    },
    {
      "epoch": 0.9384244926040591,
      "grad_norm": 0.0,
      "learning_rate": 1.0009844982599231e-05,
      "loss": 4.8796,
      "step": 8184
    },
    {
      "epoch": 0.9385391583533998,
      "grad_norm": 0.0,
      "learning_rate": 9.973093020731091e-06,
      "loss": 4.9241,
      "step": 8185
    },
    {
      "epoch": 0.9386538241027406,
      "grad_norm": 0.0,
      "learning_rate": 9.936408655630539e-06,
      "loss": 5.1165,
      "step": 8186
    },
    {
      "epoch": 0.9387684898520812,
      "grad_norm": 0.0,
      "learning_rate": 9.899791892357467e-06,
      "loss": 4.7576,
      "step": 8187
    },
    {
      "epoch": 0.9388831556014219,
      "grad_norm": 0.0,
      "learning_rate": 9.863242735962551e-06,
      "loss": 5.0149,
      "step": 8188
    },
    {
      "epoch": 0.9389978213507625,
      "grad_norm": 0.0,
      "learning_rate": 9.826761191486869e-06,
      "loss": 4.8182,
      "step": 8189
    },
    {
      "epoch": 0.9391124871001032,
      "grad_norm": 0.0,
      "learning_rate": 9.790347263962607e-06,
      "loss": 5.3391,
      "step": 8190
    },
    {
      "epoch": 0.9392271528494439,
      "grad_norm": 0.0,
      "learning_rate": 9.754000958412195e-06,
      "loss": 4.8436,
      "step": 8191
    },
    {
      "epoch": 0.9393418185987845,
      "grad_norm": 0.0,
      "learning_rate": 9.71772227984895e-06,
      "loss": 5.4599,
      "step": 8192
    },
    {
      "epoch": 0.9394564843481252,
      "grad_norm": 0.0,
      "learning_rate": 9.68151123327682e-06,
      "loss": 5.2291,
      "step": 8193
    },
    {
      "epoch": 0.9395711500974658,
      "grad_norm": 0.0,
      "learning_rate": 9.645367823690468e-06,
      "loss": 4.9786,
      "step": 8194
    },
    {
      "epoch": 0.9396858158468065,
      "grad_norm": 0.0,
      "learning_rate": 9.609292056075134e-06,
      "loss": 5.0947,
      "step": 8195
    },
    {
      "epoch": 0.9398004815961473,
      "grad_norm": 0.0,
      "learning_rate": 9.573283935406897e-06,
      "loss": 5.2344,
      "step": 8196
    },
    {
      "epoch": 0.9399151473454879,
      "grad_norm": 0.0,
      "learning_rate": 9.537343466652226e-06,
      "loss": 5.0205,
      "step": 8197
    },
    {
      "epoch": 0.9400298130948286,
      "grad_norm": 0.0,
      "learning_rate": 9.501470654768496e-06,
      "loss": 4.949,
      "step": 8198
    },
    {
      "epoch": 0.9401444788441693,
      "grad_norm": 0.0,
      "learning_rate": 9.465665504703698e-06,
      "loss": 4.9581,
      "step": 8199
    },
    {
      "epoch": 0.9402591445935099,
      "grad_norm": 0.0,
      "learning_rate": 9.429928021396443e-06,
      "loss": 5.4052,
      "step": 8200
    },
    {
      "epoch": 0.9403738103428506,
      "grad_norm": 0.0,
      "learning_rate": 9.394258209776126e-06,
      "loss": 5.0835,
      "step": 8201
    },
    {
      "epoch": 0.9404884760921912,
      "grad_norm": 0.0,
      "learning_rate": 9.358656074762488e-06,
      "loss": 5.0597,
      "step": 8202
    },
    {
      "epoch": 0.9406031418415319,
      "grad_norm": 0.0,
      "learning_rate": 9.323121621266442e-06,
      "loss": 4.932,
      "step": 8203
    },
    {
      "epoch": 0.9407178075908726,
      "grad_norm": 0.0,
      "learning_rate": 9.287654854189076e-06,
      "loss": 4.6565,
      "step": 8204
    },
    {
      "epoch": 0.9408324733402132,
      "grad_norm": 0.0,
      "learning_rate": 9.252255778422545e-06,
      "loss": 4.7698,
      "step": 8205
    },
    {
      "epoch": 0.940947139089554,
      "grad_norm": 0.0,
      "learning_rate": 9.216924398849286e-06,
      "loss": 5.1403,
      "step": 8206
    },
    {
      "epoch": 0.9410618048388946,
      "grad_norm": 0.0,
      "learning_rate": 9.181660720342744e-06,
      "loss": 4.6505,
      "step": 8207
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 0.0,
      "learning_rate": 9.146464747766767e-06,
      "loss": 4.8622,
      "step": 8208
    },
    {
      "epoch": 0.941291136337576,
      "grad_norm": 0.0,
      "learning_rate": 9.111336485975986e-06,
      "loss": 5.0653,
      "step": 8209
    },
    {
      "epoch": 0.9414058020869166,
      "grad_norm": 0.0,
      "learning_rate": 9.076275939815762e-06,
      "loss": 5.0203,
      "step": 8210
    },
    {
      "epoch": 0.9415204678362573,
      "grad_norm": 0.0,
      "learning_rate": 9.041283114121853e-06,
      "loss": 4.9146,
      "step": 8211
    },
    {
      "epoch": 0.941635133585598,
      "grad_norm": 0.0,
      "learning_rate": 9.006358013721082e-06,
      "loss": 4.847,
      "step": 8212
    },
    {
      "epoch": 0.9417497993349386,
      "grad_norm": 0.0,
      "learning_rate": 8.971500643430501e-06,
      "loss": 5.0605,
      "step": 8213
    },
    {
      "epoch": 0.9418644650842793,
      "grad_norm": 0.0,
      "learning_rate": 8.936711008058118e-06,
      "loss": 5.0568,
      "step": 8214
    },
    {
      "epoch": 0.94197913083362,
      "grad_norm": 0.0,
      "learning_rate": 8.90198911240245e-06,
      "loss": 4.9607,
      "step": 8215
    },
    {
      "epoch": 0.9420937965829607,
      "grad_norm": 0.0,
      "learning_rate": 8.867334961252791e-06,
      "loss": 5.3709,
      "step": 8216
    },
    {
      "epoch": 0.9422084623323014,
      "grad_norm": 0.0,
      "learning_rate": 8.832748559388955e-06,
      "loss": 5.3435,
      "step": 8217
    },
    {
      "epoch": 0.942323128081642,
      "grad_norm": 0.0,
      "learning_rate": 8.798229911581594e-06,
      "loss": 4.9898,
      "step": 8218
    },
    {
      "epoch": 0.9424377938309827,
      "grad_norm": 0.0,
      "learning_rate": 8.763779022591695e-06,
      "loss": 4.9632,
      "step": 8219
    },
    {
      "epoch": 0.9425524595803234,
      "grad_norm": 0.0,
      "learning_rate": 8.729395897171265e-06,
      "loss": 4.7823,
      "step": 8220
    },
    {
      "epoch": 0.942667125329664,
      "grad_norm": 0.0,
      "learning_rate": 8.695080540062701e-06,
      "loss": 4.8578,
      "step": 8221
    },
    {
      "epoch": 0.9427817910790047,
      "grad_norm": 0.0,
      "learning_rate": 8.660832955999241e-06,
      "loss": 4.8848,
      "step": 8222
    },
    {
      "epoch": 0.9428964568283453,
      "grad_norm": 0.0,
      "learning_rate": 8.626653149704687e-06,
      "loss": 5.1448,
      "step": 8223
    },
    {
      "epoch": 0.943011122577686,
      "grad_norm": 0.0,
      "learning_rate": 8.592541125893358e-06,
      "loss": 5.0595,
      "step": 8224
    },
    {
      "epoch": 0.9431257883270268,
      "grad_norm": 0.0,
      "learning_rate": 8.558496889270518e-06,
      "loss": 4.8792,
      "step": 8225
    },
    {
      "epoch": 0.9432404540763674,
      "grad_norm": 0.0,
      "learning_rate": 8.52452044453177e-06,
      "loss": 4.9918,
      "step": 8226
    },
    {
      "epoch": 0.9433551198257081,
      "grad_norm": 0.0,
      "learning_rate": 8.490611796363677e-06,
      "loss": 4.9981,
      "step": 8227
    },
    {
      "epoch": 0.9434697855750487,
      "grad_norm": 0.0,
      "learning_rate": 8.456770949443194e-06,
      "loss": 4.897,
      "step": 8228
    },
    {
      "epoch": 0.9435844513243894,
      "grad_norm": 0.0,
      "learning_rate": 8.422997908438014e-06,
      "loss": 5.27,
      "step": 8229
    },
    {
      "epoch": 0.9436991170737301,
      "grad_norm": 0.0,
      "learning_rate": 8.389292678006604e-06,
      "loss": 4.9039,
      "step": 8230
    },
    {
      "epoch": 0.9438137828230707,
      "grad_norm": 0.0,
      "learning_rate": 8.35565526279773e-06,
      "loss": 4.9835,
      "step": 8231
    },
    {
      "epoch": 0.9439284485724114,
      "grad_norm": 0.0,
      "learning_rate": 8.32208566745127e-06,
      "loss": 5.0767,
      "step": 8232
    },
    {
      "epoch": 0.9440431143217521,
      "grad_norm": 0.0,
      "learning_rate": 8.288583896597277e-06,
      "loss": 5.0789,
      "step": 8233
    },
    {
      "epoch": 0.9441577800710927,
      "grad_norm": 0.0,
      "learning_rate": 8.255149954856929e-06,
      "loss": 4.6857,
      "step": 8234
    },
    {
      "epoch": 0.9442724458204335,
      "grad_norm": 0.0,
      "learning_rate": 8.221783846841628e-06,
      "loss": 5.1966,
      "step": 8235
    },
    {
      "epoch": 0.9443871115697741,
      "grad_norm": 0.0,
      "learning_rate": 8.188485577153678e-06,
      "loss": 5.3355,
      "step": 8236
    },
    {
      "epoch": 0.9445017773191148,
      "grad_norm": 0.0,
      "learning_rate": 8.15525515038589e-06,
      "loss": 5.0041,
      "step": 8237
    },
    {
      "epoch": 0.9446164430684555,
      "grad_norm": 0.0,
      "learning_rate": 8.122092571121803e-06,
      "loss": 4.7133,
      "step": 8238
    },
    {
      "epoch": 0.9447311088177961,
      "grad_norm": 0.0,
      "learning_rate": 8.088997843935583e-06,
      "loss": 4.9994,
      "step": 8239
    },
    {
      "epoch": 0.9448457745671368,
      "grad_norm": 0.0,
      "learning_rate": 8.055970973391896e-06,
      "loss": 4.7437,
      "step": 8240
    },
    {
      "epoch": 0.9449604403164775,
      "grad_norm": 0.0,
      "learning_rate": 8.023011964046308e-06,
      "loss": 4.8568,
      "step": 8241
    },
    {
      "epoch": 0.9450751060658181,
      "grad_norm": 0.0,
      "learning_rate": 7.990120820444784e-06,
      "loss": 5.0266,
      "step": 8242
    },
    {
      "epoch": 0.9451897718151588,
      "grad_norm": 0.0,
      "learning_rate": 7.957297547124132e-06,
      "loss": 4.9975,
      "step": 8243
    },
    {
      "epoch": 0.9453044375644994,
      "grad_norm": 0.0,
      "learning_rate": 7.924542148611607e-06,
      "loss": 4.9202,
      "step": 8244
    },
    {
      "epoch": 0.9454191033138402,
      "grad_norm": 0.0,
      "learning_rate": 7.891854629425257e-06,
      "loss": 5.1356,
      "step": 8245
    },
    {
      "epoch": 0.9455337690631809,
      "grad_norm": 0.0,
      "learning_rate": 7.859234994073632e-06,
      "loss": 5.0354,
      "step": 8246
    },
    {
      "epoch": 0.9456484348125215,
      "grad_norm": 0.0,
      "learning_rate": 7.826683247056076e-06,
      "loss": 4.6908,
      "step": 8247
    },
    {
      "epoch": 0.9457631005618622,
      "grad_norm": 0.0,
      "learning_rate": 7.794199392862434e-06,
      "loss": 4.8229,
      "step": 8248
    },
    {
      "epoch": 0.9458777663112028,
      "grad_norm": 0.0,
      "learning_rate": 7.761783435973173e-06,
      "loss": 5.1406,
      "step": 8249
    },
    {
      "epoch": 0.9459924320605435,
      "grad_norm": 0.0,
      "learning_rate": 7.729435380859603e-06,
      "loss": 5.0957,
      "step": 8250
    },
    {
      "epoch": 0.9461070978098842,
      "grad_norm": 0.0,
      "learning_rate": 7.697155231983376e-06,
      "loss": 5.3679,
      "step": 8251
    },
    {
      "epoch": 0.9462217635592248,
      "grad_norm": 0.0,
      "learning_rate": 7.66494299379704e-06,
      "loss": 4.9906,
      "step": 8252
    },
    {
      "epoch": 0.9463364293085655,
      "grad_norm": 0.0,
      "learning_rate": 7.632798670743538e-06,
      "loss": 5.0982,
      "step": 8253
    },
    {
      "epoch": 0.9464510950579063,
      "grad_norm": 0.0,
      "learning_rate": 7.600722267256717e-06,
      "loss": 5.0694,
      "step": 8254
    },
    {
      "epoch": 0.9465657608072469,
      "grad_norm": 0.0,
      "learning_rate": 7.568713787760705e-06,
      "loss": 5.0356,
      "step": 8255
    },
    {
      "epoch": 0.9466804265565876,
      "grad_norm": 0.0,
      "learning_rate": 7.536773236670694e-06,
      "loss": 5.0214,
      "step": 8256
    },
    {
      "epoch": 0.9467950923059282,
      "grad_norm": 0.0,
      "learning_rate": 7.504900618392108e-06,
      "loss": 4.8782,
      "step": 8257
    },
    {
      "epoch": 0.9469097580552689,
      "grad_norm": 0.0,
      "learning_rate": 7.473095937321213e-06,
      "loss": 4.9543,
      "step": 8258
    },
    {
      "epoch": 0.9470244238046096,
      "grad_norm": 0.0,
      "learning_rate": 7.441359197844894e-06,
      "loss": 4.8386,
      "step": 8259
    },
    {
      "epoch": 0.9471390895539502,
      "grad_norm": 0.0,
      "learning_rate": 7.409690404340545e-06,
      "loss": 5.2693,
      "step": 8260
    },
    {
      "epoch": 0.9472537553032909,
      "grad_norm": 0.0,
      "learning_rate": 7.378089561176402e-06,
      "loss": 5.0542,
      "step": 8261
    },
    {
      "epoch": 0.9473684210526315,
      "grad_norm": 0.0,
      "learning_rate": 7.346556672711095e-06,
      "loss": 4.8783,
      "step": 8262
    },
    {
      "epoch": 0.9474830868019722,
      "grad_norm": 0.0,
      "learning_rate": 7.31509174329399e-06,
      "loss": 5.1002,
      "step": 8263
    },
    {
      "epoch": 0.947597752551313,
      "grad_norm": 0.0,
      "learning_rate": 7.283694777265069e-06,
      "loss": 5.0359,
      "step": 8264
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.0,
      "learning_rate": 7.252365778955045e-06,
      "loss": 4.8403,
      "step": 8265
    },
    {
      "epoch": 0.9478270840499943,
      "grad_norm": 0.0,
      "learning_rate": 7.221104752685029e-06,
      "loss": 5.0127,
      "step": 8266
    },
    {
      "epoch": 0.947941749799335,
      "grad_norm": 0.0,
      "learning_rate": 7.189911702766975e-06,
      "loss": 5.0312,
      "step": 8267
    },
    {
      "epoch": 0.9480564155486756,
      "grad_norm": 0.0,
      "learning_rate": 7.158786633503286e-06,
      "loss": 5.0382,
      "step": 8268
    },
    {
      "epoch": 0.9481710812980163,
      "grad_norm": 0.0,
      "learning_rate": 7.127729549187212e-06,
      "loss": 5.0049,
      "step": 8269
    },
    {
      "epoch": 0.9482857470473569,
      "grad_norm": 0.0,
      "learning_rate": 7.09674045410234e-06,
      "loss": 4.7547,
      "step": 8270
    },
    {
      "epoch": 0.9484004127966976,
      "grad_norm": 0.0,
      "learning_rate": 7.0658193525230455e-06,
      "loss": 5.0209,
      "step": 8271
    },
    {
      "epoch": 0.9485150785460383,
      "grad_norm": 0.0,
      "learning_rate": 7.03496624871438e-06,
      "loss": 5.0724,
      "step": 8272
    },
    {
      "epoch": 0.9486297442953789,
      "grad_norm": 0.0,
      "learning_rate": 7.004181146931846e-06,
      "loss": 5.0828,
      "step": 8273
    },
    {
      "epoch": 0.9487444100447197,
      "grad_norm": 0.0,
      "learning_rate": 6.973464051421789e-06,
      "loss": 4.7954,
      "step": 8274
    },
    {
      "epoch": 0.9488590757940604,
      "grad_norm": 0.0,
      "learning_rate": 6.942814966420896e-06,
      "loss": 4.8984,
      "step": 8275
    },
    {
      "epoch": 0.948973741543401,
      "grad_norm": 0.0,
      "learning_rate": 6.91223389615675e-06,
      "loss": 5.0887,
      "step": 8276
    },
    {
      "epoch": 0.9490884072927417,
      "grad_norm": 0.0,
      "learning_rate": 6.881720844847333e-06,
      "loss": 4.8157,
      "step": 8277
    },
    {
      "epoch": 0.9492030730420823,
      "grad_norm": 0.0,
      "learning_rate": 6.851275816701468e-06,
      "loss": 4.8912,
      "step": 8278
    },
    {
      "epoch": 0.949317738791423,
      "grad_norm": 0.0,
      "learning_rate": 6.820898815918377e-06,
      "loss": 5.123,
      "step": 8279
    },
    {
      "epoch": 0.9494324045407637,
      "grad_norm": 0.0,
      "learning_rate": 6.790589846687899e-06,
      "loss": 5.0433,
      "step": 8280
    },
    {
      "epoch": 0.9495470702901043,
      "grad_norm": 0.0,
      "learning_rate": 6.760348913190716e-06,
      "loss": 5.0053,
      "step": 8281
    },
    {
      "epoch": 0.949661736039445,
      "grad_norm": 0.0,
      "learning_rate": 6.730176019597907e-06,
      "loss": 5.0134,
      "step": 8282
    },
    {
      "epoch": 0.9497764017887856,
      "grad_norm": 0.0,
      "learning_rate": 6.700071170071393e-06,
      "loss": 4.9403,
      "step": 8283
    },
    {
      "epoch": 0.9498910675381264,
      "grad_norm": 0.0,
      "learning_rate": 6.670034368763382e-06,
      "loss": 5.1016,
      "step": 8284
    },
    {
      "epoch": 0.9500057332874671,
      "grad_norm": 0.0,
      "learning_rate": 6.6400656198169235e-06,
      "loss": 5.199,
      "step": 8285
    },
    {
      "epoch": 0.9501203990368077,
      "grad_norm": 0.0,
      "learning_rate": 6.610164927365684e-06,
      "loss": 4.7448,
      "step": 8286
    },
    {
      "epoch": 0.9502350647861484,
      "grad_norm": 0.0,
      "learning_rate": 6.580332295533897e-06,
      "loss": 4.8715,
      "step": 8287
    },
    {
      "epoch": 0.9503497305354891,
      "grad_norm": 0.0,
      "learning_rate": 6.550567728436361e-06,
      "loss": 5.1644,
      "step": 8288
    },
    {
      "epoch": 0.9504643962848297,
      "grad_norm": 0.0,
      "learning_rate": 6.520871230178601e-06,
      "loss": 5.0083,
      "step": 8289
    },
    {
      "epoch": 0.9505790620341704,
      "grad_norm": 0.0,
      "learning_rate": 6.491242804856598e-06,
      "loss": 4.9493,
      "step": 8290
    },
    {
      "epoch": 0.950693727783511,
      "grad_norm": 0.0,
      "learning_rate": 6.461682456557063e-06,
      "loss": 4.6353,
      "step": 8291
    },
    {
      "epoch": 0.9508083935328517,
      "grad_norm": 0.0,
      "learning_rate": 6.432190189357271e-06,
      "loss": 4.9537,
      "step": 8292
    },
    {
      "epoch": 0.9509230592821925,
      "grad_norm": 0.0,
      "learning_rate": 6.402766007325171e-06,
      "loss": 4.6815,
      "step": 8293
    },
    {
      "epoch": 0.951037725031533,
      "grad_norm": 0.0,
      "learning_rate": 6.373409914519166e-06,
      "loss": 5.0226,
      "step": 8294
    },
    {
      "epoch": 0.9511523907808738,
      "grad_norm": 0.0,
      "learning_rate": 6.344121914988446e-06,
      "loss": 5.1105,
      "step": 8295
    },
    {
      "epoch": 0.9512670565302144,
      "grad_norm": 0.0,
      "learning_rate": 6.314902012772765e-06,
      "loss": 4.9961,
      "step": 8296
    },
    {
      "epoch": 0.9513817222795551,
      "grad_norm": 0.0,
      "learning_rate": 6.285750211902381e-06,
      "loss": 5.0348,
      "step": 8297
    },
    {
      "epoch": 0.9514963880288958,
      "grad_norm": 0.0,
      "learning_rate": 6.256666516398235e-06,
      "loss": 4.993,
      "step": 8298
    },
    {
      "epoch": 0.9516110537782364,
      "grad_norm": 0.0,
      "learning_rate": 6.227650930271937e-06,
      "loss": 5.1261,
      "step": 8299
    },
    {
      "epoch": 0.9517257195275771,
      "grad_norm": 0.0,
      "learning_rate": 6.198703457525494e-06,
      "loss": 5.045,
      "step": 8300
    },
    {
      "epoch": 0.9518403852769178,
      "grad_norm": 0.0,
      "learning_rate": 6.1698241021518715e-06,
      "loss": 5.0532,
      "step": 8301
    },
    {
      "epoch": 0.9519550510262584,
      "grad_norm": 0.0,
      "learning_rate": 6.141012868134149e-06,
      "loss": 5.3212,
      "step": 8302
    },
    {
      "epoch": 0.9520697167755992,
      "grad_norm": 0.0,
      "learning_rate": 6.112269759446583e-06,
      "loss": 5.1488,
      "step": 8303
    },
    {
      "epoch": 0.9521843825249398,
      "grad_norm": 0.0,
      "learning_rate": 6.083594780053496e-06,
      "loss": 5.0338,
      "step": 8304
    },
    {
      "epoch": 0.9522990482742805,
      "grad_norm": 0.0,
      "learning_rate": 6.054987933910216e-06,
      "loss": 5.2311,
      "step": 8305
    },
    {
      "epoch": 0.9524137140236212,
      "grad_norm": 0.0,
      "learning_rate": 6.026449224962415e-06,
      "loss": 5.0999,
      "step": 8306
    },
    {
      "epoch": 0.9525283797729618,
      "grad_norm": 0.0,
      "learning_rate": 5.9979786571464935e-06,
      "loss": 5.03,
      "step": 8307
    },
    {
      "epoch": 0.9526430455223025,
      "grad_norm": 0.0,
      "learning_rate": 5.969576234389418e-06,
      "loss": 5.0104,
      "step": 8308
    },
    {
      "epoch": 0.9527577112716432,
      "grad_norm": 0.0,
      "learning_rate": 5.9412419606087725e-06,
      "loss": 4.9339,
      "step": 8309
    },
    {
      "epoch": 0.9528723770209838,
      "grad_norm": 0.0,
      "learning_rate": 5.912975839712763e-06,
      "loss": 5.053,
      "step": 8310
    },
    {
      "epoch": 0.9529870427703245,
      "grad_norm": 0.0,
      "learning_rate": 5.884777875600104e-06,
      "loss": 5.091,
      "step": 8311
    },
    {
      "epoch": 0.9531017085196651,
      "grad_norm": 0.0,
      "learning_rate": 5.8566480721602365e-06,
      "loss": 4.8984,
      "step": 8312
    },
    {
      "epoch": 0.9532163742690059,
      "grad_norm": 0.0,
      "learning_rate": 5.828586433273004e-06,
      "loss": 5.0369,
      "step": 8313
    },
    {
      "epoch": 0.9533310400183466,
      "grad_norm": 0.0,
      "learning_rate": 5.800592962809089e-06,
      "loss": 4.8672,
      "step": 8314
    },
    {
      "epoch": 0.9534457057676872,
      "grad_norm": 0.0,
      "learning_rate": 5.772667664629627e-06,
      "loss": 5.0102,
      "step": 8315
    },
    {
      "epoch": 0.9535603715170279,
      "grad_norm": 0.0,
      "learning_rate": 5.7448105425864305e-06,
      "loss": 4.8463,
      "step": 8316
    },
    {
      "epoch": 0.9536750372663685,
      "grad_norm": 0.0,
      "learning_rate": 5.717021600521706e-06,
      "loss": 5.1107,
      "step": 8317
    },
    {
      "epoch": 0.9537897030157092,
      "grad_norm": 0.0,
      "learning_rate": 5.689300842268617e-06,
      "loss": 5.157,
      "step": 8318
    },
    {
      "epoch": 0.9539043687650499,
      "grad_norm": 0.0,
      "learning_rate": 5.661648271650556e-06,
      "loss": 4.9912,
      "step": 8319
    },
    {
      "epoch": 0.9540190345143905,
      "grad_norm": 0.0,
      "learning_rate": 5.634063892481698e-06,
      "loss": 5.2717,
      "step": 8320
    },
    {
      "epoch": 0.9541337002637312,
      "grad_norm": 0.0,
      "learning_rate": 5.606547708566789e-06,
      "loss": 5.2171,
      "step": 8321
    },
    {
      "epoch": 0.954248366013072,
      "grad_norm": 0.0,
      "learning_rate": 5.579099723701188e-06,
      "loss": 4.8758,
      "step": 8322
    },
    {
      "epoch": 0.9543630317624126,
      "grad_norm": 0.0,
      "learning_rate": 5.55171994167088e-06,
      "loss": 5.0052,
      "step": 8323
    },
    {
      "epoch": 0.9544776975117533,
      "grad_norm": 0.0,
      "learning_rate": 5.524408366252185e-06,
      "loss": 5.21,
      "step": 8324
    },
    {
      "epoch": 0.9545923632610939,
      "grad_norm": 0.0,
      "learning_rate": 5.497165001212436e-06,
      "loss": 5.0509,
      "step": 8325
    },
    {
      "epoch": 0.9547070290104346,
      "grad_norm": 0.0,
      "learning_rate": 5.469989850309195e-06,
      "loss": 5.0155,
      "step": 8326
    },
    {
      "epoch": 0.9548216947597753,
      "grad_norm": 0.0,
      "learning_rate": 5.4428829172908124e-06,
      "loss": 4.8006,
      "step": 8327
    },
    {
      "epoch": 0.9549363605091159,
      "grad_norm": 0.0,
      "learning_rate": 5.415844205896145e-06,
      "loss": 5.1649,
      "step": 8328
    },
    {
      "epoch": 0.9550510262584566,
      "grad_norm": 0.0,
      "learning_rate": 5.3888737198547226e-06,
      "loss": 4.9855,
      "step": 8329
    },
    {
      "epoch": 0.9551656920077972,
      "grad_norm": 0.0,
      "learning_rate": 5.361971462886588e-06,
      "loss": 5.152,
      "step": 8330
    },
    {
      "epoch": 0.9552803577571379,
      "grad_norm": 0.0,
      "learning_rate": 5.3351374387022916e-06,
      "loss": 5.1783,
      "step": 8331
    },
    {
      "epoch": 0.9553950235064786,
      "grad_norm": 0.0,
      "learning_rate": 5.308371651003223e-06,
      "loss": 4.8837,
      "step": 8332
    },
    {
      "epoch": 0.9555096892558193,
      "grad_norm": 0.0,
      "learning_rate": 5.281674103481171e-06,
      "loss": 4.7768,
      "step": 8333
    },
    {
      "epoch": 0.95562435500516,
      "grad_norm": 0.0,
      "learning_rate": 5.255044799818487e-06,
      "loss": 5.1097,
      "step": 8334
    },
    {
      "epoch": 0.9557390207545007,
      "grad_norm": 0.0,
      "learning_rate": 5.228483743688255e-06,
      "loss": 4.9238,
      "step": 8335
    },
    {
      "epoch": 0.9558536865038413,
      "grad_norm": 0.0,
      "learning_rate": 5.201990938754012e-06,
      "loss": 4.9676,
      "step": 8336
    },
    {
      "epoch": 0.955968352253182,
      "grad_norm": 0.0,
      "learning_rate": 5.175566388669968e-06,
      "loss": 4.9645,
      "step": 8337
    },
    {
      "epoch": 0.9560830180025226,
      "grad_norm": 0.0,
      "learning_rate": 5.149210097080843e-06,
      "loss": 5.0876,
      "step": 8338
    },
    {
      "epoch": 0.9561976837518633,
      "grad_norm": 0.0,
      "learning_rate": 5.1229220676220316e-06,
      "loss": 5.1435,
      "step": 8339
    },
    {
      "epoch": 0.956312349501204,
      "grad_norm": 0.0,
      "learning_rate": 5.0967023039194935e-06,
      "loss": 5.1113,
      "step": 8340
    },
    {
      "epoch": 0.9564270152505446,
      "grad_norm": 0.0,
      "learning_rate": 5.070550809589695e-06,
      "loss": 4.9721,
      "step": 8341
    },
    {
      "epoch": 0.9565416809998853,
      "grad_norm": 0.0,
      "learning_rate": 5.044467588239723e-06,
      "loss": 4.9954,
      "step": 8342
    },
    {
      "epoch": 0.9566563467492261,
      "grad_norm": 0.0,
      "learning_rate": 5.018452643467285e-06,
      "loss": 4.9125,
      "step": 8343
    },
    {
      "epoch": 0.9567710124985667,
      "grad_norm": 0.0,
      "learning_rate": 4.992505978860652e-06,
      "loss": 5.0502,
      "step": 8344
    },
    {
      "epoch": 0.9568856782479074,
      "grad_norm": 0.0,
      "learning_rate": 4.966627597998712e-06,
      "loss": 4.9257,
      "step": 8345
    },
    {
      "epoch": 0.957000343997248,
      "grad_norm": 0.0,
      "learning_rate": 4.940817504450754e-06,
      "loss": 5.2982,
      "step": 8346
    },
    {
      "epoch": 0.9571150097465887,
      "grad_norm": 0.0,
      "learning_rate": 4.915075701776962e-06,
      "loss": 5.0311,
      "step": 8347
    },
    {
      "epoch": 0.9572296754959294,
      "grad_norm": 0.0,
      "learning_rate": 4.889402193527752e-06,
      "loss": 4.8948,
      "step": 8348
    },
    {
      "epoch": 0.95734434124527,
      "grad_norm": 0.0,
      "learning_rate": 4.863796983244493e-06,
      "loss": 5.1583,
      "step": 8349
    },
    {
      "epoch": 0.9574590069946107,
      "grad_norm": 0.0,
      "learning_rate": 4.838260074458839e-06,
      "loss": 5.1295,
      "step": 8350
    },
    {
      "epoch": 0.9575736727439513,
      "grad_norm": 0.0,
      "learning_rate": 4.812791470693009e-06,
      "loss": 4.9612,
      "step": 8351
    },
    {
      "epoch": 0.957688338493292,
      "grad_norm": 0.0,
      "learning_rate": 4.787391175460119e-06,
      "loss": 5.0125,
      "step": 8352
    },
    {
      "epoch": 0.9578030042426328,
      "grad_norm": 0.0,
      "learning_rate": 4.76205919226346e-06,
      "loss": 5.022,
      "step": 8353
    },
    {
      "epoch": 0.9579176699919734,
      "grad_norm": 0.0,
      "learning_rate": 4.736795524597278e-06,
      "loss": 5.2083,
      "step": 8354
    },
    {
      "epoch": 0.9580323357413141,
      "grad_norm": 0.0,
      "learning_rate": 4.711600175946046e-06,
      "loss": 5.0647,
      "step": 8355
    },
    {
      "epoch": 0.9581470014906548,
      "grad_norm": 0.0,
      "learning_rate": 4.686473149785081e-06,
      "loss": 4.9828,
      "step": 8356
    },
    {
      "epoch": 0.9582616672399954,
      "grad_norm": 0.0,
      "learning_rate": 4.6614144495801525e-06,
      "loss": 5.1833,
      "step": 8357
    },
    {
      "epoch": 0.9583763329893361,
      "grad_norm": 0.0,
      "learning_rate": 4.636424078787651e-06,
      "loss": 5.1133,
      "step": 8358
    },
    {
      "epoch": 0.9584909987386767,
      "grad_norm": 0.0,
      "learning_rate": 4.611502040854528e-06,
      "loss": 5.0545,
      "step": 8359
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 0.0,
      "learning_rate": 4.586648339218247e-06,
      "loss": 5.0401,
      "step": 8360
    },
    {
      "epoch": 0.9587203302373581,
      "grad_norm": 0.0,
      "learning_rate": 4.561862977306999e-06,
      "loss": 5.0543,
      "step": 8361
    },
    {
      "epoch": 0.9588349959866987,
      "grad_norm": 0.0,
      "learning_rate": 4.53714595853932e-06,
      "loss": 5.1044,
      "step": 8362
    },
    {
      "epoch": 0.9589496617360395,
      "grad_norm": 0.0,
      "learning_rate": 4.512497286324528e-06,
      "loss": 5.3573,
      "step": 8363
    },
    {
      "epoch": 0.9590643274853801,
      "grad_norm": 0.0,
      "learning_rate": 4.487916964062455e-06,
      "loss": 4.6448,
      "step": 8364
    },
    {
      "epoch": 0.9591789932347208,
      "grad_norm": 0.0,
      "learning_rate": 4.463404995143436e-06,
      "loss": 4.8943,
      "step": 8365
    },
    {
      "epoch": 0.9592936589840615,
      "grad_norm": 0.0,
      "learning_rate": 4.438961382948485e-06,
      "loss": 5.0152,
      "step": 8366
    },
    {
      "epoch": 0.9594083247334021,
      "grad_norm": 0.0,
      "learning_rate": 4.414586130849122e-06,
      "loss": 4.819,
      "step": 8367
    },
    {
      "epoch": 0.9595229904827428,
      "grad_norm": 0.0,
      "learning_rate": 4.390279242207379e-06,
      "loss": 5.0255,
      "step": 8368
    },
    {
      "epoch": 0.9596376562320835,
      "grad_norm": 0.0,
      "learning_rate": 4.36604072037607e-06,
      "loss": 5.0964,
      "step": 8369
    },
    {
      "epoch": 0.9597523219814241,
      "grad_norm": 0.0,
      "learning_rate": 4.341870568698241e-06,
      "loss": 4.9068,
      "step": 8370
    },
    {
      "epoch": 0.9598669877307648,
      "grad_norm": 0.0,
      "learning_rate": 4.317768790507894e-06,
      "loss": 4.914,
      "step": 8371
    },
    {
      "epoch": 0.9599816534801054,
      "grad_norm": 0.0,
      "learning_rate": 4.293735389129313e-06,
      "loss": 4.9527,
      "step": 8372
    },
    {
      "epoch": 0.9600963192294462,
      "grad_norm": 0.0,
      "learning_rate": 4.269770367877403e-06,
      "loss": 4.5939,
      "step": 8373
    },
    {
      "epoch": 0.9602109849787869,
      "grad_norm": 0.0,
      "learning_rate": 4.245873730057801e-06,
      "loss": 4.8841,
      "step": 8374
    },
    {
      "epoch": 0.9603256507281275,
      "grad_norm": 0.0,
      "learning_rate": 4.22204547896643e-06,
      "loss": 5.0613,
      "step": 8375
    },
    {
      "epoch": 0.9604403164774682,
      "grad_norm": 0.0,
      "learning_rate": 4.198285617890165e-06,
      "loss": 5.0001,
      "step": 8376
    },
    {
      "epoch": 0.9605549822268089,
      "grad_norm": 0.0,
      "learning_rate": 4.1745941501060544e-06,
      "loss": 4.8391,
      "step": 8377
    },
    {
      "epoch": 0.9606696479761495,
      "grad_norm": 0.0,
      "learning_rate": 4.150971078881938e-06,
      "loss": 5.1806,
      "step": 8378
    },
    {
      "epoch": 0.9607843137254902,
      "grad_norm": 0.0,
      "learning_rate": 4.12741640747616e-06,
      "loss": 5.0003,
      "step": 8379
    },
    {
      "epoch": 0.9608989794748308,
      "grad_norm": 0.0,
      "learning_rate": 4.1039301391376835e-06,
      "loss": 5.1045,
      "step": 8380
    },
    {
      "epoch": 0.9610136452241715,
      "grad_norm": 0.0,
      "learning_rate": 4.080512277105929e-06,
      "loss": 5.1277,
      "step": 8381
    },
    {
      "epoch": 0.9611283109735123,
      "grad_norm": 0.0,
      "learning_rate": 4.057162824610932e-06,
      "loss": 4.8356,
      "step": 8382
    },
    {
      "epoch": 0.9612429767228529,
      "grad_norm": 0.0,
      "learning_rate": 4.033881784873406e-06,
      "loss": 5.1369,
      "step": 8383
    },
    {
      "epoch": 0.9613576424721936,
      "grad_norm": 0.0,
      "learning_rate": 4.010669161104404e-06,
      "loss": 4.9623,
      "step": 8384
    },
    {
      "epoch": 0.9614723082215342,
      "grad_norm": 0.0,
      "learning_rate": 3.987524956505712e-06,
      "loss": 5.1104,
      "step": 8385
    },
    {
      "epoch": 0.9615869739708749,
      "grad_norm": 0.0,
      "learning_rate": 3.9644491742696804e-06,
      "loss": 4.7481,
      "step": 8386
    },
    {
      "epoch": 0.9617016397202156,
      "grad_norm": 0.0,
      "learning_rate": 3.941441817579109e-06,
      "loss": 4.8059,
      "step": 8387
    },
    {
      "epoch": 0.9618163054695562,
      "grad_norm": 0.0,
      "learning_rate": 3.918502889607477e-06,
      "loss": 4.9454,
      "step": 8388
    },
    {
      "epoch": 0.9619309712188969,
      "grad_norm": 0.0,
      "learning_rate": 3.895632393518768e-06,
      "loss": 4.9702,
      "step": 8389
    },
    {
      "epoch": 0.9620456369682376,
      "grad_norm": 0.0,
      "learning_rate": 3.872830332467423e-06,
      "loss": 4.7183,
      "step": 8390
    },
    {
      "epoch": 0.9621603027175782,
      "grad_norm": 0.0,
      "learning_rate": 3.850096709598721e-06,
      "loss": 5.0303,
      "step": 8391
    },
    {
      "epoch": 0.962274968466919,
      "grad_norm": 0.0,
      "learning_rate": 3.827431528048173e-06,
      "loss": 4.8777,
      "step": 8392
    },
    {
      "epoch": 0.9623896342162596,
      "grad_norm": 0.0,
      "learning_rate": 3.8048347909421333e-06,
      "loss": 4.634,
      "step": 8393
    },
    {
      "epoch": 0.9625042999656003,
      "grad_norm": 0.0,
      "learning_rate": 3.782306501397351e-06,
      "loss": 5.12,
      "step": 8394
    },
    {
      "epoch": 0.962618965714941,
      "grad_norm": 0.0,
      "learning_rate": 3.759846662521142e-06,
      "loss": 5.0129,
      "step": 8395
    },
    {
      "epoch": 0.9627336314642816,
      "grad_norm": 0.0,
      "learning_rate": 3.737455277411439e-06,
      "loss": 5.1047,
      "step": 8396
    },
    {
      "epoch": 0.9628482972136223,
      "grad_norm": 0.0,
      "learning_rate": 3.715132349156685e-06,
      "loss": 4.992,
      "step": 8397
    },
    {
      "epoch": 0.9629629629629629,
      "grad_norm": 0.0,
      "learning_rate": 3.6928778808359432e-06,
      "loss": 4.8591,
      "step": 8398
    },
    {
      "epoch": 0.9630776287123036,
      "grad_norm": 0.0,
      "learning_rate": 3.6706918755187273e-06,
      "loss": 5.0458,
      "step": 8399
    },
    {
      "epoch": 0.9631922944616443,
      "grad_norm": 0.0,
      "learning_rate": 3.6485743362652833e-06,
      "loss": 5.2048,
      "step": 8400
    },
    {
      "epoch": 0.9633069602109849,
      "grad_norm": 0.0,
      "learning_rate": 3.6265252661261997e-06,
      "loss": 4.7647,
      "step": 8401
    },
    {
      "epoch": 0.9634216259603257,
      "grad_norm": 0.0,
      "learning_rate": 3.6045446681427392e-06,
      "loss": 4.9193,
      "step": 8402
    },
    {
      "epoch": 0.9635362917096664,
      "grad_norm": 0.0,
      "learning_rate": 3.5826325453467838e-06,
      "loss": 5.0254,
      "step": 8403
    },
    {
      "epoch": 0.963650957459007,
      "grad_norm": 0.0,
      "learning_rate": 3.560788900760614e-06,
      "loss": 5.2268,
      "step": 8404
    },
    {
      "epoch": 0.9637656232083477,
      "grad_norm": 0.0,
      "learning_rate": 3.539013737397184e-06,
      "loss": 4.9389,
      "step": 8405
    },
    {
      "epoch": 0.9638802889576883,
      "grad_norm": 0.0,
      "learning_rate": 3.517307058259902e-06,
      "loss": 4.9232,
      "step": 8406
    },
    {
      "epoch": 0.963994954707029,
      "grad_norm": 0.0,
      "learning_rate": 3.495668866342907e-06,
      "loss": 4.9902,
      "step": 8407
    },
    {
      "epoch": 0.9641096204563697,
      "grad_norm": 0.0,
      "learning_rate": 3.4740991646306243e-06,
      "loss": 5.0471,
      "step": 8408
    },
    {
      "epoch": 0.9642242862057103,
      "grad_norm": 0.0,
      "learning_rate": 3.4525979560983198e-06,
      "loss": 4.9656,
      "step": 8409
    },
    {
      "epoch": 0.964338951955051,
      "grad_norm": 0.0,
      "learning_rate": 3.4311652437116026e-06,
      "loss": 5.0894,
      "step": 8410
    },
    {
      "epoch": 0.9644536177043918,
      "grad_norm": 0.0,
      "learning_rate": 3.409801030426757e-06,
      "loss": 5.0564,
      "step": 8411
    },
    {
      "epoch": 0.9645682834537324,
      "grad_norm": 0.0,
      "learning_rate": 3.3885053191905186e-06,
      "loss": 4.9411,
      "step": 8412
    },
    {
      "epoch": 0.9646829492030731,
      "grad_norm": 0.0,
      "learning_rate": 3.3672781129401894e-06,
      "loss": 4.8853,
      "step": 8413
    },
    {
      "epoch": 0.9647976149524137,
      "grad_norm": 0.0,
      "learning_rate": 3.3461194146038e-06,
      "loss": 5.1109,
      "step": 8414
    },
    {
      "epoch": 0.9649122807017544,
      "grad_norm": 0.0,
      "learning_rate": 3.3250292270996134e-06,
      "loss": 4.9797,
      "step": 8415
    },
    {
      "epoch": 0.9650269464510951,
      "grad_norm": 0.0,
      "learning_rate": 3.3040075533367886e-06,
      "loss": 4.9967,
      "step": 8416
    },
    {
      "epoch": 0.9651416122004357,
      "grad_norm": 0.0,
      "learning_rate": 3.283054396214717e-06,
      "loss": 4.9917,
      "step": 8417
    },
    {
      "epoch": 0.9652562779497764,
      "grad_norm": 0.0,
      "learning_rate": 3.2621697586235743e-06,
      "loss": 4.7933,
      "step": 8418
    },
    {
      "epoch": 0.965370943699117,
      "grad_norm": 0.0,
      "learning_rate": 3.2413536434439347e-06,
      "loss": 5.0406,
      "step": 8419
    },
    {
      "epoch": 0.9654856094484577,
      "grad_norm": 0.0,
      "learning_rate": 3.2206060535471036e-06,
      "loss": 5.061,
      "step": 8420
    },
    {
      "epoch": 0.9656002751977985,
      "grad_norm": 0.0,
      "learning_rate": 3.1999269917946713e-06,
      "loss": 5.0658,
      "step": 8421
    },
    {
      "epoch": 0.9657149409471391,
      "grad_norm": 0.0,
      "learning_rate": 3.1793164610390157e-06,
      "loss": 4.9896,
      "step": 8422
    },
    {
      "epoch": 0.9658296066964798,
      "grad_norm": 0.0,
      "learning_rate": 3.158774464122967e-06,
      "loss": 4.9666,
      "step": 8423
    },
    {
      "epoch": 0.9659442724458205,
      "grad_norm": 0.0,
      "learning_rate": 3.138301003879809e-06,
      "loss": 4.9637,
      "step": 8424
    },
    {
      "epoch": 0.9660589381951611,
      "grad_norm": 0.0,
      "learning_rate": 3.1178960831336103e-06,
      "loss": 4.7965,
      "step": 8425
    },
    {
      "epoch": 0.9661736039445018,
      "grad_norm": 0.0,
      "learning_rate": 3.0975597046986715e-06,
      "loss": 5.0532,
      "step": 8426
    },
    {
      "epoch": 0.9662882696938424,
      "grad_norm": 0.0,
      "learning_rate": 3.077291871380135e-06,
      "loss": 5.1468,
      "step": 8427
    },
    {
      "epoch": 0.9664029354431831,
      "grad_norm": 0.0,
      "learning_rate": 3.0570925859735403e-06,
      "loss": 5.0532,
      "step": 8428
    },
    {
      "epoch": 0.9665176011925238,
      "grad_norm": 0.0,
      "learning_rate": 3.0369618512649346e-06,
      "loss": 4.9219,
      "step": 8429
    },
    {
      "epoch": 0.9666322669418644,
      "grad_norm": 0.0,
      "learning_rate": 3.0168996700310422e-06,
      "loss": 5.1224,
      "step": 8430
    },
    {
      "epoch": 0.9667469326912052,
      "grad_norm": 0.0,
      "learning_rate": 2.9969060450390396e-06,
      "loss": 5.1344,
      "step": 8431
    },
    {
      "epoch": 0.9668615984405458,
      "grad_norm": 0.0,
      "learning_rate": 2.9769809790466658e-06,
      "loss": 4.8933,
      "step": 8432
    },
    {
      "epoch": 0.9669762641898865,
      "grad_norm": 0.0,
      "learning_rate": 2.95712447480217e-06,
      "loss": 5.1882,
      "step": 8433
    },
    {
      "epoch": 0.9670909299392272,
      "grad_norm": 0.0,
      "learning_rate": 2.9373365350443654e-06,
      "loss": 4.9519,
      "step": 8434
    },
    {
      "epoch": 0.9672055956885678,
      "grad_norm": 0.0,
      "learning_rate": 2.9176171625026836e-06,
      "loss": 5.2865,
      "step": 8435
    },
    {
      "epoch": 0.9673202614379085,
      "grad_norm": 0.0,
      "learning_rate": 2.8979663598970114e-06,
      "loss": 5.0374,
      "step": 8436
    },
    {
      "epoch": 0.9674349271872492,
      "grad_norm": 0.0,
      "learning_rate": 2.8783841299377965e-06,
      "loss": 5.2221,
      "step": 8437
    },
    {
      "epoch": 0.9675495929365898,
      "grad_norm": 0.0,
      "learning_rate": 2.8588704753260535e-06,
      "loss": 4.7277,
      "step": 8438
    },
    {
      "epoch": 0.9676642586859305,
      "grad_norm": 0.0,
      "learning_rate": 2.8394253987532493e-06,
      "loss": 5.1109,
      "step": 8439
    },
    {
      "epoch": 0.9677789244352711,
      "grad_norm": 0.0,
      "learning_rate": 2.82004890290158e-06,
      "loss": 5.1383,
      "step": 8440
    },
    {
      "epoch": 0.9678935901846119,
      "grad_norm": 0.0,
      "learning_rate": 2.8007409904435856e-06,
      "loss": 5.226,
      "step": 8441
    },
    {
      "epoch": 0.9680082559339526,
      "grad_norm": 0.0,
      "learning_rate": 2.781501664042424e-06,
      "loss": 5.2198,
      "step": 8442
    },
    {
      "epoch": 0.9681229216832932,
      "grad_norm": 0.0,
      "learning_rate": 2.7623309263518185e-06,
      "loss": 5.1126,
      "step": 8443
    },
    {
      "epoch": 0.9682375874326339,
      "grad_norm": 0.0,
      "learning_rate": 2.743228780016e-06,
      "loss": 5.0171,
      "step": 8444
    },
    {
      "epoch": 0.9683522531819746,
      "grad_norm": 0.0,
      "learning_rate": 2.724195227669709e-06,
      "loss": 4.802,
      "step": 8445
    },
    {
      "epoch": 0.9684669189313152,
      "grad_norm": 0.0,
      "learning_rate": 2.7052302719383043e-06,
      "loss": 5.1736,
      "step": 8446
    },
    {
      "epoch": 0.9685815846806559,
      "grad_norm": 0.0,
      "learning_rate": 2.686333915437654e-06,
      "loss": 5.1544,
      "step": 8447
    },
    {
      "epoch": 0.9686962504299965,
      "grad_norm": 0.0,
      "learning_rate": 2.667506160774134e-06,
      "loss": 4.9029,
      "step": 8448
    },
    {
      "epoch": 0.9688109161793372,
      "grad_norm": 0.0,
      "learning_rate": 2.6487470105446305e-06,
      "loss": 4.8315,
      "step": 8449
    },
    {
      "epoch": 0.968925581928678,
      "grad_norm": 0.0,
      "learning_rate": 2.630056467336647e-06,
      "loss": 5.1102,
      "step": 8450
    },
    {
      "epoch": 0.9690402476780186,
      "grad_norm": 0.0,
      "learning_rate": 2.6114345337282526e-06,
      "loss": 4.9024,
      "step": 8451
    },
    {
      "epoch": 0.9691549134273593,
      "grad_norm": 0.0,
      "learning_rate": 2.5928812122878584e-06,
      "loss": 5.1502,
      "step": 8452
    },
    {
      "epoch": 0.9692695791766999,
      "grad_norm": 0.0,
      "learning_rate": 2.5743965055746045e-06,
      "loss": 5.2348,
      "step": 8453
    },
    {
      "epoch": 0.9693842449260406,
      "grad_norm": 0.0,
      "learning_rate": 2.555980416138141e-06,
      "loss": 4.8502,
      "step": 8454
    },
    {
      "epoch": 0.9694989106753813,
      "grad_norm": 0.0,
      "learning_rate": 2.5376329465185713e-06,
      "loss": 4.7859,
      "step": 8455
    },
    {
      "epoch": 0.9696135764247219,
      "grad_norm": 0.0,
      "learning_rate": 2.519354099246561e-06,
      "loss": 5.2145,
      "step": 8456
    },
    {
      "epoch": 0.9697282421740626,
      "grad_norm": 0.0,
      "learning_rate": 2.501143876843343e-06,
      "loss": 4.8585,
      "step": 8457
    },
    {
      "epoch": 0.9698429079234033,
      "grad_norm": 0.0,
      "learning_rate": 2.4830022818207104e-06,
      "loss": 4.912,
      "step": 8458
    },
    {
      "epoch": 0.9699575736727439,
      "grad_norm": 0.0,
      "learning_rate": 2.464929316680967e-06,
      "loss": 5.0577,
      "step": 8459
    },
    {
      "epoch": 0.9700722394220846,
      "grad_norm": 0.0,
      "learning_rate": 2.4469249839168695e-06,
      "loss": 4.9766,
      "step": 8460
    },
    {
      "epoch": 0.9701869051714253,
      "grad_norm": 0.0,
      "learning_rate": 2.4289892860117384e-06,
      "loss": 4.8783,
      "step": 8461
    },
    {
      "epoch": 0.970301570920766,
      "grad_norm": 0.0,
      "learning_rate": 2.4111222254395696e-06,
      "loss": 4.8724,
      "step": 8462
    },
    {
      "epoch": 0.9704162366701067,
      "grad_norm": 0.0,
      "learning_rate": 2.393323804664701e-06,
      "loss": 4.852,
      "step": 8463
    },
    {
      "epoch": 0.9705309024194473,
      "grad_norm": 0.0,
      "learning_rate": 2.375594026142089e-06,
      "loss": 4.9061,
      "step": 8464
    },
    {
      "epoch": 0.970645568168788,
      "grad_norm": 0.0,
      "learning_rate": 2.3579328923173106e-06,
      "loss": 5.1957,
      "step": 8465
    },
    {
      "epoch": 0.9707602339181286,
      "grad_norm": 0.0,
      "learning_rate": 2.3403404056262845e-06,
      "loss": 4.9836,
      "step": 8466
    },
    {
      "epoch": 0.9708748996674693,
      "grad_norm": 0.0,
      "learning_rate": 2.322816568495605e-06,
      "loss": 4.7631,
      "step": 8467
    },
    {
      "epoch": 0.97098956541681,
      "grad_norm": 0.0,
      "learning_rate": 2.3053613833422625e-06,
      "loss": 5.0236,
      "step": 8468
    },
    {
      "epoch": 0.9711042311661506,
      "grad_norm": 0.0,
      "learning_rate": 2.2879748525740357e-06,
      "loss": 5.03,
      "step": 8469
    },
    {
      "epoch": 0.9712188969154913,
      "grad_norm": 0.0,
      "learning_rate": 2.2706569785888765e-06,
      "loss": 5.0893,
      "step": 8470
    },
    {
      "epoch": 0.9713335626648321,
      "grad_norm": 0.0,
      "learning_rate": 2.2534077637756355e-06,
      "loss": 5.1537,
      "step": 8471
    },
    {
      "epoch": 0.9714482284141727,
      "grad_norm": 0.0,
      "learning_rate": 2.236227210513449e-06,
      "loss": 5.0211,
      "step": 8472
    },
    {
      "epoch": 0.9715628941635134,
      "grad_norm": 0.0,
      "learning_rate": 2.2191153211719067e-06,
      "loss": 5.1441,
      "step": 8473
    },
    {
      "epoch": 0.971677559912854,
      "grad_norm": 0.0,
      "learning_rate": 2.202072098111495e-06,
      "loss": 5.0729,
      "step": 8474
    },
    {
      "epoch": 0.9717922256621947,
      "grad_norm": 0.0,
      "learning_rate": 2.1850975436828205e-06,
      "loss": 4.9893,
      "step": 8475
    },
    {
      "epoch": 0.9719068914115354,
      "grad_norm": 0.0,
      "learning_rate": 2.168191660227332e-06,
      "loss": 4.8264,
      "step": 8476
    },
    {
      "epoch": 0.972021557160876,
      "grad_norm": 0.0,
      "learning_rate": 2.1513544500767636e-06,
      "loss": 4.9083,
      "step": 8477
    },
    {
      "epoch": 0.9721362229102167,
      "grad_norm": 0.0,
      "learning_rate": 2.1345859155535815e-06,
      "loss": 4.8588,
      "step": 8478
    },
    {
      "epoch": 0.9722508886595574,
      "grad_norm": 0.0,
      "learning_rate": 2.117886058970592e-06,
      "loss": 5.1506,
      "step": 8479
    },
    {
      "epoch": 0.972365554408898,
      "grad_norm": 0.0,
      "learning_rate": 2.1012548826312777e-06,
      "loss": 5.1274,
      "step": 8480
    },
    {
      "epoch": 0.9724802201582388,
      "grad_norm": 0.0,
      "learning_rate": 2.0846923888296303e-06,
      "loss": 4.8601,
      "step": 8481
    },
    {
      "epoch": 0.9725948859075794,
      "grad_norm": 0.0,
      "learning_rate": 2.0681985798500937e-06,
      "loss": 4.9175,
      "step": 8482
    },
    {
      "epoch": 0.9727095516569201,
      "grad_norm": 0.0,
      "learning_rate": 2.0517734579676193e-06,
      "loss": 4.7788,
      "step": 8483
    },
    {
      "epoch": 0.9728242174062608,
      "grad_norm": 0.0,
      "learning_rate": 2.0354170254477804e-06,
      "loss": 4.8389,
      "step": 8484
    },
    {
      "epoch": 0.9729388831556014,
      "grad_norm": 0.0,
      "learning_rate": 2.0191292845466566e-06,
      "loss": 4.918,
      "step": 8485
    },
    {
      "epoch": 0.9730535489049421,
      "grad_norm": 0.0,
      "learning_rate": 2.0029102375108385e-06,
      "loss": 4.7382,
      "step": 8486
    },
    {
      "epoch": 0.9731682146542827,
      "grad_norm": 0.0,
      "learning_rate": 1.9867598865773666e-06,
      "loss": 4.9008,
      "step": 8487
    },
    {
      "epoch": 0.9732828804036234,
      "grad_norm": 0.0,
      "learning_rate": 1.9706782339739593e-06,
      "loss": 5.0586,
      "step": 8488
    },
    {
      "epoch": 0.9733975461529641,
      "grad_norm": 0.0,
      "learning_rate": 1.954665281918731e-06,
      "loss": 4.8901,
      "step": 8489
    },
    {
      "epoch": 0.9735122119023047,
      "grad_norm": 0.0,
      "learning_rate": 1.9387210326203053e-06,
      "loss": 4.8567,
      "step": 8490
    },
    {
      "epoch": 0.9736268776516455,
      "grad_norm": 0.0,
      "learning_rate": 1.922845488278036e-06,
      "loss": 4.7348,
      "step": 8491
    },
    {
      "epoch": 0.9737415434009862,
      "grad_norm": 0.0,
      "learning_rate": 1.9070386510815073e-06,
      "loss": 5.1958,
      "step": 8492
    },
    {
      "epoch": 0.9738562091503268,
      "grad_norm": 0.0,
      "learning_rate": 1.891300523211091e-06,
      "loss": 5.0379,
      "step": 8493
    },
    {
      "epoch": 0.9739708748996675,
      "grad_norm": 0.0,
      "learning_rate": 1.8756311068374446e-06,
      "loss": 5.1062,
      "step": 8494
    },
    {
      "epoch": 0.9740855406490081,
      "grad_norm": 0.0,
      "learning_rate": 1.8600304041219005e-06,
      "loss": 4.6936,
      "step": 8495
    },
    {
      "epoch": 0.9742002063983488,
      "grad_norm": 0.0,
      "learning_rate": 1.844498417216355e-06,
      "loss": 5.2977,
      "step": 8496
    },
    {
      "epoch": 0.9743148721476895,
      "grad_norm": 0.0,
      "learning_rate": 1.8290351482630471e-06,
      "loss": 4.9988,
      "step": 8497
    },
    {
      "epoch": 0.9744295378970301,
      "grad_norm": 0.0,
      "learning_rate": 1.8136405993948907e-06,
      "loss": 5.1255,
      "step": 8498
    },
    {
      "epoch": 0.9745442036463708,
      "grad_norm": 0.0,
      "learning_rate": 1.7983147727353072e-06,
      "loss": 4.9599,
      "step": 8499
    },
    {
      "epoch": 0.9746588693957114,
      "grad_norm": 0.0,
      "learning_rate": 1.7830576703981172e-06,
      "loss": 5.0143,
      "step": 8500
    },
    {
      "epoch": 0.9747735351450522,
      "grad_norm": 0.0,
      "learning_rate": 1.7678692944878152e-06,
      "loss": 5.1838,
      "step": 8501
    },
    {
      "epoch": 0.9748882008943929,
      "grad_norm": 0.0,
      "learning_rate": 1.7527496470992938e-06,
      "loss": 4.9751,
      "step": 8502
    },
    {
      "epoch": 0.9750028666437335,
      "grad_norm": 0.0,
      "learning_rate": 1.7376987303180644e-06,
      "loss": 5.0473,
      "step": 8503
    },
    {
      "epoch": 0.9751175323930742,
      "grad_norm": 0.0,
      "learning_rate": 1.7227165462200923e-06,
      "loss": 4.9273,
      "step": 8504
    },
    {
      "epoch": 0.9752321981424149,
      "grad_norm": 0.0,
      "learning_rate": 1.7078030968719067e-06,
      "loss": 5.0666,
      "step": 8505
    },
    {
      "epoch": 0.9753468638917555,
      "grad_norm": 0.0,
      "learning_rate": 1.6929583843304893e-06,
      "loss": 4.7675,
      "step": 8506
    },
    {
      "epoch": 0.9754615296410962,
      "grad_norm": 0.0,
      "learning_rate": 1.6781824106434416e-06,
      "loss": 4.8036,
      "step": 8507
    },
    {
      "epoch": 0.9755761953904368,
      "grad_norm": 0.0,
      "learning_rate": 1.6634751778487633e-06,
      "loss": 4.8633,
      "step": 8508
    },
    {
      "epoch": 0.9756908611397775,
      "grad_norm": 0.0,
      "learning_rate": 1.6488366879751278e-06,
      "loss": 4.945,
      "step": 8509
    },
    {
      "epoch": 0.9758055268891183,
      "grad_norm": 0.0,
      "learning_rate": 1.6342669430415518e-06,
      "loss": 4.853,
      "step": 8510
    },
    {
      "epoch": 0.9759201926384589,
      "grad_norm": 0.0,
      "learning_rate": 1.619765945057671e-06,
      "loss": 5.1653,
      "step": 8511
    },
    {
      "epoch": 0.9760348583877996,
      "grad_norm": 0.0,
      "learning_rate": 1.6053336960236296e-06,
      "loss": 4.9057,
      "step": 8512
    },
    {
      "epoch": 0.9761495241371403,
      "grad_norm": 0.0,
      "learning_rate": 1.590970197930136e-06,
      "loss": 4.9924,
      "step": 8513
    },
    {
      "epoch": 0.9762641898864809,
      "grad_norm": 0.0,
      "learning_rate": 1.5766754527582406e-06,
      "loss": 5.1989,
      "step": 8514
    },
    {
      "epoch": 0.9763788556358216,
      "grad_norm": 0.0,
      "learning_rate": 1.562449462479724e-06,
      "loss": 5.0573,
      "step": 8515
    },
    {
      "epoch": 0.9764935213851622,
      "grad_norm": 0.0,
      "learning_rate": 1.5482922290568208e-06,
      "loss": 4.9444,
      "step": 8516
    },
    {
      "epoch": 0.9766081871345029,
      "grad_norm": 0.0,
      "learning_rate": 1.5342037544421066e-06,
      "loss": 4.6459,
      "step": 8517
    },
    {
      "epoch": 0.9767228528838436,
      "grad_norm": 0.0,
      "learning_rate": 1.520184040578999e-06,
      "loss": 4.8761,
      "step": 8518
    },
    {
      "epoch": 0.9768375186331842,
      "grad_norm": 0.0,
      "learning_rate": 1.5062330894010912e-06,
      "loss": 5.0275,
      "step": 8519
    },
    {
      "epoch": 0.976952184382525,
      "grad_norm": 0.0,
      "learning_rate": 1.4923509028327624e-06,
      "loss": 5.0352,
      "step": 8520
    },
    {
      "epoch": 0.9770668501318656,
      "grad_norm": 0.0,
      "learning_rate": 1.4785374827887335e-06,
      "loss": 5.3061,
      "step": 8521
    },
    {
      "epoch": 0.9771815158812063,
      "grad_norm": 0.0,
      "learning_rate": 1.4647928311742902e-06,
      "loss": 5.2082,
      "step": 8522
    },
    {
      "epoch": 0.977296181630547,
      "grad_norm": 0.0,
      "learning_rate": 1.4511169498853366e-06,
      "loss": 5.1359,
      "step": 8523
    },
    {
      "epoch": 0.9774108473798876,
      "grad_norm": 0.0,
      "learning_rate": 1.4375098408081202e-06,
      "loss": 5.1882,
      "step": 8524
    },
    {
      "epoch": 0.9775255131292283,
      "grad_norm": 0.0,
      "learning_rate": 1.4239715058195068e-06,
      "loss": 4.9584,
      "step": 8525
    },
    {
      "epoch": 0.977640178878569,
      "grad_norm": 0.0,
      "learning_rate": 1.4105019467868163e-06,
      "loss": 5.1904,
      "step": 8526
    },
    {
      "epoch": 0.9777548446279096,
      "grad_norm": 0.0,
      "learning_rate": 1.3971011655679873e-06,
      "loss": 4.8751,
      "step": 8527
    },
    {
      "epoch": 0.9778695103772503,
      "grad_norm": 0.0,
      "learning_rate": 1.3837691640113563e-06,
      "loss": 4.9325,
      "step": 8528
    },
    {
      "epoch": 0.9779841761265909,
      "grad_norm": 0.0,
      "learning_rate": 1.3705059439557686e-06,
      "loss": 5.0057,
      "step": 8529
    },
    {
      "epoch": 0.9780988418759317,
      "grad_norm": 0.0,
      "learning_rate": 1.357311507230744e-06,
      "loss": 4.7689,
      "step": 8530
    },
    {
      "epoch": 0.9782135076252724,
      "grad_norm": 0.0,
      "learning_rate": 1.3441858556561448e-06,
      "loss": 4.9644,
      "step": 8531
    },
    {
      "epoch": 0.978328173374613,
      "grad_norm": 0.0,
      "learning_rate": 1.331128991042397e-06,
      "loss": 5.044,
      "step": 8532
    },
    {
      "epoch": 0.9784428391239537,
      "grad_norm": 0.0,
      "learning_rate": 1.3181409151904912e-06,
      "loss": 5.1029,
      "step": 8533
    },
    {
      "epoch": 0.9785575048732943,
      "grad_norm": 0.0,
      "learning_rate": 1.3052216298918698e-06,
      "loss": 4.9833,
      "step": 8534
    },
    {
      "epoch": 0.978672170622635,
      "grad_norm": 0.0,
      "learning_rate": 1.29237113692843e-06,
      "loss": 5.2435,
      "step": 8535
    },
    {
      "epoch": 0.9787868363719757,
      "grad_norm": 0.0,
      "learning_rate": 1.279589438072687e-06,
      "loss": 5.1871,
      "step": 8536
    },
    {
      "epoch": 0.9789015021213163,
      "grad_norm": 0.0,
      "learning_rate": 1.2668765350877213e-06,
      "loss": 4.9786,
      "step": 8537
    },
    {
      "epoch": 0.979016167870657,
      "grad_norm": 0.0,
      "learning_rate": 1.254232429726954e-06,
      "loss": 4.8802,
      "step": 8538
    },
    {
      "epoch": 0.9791308336199978,
      "grad_norm": 0.0,
      "learning_rate": 1.2416571237343718e-06,
      "loss": 4.9568,
      "step": 8539
    },
    {
      "epoch": 0.9792454993693384,
      "grad_norm": 0.0,
      "learning_rate": 1.2291506188445243e-06,
      "loss": 4.9708,
      "step": 8540
    },
    {
      "epoch": 0.9793601651186791,
      "grad_norm": 0.0,
      "learning_rate": 1.21671291678247e-06,
      "loss": 5.0792,
      "step": 8541
    },
    {
      "epoch": 0.9794748308680197,
      "grad_norm": 0.0,
      "learning_rate": 1.2043440192637764e-06,
      "loss": 5.2317,
      "step": 8542
    },
    {
      "epoch": 0.9795894966173604,
      "grad_norm": 0.0,
      "learning_rate": 1.192043927994463e-06,
      "loss": 4.9141,
      "step": 8543
    },
    {
      "epoch": 0.9797041623667011,
      "grad_norm": 0.0,
      "learning_rate": 1.1798126446710591e-06,
      "loss": 5.1103,
      "step": 8544
    },
    {
      "epoch": 0.9798188281160417,
      "grad_norm": 0.0,
      "learning_rate": 1.1676501709807127e-06,
      "loss": 5.2667,
      "step": 8545
    },
    {
      "epoch": 0.9799334938653824,
      "grad_norm": 0.0,
      "learning_rate": 1.1555565086009138e-06,
      "loss": 5.114,
      "step": 8546
    },
    {
      "epoch": 0.9800481596147231,
      "grad_norm": 0.0,
      "learning_rate": 1.1435316591998279e-06,
      "loss": 5.0056,
      "step": 8547
    },
    {
      "epoch": 0.9801628253640637,
      "grad_norm": 0.0,
      "learning_rate": 1.1315756244360178e-06,
      "loss": 4.9432,
      "step": 8548
    },
    {
      "epoch": 0.9802774911134045,
      "grad_norm": 0.0,
      "learning_rate": 1.1196884059586105e-06,
      "loss": 4.9559,
      "step": 8549
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.0,
      "learning_rate": 1.107870005407186e-06,
      "loss": 5.2201,
      "step": 8550
    },
    {
      "epoch": 0.9805068226120858,
      "grad_norm": 0.0,
      "learning_rate": 1.0961204244119432e-06,
      "loss": 4.9587,
      "step": 8551
    },
    {
      "epoch": 0.9806214883614265,
      "grad_norm": 0.0,
      "learning_rate": 1.0844396645934243e-06,
      "loss": 4.918,
      "step": 8552
    },
    {
      "epoch": 0.9807361541107671,
      "grad_norm": 0.0,
      "learning_rate": 1.07282772756279e-06,
      "loss": 5.2813,
      "step": 8553
    },
    {
      "epoch": 0.9808508198601078,
      "grad_norm": 0.0,
      "learning_rate": 1.0612846149217101e-06,
      "loss": 5.1458,
      "step": 8554
    },
    {
      "epoch": 0.9809654856094484,
      "grad_norm": 0.0,
      "learning_rate": 1.0498103282623624e-06,
      "loss": 5.1663,
      "step": 8555
    },
    {
      "epoch": 0.9810801513587891,
      "grad_norm": 0.0,
      "learning_rate": 1.038404869167323e-06,
      "loss": 5.0071,
      "step": 8556
    },
    {
      "epoch": 0.9811948171081298,
      "grad_norm": 0.0,
      "learning_rate": 1.0270682392098422e-06,
      "loss": 5.0322,
      "step": 8557
    },
    {
      "epoch": 0.9813094828574704,
      "grad_norm": 0.0,
      "learning_rate": 1.0158004399535131e-06,
      "loss": 5.1416,
      "step": 8558
    },
    {
      "epoch": 0.9814241486068112,
      "grad_norm": 0.0,
      "learning_rate": 1.0046014729526035e-06,
      "loss": 4.9405,
      "step": 8559
    },
    {
      "epoch": 0.9815388143561519,
      "grad_norm": 0.0,
      "learning_rate": 9.934713397517227e-07,
      "loss": 4.936,
      "step": 8560
    },
    {
      "epoch": 0.9816534801054925,
      "grad_norm": 0.0,
      "learning_rate": 9.824100418861009e-07,
      "loss": 4.6558,
      "step": 8561
    },
    {
      "epoch": 0.9817681458548332,
      "grad_norm": 0.0,
      "learning_rate": 9.714175808814201e-07,
      "loss": 4.9585,
      "step": 8562
    },
    {
      "epoch": 0.9818828116041738,
      "grad_norm": 0.0,
      "learning_rate": 9.60493958253871e-07,
      "loss": 4.9463,
      "step": 8563
    },
    {
      "epoch": 0.9819974773535145,
      "grad_norm": 0.0,
      "learning_rate": 9.496391755101538e-07,
      "loss": 4.8238,
      "step": 8564
    },
    {
      "epoch": 0.9821121431028552,
      "grad_norm": 0.0,
      "learning_rate": 9.388532341475314e-07,
      "loss": 4.8769,
      "step": 8565
    },
    {
      "epoch": 0.9822268088521958,
      "grad_norm": 0.0,
      "learning_rate": 9.281361356536654e-07,
      "loss": 5.0101,
      "step": 8566
    },
    {
      "epoch": 0.9823414746015365,
      "grad_norm": 0.0,
      "learning_rate": 9.174878815067807e-07,
      "loss": 4.9994,
      "step": 8567
    },
    {
      "epoch": 0.9824561403508771,
      "grad_norm": 0.0,
      "learning_rate": 9.06908473175611e-07,
      "loss": 5.1854,
      "step": 8568
    },
    {
      "epoch": 0.9825708061002179,
      "grad_norm": 0.0,
      "learning_rate": 8.963979121193985e-07,
      "loss": 5.0298,
      "step": 8569
    },
    {
      "epoch": 0.9826854718495586,
      "grad_norm": 0.0,
      "learning_rate": 8.85956199787894e-07,
      "loss": 4.9257,
      "step": 8570
    },
    {
      "epoch": 0.9828001375988992,
      "grad_norm": 0.0,
      "learning_rate": 8.755833376212459e-07,
      "loss": 5.0611,
      "step": 8571
    },
    {
      "epoch": 0.9829148033482399,
      "grad_norm": 0.0,
      "learning_rate": 8.652793270502773e-07,
      "loss": 5.0863,
      "step": 8572
    },
    {
      "epoch": 0.9830294690975806,
      "grad_norm": 0.0,
      "learning_rate": 8.550441694961538e-07,
      "loss": 4.9476,
      "step": 8573
    },
    {
      "epoch": 0.9831441348469212,
      "grad_norm": 0.0,
      "learning_rate": 8.44877866370716e-07,
      "loss": 5.0478,
      "step": 8574
    },
    {
      "epoch": 0.9832588005962619,
      "grad_norm": 0.0,
      "learning_rate": 8.347804190761459e-07,
      "loss": 5.0089,
      "step": 8575
    },
    {
      "epoch": 0.9833734663456025,
      "grad_norm": 0.0,
      "learning_rate": 8.247518290051904e-07,
      "loss": 5.1332,
      "step": 8576
    },
    {
      "epoch": 0.9834881320949432,
      "grad_norm": 0.0,
      "learning_rate": 8.147920975411045e-07,
      "loss": 5.0875,
      "step": 8577
    },
    {
      "epoch": 0.983602797844284,
      "grad_norm": 0.0,
      "learning_rate": 8.049012260577072e-07,
      "loss": 5.1586,
      "step": 8578
    },
    {
      "epoch": 0.9837174635936246,
      "grad_norm": 0.0,
      "learning_rate": 7.950792159192152e-07,
      "loss": 5.0982,
      "step": 8579
    },
    {
      "epoch": 0.9838321293429653,
      "grad_norm": 0.0,
      "learning_rate": 7.853260684803537e-07,
      "loss": 4.9063,
      "step": 8580
    },
    {
      "epoch": 0.983946795092306,
      "grad_norm": 0.0,
      "learning_rate": 7.756417850864119e-07,
      "loss": 4.7401,
      "step": 8581
    },
    {
      "epoch": 0.9840614608416466,
      "grad_norm": 0.0,
      "learning_rate": 7.660263670731321e-07,
      "loss": 5.4069,
      "step": 8582
    },
    {
      "epoch": 0.9841761265909873,
      "grad_norm": 0.0,
      "learning_rate": 7.564798157668204e-07,
      "loss": 5.0632,
      "step": 8583
    },
    {
      "epoch": 0.9842907923403279,
      "grad_norm": 0.0,
      "learning_rate": 7.470021324842366e-07,
      "loss": 4.9765,
      "step": 8584
    },
    {
      "epoch": 0.9844054580896686,
      "grad_norm": 0.0,
      "learning_rate": 7.375933185325928e-07,
      "loss": 4.9675,
      "step": 8585
    },
    {
      "epoch": 0.9845201238390093,
      "grad_norm": 0.0,
      "learning_rate": 7.282533752097208e-07,
      "loss": 5.0195,
      "step": 8586
    },
    {
      "epoch": 0.9846347895883499,
      "grad_norm": 0.0,
      "learning_rate": 7.189823038038503e-07,
      "loss": 5.0906,
      "step": 8587
    },
    {
      "epoch": 0.9847494553376906,
      "grad_norm": 0.0,
      "learning_rate": 7.097801055937194e-07,
      "loss": 4.9635,
      "step": 8588
    },
    {
      "epoch": 0.9848641210870313,
      "grad_norm": 0.0,
      "learning_rate": 7.006467818486299e-07,
      "loss": 4.8185,
      "step": 8589
    },
    {
      "epoch": 0.984978786836372,
      "grad_norm": 0.0,
      "learning_rate": 6.915823338283927e-07,
      "loss": 5.0113,
      "step": 8590
    },
    {
      "epoch": 0.9850934525857127,
      "grad_norm": 0.0,
      "learning_rate": 6.825867627832156e-07,
      "loss": 4.89,
      "step": 8591
    },
    {
      "epoch": 0.9852081183350533,
      "grad_norm": 0.0,
      "learning_rate": 6.736600699539264e-07,
      "loss": 4.9023,
      "step": 8592
    },
    {
      "epoch": 0.985322784084394,
      "grad_norm": 0.0,
      "learning_rate": 6.648022565716949e-07,
      "loss": 4.8787,
      "step": 8593
    },
    {
      "epoch": 0.9854374498337347,
      "grad_norm": 0.0,
      "learning_rate": 6.560133238583659e-07,
      "loss": 4.9326,
      "step": 8594
    },
    {
      "epoch": 0.9855521155830753,
      "grad_norm": 0.0,
      "learning_rate": 6.472932730261817e-07,
      "loss": 4.8296,
      "step": 8595
    },
    {
      "epoch": 0.985666781332416,
      "grad_norm": 0.0,
      "learning_rate": 6.386421052779486e-07,
      "loss": 4.9954,
      "step": 8596
    },
    {
      "epoch": 0.9857814470817566,
      "grad_norm": 0.0,
      "learning_rate": 6.300598218068149e-07,
      "loss": 5.1363,
      "step": 8597
    },
    {
      "epoch": 0.9858961128310973,
      "grad_norm": 0.0,
      "learning_rate": 6.215464237966597e-07,
      "loss": 4.9509,
      "step": 8598
    },
    {
      "epoch": 0.9860107785804381,
      "grad_norm": 0.0,
      "learning_rate": 6.13101912421704e-07,
      "loss": 5.0879,
      "step": 8599
    },
    {
      "epoch": 0.9861254443297787,
      "grad_norm": 0.0,
      "learning_rate": 6.047262888467325e-07,
      "loss": 5.0067,
      "step": 8600
    },
    {
      "epoch": 0.9862401100791194,
      "grad_norm": 0.0,
      "learning_rate": 5.964195542269282e-07,
      "loss": 4.9139,
      "step": 8601
    },
    {
      "epoch": 0.98635477582846,
      "grad_norm": 0.0,
      "learning_rate": 5.881817097080928e-07,
      "loss": 5.1744,
      "step": 8602
    },
    {
      "epoch": 0.9864694415778007,
      "grad_norm": 0.0,
      "learning_rate": 5.800127564265373e-07,
      "loss": 4.9145,
      "step": 8603
    },
    {
      "epoch": 0.9865841073271414,
      "grad_norm": 0.0,
      "learning_rate": 5.719126955089141e-07,
      "loss": 5.0507,
      "step": 8604
    },
    {
      "epoch": 0.986698773076482,
      "grad_norm": 0.0,
      "learning_rate": 5.63881528072551e-07,
      "loss": 4.9999,
      "step": 8605
    },
    {
      "epoch": 0.9868134388258227,
      "grad_norm": 0.0,
      "learning_rate": 5.559192552251178e-07,
      "loss": 4.8915,
      "step": 8606
    },
    {
      "epoch": 0.9869281045751634,
      "grad_norm": 0.0,
      "learning_rate": 5.480258780649037e-07,
      "loss": 4.9065,
      "step": 8607
    },
    {
      "epoch": 0.987042770324504,
      "grad_norm": 0.0,
      "learning_rate": 5.402013976806512e-07,
      "loss": 4.9649,
      "step": 8608
    },
    {
      "epoch": 0.9871574360738448,
      "grad_norm": 0.0,
      "learning_rate": 5.324458151516112e-07,
      "loss": 4.9933,
      "step": 8609
    },
    {
      "epoch": 0.9872721018231854,
      "grad_norm": 0.0,
      "learning_rate": 5.247591315474875e-07,
      "loss": 5.0075,
      "step": 8610
    },
    {
      "epoch": 0.9873867675725261,
      "grad_norm": 0.0,
      "learning_rate": 5.171413479285482e-07,
      "loss": 5.0635,
      "step": 8611
    },
    {
      "epoch": 0.9875014333218668,
      "grad_norm": 0.0,
      "learning_rate": 5.095924653454586e-07,
      "loss": 4.8441,
      "step": 8612
    },
    {
      "epoch": 0.9876160990712074,
      "grad_norm": 0.0,
      "learning_rate": 5.021124848395039e-07,
      "loss": 5.3408,
      "step": 8613
    },
    {
      "epoch": 0.9877307648205481,
      "grad_norm": 0.0,
      "learning_rate": 4.947014074423668e-07,
      "loss": 5.3137,
      "step": 8614
    },
    {
      "epoch": 0.9878454305698888,
      "grad_norm": 0.0,
      "learning_rate": 4.873592341762936e-07,
      "loss": 4.7222,
      "step": 8615
    },
    {
      "epoch": 0.9879600963192294,
      "grad_norm": 0.0,
      "learning_rate": 4.800859660539844e-07,
      "loss": 5.1345,
      "step": 8616
    },
    {
      "epoch": 0.9880747620685701,
      "grad_norm": 0.0,
      "learning_rate": 4.7288160407864704e-07,
      "loss": 4.7911,
      "step": 8617
    },
    {
      "epoch": 0.9881894278179107,
      "grad_norm": 0.0,
      "learning_rate": 4.657461492439986e-07,
      "loss": 5.3281,
      "step": 8618
    },
    {
      "epoch": 0.9883040935672515,
      "grad_norm": 0.0,
      "learning_rate": 4.586796025342086e-07,
      "loss": 4.9428,
      "step": 8619
    },
    {
      "epoch": 0.9884187593165922,
      "grad_norm": 0.0,
      "learning_rate": 4.5168196492401105e-07,
      "loss": 4.8996,
      "step": 8620
    },
    {
      "epoch": 0.9885334250659328,
      "grad_norm": 0.0,
      "learning_rate": 4.447532373785372e-07,
      "loss": 4.8958,
      "step": 8621
    },
    {
      "epoch": 0.9886480908152735,
      "grad_norm": 0.0,
      "learning_rate": 4.3789342085353814e-07,
      "loss": 4.9506,
      "step": 8622
    },
    {
      "epoch": 0.9887627565646141,
      "grad_norm": 0.0,
      "learning_rate": 4.3110251629516225e-07,
      "loss": 5.0408,
      "step": 8623
    },
    {
      "epoch": 0.9888774223139548,
      "grad_norm": 0.0,
      "learning_rate": 4.2438052464006647e-07,
      "loss": 4.9821,
      "step": 8624
    },
    {
      "epoch": 0.9889920880632955,
      "grad_norm": 0.0,
      "learning_rate": 4.1772744681547194e-07,
      "loss": 5.1171,
      "step": 8625
    },
    {
      "epoch": 0.9891067538126361,
      "grad_norm": 0.0,
      "learning_rate": 4.111432837390527e-07,
      "loss": 4.8438,
      "step": 8626
    },
    {
      "epoch": 0.9892214195619768,
      "grad_norm": 0.0,
      "learning_rate": 4.046280363188804e-07,
      "loss": 5.1304,
      "step": 8627
    },
    {
      "epoch": 0.9893360853113176,
      "grad_norm": 0.0,
      "learning_rate": 3.9818170545370163e-07,
      "loss": 4.8329,
      "step": 8628
    },
    {
      "epoch": 0.9894507510606582,
      "grad_norm": 0.0,
      "learning_rate": 3.918042920326052e-07,
      "loss": 4.9507,
      "step": 8629
    },
    {
      "epoch": 0.9895654168099989,
      "grad_norm": 0.0,
      "learning_rate": 3.854957969352439e-07,
      "loss": 4.8722,
      "step": 8630
    },
    {
      "epoch": 0.9896800825593395,
      "grad_norm": 0.0,
      "learning_rate": 3.7925622103177885e-07,
      "loss": 4.8616,
      "step": 8631
    },
    {
      "epoch": 0.9897947483086802,
      "grad_norm": 0.0,
      "learning_rate": 3.730855651828245e-07,
      "loss": 5.2024,
      "step": 8632
    },
    {
      "epoch": 0.9899094140580209,
      "grad_norm": 0.0,
      "learning_rate": 3.669838302395592e-07,
      "loss": 4.6968,
      "step": 8633
    },
    {
      "epoch": 0.9900240798073615,
      "grad_norm": 0.0,
      "learning_rate": 3.6095101704344786e-07,
      "loss": 4.9668,
      "step": 8634
    },
    {
      "epoch": 0.9901387455567022,
      "grad_norm": 0.0,
      "learning_rate": 3.5498712642679696e-07,
      "loss": 4.9828,
      "step": 8635
    },
    {
      "epoch": 0.9902534113060428,
      "grad_norm": 0.0,
      "learning_rate": 3.4909215921208843e-07,
      "loss": 5.0728,
      "step": 8636
    },
    {
      "epoch": 0.9903680770553835,
      "grad_norm": 0.0,
      "learning_rate": 3.4326611621242387e-07,
      "loss": 5.1525,
      "step": 8637
    },
    {
      "epoch": 0.9904827428047243,
      "grad_norm": 0.0,
      "learning_rate": 3.3750899823146883e-07,
      "loss": 5.0443,
      "step": 8638
    },
    {
      "epoch": 0.9905974085540649,
      "grad_norm": 0.0,
      "learning_rate": 3.318208060632309e-07,
      "loss": 4.6674,
      "step": 8639
    },
    {
      "epoch": 0.9907120743034056,
      "grad_norm": 0.0,
      "learning_rate": 3.2620154049228176e-07,
      "loss": 5.0338,
      "step": 8640
    },
    {
      "epoch": 0.9908267400527463,
      "grad_norm": 0.0,
      "learning_rate": 3.2065120229375714e-07,
      "loss": 4.9265,
      "step": 8641
    },
    {
      "epoch": 0.9909414058020869,
      "grad_norm": 0.0,
      "learning_rate": 3.151697922332458e-07,
      "loss": 5.2433,
      "step": 8642
    },
    {
      "epoch": 0.9910560715514276,
      "grad_norm": 0.0,
      "learning_rate": 3.097573110666784e-07,
      "loss": 4.8338,
      "step": 8643
    },
    {
      "epoch": 0.9911707373007682,
      "grad_norm": 0.0,
      "learning_rate": 3.044137595407164e-07,
      "loss": 4.7996,
      "step": 8644
    },
    {
      "epoch": 0.9912854030501089,
      "grad_norm": 0.0,
      "learning_rate": 2.991391383923075e-07,
      "loss": 5.0572,
      "step": 8645
    },
    {
      "epoch": 0.9914000687994496,
      "grad_norm": 0.0,
      "learning_rate": 2.939334483490748e-07,
      "loss": 5.3569,
      "step": 8646
    },
    {
      "epoch": 0.9915147345487902,
      "grad_norm": 0.0,
      "learning_rate": 2.8879669012903864e-07,
      "loss": 5.1582,
      "step": 8647
    },
    {
      "epoch": 0.991629400298131,
      "grad_norm": 0.0,
      "learning_rate": 2.837288644406169e-07,
      "loss": 5.0887,
      "step": 8648
    },
    {
      "epoch": 0.9917440660474717,
      "grad_norm": 0.0,
      "learning_rate": 2.787299719829028e-07,
      "loss": 5.0456,
      "step": 8649
    },
    {
      "epoch": 0.9918587317968123,
      "grad_norm": 0.0,
      "learning_rate": 2.738000134454424e-07,
      "loss": 5.1264,
      "step": 8650
    },
    {
      "epoch": 0.991973397546153,
      "grad_norm": 0.0,
      "learning_rate": 2.6893898950812364e-07,
      "loss": 5.0393,
      "step": 8651
    },
    {
      "epoch": 0.9920880632954936,
      "grad_norm": 0.0,
      "learning_rate": 2.6414690084145425e-07,
      "loss": 5.0562,
      "step": 8652
    },
    {
      "epoch": 0.9922027290448343,
      "grad_norm": 0.0,
      "learning_rate": 2.5942374810645046e-07,
      "loss": 4.9281,
      "step": 8653
    },
    {
      "epoch": 0.992317394794175,
      "grad_norm": 0.0,
      "learning_rate": 2.547695319545814e-07,
      "loss": 5.1154,
      "step": 8654
    },
    {
      "epoch": 0.9924320605435156,
      "grad_norm": 0.0,
      "learning_rate": 2.5018425302776945e-07,
      "loss": 5.1443,
      "step": 8655
    },
    {
      "epoch": 0.9925467262928563,
      "grad_norm": 0.0,
      "learning_rate": 2.456679119585009e-07,
      "loss": 4.8951,
      "step": 8656
    },
    {
      "epoch": 0.9926613920421969,
      "grad_norm": 0.0,
      "learning_rate": 2.4122050936971504e-07,
      "loss": 4.8534,
      "step": 8657
    },
    {
      "epoch": 0.9927760577915377,
      "grad_norm": 0.0,
      "learning_rate": 2.3684204587485975e-07,
      "loss": 5.163,
      "step": 8658
    },
    {
      "epoch": 0.9928907235408784,
      "grad_norm": 0.0,
      "learning_rate": 2.3253252207778057e-07,
      "loss": 5.0421,
      "step": 8659
    },
    {
      "epoch": 0.993005389290219,
      "grad_norm": 0.0,
      "learning_rate": 2.2829193857299786e-07,
      "loss": 4.9564,
      "step": 8660
    },
    {
      "epoch": 0.9931200550395597,
      "grad_norm": 0.0,
      "learning_rate": 2.2412029594531866e-07,
      "loss": 5.2917,
      "step": 8661
    },
    {
      "epoch": 0.9932347207889004,
      "grad_norm": 0.0,
      "learning_rate": 2.200175947702806e-07,
      "loss": 5.0941,
      "step": 8662
    },
    {
      "epoch": 0.993349386538241,
      "grad_norm": 0.0,
      "learning_rate": 2.159838356135967e-07,
      "loss": 5.1979,
      "step": 8663
    },
    {
      "epoch": 0.9934640522875817,
      "grad_norm": 0.0,
      "learning_rate": 2.1201901903182163e-07,
      "loss": 5.204,
      "step": 8664
    },
    {
      "epoch": 0.9935787180369223,
      "grad_norm": 0.0,
      "learning_rate": 2.0812314557168553e-07,
      "loss": 4.9524,
      "step": 8665
    },
    {
      "epoch": 0.993693383786263,
      "grad_norm": 0.0,
      "learning_rate": 2.0429621577064913e-07,
      "loss": 5.2905,
      "step": 8666
    },
    {
      "epoch": 0.9938080495356038,
      "grad_norm": 0.0,
      "learning_rate": 2.0053823015651515e-07,
      "loss": 5.0407,
      "step": 8667
    },
    {
      "epoch": 0.9939227152849444,
      "grad_norm": 0.0,
      "learning_rate": 1.96849189247595e-07,
      "loss": 5.2184,
      "step": 8668
    },
    {
      "epoch": 0.9940373810342851,
      "grad_norm": 0.0,
      "learning_rate": 1.9322909355281942e-07,
      "loss": 4.8248,
      "step": 8669
    },
    {
      "epoch": 0.9941520467836257,
      "grad_norm": 0.0,
      "learning_rate": 1.8967794357140577e-07,
      "loss": 5.0019,
      "step": 8670
    },
    {
      "epoch": 0.9942667125329664,
      "grad_norm": 0.0,
      "learning_rate": 1.8619573979324655e-07,
      "loss": 4.8964,
      "step": 8671
    },
    {
      "epoch": 0.9943813782823071,
      "grad_norm": 0.0,
      "learning_rate": 1.8278248269857619e-07,
      "loss": 5.1475,
      "step": 8672
    },
    {
      "epoch": 0.9944960440316477,
      "grad_norm": 0.0,
      "learning_rate": 1.7943817275824866e-07,
      "loss": 5.0578,
      "step": 8673
    },
    {
      "epoch": 0.9946107097809884,
      "grad_norm": 0.0,
      "learning_rate": 1.76162810433571e-07,
      "loss": 4.9397,
      "step": 8674
    },
    {
      "epoch": 0.9947253755303291,
      "grad_norm": 0.0,
      "learning_rate": 1.7295639617619234e-07,
      "loss": 4.7976,
      "step": 8675
    },
    {
      "epoch": 0.9948400412796697,
      "grad_norm": 0.0,
      "learning_rate": 1.6981893042849224e-07,
      "loss": 5.0759,
      "step": 8676
    },
    {
      "epoch": 0.9949547070290105,
      "grad_norm": 0.0,
      "learning_rate": 1.6675041362319247e-07,
      "loss": 5.0129,
      "step": 8677
    },
    {
      "epoch": 0.9950693727783511,
      "grad_norm": 0.0,
      "learning_rate": 1.637508461835231e-07,
      "loss": 4.825,
      "step": 8678
    },
    {
      "epoch": 0.9951840385276918,
      "grad_norm": 0.0,
      "learning_rate": 1.608202285232784e-07,
      "loss": 5.0268,
      "step": 8679
    },
    {
      "epoch": 0.9952987042770325,
      "grad_norm": 0.0,
      "learning_rate": 1.5795856104653923e-07,
      "loss": 4.9113,
      "step": 8680
    },
    {
      "epoch": 0.9954133700263731,
      "grad_norm": 0.0,
      "learning_rate": 1.5516584414817234e-07,
      "loss": 4.9229,
      "step": 8681
    },
    {
      "epoch": 0.9955280357757138,
      "grad_norm": 0.0,
      "learning_rate": 1.5244207821327564e-07,
      "loss": 5.1431,
      "step": 8682
    },
    {
      "epoch": 0.9956427015250545,
      "grad_norm": 0.0,
      "learning_rate": 1.49787263617622e-07,
      "loss": 4.8971,
      "step": 8683
    },
    {
      "epoch": 0.9957573672743951,
      "grad_norm": 0.0,
      "learning_rate": 1.472014007273264e-07,
      "loss": 4.9435,
      "step": 8684
    },
    {
      "epoch": 0.9958720330237358,
      "grad_norm": 0.0,
      "learning_rate": 1.4468448989906777e-07,
      "loss": 4.6845,
      "step": 8685
    },
    {
      "epoch": 0.9959866987730764,
      "grad_norm": 0.0,
      "learning_rate": 1.422365314800337e-07,
      "loss": 4.9377,
      "step": 8686
    },
    {
      "epoch": 0.9961013645224172,
      "grad_norm": 0.0,
      "learning_rate": 1.3985752580786472e-07,
      "loss": 5.0248,
      "step": 8687
    },
    {
      "epoch": 0.9962160302717579,
      "grad_norm": 0.0,
      "learning_rate": 1.3754747321070996e-07,
      "loss": 4.8776,
      "step": 8688
    },
    {
      "epoch": 0.9963306960210985,
      "grad_norm": 0.0,
      "learning_rate": 1.3530637400711602e-07,
      "loss": 4.9089,
      "step": 8689
    },
    {
      "epoch": 0.9964453617704392,
      "grad_norm": 0.0,
      "learning_rate": 1.3313422850636015e-07,
      "loss": 4.9677,
      "step": 8690
    },
    {
      "epoch": 0.9965600275197798,
      "grad_norm": 0.0,
      "learning_rate": 1.31031037007895e-07,
      "loss": 4.9996,
      "step": 8691
    },
    {
      "epoch": 0.9966746932691205,
      "grad_norm": 0.0,
      "learning_rate": 1.2899679980190392e-07,
      "loss": 5.053,
      "step": 8692
    },
    {
      "epoch": 0.9967893590184612,
      "grad_norm": 0.0,
      "learning_rate": 1.2703151716891218e-07,
      "loss": 5.0337,
      "step": 8693
    },
    {
      "epoch": 0.9969040247678018,
      "grad_norm": 0.0,
      "learning_rate": 1.2513518938006462e-07,
      "loss": 5.1155,
      "step": 8694
    },
    {
      "epoch": 0.9970186905171425,
      "grad_norm": 0.0,
      "learning_rate": 1.2330781669684816e-07,
      "loss": 4.8973,
      "step": 8695
    },
    {
      "epoch": 0.9971333562664833,
      "grad_norm": 0.0,
      "learning_rate": 1.2154939937136922e-07,
      "loss": 4.9458,
      "step": 8696
    },
    {
      "epoch": 0.9972480220158239,
      "grad_norm": 0.0,
      "learning_rate": 1.1985993764613177e-07,
      "loss": 4.971,
      "step": 8697
    },
    {
      "epoch": 0.9973626877651646,
      "grad_norm": 0.0,
      "learning_rate": 1.1823943175420378e-07,
      "loss": 4.9458,
      "step": 8698
    },
    {
      "epoch": 0.9974773535145052,
      "grad_norm": 0.0,
      "learning_rate": 1.1668788191905085e-07,
      "loss": 4.9214,
      "step": 8699
    },
    {
      "epoch": 0.9975920192638459,
      "grad_norm": 0.0,
      "learning_rate": 1.1520528835470257e-07,
      "loss": 4.783,
      "step": 8700
    },
    {
      "epoch": 0.9977066850131866,
      "grad_norm": 0.0,
      "learning_rate": 1.1379165126569705e-07,
      "loss": 4.8932,
      "step": 8701
    },
    {
      "epoch": 0.9978213507625272,
      "grad_norm": 0.0,
      "learning_rate": 1.1244697084696997e-07,
      "loss": 4.906,
      "step": 8702
    },
    {
      "epoch": 0.9979360165118679,
      "grad_norm": 0.0,
      "learning_rate": 1.1117124728402106e-07,
      "loss": 5.0762,
      "step": 8703
    },
    {
      "epoch": 0.9980506822612085,
      "grad_norm": 0.0,
      "learning_rate": 1.0996448075274754e-07,
      "loss": 4.9517,
      "step": 8704
    },
    {
      "epoch": 0.9981653480105492,
      "grad_norm": 0.0,
      "learning_rate": 1.0882667141972175e-07,
      "loss": 5.1363,
      "step": 8705
    },
    {
      "epoch": 0.99828001375989,
      "grad_norm": 0.0,
      "learning_rate": 1.0775781944174697e-07,
      "loss": 4.9963,
      "step": 8706
    },
    {
      "epoch": 0.9983946795092306,
      "grad_norm": 0.0,
      "learning_rate": 1.0675792496635711e-07,
      "loss": 5.0501,
      "step": 8707
    },
    {
      "epoch": 0.9985093452585713,
      "grad_norm": 0.0,
      "learning_rate": 1.0582698813137258e-07,
      "loss": 4.8221,
      "step": 8708
    },
    {
      "epoch": 0.998624011007912,
      "grad_norm": 0.0,
      "learning_rate": 1.0496500906528883e-07,
      "loss": 5.0312,
      "step": 8709
    },
    {
      "epoch": 0.9987386767572526,
      "grad_norm": 0.0,
      "learning_rate": 1.0417198788699885e-07,
      "loss": 5.1677,
      "step": 8710
    },
    {
      "epoch": 0.9988533425065933,
      "grad_norm": 0.0,
      "learning_rate": 1.034479247057932e-07,
      "loss": 4.8676,
      "step": 8711
    },
    {
      "epoch": 0.9989680082559339,
      "grad_norm": 0.0,
      "learning_rate": 1.0279281962163742e-07,
      "loss": 5.1762,
      "step": 8712
    },
    {
      "epoch": 0.9990826740052746,
      "grad_norm": 0.0,
      "learning_rate": 1.0220667272483915e-07,
      "loss": 5.1264,
      "step": 8713
    },
    {
      "epoch": 0.9991973397546153,
      "grad_norm": 0.0,
      "learning_rate": 1.0168948409621454e-07,
      "loss": 4.817,
      "step": 8714
    },
    {
      "epoch": 0.9993120055039559,
      "grad_norm": 0.0,
      "learning_rate": 1.012412538071993e-07,
      "loss": 4.9687,
      "step": 8715
    },
    {
      "epoch": 0.9994266712532967,
      "grad_norm": 0.0,
      "learning_rate": 1.0086198191951565e-07,
      "loss": 4.8618,
      "step": 8716
    },
    {
      "epoch": 0.9995413370026374,
      "grad_norm": 0.0,
      "learning_rate": 1.0055166848556087e-07,
      "loss": 5.0316,
      "step": 8717
    },
    {
      "epoch": 0.999656002751978,
      "grad_norm": 0.0,
      "learning_rate": 1.003103135481298e-07,
      "loss": 5.2277,
      "step": 8718
    },
    {
      "epoch": 0.9997706685013187,
      "grad_norm": 0.0,
      "learning_rate": 1.0013791714041477e-07,
      "loss": 5.0653,
      "step": 8719
    },
    {
      "epoch": 0.9998853342506593,
      "grad_norm": 0.0,
      "learning_rate": 1.0003447928628318e-07,
      "loss": 4.8532,
      "step": 8720
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.0,
      "learning_rate": 1.0000000000000001e-07,
      "loss": 5.1855,
      "step": 8721
    },
    {
      "epoch": 1.0,
      "step": 8721,
      "total_flos": 1.8937299656150876e+18,
      "train_loss": 5.0091617946955,
      "train_runtime": 16837.0849,
      "train_samples_per_second": 33.149,
      "train_steps_per_second": 0.518
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 8721,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.8937299656150876e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
